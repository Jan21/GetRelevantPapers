[
  {
    "paperId": "490446ac0419c2f232b481e4c73117bcffe45576",
    "url": "https://www.semanticscholar.org/paper/490446ac0419c2f232b481e4c73117bcffe45576",
    "title": "G4SATBench: Benchmarking and Advancing SAT Solving with Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2309.16941",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2309.16941, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2288036658",
        "name": "Zhaoyu Li"
      },
      {
        "authorId": "2249683739",
        "name": "Jinpei Guo"
      },
      {
        "authorId": "2249532070",
        "name": "Xujie Si"
      }
    ],
    "abstract": "Graph neural networks (GNNs) have recently emerged as a promising approach for solving the Boolean Satisfiability Problem (SAT), offering potential alternatives to traditional backtracking or local search SAT solvers. However, despite the growing volume of literature in this field, there remains a notable absence of a unified dataset and a fair benchmark to evaluate and compare existing approaches. To address this crucial gap, we present G4SATBench, the first benchmark study that establishes a comprehensive evaluation framework for GNN-based SAT solvers. In G4SATBench, we meticulously curate a large and diverse set of SAT datasets comprising 7 problems with 3 difficulty levels and benchmark a broad range of GNN models across various prediction tasks, training objectives, and inference algorithms. To explore the learning abilities and comprehend the strengths and limitations of GNN-based SAT solvers, we also compare their solving processes with the heuristics in search-based SAT solvers. Our empirical results provide valuable insights into the performance of GNN-based SAT solvers and further suggest that existing GNN models can effectively learn a solving strategy akin to greedy local search but struggle to learn backtracking search in the latent space. Our codebase is available at https://github.com/zhaoyu-li/G4SATBench.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "2c087a5d4b58ea7b5affe4d6914aa9e22af49f13",
    "url": "https://www.semanticscholar.org/paper/2c087a5d4b58ea7b5affe4d6914aa9e22af49f13",
    "title": "NeuroComb: Improving SAT Solving with Graph Neural Networks",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "47824878",
        "name": "Wenxi Wang"
      },
      {
        "authorId": "2113666979",
        "name": "Yang Hu"
      },
      {
        "authorId": "2253452054",
        "name": "Mohit Tiwari"
      },
      {
        "authorId": "145802044",
        "name": "S. Khurshid"
      },
      {
        "authorId": "2257238092",
        "name": "Kenneth L. McMillan"
      },
      {
        "authorId": "2257170509",
        "name": "Risto Miikkulainen"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a613142147ef740b2daf1265e23606c80d1c2bd2",
    "url": "https://www.semanticscholar.org/paper/a613142147ef740b2daf1265e23606c80d1c2bd2",
    "title": "NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2110.14053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47824878",
        "name": "Wenxi Wang"
      },
      {
        "authorId": "2113666979",
        "name": "Yang Hu"
      },
      {
        "authorId": "33825420",
        "name": "Mohit Tiwari"
      },
      {
        "authorId": "145802044",
        "name": "S. Khurshid"
      },
      {
        "authorId": "1720514",
        "name": "K. McMillan"
      },
      {
        "authorId": "1686788",
        "name": "R. Miikkulainen"
      }
    ],
    "abstract": "Propositional satisfiability (SAT) is an NP-complete problem that impacts many research fields, such as planning, verification, and security. Mainstream modern SAT solvers are based on the Conflict-Driven Clause Learning (CDCL) algorithm. Recent work aimed to enhance CDCL SAT solvers using Graph Neural Networks (GNNs). However, so far this approach either has not made solving more effective, or required substantial GPU resources for frequent online model inferences. Aiming to make GNN improvements practical, this paper proposes an approach called NeuroBack, which builds on two insights: (1) predicting phases (i.e., values) of variables appearing in the majority (or even all) of the satisfying assignments are essential for CDCL SAT solving, and (2) it is sufficient to query the neural model only once for the predictions before the SAT solving starts. Once trained, the offline model inference allows NeuroBack to execute exclusively on the CPU, removing its reliance on GPU resources. To train NeuroBack, a new dataset called DataBack containing 120,286 data samples is created. NeuroBack is implemented as an enhancement to a state-of-the-art SAT solver called Kissat. As a result, it allowed Kissat to solve up to 5.2% and 7.4% more problems on two recent SAT competition problem sets, SATCOMP-2022 and SATCOMP-2023, respectively. NeuroBack therefore shows how machine learning can be harnessed to improve SAT solving in an effective and practical manner.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "d481f54186caadc7b041d8cc4d447117f4209b34",
    "url": "https://www.semanticscholar.org/paper/d481f54186caadc7b041d8cc4d447117f4209b34",
    "title": "GraSS: Combining Graph Neural Networks with Expert Knowledge for SAT Solver Selection",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2405.11024",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2405.11024, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2302452881",
        "name": "Zhanguang Zhang"
      },
      {
        "authorId": "2302328451",
        "name": "Didier Ch\u00c3\u00a9telat"
      },
      {
        "authorId": "2245395221",
        "name": "Joseph Cotnareanu"
      },
      {
        "authorId": "81407699",
        "name": "Amur Ghose"
      },
      {
        "authorId": "2290127205",
        "name": "Wenyi Xiao"
      },
      {
        "authorId": "46465266",
        "name": "Hui-Ling Zhen"
      },
      {
        "authorId": "2304893501",
        "name": "Yingxue Zhang"
      },
      {
        "authorId": "2238210852",
        "name": "Jianye Hao"
      },
      {
        "authorId": "2284773438",
        "name": "Mark Coates"
      },
      {
        "authorId": "2290331022",
        "name": "Mingxuan Yuan"
      }
    ],
    "abstract": "Boolean satisfiability (SAT) problems are routinely solved by SAT solvers in real-life applications, yet solving time can vary drastically between solvers for the same instance. This has motivated research into machine learning models that can predict, for a given SAT instance, which solver to select among several options. Existing SAT solver selection methods all rely on some hand-picked instance features, which are costly to compute and ignore the structural information in SAT graphs. In this paper we present GraSS, a novel approach for automatic SAT solver selection based on tripartite graph representations of instances and a heterogeneous graph neural network (GNN) model. While GNNs have been previously adopted in other SAT-related tasks, they do not incorporate any domain-specific knowledge and ignore the runtime variation introduced by different clause orders. We enrich the graph representation with domain-specific decisions, such as novel node feature design, positional encodings for clauses in the graph, a GNN architecture tailored to our tripartite graphs and a runtime-sensitive loss function. Through extensive experiments, we demonstrate that this combination of raw representations and domain-specific choices leads to improvements in runtime for a pool of seven state-of-the-art solvers on both an industrial circuit design benchmark, and on instances from the 20-year Anniversary Track of the 2022 SAT Competition.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "43b1dc00e8e2de88b70de121daf843fd299a2a58",
    "url": "https://www.semanticscholar.org/paper/43b1dc00e8e2de88b70de121daf843fd299a2a58",
    "title": "Improving SAT Solving with Graph Neural Networks",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "47824878",
        "name": "Wenxi Wang"
      },
      {
        "authorId": "2113666290",
        "name": "Yang Hu"
      },
      {
        "authorId": "33825420",
        "name": "Mohit Tiwari"
      },
      {
        "authorId": "145802044",
        "name": "S. Khurshid"
      },
      {
        "authorId": "1720514",
        "name": "K. McMillan"
      },
      {
        "authorId": "1686788",
        "name": "R. Miikkulainen"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a6f0ac220886fbc70cb063fcb86f5f33d31ebf3d",
    "url": "https://www.semanticscholar.org/paper/a6f0ac220886fbc70cb063fcb86f5f33d31ebf3d",
    "title": "Fast and Scalable ACL Policy Solving Under Complex Constraints With Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNET.2024.3409529?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNET.2024.3409529, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3211546",
        "name": "Haifeng Sun"
      },
      {
        "authorId": "2275620034",
        "name": "Xingjian Liao"
      },
      {
        "authorId": "2200233666",
        "name": "Jingyu Wang"
      },
      {
        "authorId": "2253567598",
        "name": "Qi Qi"
      },
      {
        "authorId": "70647186",
        "name": "Zirui Zhuang"
      },
      {
        "authorId": "2153704848",
        "name": "Jianxin Liao"
      },
      {
        "authorId": "2262083284",
        "name": "D. Wu"
      }
    ],
    "abstract": "Network operators often need to modify Access Control List (ACL) policies to align with to network upgrades. An essential part of the ACL update task is reachability satisfaction. Previous studies formalize reachability requirements as a set of constraints and then use Boolean Satisfiability (SAT) or Satisfiability Modulo Theories (SMT) solvers to search for solutions. However, as today\u00e2\u0080\u0099s networks grow in size and complexity, the constraints derived from the requirements become increasingly complex, leading to an unacceptable time cost to obtain a correct policy. The sluggish updating of ACL policies can affect the properties of a network, such as connectivity and security. This paper presents a novel approach for fast and scalable ACL policy synthesis under complex constraints. We utilize Graph Neural Networks (GNNs) to learn the relations between nodes and reason the solution that satisfies the update requirements. We further integrate global position encoding into the GNN architecture, which allows for better differentiation of nodes in ACL update tasks. Additionally, an enhanced stochastic local search solver is introduced to address incorrect predictions made by the GNN. Experiments on real-world topologies show that GNN saves up $278\\times $ time costs compared to advanced SAT/SMT solvers on a 125-node network, and this advantage expands with the network size. Furthermore, our model extrapolates well when faced with different requirements and topologies, demonstrating its ability to handle frequent network upgrades.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "867c9e741b7ed6296565122dad23c09a98fc70e6",
    "url": "https://www.semanticscholar.org/paper/867c9e741b7ed6296565122dad23c09a98fc70e6",
    "title": "Solving Distributed ACL Policies Under Complex Constraints with Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICNP59255.2023.10355624?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICNP59255.2023.10355624, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2275620034",
        "name": "Xingjian Liao"
      },
      {
        "authorId": "3211546",
        "name": "Haifeng Sun"
      },
      {
        "authorId": "1519274136",
        "name": "Jingyu Wang"
      },
      {
        "authorId": "2253567598",
        "name": "Qi Qi"
      },
      {
        "authorId": "70647186",
        "name": "Zirui Zhuang"
      },
      {
        "authorId": "2153704848",
        "name": "Jianxin Liao"
      },
      {
        "authorId": "2275862248",
        "name": "Guang Yang"
      }
    ],
    "abstract": "Access Control List (ACL) policies often need to be updated due to upgrades in network architecture and services. A critical part of ACL update tasks is reachability satisfaction, which is typically handled using Boolean Satisfiability (SAT) or Satisfiability Modulo Theories (SMT) solvers. However, as modern networks grow in size and complexity, the constraints derived from reachability requirements become increasingly complex, resulting in a considerable time cost to obtain a satisfying policy. The slow update of ACL policies can endanger network connectivity and security. This paper presents a new approach for fast and scalable ACL policy synthesis under complex constraints. We leverage Graph Neural Networks (GNNs) to learn the relations between nodes and reason the solution that satisfies the update requirements. In addition, an enhanced stochastic local search solver is introduced to deal with erroneous predictions of the GNN. Evaluations show that the proposed method guarantees 100% accuracy on real-world topologies. GNN outperforms modern SAT/SMT solvers in speed, saving up to 278x time costs on a 125-node topology. Furthermore, our method extrapolates well when faced with different requirements and topologies.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "10704eb8d3f889837f54c8bf3c01d906b0c4499e",
    "url": "https://www.semanticscholar.org/paper/10704eb8d3f889837f54c8bf3c01d906b0c4499e",
    "title": "Graph neural network based time estimator for SAT solver",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-024-02327-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-024-02327-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2260178816",
        "name": "Jiawei Liu"
      },
      {
        "authorId": "2319199071",
        "name": "Wenyi Xiao"
      },
      {
        "authorId": "2315642515",
        "name": "Hongtao Cheng"
      },
      {
        "authorId": "2319185539",
        "name": "Chuan Shi"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "75a12b7facccce26e89d25993bc49dc4668a4dad",
    "url": "https://www.semanticscholar.org/paper/75a12b7facccce26e89d25993bc49dc4668a4dad",
    "title": "A Deep Reinforcement Learning Heuristic for SAT based on Antagonist Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICTAI56018.2022.00185?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICTAI56018.2022.00185, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2071913310",
        "name": "Thomas Fournier"
      },
      {
        "authorId": "2078999419",
        "name": "Arnaud Lallouet"
      },
      {
        "authorId": "2214759139",
        "name": "T\u00c3\u00a9lio Cropsal"
      },
      {
        "authorId": "11715539",
        "name": "Gael Glorian"
      },
      {
        "authorId": "2049870",
        "name": "Alexandre Papadopoulos"
      },
      {
        "authorId": "1719457",
        "name": "A. Petitet"
      },
      {
        "authorId": "2214762838",
        "name": "Guillaume Perez"
      },
      {
        "authorId": "2214759180",
        "name": "Suruthy Sekar"
      },
      {
        "authorId": "9652278",
        "name": "Wijnand Suijlen"
      }
    ],
    "abstract": "Heuristics are one of the most important tools to guide search to solve combinatorial problems. They are often specifically designed for one single problem and require both expertise and implementation work. Generic frameworks like SAT or CSP have developed heuristics that obey general principles like first fail or are able to learn and adapt from the exploration of the search tree like Dom/wDeg. In SAT, the classic VSIDS heuristic falls into both categories. The question of whether it is possible to learn from solving existing problems has been addressed for a long time by portfolio solvers where the best heuristic is chosen by Machine Learning from hand-crafted features, and more recently with Deep Learning by embedding this knowledge into a Graph Neural Network (GNN). In this paper, we build upon the latter category by proposing a new heuristic based on Deep Reinforcement Learning using two GNNs with adversarial rewards. We show that our method reduces the number of fails to get the first solution by more than 50% compared to MiniSat. This work shows the advantages of this type of techniques to extract structural and contextual knowledge from past solving experience.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "f84c5be8177b6f384fbb582979c24907b33f4e3e",
    "url": "https://www.semanticscholar.org/paper/f84c5be8177b6f384fbb582979c24907b33f4e3e",
    "title": "AsymSAT: Accelerating SAT Solving with Asymmetric Graph-Based Model Prediction",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.23919/DATE58400.2024.10546648?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/DATE58400.2024.10546648, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2282310586",
        "name": "Zhiyuan Yan"
      },
      {
        "authorId": "2157145787",
        "name": "Min Li"
      },
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "2306078950",
        "name": "Wenjie Zhang"
      },
      {
        "authorId": "2373568356",
        "name": "Yingcong Chen"
      },
      {
        "authorId": "2267023943",
        "name": "Hongce Zhang"
      }
    ],
    "abstract": "Though graph neural networks (GNNs) have been used in SAT solution prediction, for a subset of symmetric SAT problems, we unveil that the current GNN-based end-to-end SAT solvers are bound to yield incorrect outcomes as they are unable to break symmetry in variable assignments. In response, we introduce AsymSAT, a new GNN architecture coupled where a recurrent neural network is (RNN) to produce asymmetric models. Moreover, we bring up a method to integrate machine-learning-based SAT assignment prediction with classic SAT solvers and demonstrate its performance on non-trivial SAT instances including logic equivalence checking and cryptographic analysis problems with as much as 75.45% time saving.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "9e9f95168068838254f71e09743e7307ea4d904b",
    "url": "https://www.semanticscholar.org/paper/9e9f95168068838254f71e09743e7307ea4d904b",
    "title": "SAT-GATv2: A Dynamic Attention-Based Graph Neural Network for Solving Boolean Satisfiability Problem",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/electronics14030423?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/electronics14030423, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2315914633",
        "name": "Wenjing Chang"
      },
      {
        "authorId": "2341843041",
        "name": "Wenlong Liu"
      }
    ],
    "abstract": "We propose SAT-GATv2, a graph neural network (GNN)-based model designed to solve the Boolean satisfiability problem (SAT) through graph-based deep learning techniques. SAT-GATv2 transforms SAT formulas into graph structures, leveraging message-passing neural networks (MPNNs) to propagate local information and dynamic attention mechanisms (GATv2) to accurately capture inter-node dependencies and enhance node feature representations. Unlike traditional heuristic-driven SAT solvers, SAT-GATv2 adopts a data-driven approach, learning structural patterns directly from graph representations and providing a complementary framework to existing methods. Experimental results demonstrate that SAT-GATv2 achieves an accuracy improvement of 1.75\u00e2\u0080\u00935.51% over NeuroSAT on challenging random 3-SAT(n) instances, highlighting its effectiveness in handling difficult problem distributions, and outperforms other GNN-based models on SR(n) datasets, showcasing its scalability and adaptability. Ablation studies validate the critical roles of MPNNs and GATv2 in improving prediction accuracy and scalability. While SAT-GATv2 does not yet surpass CDCL-based solvers in overall performance, it addresses their limitations in scalability and adaptability to complex instances, offering an efficient graph-based alternative for tackling larger and more complex SAT problems. This study establishes a foundation for integrating deep learning with combinatorial optimization, emphasizing its potential for applications in artificial intelligence and operations research.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "195081fec2c9021112f8668ae5a4494dbc9b1734",
    "url": "https://www.semanticscholar.org/paper/195081fec2c9021112f8668ae5a4494dbc9b1734",
    "title": "Embracing Graph Neural Networks for Hardware Security",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2208.08554, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35628050",
        "name": "Lilas Alrahis"
      },
      {
        "authorId": "2466673",
        "name": "Satwik Patnaik"
      },
      {
        "authorId": "2077523138",
        "name": "Muhammad Shafique"
      },
      {
        "authorId": "48010993",
        "name": "O. Sinanoglu"
      }
    ],
    "abstract": "Graph neural networks (GNNs) have attracted increasing attention due to their superior performance in deep learning on graph-structured data. GNNs have succeeded across various domains such as social networks, chemistry, and electronic design automation (EDA). Electronic circuits have a long history of being represented as graphs, and to no surprise, GNNs have demonstrated state-of-the-art performance in solving various EDA tasks. More importantly, GNNs are now employed to address several hardware security problems, such as detecting intellectual property (IP) piracy and hardware Trojans (HTs), to name a few.In this survey, we first provide a comprehensive overview of the usage of GNNs in hardware security and propose the first taxonomy to divide the state-of-the-art GNN-based hardware security systems into four categories: (i) HT detection systems, (ii) IP piracy detection systems, (iii) reverse engineering platforms, and (iv) attacks on logic locking. We summarize the different architectures, graph types, node features, benchmark data sets, and model evaluation of the employed GNNs. Finally, we elaborate on the lessons learned and discuss future directions.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d92199f6201885c0446e197c8df6a4d600a0f510",
    "url": "https://www.semanticscholar.org/paper/d92199f6201885c0446e197c8df6a4d600a0f510",
    "title": "Structure Based Dataset on SAT Solving with Graph Neural Networks",
    "year": null,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2345876608",
        "name": "Yi Fu"
      },
      {
        "authorId": "2284773424",
        "name": "Anthony Tompkins"
      },
      {
        "authorId": "2157995570",
        "name": "Yang Song"
      },
      {
        "authorId": "1783801",
        "name": "M. Pagnucco"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f9fd55c01bf63749c7e0ed0543a3ecd56d6fd038",
    "url": "https://www.semanticscholar.org/paper/f9fd55c01bf63749c7e0ed0543a3ecd56d6fd038",
    "title": "Neural Approaches to SAT Solving: Design Choices and Interpretability",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2504.01173, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1965908193",
        "name": "David Mojz\u00c3\u00adsek"
      },
      {
        "authorId": "47655060",
        "name": "Jan Hula"
      },
      {
        "authorId": "2353523177",
        "name": "Ziwei Li"
      },
      {
        "authorId": "2353365495",
        "name": "Ziyu Zhou"
      },
      {
        "authorId": "50751618",
        "name": "Mikol\u00c3\u00a1\u00c5\u00a1 Janota"
      }
    ],
    "abstract": "In this contribution, we provide a comprehensive evaluation of graph neural networks applied to Boolean satisfiability problems, accompanied by an intuitive explanation of the mechanisms enabling the model to generalize to different instances. We introduce several training improvements, particularly a novel closest assignment supervision method that dynamically adapts to the model's current state, significantly enhancing performance on problems with larger solution spaces. Our experiments demonstrate the suitability of variable-clause graph representations with recurrent neural network updates, which achieve good accuracy on SAT assignment prediction while reducing computational demands. We extend the base graph neural network into a diffusion model that facilitates incremental sampling and can be effectively combined with classical techniques like unit propagation. Through analysis of embedding space patterns and optimization trajectories, we show how these networks implicitly perform a process very similar to continuous relaxations of MaxSAT, offering an interpretable view of their reasoning process. This understanding guides our design choices and explains the ability of recurrent architectures to scale effectively at inference time beyond their training distribution, which we demonstrate with test-time scaling experiments.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "72424eca02f7cb3a98b894b609b3575a9d5518f4",
    "url": "https://www.semanticscholar.org/paper/72424eca02f7cb3a98b894b609b3575a9d5518f4",
    "title": "Attn-JGNN: Attention Enhanced Join-Graph Neural Networks",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2510.15583, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2386551479",
        "name": "Jixin Zhang"
      },
      {
        "authorId": "2387763132",
        "name": "Y. Lai"
      }
    ],
    "abstract": "We propose an Attention Enhanced Join-Graph Neural Networks(Attn-JGNN) model for solving #SAT problems, which significantly improves the solving accuracy. Inspired by the Iterative Join Graph Propagation (IJGP) algorithm, Attn-JGNN uses tree decomposition to encode the CNF formula into a join-graph, then performs iterative message passing on the join-graph, and finally approximates the model number by learning partition functions. In order to further improve the accuracy of the solution, we apply the attention mechanism in and between clusters of the join-graphs, which makes Attn-JGNN pay more attention to the key variables and clusters in probabilistic inference, and reduces the redundant calculation. Finally, our experiments show that our Attn-JGNN model achieves better results than other neural network methods.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "9094a2e2ca0bae29856a4d5bfeb87ccaf90e9c4a",
    "url": "https://www.semanticscholar.org/paper/9094a2e2ca0bae29856a4d5bfeb87ccaf90e9c4a",
    "title": "Neural heuristics for SAT solving",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2005.13406, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "25898662",
        "name": "Sebastian Jaszczur"
      },
      {
        "authorId": "47164089",
        "name": "M. Luszczyk"
      },
      {
        "authorId": "47407464",
        "name": "H. Michalewski"
      }
    ],
    "abstract": "We use neural graph networks with a message-passing architecture and an attention mechanism to enhance the branching heuristic in two SAT-solving algorithms. We report improvements of learned neural heuristics compared with two standard human-designed heuristics.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "10a9716001ffd6f5654d61c54f68513227ee9169",
    "url": "https://www.semanticscholar.org/paper/10a9716001ffd6f5654d61c54f68513227ee9169",
    "title": "Solving Quadratic Unconstrained Binary Optimization with Collaborative Spiking Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICRC57508.2022.00021?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICRC57508.2022.00021, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1840458369",
        "name": "Yan Fang"
      },
      {
        "authorId": "2579629",
        "name": "A. Lele"
      }
    ],
    "abstract": "Quadratic Unconstrained Binary Optimization (QUBO) problem becomes an attractive and valuable optimization problem formulation in that it can easily transform into a variety of other combinatorial optimization problems such as Graph/number Partition, Max-Cut, SAT, Vertex Coloring, TSP, etc. Some of these problems are NP-hard and widely applied in industry and scientific research. Meanwhile, QUBO has been discovered to be compatible with two emerging computing paradigms, neuromorphic computing, and quantum computing, with tremendous potential to speed up future optimization solvers. In this paper, we propose a novel neuromorphic computing paradigm that employs multiple collaborative spiking neural networks to solve QUBO problems. Each SNN conducts a local stochastic gradient descent search and shares the global best solutions periodically to perform a meta-heuristic search for optima. We simulate our model and compare it to a single SNN solver and a mult-SNN solver without collaboration. Through tests on benchmark problems, the proposed method is demonstrated to be more efficient and effective in searching for QUBO optima. Specifically, it exhibits x10 and x15-20 speedup respectively on the multi-SNN solver without collaboration and the single-SNN solver.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "b9afc6d406e25bcd66e460a6fab5b08a5982928f",
    "url": "https://www.semanticscholar.org/paper/b9afc6d406e25bcd66e460a6fab5b08a5982928f",
    "title": "Addressing Variable Dependency in GNN-based SAT Solving",
    "year": 2023,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2304.08738",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2304.08738, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2143626852",
        "name": "Zhiyuan Yan"
      },
      {
        "authorId": "2157145787",
        "name": "Min Li"
      },
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "19262604",
        "name": "W. Zhang"
      },
      {
        "authorId": "2386876360",
        "name": "Yingcong Chen"
      },
      {
        "authorId": "2108639435",
        "name": "Hongce Zhang"
      }
    ],
    "abstract": "Boolean satisfiability problem (SAT) is fundamental to many applications. Existing works have used graph neural networks (GNNs) for (approximate) SAT solving. Typical GNN-based end-to-end SAT solvers predict SAT solutions concurrently. We show that for a group of symmetric SAT problems, the concurrent prediction is guaranteed to produce a wrong answer because it neglects the dependency among Boolean variables in SAT problems. % We propose AsymSAT, a GNN-based architecture which integrates recurrent neural networks to generate dependent predictions for variable assignments. The experiment results show that dependent variable prediction extends the solving capability of the GNN-based method as it improves the number of solved SAT instances on large test sets.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "f171cc5bbcadb4fae6536c4dc0d16d61c4b9d243",
    "url": "https://www.semanticscholar.org/paper/f171cc5bbcadb4fae6536c4dc0d16d61c4b9d243",
    "title": "The Elephant in the Room: Variable Dependency in GNN-based SAT Solving",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2143626852",
        "name": "Zhiyuan Yan"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "48e6174669e39c1abb627362cc63dd29669f4086",
    "url": "https://www.semanticscholar.org/paper/48e6174669e39c1abb627362cc63dd29669f4086",
    "title": "Circuit-Aware SAT Solving: Guiding CDCL via Conditional Probabilities",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2508.04235, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2359165890",
        "name": "Jiaying Zhu"
      },
      {
        "authorId": "2269764969",
        "name": "Ziyang Zheng"
      },
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "2375089575",
        "name": "Yalun Cai"
      },
      {
        "authorId": "2359816758",
        "name": "Qiang Xu"
      }
    ],
    "abstract": "Circuit Satisfiability (CSAT) plays a pivotal role in Electronic Design Automation. The standard workflow for solving CSAT problems converts circuits into Conjunctive Normal Form (CNF) and employs generic SAT solvers powered by Conflict-Driven Clause Learning (CDCL). However, this process inherently discards rich structural and functional information, leading to suboptimal solver performance. To address this limitation, we introduce CASCAD, a novel circuit-aware SAT solving framework that directly leverages circuit-level conditional probabilities computed via Graph Neural Networks (GNNs). By explicitly modeling gate-level conditional probabilities, CASCAD dynamically guides two critical CDCL heuristics -- variable phase selection and clause managementto significantly enhance solver efficiency. Extensive evaluations on challenging real-world Logical Equivalence Checking (LEC) benchmarks demonstrate that CASCAD reduces solving times by up to 10x compared to state-of-the-art CNF-based approaches, achieving an additional 23.5% runtime reduction via our probability-guided clause filtering strategy. Our results underscore the importance of preserving circuit-level structural insights within SAT solvers, providing a robust foundation for future improvements in SAT-solving efficiency and EDA tool design.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "30aa4602235d5a3836c0fe469116e6cc81745280",
    "url": "https://www.semanticscholar.org/paper/30aa4602235d5a3836c0fe469116e6cc81745280",
    "title": "Enhancing SAT Solving with GNN for Clause Weight Prediction",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICCIAA65327.2025.11013639?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICCIAA65327.2025.11013639, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1891391",
        "name": "Abdelraouf M. Ishtaiwi"
      },
      {
        "authorId": "2365110465",
        "name": "Zaid Momani"
      },
      {
        "authorId": "2351620090",
        "name": "A. Zaid"
      }
    ],
    "abstract": "Boolean satisfiability (SAT) solving is foundational in various computational domains but faces scalability challenges with large instances. This paper introduces a novel method employing Graph Neural Networks (GNNs) to predict clause weights dynamically within SAT solvers. By representing SAT problems as bipartite graphs and integrating GNNs for clause weight prediction, our approach achieves a 40% reduction in solving time and a 35% improvement in solution quality compared to state-of-the-art solvers such as MapleSAT and GAN-SAT. Extensive experiments on benchmarks and real-world applications validate the effectiveness of our method, indicating significant potential for enhancing SAT solver performance in practical settings.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "eb76c0260fda31e83779c3db3c789c039f772b1f",
    "url": "https://www.semanticscholar.org/paper/eb76c0260fda31e83779c3db3c789c039f772b1f",
    "title": "HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT Problems",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2504.11885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2355781138",
        "name": "Qiyue Chen"
      },
      {
        "authorId": "2260842227",
        "name": "Shaolin Tan"
      },
      {
        "authorId": "2318260780",
        "name": "Suixiang Gao"
      },
      {
        "authorId": "2355646922",
        "name": "J. C. I. O. S. Sciences"
      },
      {
        "authorId": "102771447",
        "name": "University of Electronic Science"
      },
      {
        "authorId": "2256059499",
        "name": "Beijing"
      },
      {
        "authorId": "152298626",
        "name": "China."
      },
      {
        "authorId": "2294197239",
        "name": "Zhongguancun Laboratory"
      },
      {
        "authorId": "102700312",
        "name": "School of Materials Science"
      },
      {
        "authorId": "70633389",
        "name": "Electrical Engineering"
      },
      {
        "authorId": "2065290661",
        "name": "B. University"
      }
    ],
    "abstract": "Graph neural networks (GNNs) have shown promising performance in solving both Boolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems due to their ability to efficiently model and capture the structural dependencies between literals and clauses. However, GNN methods for solving Weighted MaxSAT problems remain underdeveloped. The challenges arise from the non-linear dependency and sensitive objective function, which are caused by the non-uniform distribution of weights across clauses. In this paper, we present HyperSAT, a novel neural approach that employs an unsupervised hypergraph neural network model to solve Weighted MaxSAT problems. We propose a hypergraph representation for Weighted MaxSAT instances and design a cross-attention mechanism along with a shared representation constraint loss function to capture the logical interactions between positive and negative literal nodes in the hypergraph. Extensive experiments on various Weighted MaxSAT datasets demonstrate that HyperSAT achieves better performance than state-of-the-art competitors.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "0c25c768750436a3a251a967f39ea65bac99be6e",
    "url": "https://www.semanticscholar.org/paper/0c25c768750436a3a251a967f39ea65bac99be6e",
    "title": "Expressive GNNs for SAT Solving through Substructure Counting",
    "year": null,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2372070677",
        "name": "Jeremy Gleixner"
      },
      {
        "authorId": "2205658673",
        "name": "Saku Peltonen"
      },
      {
        "authorId": "2279221491",
        "name": "Jo\u00c3\u00abl Mathys Prof"
      },
      {
        "authorId": "2226647614",
        "name": "Dr. Roger Wattenhofer"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "deab727a0607fe6c7345d77eb96fd1be92f32d53",
    "url": "https://www.semanticscholar.org/paper/deab727a0607fe6c7345d77eb96fd1be92f32d53",
    "title": "MILP-SAT-GNN: Yet Another Neural SAT Solver",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2507.01825, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49490852",
        "name": "Franco Alberto Cardillo"
      },
      {
        "authorId": "2373012031",
        "name": "Hamza Khyari"
      },
      {
        "authorId": "2373004145",
        "name": "Umberto Straccia"
      }
    ],
    "abstract": "We proposes a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to Mixed Integer Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "c8826232676135e1ccd0bc1cfc8035893461a0e2",
    "url": "https://www.semanticscholar.org/paper/c8826232676135e1ccd0bc1cfc8035893461a0e2",
    "title": "Alleviating Cold-Start Problems in Recommendation through Pseudo-Labelling over Knowledge Graph",
    "year": 2020,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2011.05061",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2011.05061, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "15743044",
        "name": "Riku Togashi"
      },
      {
        "authorId": "3186326",
        "name": "Mayu Otani"
      },
      {
        "authorId": "1700567",
        "name": "S. Satoh"
      }
    ],
    "abstract": "Solving cold-start problems is indispensable to provide meaningful recommendation results for new users and items. Under sparsely observed data, unobserved user-item pairs are also a vital source for distilling latent users' information needs. Most present works leverage unobserved samples for extracting negative signals. However, such an optimisation strategy can lead to biased results toward already popular items by frequently handling new items as negative instances. In this study, we tackle the cold-start problems for new users/items by appropriately leveraging unobserved samples. We propose a knowledge graph (KG)-aware recommender based on graph neural networks, which augments labelled samples through pseudo-labelling. Our approach aggressively employs unobserved samples as positive instances and brings new items into the spotlight. To avoid exhaustive label assignments to all possible pairs of users and items, we exploit a KG for selecting probably positive items for each user. We also utilise an improved negative sampling strategy and thereby suppress the exacerbation of popularity biases. Through experiments, we demonstrate that our approach achieves improvements over the state-of-the-art KG-aware recommenders in a variety of scenarios; in particular, our methodology successfully improves recommendation performance for cold-start users/items.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "7c5f943cf67c92a17c3a6dad62de758d1d4ae168",
    "url": "https://www.semanticscholar.org/paper/7c5f943cf67c92a17c3a6dad62de758d1d4ae168",
    "title": "DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2502.01681, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2269764969",
        "name": "Ziyang Zheng"
      },
      {
        "authorId": "2268727886",
        "name": "Shan Huang"
      },
      {
        "authorId": "2290246920",
        "name": "Jianyuan Zhong"
      },
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "2277327801",
        "name": "Guohao Dai"
      },
      {
        "authorId": "2263866100",
        "name": "Ningyi Xu"
      },
      {
        "authorId": "2303429383",
        "name": "Qiang Xu"
      }
    ],
    "abstract": "Circuit representation learning has become pivotal in electronic design automation, enabling critical tasks such as testability analysis, logic reasoning, power estimation, and SAT solving. However, existing models face significant challenges in scaling to large circuits due to limitations like over-squashing in graph neural networks and the quadratic complexity of transformer-based models. To address these issues, we introduce DeepGate4, a scalable and efficient graph transformer specifically designed for large-scale circuits. DeepGate4 incorporates several key innovations: (1) an update strategy tailored for circuit graphs, which reduce memory complexity to sub-linear and is adaptable to any graph transformer; (2) a GAT-based sparse transformer with global and local structural encodings for AIGs; and (3) an inference acceleration CUDA kernel that fully exploit the unique sparsity patterns of AIGs. Our extensive experiments on the ITC99 and EPFL benchmarks show that DeepGate4 significantly surpasses state-of-the-art methods, achieving 15.5% and 31.1% performance improvements over the next-best models. Furthermore, the Fused-DeepGate4 variant reduces runtime by 35.1% and memory usage by 46.8%, making it highly efficient for large-scale circuit analysis. These results demonstrate the potential of DeepGate4 to handle complex EDA tasks while offering superior scalability and efficiency. Code is available at https://github.com/zyzheng17/DeepGate4-ICLR-25.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "169de5c7d9ad2c40239f34f14948ad037b525554",
    "url": "https://www.semanticscholar.org/paper/169de5c7d9ad2c40239f34f14948ad037b525554",
    "title": "IB-Net: Initial Branch Network for Variable Decision in Boolean Satisfiability",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2403.03517, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2290271874",
        "name": "T. H. Chan"
      },
      {
        "authorId": "2290127205",
        "name": "Wenyi Xiao"
      },
      {
        "authorId": "2198463494",
        "name": "Junhua Huang"
      },
      {
        "authorId": "46465266",
        "name": "Hui-Ling Zhen"
      },
      {
        "authorId": "2290073178",
        "name": "Guangji Tian"
      },
      {
        "authorId": "2290331022",
        "name": "Mingxuan Yuan"
      }
    ],
    "abstract": "Boolean Satisfiability problems are vital components in Electronic Design Automation, particularly within the Logic Equivalence Checking process. Currently, SAT solvers are employed for these problems and neural network is tried as assistance to solvers. However, as SAT problems in the LEC context are distinctive due to their predominantly unsatisfiability nature and a substantial proportion of UNSAT-core variables, existing neural network assistance has proven unsuccessful in this specialized domain. To tackle this challenge, we propose IB-Net, an innovative framework utilizing graph neural networks and novel graph encoding techniques to model unsatisfiable problems and interact with state-of-the-art solvers. Extensive evaluations across solvers and datasets demonstrate IB-Net's acceleration, achieving an average runtime speedup of 5.0% on industrial data and 8.3% on SAT competition data empirically. This breakthrough advances efficient solving in LEC workflows.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "ce4feca2759f58b83beed6ce7bfbd9f02b5d786c",
    "url": "https://www.semanticscholar.org/paper/ce4feca2759f58b83beed6ce7bfbd9f02b5d786c",
    "title": "A unified pre-training and adaptation framework for combinatorial optimization on graphs",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2312.11547, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2275238534",
        "name": "Ruibin Zeng"
      },
      {
        "authorId": "46173756",
        "name": "Minglong Lei"
      },
      {
        "authorId": "2275205629",
        "name": "Lingfeng Niu"
      },
      {
        "authorId": "2275529711",
        "name": "Lan Cheng"
      }
    ],
    "abstract": "Combinatorial optimization (CO) on graphs is a classic topic that has been extensively studied across many scientific and industrial fields. Recently, solving CO problems on graphs through learning methods has attracted great attention. Advanced deep learning methods, e.g., graph neural networks (GNNs), have been used to effectively assist the process of solving COs. However, current frameworks based on GNNs are mainly designed for certain CO problems, thereby failing to consider their transferable and generalizable abilities among different COs on graphs. Moreover, simply using original graphs to model COs only captures the direct correlations among objects, which does not consider the mathematical logicality and properties of COs. In this paper, we propose a unified pre-training and adaptation framework for COs on graphs with the help of the maximum satisfiability (Max-SAT) problem. We first use Max-SAT to bridge different COs on graphs since they can be converted to Max-SAT problems represented by standard formulas and clauses with logical information. Then we further design a pre-training and domain adaptation framework to extract the transferable and generalizable features so that different COs can benefit from them. In the pre-training stage, Max-SAT instances are generated to initialize the parameters of the model. In the fine-tuning stage, instances from CO and Max-SAT problems are used for adaptation so that the transferable ability can be further improved. Numerical experiments on several datasets show that features extracted by our framework exhibit superior transferability and Max-SAT can boost the ability to solve COs on graphs.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "63604fd867552a7b518462cf9b3ac0d99352d224",
    "url": "https://www.semanticscholar.org/paper/63604fd867552a7b518462cf9b3ac0d99352d224",
    "title": "Algorithms and Computation: 5th International Symposium, Isaac '94, Beijing, P.R. China, August 25-27, 1994 : Proceedings",
    "year": 1994,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2292163933",
        "name": "Isaac"
      },
      {
        "authorId": "3153945",
        "name": "Xiangde Zhang"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f3c995f08914523bf8996da489d69bcebee6e6c3",
    "url": "https://www.semanticscholar.org/paper/f3c995f08914523bf8996da489d69bcebee6e6c3",
    "title": "Guiding Word Equation Solving using Graph Neural Networks (Extended Technical Report)",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2411.15194, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1686895",
        "name": "P. Abdulla"
      },
      {
        "authorId": "3271072",
        "name": "M. Atig"
      },
      {
        "authorId": "2180206016",
        "name": "Julie Cailler"
      },
      {
        "authorId": "2279367051",
        "name": "Chencheng Liang"
      },
      {
        "authorId": "2279347837",
        "name": "Philipp R\u00c3\u00bcmmer"
      }
    ],
    "abstract": "This paper proposes a Graph Neural Network-guided algorithm for solving word equations, based on the well-known Nielsen transformation for splitting equations. The algorithm iteratively rewrites the first terms of each side of an equation, giving rise to a tree-like search space. The choice of path at each split point of the tree significantly impacts solving time, motivating the use of Graph Neural Networks (GNNs) for efficient split decision-making. Split decisions are encoded as multi-classification tasks, and five graph representations of word equations are introduced to encode their structural information for GNNs. The algorithm is implemented as a solver named DragonLi. Experiments are conducted on artificial and real-world benchmarks. The algorithm performs particularly well on satisfiable problems. For single word \\mbox{equations}, DragonLi can solve significantly more problems than well-established string solvers. For the conjunction of multiple word equations, DragonLi is competitive with state-of-the-art string solvers.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "8694bbf386616b1f7bd0e151693ad16a0d805bb6",
    "url": "https://www.semanticscholar.org/paper/8694bbf386616b1f7bd0e151693ad16a0d805bb6",
    "title": "Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2310.10603, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2253440539",
        "name": "Chendi Qian"
      },
      {
        "authorId": "2066421682",
        "name": "Didier Ch'etelat"
      },
      {
        "authorId": "2253424002",
        "name": "Christopher Morris"
      }
    ],
    "abstract": "Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1f96eda505cdf04f3b472a8e67fe93fddfcc9784",
    "url": "https://www.semanticscholar.org/paper/1f96eda505cdf04f3b472a8e67fe93fddfcc9784",
    "title": "Expressive Power of Graph Neural Networks for (Mixed-Integer) Quadratic Programs",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2406.05938, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2283850392",
        "name": "Ziang Chen"
      },
      {
        "authorId": "2261359342",
        "name": "Xiaohan Chen"
      },
      {
        "authorId": "2108415378",
        "name": "Jialin Liu"
      },
      {
        "authorId": "2261241838",
        "name": "Xinshang Wang"
      },
      {
        "authorId": "2261082763",
        "name": "Wotao Yin"
      }
    ],
    "abstract": "Quadratic programming (QP) is the most widely applied category of problems in nonlinear programming. Many applications require real-time/fast solutions, though not necessarily with high precision. Existing methods either involve matrix decomposition or use the preconditioned conjugate gradient method. For relatively large instances, these methods cannot achieve the real-time requirement unless there is an effective preconditioner. Recently, graph neural networks (GNNs) opened new possibilities for QP. Some promising empirical studies of applying GNNs for QP tasks show that GNNs can capture key characteristics of an optimization instance and provide adaptive guidance accordingly to crucial configurations during the solving process, or directly provide an approximate solution. However, the theoretical understanding of GNNs in this context remains limited. Specifically, it is unclear what GNNs can and cannot achieve for QP tasks in theory. This work addresses this gap in the context of linearly constrained QP tasks. In the continuous setting, we prove that message-passing GNNs can universally represent fundamental properties of convex quadratic programs, including feasibility, optimal objective values, and optimal solutions. In the more challenging mixed-integer setting, while GNNs are not universal approximators, we identify a subclass of QP problems that GNNs can reliably represent.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "fe4a65fef96e2d04beb560ac3f0be55a7d2ed3b9",
    "url": "https://www.semanticscholar.org/paper/fe4a65fef96e2d04beb560ac3f0be55a7d2ed3b9",
    "title": "Graph Neural Networks for Job Shop Scheduling Problems: A Survey",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2406.14096, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2296602422",
        "name": "Igor G. Smit"
      },
      {
        "authorId": "51292460",
        "name": "Jianan Zhou"
      },
      {
        "authorId": "2045770034",
        "name": "Robbert Reijnen"
      },
      {
        "authorId": "2301537762",
        "name": "Yaoxin Wu"
      },
      {
        "authorId": "2307509850",
        "name": "Jian Chen"
      },
      {
        "authorId": "2287878423",
        "name": "Cong Zhang"
      },
      {
        "authorId": "2254592",
        "name": "Z. Bukhsh"
      },
      {
        "authorId": "145732295",
        "name": "Wim P. M. Nuijten"
      },
      {
        "authorId": "2297344146",
        "name": "Yingqian Zhang"
      }
    ],
    "abstract": "Job shop scheduling problems (JSSPs) represent a critical and challenging class of combinatorial optimization problems. Recent years have witnessed a rapid increase in the application of graph neural networks (GNNs) to solve JSSPs, albeit lacking a systematic survey of the relevant literature. This paper aims to thoroughly review prevailing GNN methods for different types of JSSPs and the closely related flow-shop scheduling problems (FSPs), especially those leveraging deep reinforcement learning (DRL). We begin by presenting the graph representations of various JSSPs, followed by an introduction to the most commonly used GNN architectures. We then review current GNN-based methods for each problem type, highlighting key technical elements such as graph representations, GNN architectures, GNN tasks, and training algorithms. Finally, we summarize and analyze the advantages and limitations of GNNs in solving JSSPs and provide potential future research opportunities. We hope this survey can motivate and inspire innovative approaches for more powerful GNN-based approaches in tackling JSSPs and other scheduling problems.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6a432820b17f4e62144ade8079c2f91604dd0f3c",
    "url": "https://www.semanticscholar.org/paper/6a432820b17f4e62144ade8079c2f91604dd0f3c",
    "title": "Solving the kidney exchange problem via graph neural networks with no supervision",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2304.09975",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2304.09975, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "104354709",
        "name": "P. F. Pimenta"
      },
      {
        "authorId": "144862483",
        "name": "Pedro H. C. Avelar"
      },
      {
        "authorId": "2335532",
        "name": "L. Lamb"
      }
    ],
    "abstract": "This paper introduces a new learning-based approach for approximately solving the Kidney-Exchange Problem (KEP), an NP-hard problem on graphs. The KEP consists of, given a pool of kidney donors and patients waiting for kidney donations, optimally selecting a set of donations to optimize the quantity and quality of transplants performed while respecting a set of constraints about the arrangement of these donations. The proposed technique consists of two major steps: the first is a Graph Neural Network (GNN) trained without supervision; the second is a deterministic non-learned search heuristic that uses the output of the GNN to find a valid solution. To allow for comparisons, we also implemented and tested an exact solution method using integer programming, two greedy search heuristics without the machine learning module, and the GNN alone without a heuristic. We analyze and compare the methods and conclude that the learning-based two-stage approach is the best solution quality, outputting approximate solutions on average 1.1 times more valuable than the ones from the deterministic heuristic alone.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "2cda20b9281aa2b4171893f3659ce97765a5aa40",
    "url": "https://www.semanticscholar.org/paper/2cda20b9281aa2b4171893f3659ce97765a5aa40",
    "title": "Opportunities and challenges of graph neural networks in electrical engineering",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s44287-024-00076-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s44287-024-00076-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "121307942",
        "name": "Eli Chien"
      },
      {
        "authorId": "2112144150",
        "name": "Mufei Li"
      },
      {
        "authorId": "117671580",
        "name": "Anthony Aportela"
      },
      {
        "authorId": "2215835857",
        "name": "Kerr Ding"
      },
      {
        "authorId": "2057420225",
        "name": "Shuyi Jia"
      },
      {
        "authorId": "3034489",
        "name": "S. Maji"
      },
      {
        "authorId": "2257082077",
        "name": "Zhongyuan Zhao"
      },
      {
        "authorId": "2239026481",
        "name": "J. Duarte"
      },
      {
        "authorId": "2287577728",
        "name": "Victor Fung"
      },
      {
        "authorId": "2314993482",
        "name": "Cong Hao"
      },
      {
        "authorId": "6426643",
        "name": "Yunan Luo"
      },
      {
        "authorId": "2286174723",
        "name": "Olgica Milenkovic"
      },
      {
        "authorId": "2314974210",
        "name": "David Pan"
      },
      {
        "authorId": "2256999084",
        "name": "Santiago Segarra"
      },
      {
        "authorId": "2276750869",
        "name": "Pan Li"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "93c9f9ac6962d38ea937160a11b66ca09290d394",
    "url": "https://www.semanticscholar.org/paper/93c9f9ac6962d38ea937160a11b66ca09290d394",
    "title": "Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like maximum independent set",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2206.13211, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3199668",
        "name": "Maria Chiara Angelini"
      },
      {
        "authorId": "1388759973",
        "name": "F. Ricci-Tersenghi"
      }
    ],
    "abstract": "The recent work ``Combinatorial Optimization with Physics-Inspired Graph Neural Networks'' [Nat Mach Intell 4 (2022) 367] introduces a physics-inspired unsupervised Graph Neural Network (GNN) to solve combinatorial optimization problems on sparse graphs. To test the performances of these GNNs, the authors of the work show numerical results for two fundamental problems: maximum cut and maximum independent set (MIS). They conclude that\"the graph neural network optimizer performs on par or outperforms existing solvers, with the ability to scale beyond the state of the art to problems with millions of variables.\"In this comment, we show that a simple greedy algorithm, running in almost linear time, can find solutions for the MIS problem of much better quality than the GNN. The greedy algorithm is faster by a factor of $10^4$ with respect to the GNN for problems with a million variables. We do not see any good reason for solving the MIS with these GNN, as well as for using a sledgehammer to crack nuts. In general, many claims of superiority of neural networks in solving combinatorial problems are at risk of being not solid enough, since we lack standard benchmarks based on really hard problems. We propose one of such hard benchmarks, and we hope to see future neural network optimizers tested on these problems before any claim of superiority is made.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "faddd31ce295f431f34c357c2fe8cac516027ac5",
    "url": "https://www.semanticscholar.org/paper/faddd31ce295f431f34c357c2fe8cac516027ac5",
    "title": "Solving AC Power Flow with Graph Neural Networks under Realistic Constraints",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2204.07000",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2204.07000, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2162464823",
        "name": "Luis Bottcher"
      },
      {
        "authorId": "152710659",
        "name": "Hinrikus Wolf"
      },
      {
        "authorId": "98433313",
        "name": "B. Jung"
      },
      {
        "authorId": "1750926681",
        "name": "Philipp Lutat"
      },
      {
        "authorId": "103366815",
        "name": "M. Trageser"
      },
      {
        "authorId": "46710560",
        "name": "O. Pohl"
      },
      {
        "authorId": "2749519",
        "name": "Andreas Ulbig"
      },
      {
        "authorId": "1744396",
        "name": "Martin Grohe"
      }
    ],
    "abstract": "In this paper, we propose a graph neural network architecture to solve the AC power flow problem under realistic constraints. To ensure a safe and resilient operation of distribution grids, AC power flow calculations are the means of choice to determine grid operating limits or analyze grid asset utilization in planning procedures. In our approach, we demonstrate the development of a framework that uses graph neural networks to learn the physical constraints of the power flow. We present our model architecture on which we perform unsupervised training to learn a general solution of the AC power flow formulation independent of the specific topologies and supply tasks used for training. Finally, we demonstrate, validate and discuss our results on medium voltage benchmark grids. In our approach, we focus on the physical and topological properties of distribution grids to provide scalable solutions for real grid topologies. Therefore, we take a data-driven approach, using large and diverse data sets consisting of realistic grid topologies, for the unsupervised training of the AC power flow graph neural network architecture and compare the results to a prior neural architecture and the Newton-Raphson method. Our approach shows a high increase in computation time and good accuracy compared to state-of-the-art solvers. It also out-performs that neural solver for power flow in terms of accuracy.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "347e837b1aa03c9d17c69a522929000f0a0f0a51",
    "url": "https://www.semanticscholar.org/paper/347e837b1aa03c9d17c69a522929000f0a0f0a51",
    "title": "SuperGlue: Learning Feature Matching With Graph Neural Networks",
    "year": 2019,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/1911.11763",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1911.11763, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51435497",
        "name": "Paul-Edouard Sarlin"
      },
      {
        "authorId": "3422291",
        "name": "Daniel DeTone"
      },
      {
        "authorId": "3045340",
        "name": "Tomasz Malisiewicz"
      },
      {
        "authorId": "39863668",
        "name": "Andrew Rabinovich"
      }
    ],
    "abstract": "This paper introduces SuperGlue, a neural network that matches two sets of local features by jointly finding correspondences and rejecting non-matchable points. Assignments are estimated by solving a differentiable optimal transport problem, whose costs are predicted by a graph neural network. We introduce a flexible context aggregation mechanism based on attention, enabling SuperGlue to reason about the underlying 3D scene and feature assignments jointly. Compared to traditional, hand-designed heuristics, our technique learns priors over geometric transformations and regularities of the 3D world through end-to-end training from image pairs. SuperGlue outperforms other learned approaches and achieves state-of-the-art results on the task of pose estimation in challenging real-world indoor and outdoor environments. The proposed method performs matching in real-time on a modern GPU and can be readily integrated into modern SfM or SLAM systems. The code and trained weights are publicly available at github.com/magicleap/SuperGluePretrainedNetwork.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "c7ac48f6e7a621375785efe3b3f32deec407efb0",
    "url": "https://www.semanticscholar.org/paper/c7ac48f6e7a621375785efe3b3f32deec407efb0",
    "title": "Learning Strong Graph Neural Networks with Weak Information",
    "year": 2023,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2305.18457",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2305.18457, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2116018493",
        "name": "Yixin Liu"
      },
      {
        "authorId": "66807781",
        "name": "Kaize Ding"
      },
      {
        "authorId": "2110273966",
        "name": "Jianling Wang"
      },
      {
        "authorId": "2187919914",
        "name": "Vincent Lee"
      },
      {
        "authorId": "2155337763",
        "name": "Huan Liu"
      },
      {
        "authorId": "2153326034",
        "name": "Shirui Pan"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have exhibited impressive performance in many graph learning tasks. Nevertheless, the performance of GNNs can deteriorate when the input graph data suffer from weak information, i.e., incomplete structure, incomplete features, and insufficient labels. Most prior studies, which attempt to learn from the graph data with a specific type of weak information, are far from effective in dealing with the scenario where diverse data deficiencies exist and mutually affect each other. To fill the gap, in this paper, we aim to develop an effective and principled approach to the problem of graph learning with weak information (GLWI). Based on the findings from our empirical analysis, we derive two design focal points for solving the problem of GLWI, i.e., enabling long-range propagation in GNNs and allowing information propagation to those stray nodes isolated from the largest connected component. Accordingly, we propose D2PT, a dual-channel GNN framework that performs long-range information propagation not only on the input graph with incomplete structure, but also on a global graph that encodes global semantic similarities. We further develop a prototype contrastive alignment algorithm that aligns the class-level prototypes learned from two channels, such that the two different information propagation processes can mutually benefit from each other and the finally learned model can well handle the GLWI problem. Extensive experiments on eight real-world benchmark datasets demonstrate the effectiveness and efficiency of our proposed methods in various GLWI scenarios.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "ca02d77c4a9fed756df4c2c6ac131e03e98cd7cb",
    "url": "https://www.semanticscholar.org/paper/ca02d77c4a9fed756df4c2c6ac131e03e98cd7cb",
    "title": "Fast and Exact Synthesis of Application Deployment Plans using Graph Neural Networks and Satisfiability Modulo Theory",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN60899.2024.10650114?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN60899.2024.10650114, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2896054",
        "name": "Madalina Erascu"
      }
    ],
    "abstract": "Learning-augmented algorithms use machine learning predictions to boost optimization algorithms performance. The extra information incorporated into learning-augmented algorithms is, for example, the input which resembles prior instances, potentially aiding in circumventing the need to compute solutions from scratch or facilitating the utilization of existing solutions for deriving new ones.In previous works, we synthesized leasing cost optimal, subsequently named optimal, Cloud deployment plans by solving the corresponding constrained optimization problem using Satisfiability Modulo Theory (SMT) solvers and symmetry breakers. In this paper, we leverage the previously generated deployment plans to create a model of the deployed application. We employ graph neural networks (GNNs) for this purpose, encoding past deployment plans as graphs, with components and virtual machines as nodes and their interactions as edges. The GNN model trained can learn from historical data to predict optimal assignments by solving the corresponding edge classification problem. These predictions are then used as soft constraints in the exact SMT solver Z3, efficiently guiding the solver towards the optimal solution.We exemplify our approach on a Secure Web Container application.The accompanying material of this paper, as well as the application of our approach to other case studies, is publicly available at https://github.com/SAGE-Project/SAGE-GNN/tree/IJCNN2024.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "c7fdb033ff15771e9bcea4336135eec171a595f3",
    "url": "https://www.semanticscholar.org/paper/c7fdb033ff15771e9bcea4336135eec171a595f3",
    "title": "Approximation Ratios of Graph Neural Networks for Combinatorial Problems",
    "year": 2019,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1905.10261, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51442285",
        "name": "R. Sato"
      },
      {
        "authorId": "50142992",
        "name": "M. Yamada"
      },
      {
        "authorId": "2785830",
        "name": "H. Kashima"
      }
    ],
    "abstract": "In this paper, from a theoretical perspective, we study how powerful graph neural networks (GNNs) can be for learning approximation algorithms for combinatorial problems. To this end, we first establish a new class of GNNs that can solve a strictly wider variety of problems than existing GNNs. Then, we bridge the gap between GNN theory and the theory of distributed local algorithms. We theoretically demonstrate that the most powerful GNN can learn approximation algorithms for the minimum dominating set problem and the minimum vertex cover problem with some approximation ratios with the aid of the theory of distributed local algorithms. We also show that most of the existing GNNs such as GIN, GAT, GCN, and GraphSAGE cannot perform better than with these ratios. This paper is the first to elucidate approximation ratios of GNNs for combinatorial problems. Furthermore, we prove that adding coloring or weak-coloring to each node feature improves these approximation ratios. This indicates that preprocessing and feature engineering theoretically strengthen model capabilities.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "0ef0f7ff1f6e4628a8d16609b23a27d5574ab803",
    "url": "https://www.semanticscholar.org/paper/0ef0f7ff1f6e4628a8d16609b23a27d5574ab803",
    "title": "Mixed-Integer Optimisation of Graph Neural Networks for Computer-Aided Molecular Design",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2312.01228, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2269469463",
        "name": "Tom McDonald"
      },
      {
        "authorId": "2281744446",
        "name": "Calvin Tsay"
      },
      {
        "authorId": "41072400",
        "name": "Artur M. Schweidtmann"
      },
      {
        "authorId": "2374407700",
        "name": "Neil Yorke-Smith"
      }
    ],
    "abstract": "ReLU neural networks have been modelled as constraints in mixed integer linear programming (MILP), enabling surrogate-based optimisation in various domains and efficient solution of machine learning certification problems. However, previous works are mostly limited to MLPs. Graph neural networks (GNNs) can learn from non-euclidean data structures such as molecular structures efficiently and are thus highly relevant to computer-aided molecular design (CAMD). We propose a bilinear formulation for ReLU Graph Convolutional Neural Networks and a MILP formulation for ReLU GraphSAGE models. These formulations enable solving optimisation problems with trained GNNs embedded to global optimality. We apply our optimization approach to an illustrative CAMD case study where the formulations of the trained GNNs are used to design molecules with optimal boiling points.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "80268d1413fadfb988051fb9fe917021250372e1",
    "url": "https://www.semanticscholar.org/paper/80268d1413fadfb988051fb9fe917021250372e1",
    "title": "Predicting Global Label Relationship Matrix for Graph Neural Networks under Heterophily",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2155276820",
        "name": "Langzhang Liang"
      },
      {
        "authorId": "1471731078",
        "name": "Xiangjing Hu"
      },
      {
        "authorId": "2237959156",
        "name": "Zenglin Xu"
      },
      {
        "authorId": "2114791973",
        "name": "Zixing Song"
      },
      {
        "authorId": "2259418768",
        "name": "Irwin King"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f945b6788d4042c950e57e6032c0ad122566661e",
    "url": "https://www.semanticscholar.org/paper/f945b6788d4042c950e57e6032c0ad122566661e",
    "title": "Distill n' Explain: explaining graph neural networks using simple surrogates",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2303.10139",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2303.10139, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2061161328",
        "name": "Tamara A. Pereira"
      },
      {
        "authorId": "2211967383",
        "name": "Erik Nasciment"
      },
      {
        "authorId": "2164014168",
        "name": "Lucas Resck"
      },
      {
        "authorId": "144128644",
        "name": "Diego Mesquita"
      },
      {
        "authorId": "3383481",
        "name": "A. Souza"
      }
    ],
    "abstract": "Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faithfulness of explanations.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "16a5e3150652f96dde10852769d3b62d25f3b7c9",
    "url": "https://www.semanticscholar.org/paper/16a5e3150652f96dde10852769d3b62d25f3b7c9",
    "title": "NodeMixup: Tackling Under-Reaching for Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2312.13032, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2154002550",
        "name": "Weigang Lu"
      },
      {
        "authorId": "2265665200",
        "name": "Ziyu Guan"
      },
      {
        "authorId": "144876291",
        "name": "Wei Zhao"
      },
      {
        "authorId": "1455886221",
        "name": "Yaming Yang"
      },
      {
        "authorId": "2275271936",
        "name": "Long Jin"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have become mainstream methods for solving the semi-supervised node classification problem. However, due to the uneven location distribution of labeled nodes in the graph, labeled nodes are only accessible to a small portion of unlabeled nodes, leading to the under-reaching issue. In this study, we firstly reveal under-reaching by conducting an empirical investigation on various well-known graphs. Then, we demonstrate that under-reaching results in unsatisfactory distribution alignment between labeled and unlabeled nodes through systematic experimental analysis, significantly degrading GNNs' performance. To tackle under-reaching for GNNs, we propose an architecture-agnostic method dubbed NodeMixup. The fundamental idea is to (1) increase the reachability of labeled nodes by labeled-unlabeled pairs mixup, (2) leverage graph structures via fusing the neighbor connections of intra-class node pairs to improve performance gains of mixup, and (3) use neighbor label distribution similarity incorporating node degrees to determine sampling weights for node mixup. Extensive experiments demonstrate the efficacy of NodeMixup in assisting GNNs in handling under-reaching. The source code is available at https://github.com/WeigangLu/NodeMixup.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "e7987503524dfbcf118c4ccdd303cc798bb90b47",
    "url": "https://www.semanticscholar.org/paper/e7987503524dfbcf118c4ccdd303cc798bb90b47",
    "title": "A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://doi.org/10.1109/tkde.2024.3454328",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2308.16375, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153911450",
        "name": "Yi Zhang"
      },
      {
        "authorId": "2124210729",
        "name": "Yuying Zhao"
      },
      {
        "authorId": "2236698799",
        "name": "Zhaoqing Li"
      },
      {
        "authorId": "2226196831",
        "name": "Xueqi Cheng"
      },
      {
        "authorId": "2153607948",
        "name": "Yu Wang"
      },
      {
        "authorId": "7731413",
        "name": "O. Kotevska"
      },
      {
        "authorId": "2721708",
        "name": "P. Yu"
      },
      {
        "authorId": "2067148039",
        "name": "Tyler Derr"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have gained significant attention owing to their ability to handle graph-structured data and the improvement in practical applications. However, many of these models prioritize high utility performance, such as accuracy, with a lack of privacy consideration, which is a major concern in modern society where privacy attacks are rampant. To address this issue, researchers have started to develop privacy-preserving GNNs. Despite this progress, there is a lack of a comprehensive overview of the attacks and the techniques for preserving privacy in the graph domain. In this survey, we aim to address this gap by summarizing the attacks on graph data according to the targeted information, categorizing the privacy preservation techniques in GNNs, and reviewing the datasets and applications that could be used for analyzing/solving privacy issues in GNNs. We also outline potential directions for future research in order to build better privacy-preserving GNNs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "02bbea2a019eb63cbd2298f3813c8153423e3e82",
    "url": "https://www.semanticscholar.org/paper/02bbea2a019eb63cbd2298f3813c8153423e3e82",
    "title": "Vulcan: Solving the Steiner Tree Problem with Graph Neural Networks and Deep Reinforcement Learning",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2111.10810, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2086128",
        "name": "Haizhou Du"
      },
      {
        "authorId": "2125427164",
        "name": "Zong Yan"
      },
      {
        "authorId": "2056006673",
        "name": "Qiao Xiang"
      },
      {
        "authorId": "2142119962",
        "name": "Qinqing Zhan"
      }
    ],
    "abstract": "Steiner Tree Problem (STP) in graphs aims to find a tree of minimum weight in the graph that connects a given set of vertices. It is a classic NP-hard combinatorial optimization problem and has many real-world applications (e.g., VLSI chip design, transportation network planning and wireless sensor networks). Many exact and approximate algorithms have been developed for STP, but they suffer from high computational complexity and weak worst-case solution guarantees, respectively. Heuristic algorithms are also developed. However, each of them requires application domain knowledge to design and is only suitable for specific scenarios. Motivated by the recently reported observation that instances of the same NP-hard combinatorial problem may maintain the same or similar combinatorial structure but mainly differ in their data, we investigate the feasibility and benefits of applying machine learning techniques to solving STP. To this end, we design a novel model Vulcan based on novel graph neural networks and deep reinforcement learning. The core of Vulcan is a novel, compact graph embedding that transforms highdimensional graph structure data (i.e., path-changed information) into a low-dimensional vector representation. Given an STP instance, Vulcan uses this embedding to encode its pathrelated information and sends the encoded graph to a deep reinforcement learning component based on a double deep Q network (DDQN) to find solutions. In addition to STP, Vulcan can also find solutions to a wide range of NP-hard problems (e.g., SAT, MVC and X3C) by reducing them to STP. We implement a prototype of Vulcan and demonstrate its efficacy and efficiency with extensive experiments using real-world and synthetic datasets.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "a4697474a885787e4312765be5af29a8b6d908c0",
    "url": "https://www.semanticscholar.org/paper/a4697474a885787e4312765be5af29a8b6d908c0",
    "title": "Physics-informed graph neural Galerkin networks: A unified framework for solving PDE-governed forward and inverse problems",
    "year": 2021,
    "openAccessPdf": {
      "url": "http://manuscript.elsevier.com/S0045782521007076/pdf/S0045782521007076.pdf",
      "status": "BRONZE",
      "license": "publisher-specific-oa",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2107.12146, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2112513091",
        "name": "Han Gao"
      },
      {
        "authorId": "2716423",
        "name": "M. Zahr"
      },
      {
        "authorId": "2110206668",
        "name": "Jian-Xun Wang"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6c7b4505634d7dc16fb1596864644a481eea3acb",
    "url": "https://www.semanticscholar.org/paper/6c7b4505634d7dc16fb1596864644a481eea3acb",
    "title": "Graph neural networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1038/s43586-024-00294-7?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1038/s43586-024-00294-7, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2312199228",
        "name": "Gabriele Corso"
      },
      {
        "authorId": "2124211700",
        "name": "Hannes St\u00c3\u00a4rk"
      },
      {
        "authorId": "2294128072",
        "name": "Stefanie Jegelka"
      },
      {
        "authorId": "35132120",
        "name": "T. Jaakkola"
      },
      {
        "authorId": "2254308896",
        "name": "R. Barzilay"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "2c2a0534d7da4f7a5d6e009ae73fe352f4ebfe22",
    "url": "https://www.semanticscholar.org/paper/2c2a0534d7da4f7a5d6e009ae73fe352f4ebfe22",
    "title": "Extending the Design Space of Graph Neural Networks by Rethinking Folklore Weisfeiler-Lehman",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2306.03266, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48441034",
        "name": "Jiarui Feng"
      },
      {
        "authorId": "2164063663",
        "name": "Lecheng Kong"
      },
      {
        "authorId": "2264134998",
        "name": "Hao Liu"
      },
      {
        "authorId": "2082545536",
        "name": "Dacheng Tao"
      },
      {
        "authorId": "2146340100",
        "name": "Fuhai Li"
      },
      {
        "authorId": "3098251",
        "name": "Muhan Zhang"
      },
      {
        "authorId": "2116664181",
        "name": "Yixin Chen"
      }
    ],
    "abstract": "Message passing neural networks (MPNNs) have emerged as the most popular framework of graph neural networks (GNNs) in recent years. However, their expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Some works are inspired by $k$-WL/FWL (Folklore WL) and design the corresponding neural versions. Despite the high expressive power, there are serious limitations in this line of research. In particular, (1) $k$-WL/FWL requires at least $O(n^k)$ space complexity, which is impractical for large graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the only adjustable hyper-parameter being $k$. To tackle the first limitation, we propose an extension, $(k,t)$-FWL. We theoretically prove that even if we fix the space complexity to $O(n^k)$ (for any $k\\geq 2$) in $(k,t)$-FWL, we can construct an expressiveness hierarchy up to solving the graph isomorphism problem. To tackle the second problem, we propose $k$-FWL+, which considers any equivariant set as neighbors instead of all nodes, thereby greatly expanding the design space of $k$-FWL. Combining these two modifications results in a flexible and powerful framework $(k,t)$-FWL+. We demonstrate $(k,t)$-FWL+ can implement most existing models with matching expressiveness. We then introduce an instance of $(k,t)$-FWL+ called Neighborhood$^2$-FWL (N$^2$-FWL), which is practically and theoretically sound. We prove that N$^2$-FWL is no less powerful than 3-WL, and can encode many substructures while only requiring $O(n^2)$ space. Finally, we design its neural version named N$^2$-GNN and evaluate its performance on various tasks. N$^2$-GNN achieves record-breaking results on ZINC-Subset (0.059), outperforming previous SOTA results by 10.6%. Moreover, N$^2$-GNN achieves new SOTA results on the BREC dataset (71.8%) among all existing high-expressive GNN methods.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "21dce0407d0ee3bec185b0361593d73bb26a532e",
    "url": "https://www.semanticscholar.org/paper/21dce0407d0ee3bec185b0361593d73bb26a532e",
    "title": "XGBoost-Enhanced Graph Neural Networks: A New Architecture for Heterogeneous Tabular Data",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2076-3417/14/13/5826/pdf?version=1720168354",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/app14135826?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app14135826, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2310275645",
        "name": "Liuxi Yan"
      },
      {
        "authorId": "2143001003",
        "name": "Yaoqun Xu"
      }
    ],
    "abstract": "Graph neural networks (GNNs) perform well in text analysis tasks. Their unique structure allows them to capture complex patterns and dependencies in text, making them ideal for processing natural language tasks. At the same time, XGBoost (version 1.6.2.) outperforms other machine learning methods on heterogeneous tabular data. However, traditional graph neural networks mainly study isomorphic and sparse data features. Therefore, when dealing with tabular data, traditional graph neural networks encounter challenges such as data structure mismatch, feature selection, and processing difficulties. To solve these problems, we propose a novel architecture, XGNN, which combines the advantages of XGBoost and GNNs to deal with heterogeneous features and graph structures. In this paper, we use GAT for our graph neural network model. We can train XGBoost and GNN end-to-end to fit and adjust the new tree in XGBoost based on the gradient information from the GNN. Extensive experiments on node prediction and node classification tasks demonstrate that the performance of our proposed new model is significantly improved for both prediction and classification tasks and performs particularly well on heterogeneous tabular data.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a5805fc04ef9c6bd5534b36fbc2a6a1838c094d5",
    "url": "https://www.semanticscholar.org/paper/a5805fc04ef9c6bd5534b36fbc2a6a1838c094d5",
    "title": "Multiscale graph neural networks with adaptive mesh refinement for accelerating mesh-based simulations",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2402.08863, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2119572958",
        "name": "Roberto Perera"
      },
      {
        "authorId": "26765140",
        "name": "V. Agrawal"
      }
    ],
    "abstract": "Mesh-based Graph Neural Networks (GNNs) have recently shown capabilities to simulate complex multiphysics problems with accelerated performance times. However, mesh-based GNNs require a large number of message-passing (MP) steps and suffer from over-smoothing for problems involving very fine mesh. In this work, we develop a multiscale mesh-based GNN framework mimicking a conventional iterative multigrid solver, coupled with adaptive mesh refinement (AMR), to mitigate challenges with conventional mesh-based GNNs. We use the framework to accelerate phase field (PF) fracture problems involving coupled partial differential equations with a near-singular operator due to near-zero modulus inside the crack. We define the initial graph representation using all mesh resolution levels. We perform a series of downsampling steps using Transformer MP GNNs to reach the coarsest graph followed by upsampling steps to reach the original graph. We use skip connectors from the generated embedding during coarsening to prevent over-smoothing. We use Transfer Learning (TL) to significantly reduce the size of training datasets needed to simulate different crack configurations and loading conditions. The trained framework showed accelerated simulation times, while maintaining high accuracy for all cases compared to physics-based PF fracture model. Finally, this work provides a new approach to accelerate a variety of mesh-based engineering multiphysics problems",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "33e31195ab6853dfb8b1d90b07da5755f9bf5de0",
    "url": "https://www.semanticscholar.org/paper/33e31195ab6853dfb8b1d90b07da5755f9bf5de0",
    "title": "Random Features Strengthen Graph Neural Networks",
    "year": 2020,
    "openAccessPdf": {
      "url": "https://epubs.siam.org/doi/pdf/10.1137/1.9781611976700.38",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2002.03155, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51442285",
        "name": "R. Sato"
      },
      {
        "authorId": "50142992",
        "name": "M. Yamada"
      },
      {
        "authorId": "2785830",
        "name": "H. Kashima"
      }
    ],
    "abstract": "Graph neural networks (GNNs) are powerful machine learning models for various graph learning tasks. Recently, the limitations of the expressive power of various GNN models have been revealed. For example, GNNs cannot distinguish some non-isomorphic graphs and they cannot learn efficient graph algorithms, and several GNN models have been proposed to overcome these limitations. In this paper, we demonstrate that GNNs become powerful just by adding a random feature to each node. We prove that the random features enable GNNs to learn almost optimal polynomial-time approximation algorithms for the minimum dominating set problem and maximum matching problem in terms of the approximation ratio. The main advantage of our method is that it can be combined with off-the-shelf GNN models with slight modifications. Through experiments, we show that the addition of random features enables GNNs to solve various problems that normal GNNs, including GCNs and GINs, cannot solve.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "8da9f2afeeb426da2e90bc651b2b375c50a83b58",
    "url": "https://www.semanticscholar.org/paper/8da9f2afeeb426da2e90bc651b2b375c50a83b58",
    "title": "Guiding an Instantiation Prover with Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://easychair.org/publications/open/5z94",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.29007/tp23?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.29007/tp23, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3233331",
        "name": "Karel Chvalovsk\u00c3\u00bd"
      },
      {
        "authorId": "144880146",
        "name": "Konstantin Korovin"
      },
      {
        "authorId": "2048060685",
        "name": "Jelle Piepenbrock"
      },
      {
        "authorId": "2087993",
        "name": "J. Urban"
      }
    ],
    "abstract": "In this work we extend an instantiation-based theorem prover iProver with machine learning (ML) guidance based on graph neural networks. For this we implement an interactive mode in iProver, which allows communication with an external agent via network sockets. The external (ML-based) agent guides the proof search by scoring generated clauses in the given clause loop. Our evaluation on a large set of Mizar problems shows that the ML guidance outperforms iProver\u00e2\u0080\u0099s standard human-programmed priority queues, solving more than twice as many problems in the same time. To our knowledge, this is the first time the performance of a state-of-the-art instantiation-based system is doubled by ML guidance.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "6644e8671e6c344c06ff7cbc925d831fc4d18e05",
    "url": "https://www.semanticscholar.org/paper/6644e8671e6c344c06ff7cbc925d831fc4d18e05",
    "title": "Are Graph Neural Networks Optimal Approximation Algorithms?",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2310.00526",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2310.00526, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2249763561",
        "name": "Morris Yau"
      },
      {
        "authorId": "2249763796",
        "name": "Eric Lu"
      },
      {
        "authorId": "7651587",
        "name": "Nikolaos Karalias"
      },
      {
        "authorId": "2249891086",
        "name": "Jessica Xu"
      },
      {
        "authorId": "2249763643",
        "name": "Stefanie Jegelka"
      }
    ],
    "abstract": "In this work we design graph neural network architectures that capture optimal approximation algorithms for a large class of combinatorial optimization problems, using powerful algorithmic tools from semidefinite programming (SDP). Concretely, we prove that polynomial-sized message-passing algorithms can represent the most powerful polynomial time algorithms for Max Constraint Satisfaction Problems assuming the Unique Games Conjecture. We leverage this result to construct efficient graph neural network architectures, OptGNN, that obtain high-quality approximate solutions on landmark combinatorial optimization problems such as Max-Cut, Min-Vertex-Cover, and Max-3-SAT. Our approach achieves strong empirical results across a wide range of real-world and synthetic datasets against solvers and neural baselines. Finally, we take advantage of OptGNN's ability to capture convex relaxations to design an algorithm for producing bounds on the optimal solution from the learned embeddings of OptGNN.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "4f7cc5572974c49e5417707b3a491e59cd3d10a3",
    "url": "https://www.semanticscholar.org/paper/4f7cc5572974c49e5417707b3a491e59cd3d10a3",
    "title": "Can Graph Neural Networks Learn to Solve the MaxSAT Problem? (Student Abstract)",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/26992/26764",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1609/aaai.v37i13.26992?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aaai.v37i13.26992, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49354237",
        "name": "Minghao Liu"
      },
      {
        "authorId": "70462118",
        "name": "Pei Huang"
      },
      {
        "authorId": "1619536054",
        "name": "Fuqi Jia"
      },
      {
        "authorId": "50212920",
        "name": "Fan Zhang"
      },
      {
        "authorId": "2109029213",
        "name": "Yuchen Sun"
      },
      {
        "authorId": "38598067",
        "name": "Shaowei Cai"
      },
      {
        "authorId": "2901930",
        "name": "Feifei Ma"
      },
      {
        "authorId": "2151809741",
        "name": "Jian Zhang"
      }
    ],
    "abstract": "The paper presents an attempt to bridge the gap between machine learning and symbolic reasoning. We build graph neural networks (GNNs) to predict the solution of the Maximum Satisfiability (MaxSAT) problem, an optimization variant of SAT. Two closely related graph representations are adopted, and we prove their theoretical equivalence. We also show that GNNs can achieve attractive performance to solve hard MaxSAT problems in certain distributions even compared with state-of-the-art solvers through experimental evaluation.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "065e266387b843d9fbc022db4235a1be06d64c8b",
    "url": "https://www.semanticscholar.org/paper/065e266387b843d9fbc022db4235a1be06d64c8b",
    "title": "Graph Neural Networks for Minimum Independent Dominating Set Problem",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.23919/softcom66362.2025.11197433?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/softcom66362.2025.11197433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2386137832",
        "name": "Marko Kozlik"
      },
      {
        "authorId": "2105360520",
        "name": "Marko Kri\u00c5\u00beman\u00c4\u008di\u00c4\u0087"
      },
      {
        "authorId": "2295135874",
        "name": "Stjepan Bogdan"
      }
    ],
    "abstract": "In this paper, we present a novel method for determining the Minimum Independent Dominating Set (MIDS) based on Graph Neural Networks (GNNs). Finding MIDS is useful for multiple applications in various fields such as IoT, robotics, advertising, etc. Our approach focuses on finding the best possible parameters and GNN architecture for determining the MIDS on a labeled dataset. As the main contribution of this work, we propose a method for training the neural network that enables solving problems with multiple equivalent solutions. Additionally, we study the difference in performance between a dual model and a single large model for GNNs. Finally, we show that MIDS calculation with the utilization of GNNs significantly improves calculation time for larger graphs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "60a6b17f28e88f17e58f60923d98674358dbd0e4",
    "url": "https://www.semanticscholar.org/paper/60a6b17f28e88f17e58f60923d98674358dbd0e4",
    "title": "A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831453.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/access.2022.3191784?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/access.2022.3191784, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2151462695",
        "name": "Zi Ye"
      },
      {
        "authorId": "1734844",
        "name": "Y. J. Kumar"
      },
      {
        "authorId": "52260359",
        "name": "G. O. Sing"
      },
      {
        "authorId": "2175668485",
        "name": "Fengyan Song"
      },
      {
        "authorId": "2110181593",
        "name": "Junsong Wang"
      }
    ],
    "abstract": "The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "24cff2aafcd66e1b7be4f647e478e8e73cf410a5",
    "url": "https://www.semanticscholar.org/paper/24cff2aafcd66e1b7be4f647e478e8e73cf410a5",
    "title": "Spatial-Temporal Fusion Graph Neural Networks for Traffic Flow Forecasting",
    "year": 2020,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/16542/16349",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2012.09641, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "32561347",
        "name": "Mengzhang Li"
      },
      {
        "authorId": "1703952",
        "name": "Zhanxing Zhu"
      }
    ],
    "abstract": "Spatial-temporal data forecasting of traffic flow is a challenging task because of complicated spatial dependencies and dynamical trends of temporal pattern between different roads. Existing frameworks usually utilize given spatial adjacency graph and sophisticated mechanisms for modeling spatial and temporal correlations. However, limited representations of given spatial graph structure with incomplete adjacent connections may restrict effective spatial-temporal dependencies learning of those models. Furthermore, existing methods were out at elbows when solving complicated spatial-temporal data: they usually utilize separate modules for spatial and temporal correlations, or they only use independent components capturing localized or global heterogeneous dependencies. To overcome those limitations, our paper proposes a novel Spatial-Temporal Fusion Graph Neural Networks (STFGNN) for traffic flow forecasting. First, a data-driven method of generating \u00e2\u0080\u009ctemporal graph\u00e2\u0080\u009d is proposed to compensate several genuine correlations that spatial graph may not reflect. STFGNN could effectively learn hidden spatial-temporal dependencies by a novel fusion operation of various spatial and temporal graphs, treated for different time periods in parallel. Meanwhile, by integrating this fusion graph module and a novel gated convolution module into a unified layer parallelly, STFGNN could handle long sequences by learning more spatial-temporal dependencies with layers stacked. Experimental results on several public traffic datasets demonstrate that our method achieves state-of-the-art performance consistently than other baselines.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "203b2865e2c42a129631d3d4a78474b25d0236c6",
    "url": "https://www.semanticscholar.org/paper/203b2865e2c42a129631d3d4a78474b25d0236c6",
    "title": "Multi-scale rotation-equivariant graph neural networks for unsteady Eulerian fluid dynamics",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://aip.scitation.org/doi/pdf/10.1063/5.0097679",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1063/5.0097679?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1063/5.0097679, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2109420189",
        "name": "Mario Lino"
      },
      {
        "authorId": "123727301",
        "name": "Stathi Fotiadis"
      },
      {
        "authorId": "2815535",
        "name": "A. Bharath"
      },
      {
        "authorId": "12717675",
        "name": "C. Cantwell"
      }
    ],
    "abstract": "The simulation of fluid dynamics, typically by numerically solving partial differential equations, is an essential tool in many areas of science and engineering. However, the high computational cost can limit application in practice and may prohibit exploring large parameter spaces. Recent deep-learning approaches have demonstrated the potential to yield surrogate models for the simulation of fluid dynamics. While such models exhibit lower accuracy in comparison, their low runtime makes them appealing for design-space exploration. We introduce two novel graph neural network (GNN) models, multi-scale GNN (MuS-GNN) and rotation-equivariant multi-scale GNN (REMuS-GNN), for extrapolating the time evolution of fluid flow. In both models, previous states are processed through multiple coarsenings of the graph, which enables faster information propagation through the network and improves the capture and forecast of the system state, particularly in problems encompassing phenomena spanning a range of length scales. Additionally, REMuS-GNN is architecturally equivariant to rotations, which allows the network to learn the underlying physics more efficiently, leading to improved accuracy and generalisation. We analyse these models using two canonical fluid models: advection and incompressible fluid dynamics. Our results show that the proposed GNN models can generalise from uniform advection fields to high-gradient fields on complex domains. The multi-scale graph architecture allows for inference of incompressible Navier-Stokes solutions, within a range of Reynolds numbers and design parameters, more effectively than a baseline single-scale GNN. Simulations obtained with MuS-GNN and REMuS-GNN are between two and four orders of magnitude faster than the numerical solutions on which they were trained.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "aae1805c481055c0970a4606f0e56d69f0c1291f",
    "url": "https://www.semanticscholar.org/paper/aae1805c481055c0970a4606f0e56d69f0c1291f",
    "title": "AMGNET: multi-scale graph neural networks for flow field prediction",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://doi.org/10.1080/09540091.2022.2131737",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/09540091.2022.2131737?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/09540091.2022.2131737, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2362515997",
        "name": "Zhishuang Yang"
      },
      {
        "authorId": "51940820",
        "name": "Yidao Dong"
      },
      {
        "authorId": "2116834677",
        "name": "Xiaogang Deng"
      },
      {
        "authorId": "2109005600",
        "name": "Laiping Zhang"
      }
    ],
    "abstract": "Solving partial differential equations of complex physical systems is a computationally expensive task, especially in Computational Fluid Dynamics(CFD). This drives the application of deep learning methods in solving physical systems. There exist a few deep learning models that are very successful in predicting flow fields of complex physical models, yet most of these still exhibit large errors compared to simulation. Here we introduce AMGNET, a multi-scale graph neural network model based on Encoder-Process-Decoder structure for flow field prediction. Our model employs message passing of graph neural networks at different mesh graph scales. Our method has significantly lower prediction errors than the GCN baseline on several complex fluid prediction tasks, such as airfoil flow and cylinder flow. Our results show that multi-scale representation learning at the graph level is more effective in improving the prediction accuracy of flow field.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "0597fc25f914077556c30ce825420af96a3f4db0",
    "url": "https://www.semanticscholar.org/paper/0597fc25f914077556c30ce825420af96a3f4db0",
    "title": "Active and Semi-Supervised Graph Neural Networks for Graph Classification",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/tbdata.2021.3140205?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/tbdata.2021.3140205, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2118596737",
        "name": "Yujia Xie"
      },
      {
        "authorId": "1742505472",
        "name": "Shengze Lv"
      },
      {
        "authorId": "1771193",
        "name": "Y. Qian"
      },
      {
        "authorId": "2150350656",
        "name": "Chao Wen"
      },
      {
        "authorId": "3300112",
        "name": "Jiye Liang"
      }
    ],
    "abstract": "Graph classification aims to predict the class labels of graphs and has a wide range of applications in many real-world domains. However, most of existing graph neural networks for graph classification tasks use 90<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math><alternatives><mml:math><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href=\"qian-ieq1-3140205.gif\"/></alternatives></inline-formula> of labeled graphs for training and the remaining 10<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math><alternatives><mml:math><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href=\"qian-ieq2-3140205.gif\"/></alternatives></inline-formula> for testing, which obviously struggle in solving the problem of the scarcity of labeled graphs in real-world graph classification scenarios. And it is arduous to label a large number of graph examples for training because of the difficulty and resource consumption in the tagging process. Motivated by this, we propose a novel active and semi-supervised graph neural network (ASGNN) framework, which endeavors to complete graph classification tasks with a small number of labeled graph examples and available unlabeled graph examples. In our framework, active learning selects high-uncertain and representative graph examples from the test set and add them to the training set after annotation. Semi-supervised learning is utilized to select the high-confidence unlabeled graph examples containing structural information from the test set, and add them to the training set after pseudo labeling. To improve the generalization performance of the graph classification model, multiple GNNs are trained collaboratively for promoting the expressiveness of each other and increasing the reliability of graph classification results. Overall, the ASGNN framework takes fully use of unlabeled graph examples to reinforce graph classification effectively, and can be applied to any existing supervised graph neural networks for graph classification. Experimental results on benchmark graph datasets demonstrate that the proposed framework yields competitive performance on graph classification tasks with only a small number of labeled graph examples.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "48f1ccdb33119a0a17c91149a598b28064b01feb",
    "url": "https://www.semanticscholar.org/paper/48f1ccdb33119a0a17c91149a598b28064b01feb",
    "title": "Multigrid-Inspired Graph Neural Networks for Selection of Solvers and Preconditioners in Sparse Linear Systems",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN64981.2025.11228469?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN64981.2025.11228469, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2392721186",
        "name": "Xingyu Zhou"
      },
      {
        "authorId": "2362924410",
        "name": "Shuzi Niu"
      },
      {
        "authorId": "2391998695",
        "name": "Huiyuan Li"
      },
      {
        "authorId": "2362924866",
        "name": "Tao Yuan"
      },
      {
        "authorId": "2363186414",
        "name": "Ziwei Li"
      }
    ],
    "abstract": "Solving sparse linear systems is a fundamental task in science and engineering computing. Multiple iterative solvers have been developed to iteratively refining an initial guess to con-verge to the solution, with preconditioning techniques for better convergence. However, it\u00e2\u0080\u0099s challenging to select a quasi-optimal solver and preconditioner without background knowledge and domain expertise to reduce time and space cost. Meanwhile, a suboptimal selection may incur exponential computational overhead and even solution divergence. We designed a graph neural network model to help select optimal solver and preconditioner for sparse linear systems, where a multigrid-inspired GNN structure was introduced to synergistically aggregate local matrix patterns and global spectral features through hierarchical structure. Experimental results on benchmark sparse matrix collection show that our model outperforms state-of-the-art baseline selectors.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6c752a067bb7bc68c3b0dbb8144737592137d35a",
    "url": "https://www.semanticscholar.org/paper/6c752a067bb7bc68c3b0dbb8144737592137d35a",
    "title": "Topology-Aware Graph Neural Networks for Learning Feasible and Adaptive AC-OPF Solutions",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2205.10129",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2205.10129, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2119052218",
        "name": "Shaohui Liu"
      },
      {
        "authorId": "4114071",
        "name": "Chengyang Wu"
      },
      {
        "authorId": "145153303",
        "name": "Hao Zhu"
      }
    ],
    "abstract": "Solving the optimal power flow (OPF) problem is a fundamental task to ensure the system efficiency and reliability in real-time electricity grid operations. We develop a new topology-informed graph neural network (GNN) approach for predicting the optimal solutions of real-time ac-OPF problem. To incorporate grid topology to the NN model, the proposed GNN-for-OPF framework innovatively exploits the locality property of locational marginal prices and voltage magnitude. Furthermore, we develop a physics-aware (ac-)flow feasibility regularization approach for general OPF learning. The advantages of our proposed designs include reduced model complexity, improved generalizability and feasibility guarantees. By providing the analytical understanding on the graph subspace stability under grid topology contingency, we show the proposed GNN can quickly adapt to varying grid topology by an efficient re-training strategy. Numerical tests on various test systems of different sizes have validated the prediction accuracy, improved flow feasibility, and topology adaptivity capability of our proposed GNN-based learning framework.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6e12c2a97aac2930aa2c7990402946b57ec543da",
    "url": "https://www.semanticscholar.org/paper/6e12c2a97aac2930aa2c7990402946b57ec543da",
    "title": "Frequency Domain-Oriented Complex Graph Neural Networks for Graph Classification",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2024.3351762?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2024.3351762, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1614035793",
        "name": "Youfa Liu"
      },
      {
        "authorId": "2064619450",
        "name": "Bo Du"
      }
    ],
    "abstract": "Graph neural networks (GNNs) could directly deal with the data of graph structure. Current GNNs are confined to the spatial domain and learn real low-dimensional embeddings in graph classification tasks. In this article, we explore frequency domain-oriented complex GNNs in which the node\u00e2\u0080\u0099s embedding in each layer is a complex vector. The difficulty lies in the design of graph pooling and we propose a mirror-connected design with two crucial problems: parameter reduction problem and complex gradient backpropagation problem. To deal with the former problem, we propose the notion of squared singular value pooling (SSVP) and prove that the representation power of SSVP followed by a fully connected layer with nonnegative weights is exactly equivalent to that of a mirror-connected layer. To resolve the latter problem, we provide an alternative feasible method to solve singular values of complex embeddings with a theoretical guarantee. Finally, we propose a mixture of pooling strategies in which first-order statistics information is employed to enrich the last low-dimensional representation. Experiments on benchmarks demonstrate the effectiveness of the complex GNNs with mirror-connected layers.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "5c4bb681fe5cb159b0d577b784fa52c952871e17",
    "url": "https://www.semanticscholar.org/paper/5c4bb681fe5cb159b0d577b784fa52c952871e17",
    "title": "On EDA-Driven Learning for SAT Solving",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2205.13745, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2157145787",
        "name": "Min Li"
      },
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "30469750",
        "name": "Qiuxia Lai"
      },
      {
        "authorId": "2155828355",
        "name": "Sadaf Khan"
      },
      {
        "authorId": "2241614334",
        "name": "Shaowei Cai"
      },
      {
        "authorId": "2149106517",
        "name": "Qiang Xu"
      }
    ],
    "abstract": "We present DeepSAT, a novel end-to-end learning framework for the Boolean satisfiability (SAT) problem. Unlike existing solutions trained on random SAT instances with relatively weak supervision, we propose applying the knowledge of the well-developed electronic design automation (EDA) field for SAT solving. Specifically, we first resort to logic synthesis algorithms to pre-process SAT instances into optimized and-inverter graphs (AIGs). By doing so, the distribution diversity among various SAT instances can be dramatically reduced, which facilitates improving the generalization capability of the learned model. Next, we regard the distribution of SAT solutions being a product of conditional Bernoulli distributions. Based on this observation, we approximate the SAT solving procedure with a conditional generative model, leveraging a novel directed acyclic graph neural network (DAGNN) with two polarity prototypes for conditional SAT modeling. To effectively train the generative model, with the help of logic simulation tools, we obtain the probabilities of nodes in the AIG being logic \u00e2\u0080\u00981\u00e2\u0080\u0099 as rich supervision. We conduct comprehensive experiments on various SAT problems. Our results show that, DeepSAT achieves significant accuracy improvements over state-of-the-art learning-based SAT solutions, especially when generalized to SAT instances that are relatively large or with diverse distributions.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "1c764c3f3c1222f61bd6625bfc68fc0a1859a4d7",
    "url": "https://www.semanticscholar.org/paper/1c764c3f3c1222f61bd6625bfc68fc0a1859a4d7",
    "title": "Rethinking the Capacity of Graph Neural Networks for Branching Strategy",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2402.07099, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2283850392",
        "name": "Ziang Chen"
      },
      {
        "authorId": "2108415378",
        "name": "Jialin Liu"
      },
      {
        "authorId": "2261359342",
        "name": "Xiaohan Chen"
      },
      {
        "authorId": "2261241838",
        "name": "Xinshang Wang"
      },
      {
        "authorId": "2261082763",
        "name": "Wotao Yin"
      }
    ],
    "abstract": "Graph neural networks (GNNs) have been widely used to predict properties and heuristics of mixed-integer linear programs (MILPs) and hence accelerate MILP solvers. This paper investigates the capacity of GNNs to represent strong branching (SB), the most effective yet computationally expensive heuristic employed in the branch-and-bound algorithm. In the literature, message-passing GNN (MP-GNN), as the simplest GNN structure, is frequently used as a fast approximation of SB and we find that not all MILPs's SB can be represented with MP-GNN. We precisely define a class of\"MP-tractable\"MILPs for which MP-GNNs can accurately approximate SB scores. Particularly, we establish a universal approximation theorem: for any data distribution over the MP-tractable class, there always exists an MP-GNN that can approximate the SB score with arbitrarily high accuracy and arbitrarily high probability, which lays a theoretical foundation of the existing works on imitating SB with MP-GNN. For MILPs without the MP-tractability, unfortunately, a similar result is impossible, which can be illustrated by two MILP instances with different SB scores that cannot be distinguished by any MP-GNN, regardless of the number of parameters. Recognizing this, we explore another GNN structure called the second-order folklore GNN (2-FGNN) that overcomes this limitation, and the aforementioned universal approximation theorem can be extended to the entire MILP space using 2-FGNN, regardless of the MP-tractability. A small-scale numerical experiment is conducted to directly validate our theoretical findings.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f30d4f1a2cbeb4bec90ad53ca2585963c2b95f11",
    "url": "https://www.semanticscholar.org/paper/f30d4f1a2cbeb4bec90ad53ca2585963c2b95f11",
    "title": "On the Power of Small-size Graph Neural Networks for Linear Programming",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.52202/079017-1222?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52202/079017-1222, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2322829874",
        "name": "Qian Li"
      },
      {
        "authorId": "2287824247",
        "name": "Tian Ding"
      },
      {
        "authorId": "2305470082",
        "name": "Linxin Yang"
      },
      {
        "authorId": "2322505890",
        "name": "Minghui Ouyang"
      },
      {
        "authorId": "2345442112",
        "name": "Qingjiang Shi"
      },
      {
        "authorId": "2324219295",
        "name": "Ruoyu Sun"
      }
    ],
    "abstract": "Graph neural networks (GNNs) have recently emerged as powerful tools for addressing complex optimization problems. It has been theoretically demonstrated that GNNs can universally approximate the solution mapping functions of linear programming (LP) problems. However, these theoretical results typically require GNNs to have large parameter sizes. Conversely, empirical experiments have shown that relatively small GNNs can solve LPs effectively, revealing a significant discrepancy between theoretical predictions and practical observations. In this work, we aim to bridge this gap by providing a theoretical foundation for the effectiveness of smaller GNNs. We prove that polylogarithmic-depth, constant-width GNNs are sufficient to solve packing and covering LPs, two widely used classes of LPs. Our proof leverages the capability of GNNs to simulate a variant of the gradient descent algorithm on a carefully selected potential function. Additionally, we introduce a new GNN architecture, termed GD-Net. Experimental results demonstrate that GD-Net significantly outperforms conventional GNN structures while using fewer parameters.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d09608593caa20b79a8aaddfe19df7e31513d711",
    "url": "https://www.semanticscholar.org/paper/d09608593caa20b79a8aaddfe19df7e31513d711",
    "title": "Graph Neural Networks in IoT: A Survey",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2203.15935",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2203.15935, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2059262418",
        "name": "Guimin Dong"
      },
      {
        "authorId": "2113728300",
        "name": "Mingyue Tang"
      },
      {
        "authorId": "2118363186",
        "name": "Zhiyuan Wang"
      },
      {
        "authorId": "1505808706",
        "name": "Jiechao Gao"
      },
      {
        "authorId": "2027663689",
        "name": "Sikun Guo"
      },
      {
        "authorId": "2310504",
        "name": "Lihua Cai"
      },
      {
        "authorId": "2160711603",
        "name": "Robert Gutierrez"
      },
      {
        "authorId": "2064476887",
        "name": "Brad Campbell"
      },
      {
        "authorId": "1771388",
        "name": "Laura E. Barnes"
      },
      {
        "authorId": "145380539",
        "name": "M. Boukhechba"
      }
    ],
    "abstract": "The Internet of Things (IoT) boom has revolutionized almost every corner of people\u00e2\u0080\u0099s daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source codes from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at GNN4IoT.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "64924e048dc6f82fb2ce4156eca5bc482a813e66",
    "url": "https://www.semanticscholar.org/paper/64924e048dc6f82fb2ce4156eca5bc482a813e66",
    "title": "Scalable and Consistent Graph Neural Networks for Distributed Mesh-based Data-driven Modeling",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2410.01657, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "89675914",
        "name": "Shivam Barwey"
      },
      {
        "authorId": "2320806643",
        "name": "Riccardo Balin"
      },
      {
        "authorId": "1477973152",
        "name": "Bethany Lusch"
      },
      {
        "authorId": "2320827904",
        "name": "Saumil Patel"
      },
      {
        "authorId": "2320804950",
        "name": "Ramesh Balakrishnan"
      },
      {
        "authorId": "2290017845",
        "name": "Pinaki Pal"
      },
      {
        "authorId": "20693875",
        "name": "R. Maulik"
      },
      {
        "authorId": "2267938602",
        "name": "Venkat Vishwanath"
      }
    ],
    "abstract": "This work develops a distributed graph neural network (GNN) methodology for mesh-based modeling applications using a consistent neural message passing layer. As the name implies, the focus is on enabling scalable operations that satisfy physical consistency via halo nodes at sub-graph boundaries. Here, consistency refers to the fact that a GNN trained and evaluated on one rank (one large graph) is arithmetically equivalent to evaluations on multiple ranks (a partitioned graph). This concept is demonstrated by interfacing GNNs with NekRS, a GPU-capable exascale CFD solver developed at Argonne National Laboratory. It is shown how the NekRS mesh partitioning can be linked to the distributed GNN training and inference routines, resulting in a scalable mesh-based data-driven modeling workflow. We study the impact of consistency on the scalability of mesh-based GNNs, demonstrating efficient scaling in consistent GNNs for up to O(1B) graph nodes on the Frontier exascale supercomputer.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "9cc1cec414aa9e904207146cb466531323b0b5be",
    "url": "https://www.semanticscholar.org/paper/9cc1cec414aa9e904207146cb466531323b0b5be",
    "title": "Solving the SAT problem using spiking neural P systems with coloured spikes and division rules",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s41965-024-00153-0.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s41965-024-00153-0?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s41965-024-00153-0, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2293615488",
        "name": "Prithwineel Paul"
      },
      {
        "authorId": "2303030416",
        "name": "Petr Sos\u00c3\u00adk"
      }
    ],
    "abstract": "Spiking neural P systems (SNPS) are variants of the third-generation neural networks. In the last few decades, different variants of SNPS models have been introduced. In most of the SNPS models, spikes are represented using an alphabet with just one letter. In this paper, we use a deterministic SNPS model with coloured spikes (i.e. the alphabet representing spikes contains multiple letters), together with neuron division rules to demonstrate an efficient solution to the SAT problem. As a result, we provide a simpler construction with significantly less class resources to solve the SAT problem in comparison to previously reported results using SNPSs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "37f83dc2712fdf14546ae0c313b764434b362eef",
    "url": "https://www.semanticscholar.org/paper/37f83dc2712fdf14546ae0c313b764434b362eef",
    "title": "Solving Cold Start Problem in Recommendation with Attribute Graph Neural Networks",
    "year": 2019,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1912.12398, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34559283",
        "name": "T. Qian"
      },
      {
        "authorId": "2119122936",
        "name": "Yile Liang"
      },
      {
        "authorId": "2117897280",
        "name": "Qing Li"
      }
    ],
    "abstract": "Matrix completion is a classic problem underlying recommender systems. It is traditionally tackled with matrix factorization. Recently, deep learning based methods, especially graph neural networks, have made impressive progress on this problem. Despite their effectiveness, existing methods focus on modeling the user-item interaction graph. The inherent drawback of such methods is that their performance is bound to the density of the interactions, which is however usually of high sparsity. More importantly, for a cold start user/item that does not have any interactions, such methods are unable to learn the preference embedding of the user/item since there is no link to this user/item in the graph. In this work, we develop a novel framework Attribute Graph Neural Networks (AGNN) by exploiting the attribute graph rather than the commonly used interaction graph. This leads to the capability of learning embeddings for cold start users/items. Our AGNN can produce the preference embedding for a cold user/item by learning on the distribution of attributes with an extended variational auto-encoder structure. Moreover, we propose a new graph neural network variant, i.e., gated-GNN, to effectively aggregate various attributes of different modalities in a neighborhood. Empirical results on two real-world datasets demonstrate that our model yields significant improvements for cold start recommendations and outperforms or matches state-of-the-arts performance in the warm start scenario.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "901b764318aa8cc887d511f0f04666fed87ccfd6",
    "url": "https://www.semanticscholar.org/paper/901b764318aa8cc887d511f0f04666fed87ccfd6",
    "title": "Graph Neural Networks are Dynamic Programmers",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2203.15544",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2203.15544, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145585375",
        "name": "A. Dudzik"
      },
      {
        "authorId": "3444569",
        "name": "Petar Velickovic"
      }
    ],
    "abstract": "Recent advances in neural algorithmic reasoning with graph neural networks (GNNs) are propped up by the notion of algorithmic alignment. Broadly, a neural network will be better at learning to execute a reasoning task (in terms of sample complexity) if its individual components align well with the target algorithm. Specifically, GNNs are claimed to align with dynamic programming (DP), a general problem-solving strategy which expresses many polynomial-time algorithms. However, has this alignment truly been demonstrated and theoretically quantified? Here we show, using methods from category theory and abstract algebra, that there exists an intricate connection between GNNs and DP, going well beyond the initial observations over individual algorithms such as Bellman-Ford. Exposing this connection, we easily verify several prior findings in the literature, produce better-grounded GNN architectures for edge-centric tasks, and demonstrate empirical results on the CLRS algorithmic reasoning benchmark. We hope our exposition will serve as a foundation for building stronger algorithmically aligned GNNs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "fabacde74bd62b59eb6cad22efaf834b0ab32e90",
    "url": "https://www.semanticscholar.org/paper/fabacde74bd62b59eb6cad22efaf834b0ab32e90",
    "title": "Graph Neural Networks for Propositional Model Counting",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2205.04423",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2205.04423, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2164383753",
        "name": "Gaia Saveri"
      },
      {
        "authorId": "1774460",
        "name": "L. Bortolussi"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have been recently leveraged to solve several logical reasoning tasks. Nevertheless, counting problems such as propositional model counting (#SAT) are still mostly approached with traditional solvers. Here we tackle this gap by presenting an architecture based on the GNN framework for belief propagation (BP) of Kuch et al., extended with self-attentive GNN and trained to approximately solve the #SAT problem. We ran a thorough experimental investigation, showing that our model, trained on a small set of random Boolean formulae, is able to scale effectively to much larger problem sizes, with comparable or better performances of state of the art approximate solvers. Moreover, we show that it can be efficiently fine-tuned to provide good generalization results on different formulae distributions, such as those coming from SAT-encoded combinatorial problems.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "a2e88ff6bc48ac8f4779ccb77debfee25c954b6f",
    "url": "https://www.semanticscholar.org/paper/a2e88ff6bc48ac8f4779ccb77debfee25c954b6f",
    "title": "Graph Neural Networks for Selection of Preconditioners and Krylov Solvers \u00e2\u0088\u0097",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2392385229",
        "name": "Ziyuan Tang"
      },
      {
        "authorId": "46701734",
        "name": "Hong Zhang"
      },
      {
        "authorId": "2286258850",
        "name": "Jie Chen"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "8899cfd64179c21845a1cc3476962569a0e70bf6",
    "url": "https://www.semanticscholar.org/paper/8899cfd64179c21845a1cc3476962569a0e70bf6",
    "title": "Multiclass Graph-Based Large Margin Classifiers: Unified Approach for Support Vectors and Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2024.3420227?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2024.3420227, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1580628306",
        "name": "V. M. Hanriot"
      },
      {
        "authorId": "2211375",
        "name": "L. Torres"
      },
      {
        "authorId": "2314088709",
        "name": "A. P. Braga"
      }
    ],
    "abstract": "While large margin classifiers are originally an outcome of an optimization framework, support vectors (SVs) can be obtained from geometric approaches. This article presents advances in the use of Gabriel graphs (GGs) in binary and multiclass classification problems. For Chipclass, a hyperparameterless and optimization-less GG-based binary classifier, we discuss how activation functions and support edge (SE)-centered neurons affect the classification, proposing smoother functions and structural SV (SSV)-centered neurons to achieve margins with low probabilities and smoother classification contours. We extend the neural network architecture, which can be trained with backpropagation with a softmax function and a cross-entropy loss, or by solving a system of linear equations. A new subgraph-/distance-based membership function for graph regularization is also proposed, along with a new GG recomputation algorithm that is less computationally expensive than the standard approach. Experimental results with the Friedman test show that our method was better than previous GG-based classifiers and statistically equivalent to tree-based models.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "cf5eb6ce6109bff5037bc5c5f20bbe65497c3ee6",
    "url": "https://www.semanticscholar.org/paper/cf5eb6ce6109bff5037bc5c5f20bbe65497c3ee6",
    "title": "Solving Interactive Video Object Segmentation with Label-Propagating Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN60899.2024.10650871?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN60899.2024.10650871, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2320593013",
        "name": "Viktor Varga"
      },
      {
        "authorId": "2320595936",
        "name": "Mil\u00c3\u00a1n Sz\u00c3\u00a1sz"
      }
    ],
    "abstract": "Interactive Video Object Segmentation (IVOS) addresses the problem of pixel-wise video annotation in collaboration with a human supervisor. Deep convolutional network-based approaches are a popular choice for solving IVOS problems. However, their performance is limited unless millions of parameters and huge datasets are used in their training. In this paper, we investigate an alternative solution, that interprets the core of the IVOS problem as a graph-based semi-supervised learning task and solves it with a label-propagating graph neural network architecture. The training of our method is sample efficient and outperforms all other methods with a similar property on the DAVIS dataset. We release the source code and the trained models.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "bdb8976aa73ff51b395061494d20658c0dd35ee4",
    "url": "https://www.semanticscholar.org/paper/bdb8976aa73ff51b395061494d20658c0dd35ee4",
    "title": "SATformer: Transformers for SAT Solving",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2209.00953",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.48550/arXiv.2209.00953?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48550/arXiv.2209.00953, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "2157145787",
        "name": "Min Li"
      },
      {
        "authorId": "2155828355",
        "name": "Sadaf Khan"
      },
      {
        "authorId": "46465266",
        "name": "Hui-Ling Zhen"
      },
      {
        "authorId": "2075357674",
        "name": "M. Yuan"
      },
      {
        "authorId": "2269061925",
        "name": "Qiang Xu"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "e0fe6efa4e0046f6b03d83e5bad4516277c22cee",
    "url": "https://www.semanticscholar.org/paper/e0fe6efa4e0046f6b03d83e5bad4516277c22cee",
    "title": "On Representing Linear Programs by Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2209.12288",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2209.12288, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2117097761",
        "name": "Ziang Chen"
      },
      {
        "authorId": "1685638",
        "name": "Jialin Liu"
      },
      {
        "authorId": "4191997",
        "name": "Xinshang Wang"
      },
      {
        "authorId": "2152962102",
        "name": "Jian Lu"
      },
      {
        "authorId": "6833606",
        "name": "W. Yin"
      }
    ],
    "abstract": "Learning to optimize is a rapidly growing area that aims to solve optimization problems or improve existing optimization algorithms using machine learning (ML). In particular, the graph neural network (GNN) is considered a suitable ML model for optimization problems whose variables and constraints are permutation--invariant, for example, the linear program (LP). While the literature has reported encouraging numerical results, this paper establishes the theoretical foundation of applying GNNs to solving LPs. Given any size limit of LPs, we construct a GNN that maps different LPs to different outputs. We show that properly built GNNs can reliably predict feasibility, boundedness, and an optimal solution for each LP in a broad class. Our proofs are based upon the recently--discovered connections between the Weisfeiler--Lehman isomorphism test and the GNN. To validate our results, we train a simple GNN and present its accuracy in mapping LPs to their feasibilities and solutions.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "04c63f754bc8a20f603e5784f89b945e71aa72a5",
    "url": "https://www.semanticscholar.org/paper/04c63f754bc8a20f603e5784f89b945e71aa72a5",
    "title": "Learning to Compare Nodes in Branch and Bound with Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2210.16934",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2210.16934, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2189373786",
        "name": "Abdel Ghani Labassi"
      },
      {
        "authorId": "2066421682",
        "name": "Didier Ch'etelat"
      },
      {
        "authorId": "144390922",
        "name": "Andrea Lodi"
      }
    ],
    "abstract": "Branch-and-bound approaches in integer programming require ordering portions of the space to explore next, a problem known as node comparison. We propose a new siamese graph neural network model to tackle this problem, where the nodes are represented as bipartite graphs with attributes. Similar to prior work, we train our model to imitate a diving oracle that plunges towards the optimal solution. We evaluate our method by solving the instances in a plain framework where the nodes are explored according to their rank. On three NP-hard benchmarks chosen to be particularly primal-difficult, our approach leads to faster solving and smaller branch- and-bound trees than the default ranking function of the open-source solver SCIP, as well as competing machine learning methods. Moreover, these results generalize to instances larger than used for training. Code for reproducing the experiments can be found at https://github.com/ds4dm/learn2comparenodes.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "0b48ff078abf9f38440952a6719b8748090e1604",
    "url": "https://www.semanticscholar.org/paper/0b48ff078abf9f38440952a6719b8748090e1604",
    "title": "One Model, Any CSP: Graph Neural Networks as Fast Global Search Heuristics for Constraint Satisfaction",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2208.10227",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2208.10227, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2182291897",
        "name": "Jan Tonshoff"
      },
      {
        "authorId": "2182292815",
        "name": "Berke Kisin"
      },
      {
        "authorId": "2182292675",
        "name": "Jakob Lindner"
      },
      {
        "authorId": "1744396",
        "name": "Martin Grohe"
      }
    ],
    "abstract": "We propose a universal Graph Neural Network architecture which can be trained as an end-2-end search heuristic for any Constraint Satisfaction Problem (CSP). Our architecture can be trained unsupervised with policy gradient descent to generate problem specific heuristics for any CSP in a purely data driven manner.\n\nThe approach is based on a novel graph representation for CSPs that is both generic and compact and enables us to process every possible CSP instance with one GNN, regardless of constraint arity, relations or domain size. Unlike previous RL-based methods, we operate on a global search action space and allow our GNN to modify any number of variables in every step of the stochastic search. This enables our method to properly leverage the inherent parallelism of GNNs.\n\nWe perform a thorough empirical evaluation where we learn heuristics for well known and important CSPs, both decision and optimisation problems, from random data, including graph coloring, MAXCUT, and MAX-k-SAT, and the general RB model. Our approach significantly outperforms prior end-2-end approaches for neural combinatorial optimization. It can compete with conventional heuristics and solvers on test instances that are several orders of magnitude larger and structurally more complex than those seen during training.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "7d08a37ce265f0ca43c72142f8580b0dd664fc79",
    "url": "https://www.semanticscholar.org/paper/7d08a37ce265f0ca43c72142f8580b0dd664fc79",
    "title": "A review of graph neural network applications in mechanics-related domains",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://doi.org/10.1007/s10462-024-10931-y",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2407.11060, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2265490349",
        "name": "Ying Zhao"
      },
      {
        "authorId": "2311684956",
        "name": "Haoran Li"
      },
      {
        "authorId": "2259257934",
        "name": "Haosu Zhou"
      },
      {
        "authorId": "98690207",
        "name": "H. Attar"
      },
      {
        "authorId": "2311504098",
        "name": "Tobias Pfaff"
      },
      {
        "authorId": "2311690584",
        "name": "Nan Li"
      }
    ],
    "abstract": "Mechanics-related tasks often present unique challenges in achieving accurate geometric and physical representations, particularly for non-uniform structures. Graph neural networks (GNNs) have emerged as a promising tool to tackle these challenges by adeptly learning from graph data with irregular underlying structures. Consequently, recent years have witnessed a surge in complex mechanics-related applications inspired by the advancements of GNNs. Despite this process, there is a notable absence of a systematic review addressing the recent advancement of GNNs in solving mechanics-related tasks. To bridge this gap, this review article aims to provide an in-depth overview of the GNN applications in mechanics-related domains while identifying key challenges and outlining potential future research directions. In this review article, we begin by introducing the fundamental algorithms of GNNs that are widely employed in mechanics-related applications. We provide a concise explanation of their underlying principles to establish a solid understanding that will serve as a basis for exploring the applications of GNNs in mechanics-related domains. The scope of this paper is intended to cover the categorisation of literature into solid mechanics, fluid mechanics, and interdisciplinary mechanics-related domains, providing a comprehensive summary of graph representation methodologies, GNN architectures, and further discussions in their respective subdomains. Additionally, open data and source codes relevant to these applications are summarised for the convenience of future researchers. This article promotes an interdisciplinary integration of GNNs and mechanics and provides a guide for researchers interested in applying GNNs to solve complex mechanics-related tasks.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "ec568050b74edfdb7e463200daf42ba36663505c",
    "url": "https://www.semanticscholar.org/paper/ec568050b74edfdb7e463200daf42ba36663505c",
    "title": "Interpreting Unfairness in Graph Neural Networks via Training Node Attribution",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2211.14383",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.14383, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "123918726",
        "name": "Yushun Dong"
      },
      {
        "authorId": "2117075272",
        "name": "Song Wang"
      },
      {
        "authorId": "2157405959",
        "name": "Jing Ma"
      },
      {
        "authorId": "47717322",
        "name": "Ninghao Liu"
      },
      {
        "authorId": "1737121128",
        "name": "Jundong Li"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as the leading paradigm for solving graph analytical problems in various real-world applications. Nevertheless, GNNs could potentially render biased predictions towards certain demographic subgroups. Understanding how the bias in predictions arises is critical, as it guides the design of GNN debiasing mechanisms. However, most existing works overwhelmingly focus on GNN debiasing, but fall short on explaining how such bias is induced. In this paper, we study a novel problem of interpreting GNN unfairness through attributing it to the influence of training nodes. Specifically, we propose a novel strategy named Probabilistic Distribution Disparity (PDD) to measure the bias exhibited in GNNs, and develop an algorithm to efficiently estimate the influence of each training node on such bias. We verify the validity of PDD and the effectiveness of influence estimation through experiments on real-world datasets. Finally, we also demonstrate how the proposed framework could be used for debiasing GNNs. Open-source code can be found at https://github.com/yushundong/BIND.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d21cd51e91340e6a32dda179a878107e5c51c616",
    "url": "https://www.semanticscholar.org/paper/d21cd51e91340e6a32dda179a878107e5c51c616",
    "title": "SCARA: Scalable Graph Neural Networks with Feature-Oriented Optimization",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2207.09179",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2207.09179, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1940000983",
        "name": "Ningyi Liao"
      },
      {
        "authorId": "2135922552",
        "name": "Dingheng Mo"
      },
      {
        "authorId": "3270262",
        "name": "Siqiang Luo"
      },
      {
        "authorId": null,
        "name": "Xiang Li"
      },
      {
        "authorId": "38253388",
        "name": "Pengcheng Yin"
      }
    ],
    "abstract": "Recent advances in data processing have stimulated the demand for learning graphs of very large scales. Graph Neural Networks (GNNs), being an emerging and powerful approach in solving graph learning tasks, are known to be difficult to scale up. Most scalable models apply node-based techniques in simplifying the expensive graph message-passing propagation procedure of GNN. However, we find such acceleration insufficient when applied to million- or even billion-scale graphs. In this work, we propose SCARA, a scalable GNN with feature-oriented optimization for graph computation. SCARA efficiently computes graph embedding from node features, and further selects and reuses feature computation results to reduce overhead. Theoretical analysis indicates that our model achieves sub-linear time complexity with a guaranteed precision in propagation process as well as GNN training and inference. We conduct extensive experiments on various datasets to evaluate the efficacy and efficiency of SCARA. Performance comparison with baselines shows that SCARA can reach up to 100x graph propagation acceleration than current state-of-the-art methods with fast convergence and comparable accuracy. Most notably, it is efficient to process precomputation on the largest available billion-scale GNN dataset Papers100M (111M nodes, 1.6B edges) in 100 seconds.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "680f454be60d79126c54eb2216bd1a1392249e79",
    "url": "https://www.semanticscholar.org/paper/680f454be60d79126c54eb2216bd1a1392249e79",
    "title": "Graph Neural Networks: A Powerful and Versatile Tool for Advancing Design, Reliability, and Security of ICs",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://doi.org/10.1145/3566097.3568345",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.16495, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35628050",
        "name": "Lilas Alrahis"
      },
      {
        "authorId": "1978598",
        "name": "J. Knechtel"
      },
      {
        "authorId": "48010993",
        "name": "O. Sinanoglu"
      }
    ],
    "abstract": "Graph neural networks (GNNs) have pushed the state-of-the-art (SOTA) for performance in learning and predicting on large-scale data present in social networks, biology, etc. Since integrated circuits (ICs) can naturally be represented as graphs, there has been a tremendous surge in employing GNNs for machine learning (ML)-based methods for various aspects of IC design. Given this trajectory, there is a timely need to review and discuss some powerful and versatile GNN approaches for advancing IC design. In this paper, we propose a generic pipeline for tailoring GNN models toward solving challenging problems for IC design. We out-line promising options for each pipeline element, and we discuss selected and promising works, like leveraging GNNs to break SOTA logic obfuscation. Our comprehensive overview of GNNs frame-works covers (i) electronic design automation (EDA) and IC design in general, (ii) design of reliable ICs, and (iii) design as well as analysis of secure ICs. We provide our overview and related resources also in the GNN4IC hub at https://github.com/DfX-NYUAD/GNN4IC. Finally, we discuss interesting open problems for future research.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "b21a3862b5655cc2758f1648040b0213cf2045e4",
    "url": "https://www.semanticscholar.org/paper/b21a3862b5655cc2758f1648040b0213cf2045e4",
    "title": "Enhanced neighborhood node graph neural networks for load forecasting in smart grid",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s13042-023-01796-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s13042-023-01796-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2150061390",
        "name": "Yanmei Jiang"
      },
      {
        "authorId": "2278445947",
        "name": "Mingsheng Liu"
      },
      {
        "authorId": "2278402130",
        "name": "Yangyang Li"
      },
      {
        "authorId": "2278386633",
        "name": "Yaping Liu"
      },
      {
        "authorId": "2296662254",
        "name": "Jingyun Zhang"
      },
      {
        "authorId": "2278399028",
        "name": "Yifeng Liu"
      },
      {
        "authorId": "2278657511",
        "name": "Chunyang Liu"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f22153dd741d0e2e32b381ed56e5d81ed1131185",
    "url": "https://www.semanticscholar.org/paper/f22153dd741d0e2e32b381ed56e5d81ed1131185",
    "title": "Unifying Homophily and Heterophily for Spectral Graph Neural Networks via Triple Filter Ensembles",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.52202/079017-2966?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.52202/079017-2966, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2238857842",
        "name": "Rui Duan"
      },
      {
        "authorId": "2111420408",
        "name": "Mingjian Guang"
      },
      {
        "authorId": "2135841686",
        "name": "Junli Wang"
      },
      {
        "authorId": "2150515988",
        "name": "Chungang Yan"
      },
      {
        "authorId": "51461354",
        "name": "Hongda Qi"
      },
      {
        "authorId": "2346815880",
        "name": "Wenkang Su"
      },
      {
        "authorId": "2345359697",
        "name": "Can Tian"
      },
      {
        "authorId": "2257353147",
        "name": "Haoran Yang"
      }
    ],
    "abstract": "Polynomial-based learnable spectral graph neural networks (GNNs) utilize polynomial to approximate graph convolutions and have achieved impressive performance on graphs. Nevertheless, there are three progressive problems to be solved. Some models use polynomials with better approximation for approximating filters, yet perform worse on real-world graphs. Carefully crafted graph learning methods, sophisticated polynomial approximations, and refined coefficient constraints leaded to overfitting, which diminishes the generalization of the models. How to design a model that retains the ability of polynomial-based spectral GNNs to approximate filters while it possesses higher generalization and performance? In this paper, we propose a spectral GNN with t riple f ilter e nsemble (TFE-GNN), which extracts ho-mophily and heterophily from graphs with different levels of homophily adaptively while utilizing the initial features. Specifically, the first and second ensembles are combinations of a set of base low-pass and high-pass filters, respectively, after which the third ensemble combines them with two learnable coefficients and yield a graph convolution (TFE-Conv). Theoretical analysis shows that the approximation ability of TFE-GNN is consistent with that of ChebNet under certain conditions, namely it can learn arbitrary filters. TFE-GNN can be viewed as a reasonable combination of two unfolded and integrated excellent spectral GNNs, which motivates it to perform well. Experiments show that TFE-GNN",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "e41871240b55d33f040d8a7a7747cf16b4a6c81a",
    "url": "https://www.semanticscholar.org/paper/e41871240b55d33f040d8a7a7747cf16b4a6c81a",
    "title": "Graph Neural Networks: Self-supervised Learning",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-981-16-6054-2_18?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-981-16-6054-2_18, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153607948",
        "name": "Yu Wang"
      },
      {
        "authorId": "144767914",
        "name": "Wei Jin"
      },
      {
        "authorId": "12524628",
        "name": "Tyler Derr"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "77b5ef59a5c49bde4553d106404d91e923ebb72e",
    "url": "https://www.semanticscholar.org/paper/77b5ef59a5c49bde4553d106404d91e923ebb72e",
    "title": "Study-GNN: A Novel Pipeline for Student Performance Prediction Based on Multi-Topology Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2071-1050/14/13/7965/pdf?version=1656568232",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/su14137965?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/su14137965, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2150655634",
        "name": "Ming Li"
      },
      {
        "authorId": "2144799393",
        "name": "Xiangru Wang"
      },
      {
        "authorId": "2154459716",
        "name": "Yi Wang"
      },
      {
        "authorId": "2109324503",
        "name": "Yuting Chen"
      },
      {
        "authorId": "2174535778",
        "name": "Yixuan Chen"
      }
    ],
    "abstract": "Student performance prediction has attracted increasing attention in the field of educational data mining, or more broadly, intelligent education or \u00e2\u0080\u009cAI + education\u00e2\u0080\u009d. Accurate performance prediction plays a significant role in solving the problem of a student dropping out, promoting personalized learning and improving teaching efficiency, etc. Traditional student performance prediction methods usually ignore the potential (underlying) relationship among students. In this paper, we use graph structure to reflect the students\u00e2\u0080\u0099 relationships and propose a novel pipeline for student performance prediction based on newly-developed multi-topology graph neural networks (termed MTGNN). In particular, we propose various ways for graph construction based on similarity learning using different distance metrics. Based on the multiple graphs of different topologies, we design an MTGNN module, as a key module in the pipeline, to deal with the semi-supervised node classification problem where each node represents a student (and the node label is the student\u00e2\u0080\u0099s performance, e.g., Pass/Fail/Withdrawal). An attention-based method is developed to produce the unified graph representation in MTGNN. The effectiveness of the proposed pipeline is verified in a case study, where a real-world educational dataset and several existing approaches are used for performance comparison. The experiment results show that, compared with some traditional machine learning methods and the vanilla graph convolutional network with only a single graph topology, our proposed pipeline works effectively and favorably in student performance prediction.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1f5350949cfacabde7234f27d55ad8690ce214f8",
    "url": "https://www.semanticscholar.org/paper/1f5350949cfacabde7234f27d55ad8690ce214f8",
    "title": "NeuroDual: A Hybrid SAT Solver Combining Graph Attention Networks with Algorithmic Techniques",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ISNCC62547.2024.10759050?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ISNCC62547.2024.10759050, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1712015",
        "name": "Mahfuza Farooque"
      },
      {
        "authorId": "2332541842",
        "name": "Matthew Walter"
      },
      {
        "authorId": "2332560158",
        "name": "Aaron Falk"
      }
    ],
    "abstract": "In this paper, we introduce NeuroDual, a hybrid Boolean satisfiability (SAT) solver architecture that integrates Graph Attention Networks (GATs) into the Conflict-Driven Clause Learning (CDCL) process. Unlike traditional SAT solvers with fixed decision heuristics, NeuroDual leverages GATs to dynamically learn a decision heuristic specific to each SAT instance by computing an assignment score for each variable in the problem. Also, GATs in the context of SAT-solving allow NeuroDual to better understand the spatial relations of the dynamic features within a CNF clause and make informed predictions for variable assignments in the SAT instance that align more closely with the current state of the problem. For our CDCL component of NeuroDual, we implement MINISAT as the baseline solver. Our results show that incorporating machine learning techniques, specifically GATs, into SAT-solving algorithms as a decision heuristic has the potential to increase solver efficiency. These findings indicate that integrating machine learning techniques with traditional SAT-solving algorithms like CDCL to enhance the decision heuristic has the potential to drive efficiency improvements, paving the way for smarter decision-making, reduced conflict occurrences, and expedited problem resolution.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "0a3bf9ee0f618389e49927b437f74d4329587d45",
    "url": "https://www.semanticscholar.org/paper/0a3bf9ee0f618389e49927b437f74d4329587d45",
    "title": "Combining Differentiable PDE Solvers and Graph Neural Networks for Fluid Flow Prediction",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2007.04439, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1406677814",
        "name": "Filipe de Avila Belbute-Peres"
      },
      {
        "authorId": "51441506",
        "name": "T. Economon"
      },
      {
        "authorId": "145116464",
        "name": "J. Z. Kolter"
      }
    ],
    "abstract": "Solving large complex partial differential equations (PDEs), such as those that arise in computational fluid dynamics (CFD), is a computationally expensive process. This has motivated the use of deep learning approaches to approximate the PDE solutions, yet the simulation results predicted from these approaches typically do not generalize well to truly novel scenarios. In this work, we develop a hybrid (graph) neural network that combines a traditional graph convolutional network with an embedded differentiable fluid dynamics simulator inside the network itself. By combining an actual CFD simulator (run on a much coarser resolution representation of the problem) with the graph network, we show that we can both generalize well to new situations and benefit from the substantial speedup of neural network CFD predictions, while also substantially outperforming the coarse CFD simulation alone.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6f05cc5b2c9c93fe2665e801fd2ff9296c5d0e36",
    "url": "https://www.semanticscholar.org/paper/6f05cc5b2c9c93fe2665e801fd2ff9296c5d0e36",
    "title": "Unfolding WMMSE Using Graph Neural Networks for Efficient Power Allocation",
    "year": 2020,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2009.10812",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2009.10812, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1740709566",
        "name": "Arindam Chowdhury"
      },
      {
        "authorId": "70180972",
        "name": "Gunjan Verma"
      },
      {
        "authorId": "143666946",
        "name": "Chirag R. Rao"
      },
      {
        "authorId": "144231976",
        "name": "A. Swami"
      },
      {
        "authorId": "2262891",
        "name": "Santiago Segarra"
      }
    ],
    "abstract": "We study the problem of optimal power allocation in a single-hop ad hoc wireless network. In solving this problem, we depart from classical purely model-based approaches and propose a hybrid method that retains key modeling elements in conjunction with data-driven components. More precisely, we put forth a neural network architecture inspired by the algorithmic unfolding of the iterative weighted minimum mean squared error (WMMSE) method, that we denote by unfolded WMMSE (UWMMSE). The learnable weights within UWMMSE are parameterized using graph neural networks (GNNs), where the time-varying underlying graphs are given by the fading interference coefficients in the wireless network. These GNNs are trained through a gradient descent approach based on multiple instances of the power allocation problem. We show that the proposed architecture is permutation equivariant, thus facilitating generalizability across network topologies. Comprehensive numerical experiments illustrate the performance attained by UWMMSE along with its robustness to hyper-parameter selection and generalizability to unseen scenarios such as different network densities and network sizes.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "536da0e76290aea9cbe75c29bac096aeb45ef875",
    "url": "https://www.semanticscholar.org/paper/536da0e76290aea9cbe75c29bac096aeb45ef875",
    "title": "Can graph neural networks count substructures?",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2002.04025, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "8157979",
        "name": "Zhengdao Chen"
      },
      {
        "authorId": "143891665",
        "name": "Lei Chen"
      },
      {
        "authorId": "144790990",
        "name": "Soledad Villar"
      },
      {
        "authorId": "143627859",
        "name": "Joan Bruna"
      }
    ],
    "abstract": "The ability to detect and count certain substructures in graphs is important for solving many tasks on graph-structured data, especially in the contexts of computational chemistry and biology as well as social network analysis. Inspired by this, we propose to study the expressive power of graph neural networks (GNNs) via their ability to count attributed graph substructures, extending recent works that examine their power in graph isomorphism testing and function approximation. We distinguish between two types of substructure counting: induced-subgraph-count and subgraph-count, and establish both positive and negative answers for popular GNN architectures. Specifically, we prove that Message Passing Neural Networks (MPNNs), 2-Weisfeiler-Lehman (2-WL) and 2-Invariant Graph Networks (2-IGNs) cannot perform induced-subgraph-count of substructures consisting of 3 or more nodes, while they can perform subgraph-count of star-shaped substructures. As an intermediary step, we prove that 2-WL and 2-IGNs are equivalent in distinguishing non-isomorphic graphs, partly answering an open problem raised in Maron et al. (2019). We also prove positive results for k-WL and k-IGNs as well as negative results for k-WL with a finite number of iterations. We then conduct experiments that support the theoretical results for MPNNs and 2-IGNs. Moreover, motivated by substructure counting, we propose a local relational pooling approach with inspirations from Murphy et al. (2019) and demonstrate that it is not only effective for substructure counting but also able to achieve competitive performance on real-world tasks.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d596ac251729fc3647b08b51c5208fdf5414c7c1",
    "url": "https://www.semanticscholar.org/paper/d596ac251729fc3647b08b51c5208fdf5414c7c1",
    "title": "Combinatorial optimization and reasoning with graph neural networks",
    "year": 2021,
    "openAccessPdf": {
      "url": "https://www.ijcai.org/proceedings/2021/0595.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2102.09544, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1907863",
        "name": "Quentin Cappart"
      },
      {
        "authorId": "3394738",
        "name": "D. Ch\u00c3\u00a9telat"
      },
      {
        "authorId": "35252180",
        "name": "Elias Boutros Khalil"
      },
      {
        "authorId": "144390922",
        "name": "Andrea Lodi"
      },
      {
        "authorId": "2064641533",
        "name": "Christopher Morris"
      },
      {
        "authorId": "3444569",
        "name": "Petar Velickovic"
      }
    ],
    "abstract": "Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have mostly focused on solving problem instances in isolation, ignoring the fact that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning, especially graph neural networks, as a key building block for combinatorial tasks, either directly as solvers or by enhancing the former. This paper presents a conceptual review of recent key advancements in this emerging field, aiming at researchers in both optimization and machine learning.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "537fcb1a77e5e39996a524d0f14bbedbb8647a70",
    "url": "https://www.semanticscholar.org/paper/537fcb1a77e5e39996a524d0f14bbedbb8647a70",
    "title": "Forecasting Unobserved Node States with spatio-temporal Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2211.11596",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.11596, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2054025136",
        "name": "Andreas Roth"
      },
      {
        "authorId": "115803918",
        "name": "T. Liebig"
      }
    ],
    "abstract": "Forecasting future states of sensors is key to solving tasks like weather prediction, route planning, and many others when dealing with networks of sensors. But complete spatial coverage of sensors is generally unavailable and would practically be infeasible due to limitations in budget and other resources during deployment and maintenance. Currently existing approaches using machine learning are limited to the spatial locations where data was observed, causing limitations to downstream tasks. Inspired by the recent surge of Graph Neural Networks for spatio-temporal data processing, we investigate whether these can also forecast the state of locations with no sensors available. For this purpose, we develop a framework, named Forecasting Unobserved Node States (FUNS), that allows forecasting the state at entirely unobserved locations based on spatio-temporal correlations and the graph inductive bias. FUNS serves as a blueprint for optimizing models only on observed data and demonstrates good generalization capabilities for predicting the state at entirely unobserved locations during the testing stage. Our framework can be combined with any spatio-temporal Graph Neural Network, that exploits spatio-temporal correlations with surrounding observed locations by using the network's graph structure. Our employed model builds on a previous model by also allowing us to exploit prior knowledge about locations of interest, e.g. the road type. Our empirical evaluation of both simulated and real-world datasets demonstrates that Graph Neural Networks are well-suited for this task.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f2ba59ca1491dc7d22825b9c92e8af1915ab20a7",
    "url": "https://www.semanticscholar.org/paper/f2ba59ca1491dc7d22825b9c92e8af1915ab20a7",
    "title": "Capturing Symmetries of Quantum Optimization Algorithms Using Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://www.mdpi.com/2073-8994/14/12/2593/pdf?version=1670423542",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/sym14122593?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/sym14122593, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2064020741",
        "name": "Ajinkya Deshpande"
      },
      {
        "authorId": "2113841750",
        "name": "A. Melnikov"
      }
    ],
    "abstract": "Quantum optimization algorithms are some of the most promising algorithms expected to show a quantum advantage. When solving quadratic unconstrained binary optimization problems, quantum optimization algorithms usually provide an approximate solution. The solution quality, however, is not guaranteed to be good enough to warrant selecting it over the classical optimizer solution, as it depends on the problem instance. Here, we present an algorithm based on a graph neural network that can choose between a quantum optimizer and classical optimizer using performance prediction. In addition, we present an approach that predicts the optimal parameters of a variational quantum optimizer. We tested our approach with a specific quantum optimizer, the quantum approximate optimization algorithm, applied to the Max-Cut problem, which is an example of a quadratic unconstrained binary optimization problem. We observed qualitatively and quantitatively that graph neural networks are suited for a performance prediction of up to nine-vertex Max-Cut instances with a quantum approximate optimization algorithm with a depth of up to three. For the performance prediction task, the average difference between the actual quantum algorithm performance and the predicted performance is below 19.7% and, for the parameter prediction task, the solution using the predicted parameters is within 2.7% of the optimal parameter solution. Our method therefore has the capacity to find problems that are best suited for quantum solvers. The proposed method and the corresponding algorithm can be used for hybrid quantum algorithm selection.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "88d15996b0eb81c348ab9e145b14655171d35d67",
    "url": "https://www.semanticscholar.org/paper/88d15996b0eb81c348ab9e145b14655171d35d67",
    "title": "Learning time-dependent PDE solver using Message Passing Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2204.07651",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2204.07651, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2267968931",
        "name": "Pourya Pilva"
      },
      {
        "authorId": "3432819",
        "name": "A. Zareei"
      }
    ],
    "abstract": "One of the main challenges in solving time-dependent partial differential equations is to develop computationally efficient solvers that are accurate and stable. Here, we introduce a graph neural network approach to finding efficient PDE solvers through learning using message-passing models. We first introduce domain invariant features for PDE-data inspired by classical PDE solvers for an efficient physical representation. Next, we use graphs to represent PDE-data on an unstructured mesh and show that message passing graph neural networks (MPGNN) can parameterize governing equations, and as a result, efficiently learn accurate solver schemes for linear/nonlinear PDEs. We further show that the solvers are independent of the initial trained geometry, i.e. the trained solver can find PDE solution on different complex domains. Lastly, we show that a recurrent graph neural network approach can find a temporal sequence of solutions to a PDE.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1ec5ae45b687401fa6cef9da6a866395027f3c4f",
    "url": "https://www.semanticscholar.org/paper/1ec5ae45b687401fa6cef9da6a866395027f3c4f",
    "title": "Graph Neural Networks for Joint Communication and Sensing Optimization in Vehicular Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2302.02878",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2302.02878, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35789702",
        "name": "Xuefei Li"
      },
      {
        "authorId": "2292143998",
        "name": "Mingzhe Chen"
      },
      {
        "authorId": "2116487008",
        "name": "Yuchen Liu"
      },
      {
        "authorId": "144243147",
        "name": "Zhilong Zhang"
      },
      {
        "authorId": "1901365",
        "name": "Danpu Liu"
      },
      {
        "authorId": "145536403",
        "name": "S. Mao"
      }
    ],
    "abstract": "In this paper, the problem of joint communication and sensing is studied in the context of terahertz (THz) vehicular networks. In the studied model, a set of service provider vehicles (SPVs) provide either communication service or sensing service to target vehicles, where it is essential to determine 1) the service mode (i.e., providing either communication or sensing service) for each SPV and 2) the subset of target vehicles that each SPV will serve. The problem is formulated as an optimization problem aiming to maximize the sum of the data rates of the communication target vehicles, while satisfying the sensing service requirements of the sensing target vehicles, by determining the service mode and the target vehicle association for each SPV. To solve this problem, a graph neural network (GNN) based algorithm with a heterogeneous graph representation is proposed. The proposed algorithm enables the central controller to extract each vehicle\u00e2\u0080\u0099s graph information related to its location, connection, and communication interference. Using this extracted graph information, a joint service mode selection and target vehicle association strategy is then determined to adapt to the dynamic vehicle topology with various vehicle types (e.g., target vehicles and service provider vehicles). Simulation results show that the proposed GNN-based scheme can achieve 93.66% of the sum rate achieved by the optimal solution, and yield up to 3.16% and 31.86% improvements in sum rate, respectively, over a homogeneous GNN-based algorithm and a conventional optimization algorithm without using GNNs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "bb70a8354b634b7f9d35ca9c0beb6d881b79c7db",
    "url": "https://www.semanticscholar.org/paper/bb70a8354b634b7f9d35ca9c0beb6d881b79c7db",
    "title": "Rapid spatio-temporal flood modelling via hydraulics-based graph neural networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://hess.copernicus.org/articles/27/4227/2023/hess-27-4227-2023.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.5194/hess-27-4227-2023?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.5194/hess-27-4227-2023, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2088518110",
        "name": "Roberto Bentivoglio"
      },
      {
        "authorId": "1815210",
        "name": "Elvin Isufi"
      },
      {
        "authorId": "32046781",
        "name": "S. Jonkman"
      },
      {
        "authorId": "2579612",
        "name": "Riccardo Taormina"
      }
    ],
    "abstract": "Abstract. Numerical modelling is a reliable tool for flood simulations, but accurate solutions are computationally expensive. In recent years, researchers have explored data-driven methodologies based on neural networks to overcome this limitation. However, most models are only used for a specific case study and disregard the dynamic evolution of the flood wave. This limits their generalizability to topographies that the model was not trained on and in time-dependent applications. In this paper, we introduce shallow water equation\u00e2\u0080\u0093graph neural network (SWE\u00e2\u0080\u0093GNN), a hydraulics-inspired surrogate model based on GNNs that can be used for rapid spatio-temporal flood modelling. The model exploits the analogy between finite-volume methods used to solve SWEs and GNNs. For a computational mesh, we create a graph by considering finite-volume cells as nodes and adjacent cells as being connected by edges. The inputs are determined by the topographical properties of the domain and the initial hydraulic conditions. The GNN then determines how fluxes are exchanged between cells via a learned local function. We overcome the time-step constraints by stacking multiple GNN layers, which expand the considered space instead of increasing the time resolution. We also propose a multi-step-ahead loss function along with a curriculum learning strategy to improve the stability and performance. We validate this approach using a dataset of two-dimensional dike breach flood simulations in randomly generated digital elevation models generated with a high-fidelity numerical solver. The SWE\u00e2\u0080\u0093GNN model predicts the spatio-temporal evolution of the flood for unseen topographies with mean average errors in time of 0.04\u00e2\u0080\u0089m for water depths and 0.004\u00e2\u0080\u0089m2\u00e2\u0080\u0089s\u00e2\u0088\u00921 for unit discharges. Moreover, it generalizes well to unseen breach locations, bigger domains, and longer periods of time compared to those of the training set, outperforming other deep-learning models. On top of this, SWE\u00e2\u0080\u0093GNN has a computational speed-up of up to 2 orders of magnitude faster than the numerical solver. Our framework opens the doors to a new approach to replace numerical solvers in time-sensitive applications with spatially dependent uncertainties.\n",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "ab829ad1fad43d5ee5770f2079825b1508802f11",
    "url": "https://www.semanticscholar.org/paper/ab829ad1fad43d5ee5770f2079825b1508802f11",
    "title": "Hybrid Chance-Constrained Optimal Power Flow under Load and Renewable Generation Uncertainty using Enhanced Multi-Fidelity Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1615/jmachlearnmodelcomput.2024054885?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1615/jmachlearnmodelcomput.2024054885, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2238178642",
        "name": "Kamiar Khayambashi"
      },
      {
        "authorId": "1773090",
        "name": "Abul Hasnat"
      },
      {
        "authorId": "51122565",
        "name": "Negin Alemazkoor"
      }
    ],
    "abstract": "Power systems are transitioning toward renewable sources and electri\u00ef\u00ac\u0081cation, introducing signi\u00ef\u00ac\u0081-cant uncertainties in generation and demand that optimal power \u00ef\u00ac\u0082ow (OPF) methods must manage. Traditional deterministic methods struggle with these variabilities. Additionally, addressing uncertainty in OPF calculations incurs computational burdens due to the need for multiple evaluations across various scenarios. This necessitates the use of advanced surrogate models. However, these models require signi\u00ef\u00ac\u0081cant data for training, and surrogate-based optimization can yield unreliable results due to inaccuracies in constraint handling. To overcome these issues, this paper proposes a novel surrogate-based hybrid chance-constrained optimal power \u00ef\u00ac\u0082ow (HCC-OPF) methodology employing enhanced multi-\u00ef\u00ac\u0081delity graph neural networks (EMF-GNN) as power \u00ef\u00ac\u0082ow solver surro-gates. This model integrates low-\u00ef\u00ac\u0081delity and high-\u00ef\u00ac\u0081delity simulations to signi\u00ef\u00ac\u0081cantly reduce training cost while maintaining high accuracy. We further enhance the robustness and accuracy of OPF solutions through a hybrid methodology that selectively uses exact power \u00ef\u00ac\u0082ow solver to correct surrogate inaccuracies near critical thresholds. Extensive testing on multiple IEEE systems under high-dimensional correlated uncertainty of load and generation shows the EMF-GNN model out-performs existing single-\u00ef\u00ac\u0081delity and multi-\u00ef\u00ac\u0081delity models. Furthermore, the proposed HCC-OPF methodology accurately solves OPF problems across various system sizes and conditions, exhibiting scalability and ef\u00ef\u00ac\u0081ciency. Additionally, it effectively manages N-1 security constraints to further exhibit its robustness under operational challenges.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d1b1857a365a5da49faaabf877b27e16f5eafbe4",
    "url": "https://www.semanticscholar.org/paper/d1b1857a365a5da49faaabf877b27e16f5eafbe4",
    "title": "Enhancing Graph Neural Network for Boolean Satisfiability Solving via Data Augmentation",
    "year": null,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2345876608",
        "name": "Yi Fu"
      },
      {
        "authorId": "2284773424",
        "name": "Anthony Tompkins"
      },
      {
        "authorId": "2157995570",
        "name": "Yang Song"
      },
      {
        "authorId": "1783801",
        "name": "M. Pagnucco"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "9602475e33d4dcfae4ddc10b817ec69097cb19a9",
    "url": "https://www.semanticscholar.org/paper/9602475e33d4dcfae4ddc10b817ec69097cb19a9",
    "title": "Learning the Satisfiability of Pseudo-Boolean Problem with Graph Neural Networks",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-030-58475-7_51?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-030-58475-7_51, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49354237",
        "name": "Minghao Liu"
      },
      {
        "authorId": "50212920",
        "name": "Fan Zhang"
      },
      {
        "authorId": "96359470",
        "name": "Pei-Pei Huang"
      },
      {
        "authorId": "2944201",
        "name": "Shuzi Niu"
      },
      {
        "authorId": "2901930",
        "name": "Feifei Ma"
      },
      {
        "authorId": "2151809741",
        "name": "Jian Zhang"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "bae895561de0634e58f96a1a29d73b06e9b2447c",
    "url": "https://www.semanticscholar.org/paper/bae895561de0634e58f96a1a29d73b06e9b2447c",
    "title": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2508.21513, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2127600715",
        "name": "Geri Skenderi"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have recently shown promise as solvers for Boolean Satisfiability Problems (SATs) by operating on graph representations of logical formulas. However, their performance degrades sharply on harder instances, raising the question of whether this reflects fundamental architectural limitations. In this work, we provide a geometric explanation through the lens of graph Ricci Curvature (RC), which quantifies local connectivity bottlenecks. We prove that bipartite graphs derived from random k-SAT formulas are inherently negatively curved, and that this curvature decreases with instance difficulty. Building on this, we show that GNN-based SAT solvers are affected by oversquashing, a phenomenon where long-range dependencies become impossible to compress into fixed-length representations. We validate our claims empirically across different SAT benchmarks and confirm that curvature is both a strong indicator of problem complexity and can be used to predict performance. Finally, we connect our findings to design principles of existing solvers and outline promising directions for future work.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "aef72ff2c5422fda589ba853f7d6ff7424786622",
    "url": "https://www.semanticscholar.org/paper/aef72ff2c5422fda589ba853f7d6ff7424786622",
    "title": "Graph Neural Reasoning May Fail in Certifying Boolean Unsatisfiability",
    "year": 2019,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.11588, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "49865638",
        "name": "Ziliang Chen"
      },
      {
        "authorId": "115927752",
        "name": "Zhanfu Yang"
      }
    ],
    "abstract": "It is feasible and practically-valuable to bridge the characteristics between graph neural networks (GNNs) and logical reasoning. Despite considerable efforts and successes witnessed to solve Boolean satisfiability (SAT), it remains a mystery of GNN-based solvers for more complex predicate logic formulae. In this work, we conjectures with some evidences, that generally-defined GNNs present several limitations to certify the unsatisfiability (UNSAT) in Boolean formulae. It implies that GNNs may probably fail in learning the logical reasoning tasks if they contain proving UNSAT as the sub-problem included by most predicate logic formulae.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "ac72f634de81801ddb77c20190b2f39fd033d65d",
    "url": "https://www.semanticscholar.org/paper/ac72f634de81801ddb77c20190b2f39fd033d65d",
    "title": "Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas",
    "year": 2019,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2148955949",
        "name": "Fei Wang"
      },
      {
        "authorId": "115927752",
        "name": "Zhanfu Yang"
      },
      {
        "authorId": "49865638",
        "name": "Ziliang Chen"
      },
      {
        "authorId": "2113006",
        "name": "Guannan Wei"
      },
      {
        "authorId": "1712987",
        "name": "Tiark Rompf"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f126207a366ffb70d01d826640989e019154bffe",
    "url": "https://www.semanticscholar.org/paper/f126207a366ffb70d01d826640989e019154bffe",
    "title": "Concept Learning in the Wild: Towards Algorithmic Understanding of Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2412.11205, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1801722803",
        "name": "Elad Shoham"
      },
      {
        "authorId": "2341329150",
        "name": "Hadar Cohen"
      },
      {
        "authorId": "2341315304",
        "name": "Khalil Wattad"
      },
      {
        "authorId": "51915451",
        "name": "Havana Rika"
      },
      {
        "authorId": "2309762899",
        "name": "Dan Vilenchik"
      }
    ],
    "abstract": "Explainable AI (XAI) methods typically focus on identifying essential input features or more abstract concepts for tasks like image or text classification. However, for algorithmic tasks like combinatorial optimization, these concepts may depend not only on the input but also on the current state of the network, like in the graph neural networks (GNN) case. This work studies concept learning for an existing GNN model trained to solve Boolean satisfiability (SAT). \\textcolor{black}{Our analysis reveals that the model learns key concepts matching those guiding human-designed SAT heuristics, particularly the notion of 'support.' We demonstrate that these concepts are encoded in the top principal components (PCs) of the embedding's covariance matrix, allowing for unsupervised discovery. Using sparse PCA, we establish the minimality of these concepts and show their teachability through a simplified GNN. Two direct applications of our framework are (a) We improve the convergence time of the classical WalkSAT algorithm and (b) We use the discovered concepts to\"reverse-engineer\"the black-box GNN and rewrite it as a white-box textbook algorithm. Our results highlight the potential of concept learning in understanding and enhancing algorithmic neural networks for combinatorial optimization tasks.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "dd41747d8a967015f93c0052baa6f2c491a40195",
    "url": "https://www.semanticscholar.org/paper/dd41747d8a967015f93c0052baa6f2c491a40195",
    "title": "Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2505.16053, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2220768140",
        "name": "Jan T\u00c3\u00b6nshoff"
      },
      {
        "authorId": "2319132506",
        "name": "Martin Grohe"
      }
    ],
    "abstract": "Boolean Satisfiability (SAT) solvers are foundational to computer science, yet their performance typically hinges on hand-crafted heuristics. This work introduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm for learning to guide SAT solver branching heuristics with Graph Neural Networks (GNNs). Central to our approach is a novel and generic mechanism for injecting inferred variable weights and polarities into the branching heuristics of existing SAT solvers. In a single forward pass, a GNN assigns these parameters to all variables. Casting this one-shot guidance as a reinforcement learning problem lets us train the GNN with off-the-shelf policy-gradient methods, such as GRPO, directly using the solver's computational cost as the sole reward signal. Extensive evaluations demonstrate that RLAF-trained policies significantly reduce the mean solve times of different base solvers across diverse SAT problem distributions, achieving more than a 2x speedup in some cases, while generalizing effectively to larger and harder problems after training. Notably, these policies consistently outperform expert-supervised approaches based on learning handcrafted weighting heuristics, offering a promising path towards data-driven heuristic design in combinatorial optimization.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "55c26898a5255536ec66b0ce4ab26510efe2bbe1",
    "url": "https://www.semanticscholar.org/paper/55c26898a5255536ec66b0ce4ab26510efe2bbe1",
    "title": "Using deep learning to construct stochastic local search SAT solvers with performance bounds",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2309.11452",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2309.11452, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2242896109",
        "name": "Maximilian Kramer"
      },
      {
        "authorId": "2243274550",
        "name": "Paul Boes"
      }
    ],
    "abstract": "The Boolean Satisfiability problem (SAT) is the most prototypical NP-complete problem and of great practical relevance. One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment. Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable\"oracles\"that provide samples from an instance-specific distribution, exploiting an instance's local structure. Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty. We find that access to GNN-based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve 17% more difficult instances (as measured by the ratio between clauses and variables), and to do so in 35% fewer steps, with improvements in the median number of steps of up to a factor of 8. As such, this work bridges formal results from theoretical computer science and practically motivated research on deep learning for constraint satisfaction problems and establishes the promise of purpose-trained SAT solvers with performance guarantees.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "2a0879ef40de11f5d2735eecc1dd0c22ed7e0047",
    "url": "https://www.semanticscholar.org/paper/2a0879ef40de11f5d2735eecc1dd0c22ed7e0047",
    "title": "Can Graph Neural Networks Learn to Solve MaxSAT Problem?",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2111.07568, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2128166660",
        "name": "Minghao Liu"
      },
      {
        "authorId": "1619536054",
        "name": "Fuqi Jia"
      },
      {
        "authorId": "70462118",
        "name": "Pei Huang"
      },
      {
        "authorId": "2153306748",
        "name": "Fan Zhang"
      },
      {
        "authorId": "2109029213",
        "name": "Yuchen Sun"
      },
      {
        "authorId": "38598067",
        "name": "Shaowei Cai"
      },
      {
        "authorId": "2901930",
        "name": "Feifei Ma"
      },
      {
        "authorId": "2151809741",
        "name": "Jian Zhang"
      }
    ],
    "abstract": "With the rapid development of deep learning techniques, various recent work has tried to apply graph neural networks (GNNs) to solve NP-hard problems such as Boolean Satisfiability (SAT), which shows the potential in bridging the gap between machine learning and symbolic reasoning. However, the quality of solutions predicted by GNNs has not been well investigated in the literature. In this paper, we study the capability of GNNs in learning to solve Maximum Satisfiability (MaxSAT) problem, both from theoretical and practical perspectives. We build two kinds of GNN models to learn the solution of MaxSAT instances from benchmarks, and show that GNNs have attractive potential to solve MaxSAT problem through experimental evaluation. We also present a theoretical explanation of the effect that GNNs can learn to solve MaxSAT problem to some extent for the first time, based on the algorithmic alignment theory.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "b51499cb9a5dded9ae6fd7f821bcd3e43043db94",
    "url": "https://www.semanticscholar.org/paper/b51499cb9a5dded9ae6fd7f821bcd3e43043db94",
    "title": "Understanding GNNs for Boolean Satisfiability through Approximation Algorithms",
    "year": 2024,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2408.15418",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2408.15418, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "47655060",
        "name": "Jan Hula"
      },
      {
        "authorId": "1965908193",
        "name": "David Mojz\u00c3\u00adsek"
      },
      {
        "authorId": "50751618",
        "name": "Mikol\u00c3\u00a1\u00c5\u00a1 Janota"
      }
    ],
    "abstract": "This paper delves into the interpretability of Graph Neural Networks in the context of Boolean Satisfiability. The goal is to demystify the internal workings of these models and provide insightful perspectives into their decision-making processes. This is done by uncovering connections to two approximation algorithms studied in the domain of Boolean Satisfiability: Belief Propagation and Semidefinite Programming Relaxations. Revealing these connections has empowered us to introduce a suite of impactful enhancements. The first significant enhancement is a curriculum training procedure, which incrementally increases the problem complexity in the training set, together with increasing the number of message passing iterations of the Graph Neural Network. We show that the curriculum, together with several other optimizations, reduces the training time by more than an order of magnitude compared to the baseline without the curriculum. Furthermore, we apply decimation and sampling of initial embeddings, which significantly increase the percentage of solved problems.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "451c0b729d31aa14d278e14a2e2465d63e62d99c",
    "url": "https://www.semanticscholar.org/paper/451c0b729d31aa14d278e14a2e2465d63e62d99c",
    "title": "Graph Neural Networks and Boolean Satisfiability",
    "year": 2017,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1702.03592, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2364429",
        "name": "Benedikt B\u00c3\u00bcnz"
      },
      {
        "authorId": "48024953",
        "name": "Matthew Lamm"
      }
    ],
    "abstract": "In this paper we explore whether or not deep neural architectures can learn to classify Boolean satisfiability (SAT). We devote considerable time to discussing the theoretical properties of SAT. Then, we define a graph representation for Boolean formulas in conjunctive normal form, and train neural classifiers over general graph structures called Graph Neural Networks, or GNNs, to recognize features of satisfiability. To the best of our knowledge this has never been tried before. Our preliminary findings are potentially profound. In a weakly-supervised setting, that is, without problem specific feature engineering, Graph Neural Networks can learn features of satisfiability.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "33cd42e9699189c7921ab1bc1a1120a331b58359",
    "url": "https://www.semanticscholar.org/paper/33cd42e9699189c7921ab1bc1a1120a331b58359",
    "title": "STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2506.11057, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2360437758",
        "name": "Xijun Li"
      },
      {
        "authorId": "2367131961",
        "name": "Jiexiang Yang"
      },
      {
        "authorId": "2367099403",
        "name": "Jinghao Wang"
      },
      {
        "authorId": "2367109879",
        "name": "Bo Peng"
      },
      {
        "authorId": "8248062",
        "name": "Jianguo Yao"
      },
      {
        "authorId": "2367041064",
        "name": "Haibing Guan"
      }
    ],
    "abstract": "Combinatorial optimization (CO) problems, central to operation research and theoretical computer science, present significant computational challenges due to their NP-hard nature. While large language models (LLMs) have emerged as promising tools for CO--either by directly generating solutions or synthesizing solver-specific codes--existing approaches often neglect critical structural priors inherent to CO problems, leading to suboptimality and iterative inefficiency. Inspired by human experts' success in leveraging CO structures for algorithm design, we propose STRCMP, a novel structure-aware LLM-based algorithm discovery framework that systematically integrates structure priors to enhance solution quality and solving efficiency. Our framework combines a graph neural network (GNN) for extracting structural embeddings from CO instances with an LLM conditioned on these embeddings to identify high-performing algorithms in the form of solver-specific codes. This composite architecture ensures syntactic correctness, preserves problem topology, and aligns with natural language objectives, while an evolutionary refinement process iteratively optimizes generated algorithm. Extensive evaluations across Mixed Integer Linear Programming and Boolean Satisfiability problems, using nine benchmark datasets, demonstrate that our proposed STRCMP outperforms five strong neural and LLM-based methods by a large margin, in terms of both solution optimality and computational efficiency. The code and learned model will be publicly available upon the acceptance of the paper.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "5617f04b34aafb19f19acb03a405fe6d90dffe28",
    "url": "https://www.semanticscholar.org/paper/5617f04b34aafb19f19acb03a405fe6d90dffe28",
    "title": "DeepGate2: Functionality-Aware Circuit Representation Learning",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2305.16373",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2305.16373, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2144146134",
        "name": "Zhengyuan Shi"
      },
      {
        "authorId": "1992806818",
        "name": "Hongyang Pan"
      },
      {
        "authorId": "2155828355",
        "name": "Sadaf Khan"
      },
      {
        "authorId": "2157145787",
        "name": "Min Li"
      },
      {
        "authorId": "2153629193",
        "name": "Yi Liu"
      },
      {
        "authorId": "2198463494",
        "name": "Junhua Huang"
      },
      {
        "authorId": "46465266",
        "name": "Hui-Ling Zhen"
      },
      {
        "authorId": "2075357674",
        "name": "M. Yuan"
      },
      {
        "authorId": "38218168",
        "name": "Zhufei Chu"
      },
      {
        "authorId": "2149106517",
        "name": "Qiang Xu"
      }
    ],
    "abstract": "Circuit representation learning aims to obtain neural repre-sentations of circuit elements and has emerged as a promising research direction that can be applied to various EDA and logic reasoning tasks. Existing solutions, such as DeepGate, have the potential to embed both circuit structural information and functional behavior. However, their capabilities are limited due to weak supervision or flawed model design, resulting in unsatisfactory performance in downstream tasks. In this paper, we introduce Deep Gate2, a novel functionality-aware learning framework that significantly improves upon the original DeepGate solution in terms of both learning effectiveness and efficiency. Our approach involves using pairwise truth table differences between sampled logic gates as training supervision, along with a well-designed and scalable loss function that explicitly considers circuit functionality. Additionally, we consider inherent circuit characteristics and design an efficient one-round graph neural network (GNN), resulting in an order of magnitude faster learning speed than the original DeepGate solution. Experimental results demonstrate significant improvements in two practical downstream tasks: logic synthesis and Boolean satisfiability solving. The code is available at https://github.com/cure-lablDeepGate2.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "cd9452a27c51cb114dc6d793f987a65e4c002b0d",
    "url": "https://www.semanticscholar.org/paper/cd9452a27c51cb114dc6d793f987a65e4c002b0d",
    "title": "Graph Neural Networks for Maximum Constraint Satisfaction",
    "year": 2019,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.580607/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1909.08387, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1388017977",
        "name": "Jan Toenshoff"
      },
      {
        "authorId": "8787552",
        "name": "Martin Ritzert"
      },
      {
        "authorId": "152710659",
        "name": "Hinrikus Wolf"
      },
      {
        "authorId": "1744396",
        "name": "Martin Grohe"
      }
    ],
    "abstract": "Many combinatorial optimization problems can be phrased in the language of constraint satisfaction problems. We introduce a graph neural network architecture for solving such optimization problems. The architecture is generic; it works for all binary constraint satisfaction problems. Training is unsupervised, and it is sufficient to train on relatively small instances; the resulting networks perform well on much larger instances (at least 10-times larger). We experimentally evaluate our approach for a variety of problems, including Maximum Cut and Maximum Independent Set. Despite being generic, we show that our approach matches or surpasses most greedy and semi-definite programming based algorithms and sometimes even outperforms state-of-the-art heuristics for the specific problems.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "e5d9e972950a670aee1f33aae7c8e7a554f823fa",
    "url": "https://www.semanticscholar.org/paper/e5d9e972950a670aee1f33aae7c8e7a554f823fa",
    "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2508.09320, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2261525102",
        "name": "Minghao Liu"
      },
      {
        "authorId": "2110038185",
        "name": "Chia-Hsuan Lu"
      },
      {
        "authorId": "2361505685",
        "name": "Marta Kwiatkowska"
      }
    ],
    "abstract": "Graph neural networks (GNNs) are increasingly employed in high-stakes applications, such as fraud detection or healthcare, but are susceptible to adversarial attacks. A number of techniques have been proposed to provide adversarial robustness guarantees, but support for commonly used aggregation functions in message-passing GNNs is still lacking. In this paper, we develop an exact (sound and complete) verification method for GNNs to compute guarantees against attribute and structural perturbations that involve edge addition or deletion, subject to budget constraints. Focusing on node classification tasks, our method employs constraint solving with bound tightening, and iteratively solves a sequence of relaxed constraint satisfaction problems while relying on incremental solving capabilities of solvers to improve efficiency. We implement GNNev, a versatile solver for message-passing neural networks, which supports three aggregation functions, sum, max and mean, with the latter two considered here for the first time. Extensive experimental evaluation of GNNev on two standard benchmarks (Cora and CiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its usability and effectiveness, as well as superior performance compared to existing {exact verification} tools on sum-aggregated node classification tasks.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "29c9e3107a69be7658f2b37c77ccb6a1081a836d",
    "url": "https://www.semanticscholar.org/paper/29c9e3107a69be7658f2b37c77ccb6a1081a836d",
    "title": "Deep Constraint-Based Propagation in Graph Neural Networks",
    "year": 2020,
    "openAccessPdf": {
      "url": "https://lirias.kuleuven.be/bitstream/20.500.12942/697276/2/accepted_version_tpami_unedited.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2005.02392, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51231820",
        "name": "Matteo Tiezzi"
      },
      {
        "authorId": "2065039297",
        "name": "G. Marra"
      },
      {
        "authorId": "1760309",
        "name": "S. Melacci"
      },
      {
        "authorId": "35251916",
        "name": "Marco Maggini"
      }
    ],
    "abstract": "The popularity of deep learning techniques renewed the interest in neural architectures able to process complex structures that can be represented using graphs, inspired by Graph Neural Networks (GNNs). We focus our attention on the originally proposed GNN model of Scarselli et al. 2009, which encodes the state of the nodes of the graph by means of an iterative diffusion procedure that, during the learning stage, must be computed at every epoch, until the fixed point of a learnable state transition function is reached, propagating the information among the neighbouring nodes. We propose a novel approach to learning in GNNs, based on constrained optimization in the Lagrangian framework. Learning both the transition function and the node states is the outcome of a joint process, in which the state convergence procedure is implicitly expressed by a constraint satisfaction mechanism, avoiding iterative epoch-wise procedures and the network unfolding. Our computational structure searches for saddle points of the Lagrangian in the adjoint space composed of weights, nodes state variables and Lagrange multipliers. This process is further enhanced by multiple layers of constraints that accelerate the diffusion process. An experimental analysis shows that the proposed approach compares favourably with popular models on several benchmarks.",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "91b770234ed2ccc3cd25e2bf78c0948c0f2f98d6",
    "url": "https://www.semanticscholar.org/paper/91b770234ed2ccc3cd25e2bf78c0948c0f2f98d6",
    "title": "Deep Lagrangian Constraint-based Propagation in Graph Neural Networks",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "51231820",
        "name": "Matteo Tiezzi"
      },
      {
        "authorId": "2065039297",
        "name": "G. Marra"
      },
      {
        "authorId": "1760309",
        "name": "S. Melacci"
      },
      {
        "authorId": "35251916",
        "name": "Marco Maggini"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "b89a92318a56dd12ae860164f5cfc53f77965d9f",
    "url": "https://www.semanticscholar.org/paper/b89a92318a56dd12ae860164f5cfc53f77965d9f",
    "title": "Learning Branching Heuristics from Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2211.14405",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.14405, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "20942856",
        "name": "Congsong Zhang"
      },
      {
        "authorId": "2109355607",
        "name": "Yong Gao"
      },
      {
        "authorId": "2346133",
        "name": "James Nastos"
      }
    ],
    "abstract": "Backtracking has been widely used for solving problems in artificial intelligence (AI), including constraint satisfaction problems and combinatorial optimization problems. Good branching heuristics can efficiently improve the performance of backtracking by helping prune the search space and leading the search to the most promising direction. In this paper, we first propose a new graph neural network (GNN) model designed using the probabilistic method. From the GNN model, we introduce an approach to learn a branching heuristic for combinatorial optimization problems. In particular, our GNN model learns appropriate probability distributions on vertices in given graphs from which the branching heuristic is extracted and used in a backtracking search. Our experimental results for the (minimum) dominating-clique problem show that this learned branching heuristic performs better than the minimum-remaining-values heuristic in terms of the number of branches of the whole search tree. Our approach introduces a new way of applying GNNs towards enhancing the classical backtracking algorithm used in AI.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "eb1a7d811ac4041963841cae7a0d49713dbce9aa",
    "url": "https://www.semanticscholar.org/paper/eb1a7d811ac4041963841cae7a0d49713dbce9aa",
    "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective",
    "year": 2020,
    "openAccessPdf": {
      "url": "https://www.ijcai.org/proceedings/2020/0670.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2003.00330, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2257277957",
        "name": "Lu\u00c3\u00ads C. Lamb"
      },
      {
        "authorId": "2257289730",
        "name": "Artur S. d'Avila Garcez"
      },
      {
        "authorId": "2259976374",
        "name": "Marco Gori"
      },
      {
        "authorId": "144677268",
        "name": "Marcelo O. R. Prates"
      },
      {
        "authorId": "144862483",
        "name": "Pedro H. C. Avelar"
      },
      {
        "authorId": "2285833557",
        "name": "M. Vardi"
      }
    ],
    "abstract": "Neural-symbolic computing has now become the subject of interest of both academic and industry research laboratories. \n\nGraph Neural Networks (GNNs) have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains.\n\nThe need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing. \n\nIn this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several domains as well as their relationship to current developments in neural-symbolic computing.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "986d9fb826b3bef4b125fd4a66b6581d0ea9c338",
    "url": "https://www.semanticscholar.org/paper/986d9fb826b3bef4b125fd4a66b6581d0ea9c338",
    "title": "A Graph-Neural-Network-Powered Solver Framework for Graph Optimization Problems",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2024.3397926?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2024.3397926, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "20942856",
        "name": "Congsong Zhang"
      },
      {
        "authorId": "2302606992",
        "name": "Yong Gao"
      },
      {
        "authorId": "2346133",
        "name": "James Nastos"
      }
    ],
    "abstract": "Backtracking combined with branching heuristics is a prevalent approach for tackling constraint satisfaction problems (CSPs) and combinatorial optimization problems (COPs). While branching heuristics specifically designed for certain problems can be theoretically efficient, they are often complex and difficult to implement in practice. On the other hand, general branching heuristics can be applied across various problems, but at the risk of suboptimality. We introduce a solver framework that leverages the Shannon entropy in branching heuristics to bridge the gap between generality and specificity in branching heuristics. This enables backtracking to follow the path of least uncertainty, based on probability distributions that conform to problem constraints. We employ graph neural network (GNN) models with loss functions derived from the probabilistic method to learn these probability distributions. We have evaluated our approach by its applications to two NP-hard problems: the (minimum) dominating-clique problem and the edge-clique-cover problem. Compared with the state-of-the-art solvers for both problems, our solver framework outputs competitive results. Specifically, for the (minimum) dominating-clique problem, our approach generates fewer branches than the solver presented by Culberson et al. (2005). For the edge-clique-cover problem, our approach produces smaller-sized edge clique covers (ECCs) than the solvers referenced by Conte et al. (2020) and Kellerman (1973).",
    "vllm_relevant": true,
    "openrouter_relevant": false,
    "models_agree": false
  },
  {
    "paperId": "96dd92c82d3ca3eaab31e71d2bfba420ba127746",
    "url": "https://www.semanticscholar.org/paper/96dd92c82d3ca3eaab31e71d2bfba420ba127746",
    "title": "A Lagrangian Approach to Information Propagation in Graph Neural Networks",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2002.07684, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51231820",
        "name": "Matteo Tiezzi"
      },
      {
        "authorId": "2065039297",
        "name": "G. Marra"
      },
      {
        "authorId": "1760309",
        "name": "S. Melacci"
      },
      {
        "authorId": "35251916",
        "name": "Marco Maggini"
      },
      {
        "authorId": "145467467",
        "name": "M. Gori"
      }
    ],
    "abstract": "In many real world applications, data are characterized by a complex structure, that can be naturally encoded as a graph. In the last years, the popularity of deep learning techniques has renewed the interest in neural models able to process complex patterns. In particular, inspired by the Graph Neural Network (GNN) model, different architectures have been proposed to extend the original GNN scheme. GNNs exploit a set of state variables, each assigned to a graph node, and a diffusion mechanism of the states among neighbor nodes, to implement an iterative procedure to compute the fixed point of the (learnable) state transition function. In this paper, we propose a novel approach to the state computation and the learning algorithm for GNNs, based on a constraint optimisation task solved in the Lagrangian framework. The state convergence procedure is implicitly expressed by the constraint satisfaction mechanism and does not require a separate iterative phase for each epoch of the learning procedure. In fact, the computational structure is based on the search for saddle points of the Lagrangian in the adjoint space composed of weights, neural outputs (node states), and Lagrange multipliers. The proposed approach is compared experimentally with other popular models for processing graphs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "79e3fe347c0f47dba9e4e8438b99f96a1d89d971",
    "url": "https://www.semanticscholar.org/paper/79e3fe347c0f47dba9e4e8438b99f96a1d89d971",
    "title": "Lagrangian Propagation Graph Neural Networks",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "51231820",
        "name": "Matteo Tiezzi"
      },
      {
        "authorId": "2065039297",
        "name": "G. Marra"
      },
      {
        "authorId": "1760309",
        "name": "S. Melacci"
      },
      {
        "authorId": "35251916",
        "name": "Marco Maggini"
      },
      {
        "authorId": "145467467",
        "name": "M. Gori"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d483c90bb6557898589dcb2c9f0b25dae590d169",
    "url": "https://www.semanticscholar.org/paper/d483c90bb6557898589dcb2c9f0b25dae590d169",
    "title": "Fast and flexible design of novel proteins using graph neural networks",
    "year": 2019,
    "openAccessPdf": {
      "url": "https://www.biorxiv.org/content/biorxiv/early/2020/03/14/868935.full.pdf",
      "status": "GREEN",
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1101/868935?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1101/868935, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "146198684",
        "name": "Alexey Strokach"
      },
      {
        "authorId": "2064549370",
        "name": "David Becerra"
      },
      {
        "authorId": "1403038802",
        "name": "Carles Corbi-Verge"
      },
      {
        "authorId": "1389241628",
        "name": "Albert Perez-Riba"
      },
      {
        "authorId": "1806601",
        "name": "Philip M. Kim"
      }
    ],
    "abstract": "Protein structure and function is determined by the arrangement of the linear sequence of amino acids in 3D space. Despite substantial advances, precisely designing sequences that fold into a predetermined shape (the \u00e2\u0080\u009cprotein design\u00e2\u0080\u009d problem) remains difficult. We show that a deep graph neural network, ProteinSolver, can solve protein design by phrasing it as a constraint satisfaction problem (CSP). To sidestep the considerable issue of optimizing the network architecture, we first develop a network that is accurately able to solve the related and straightforward problem of Sudoku puzzles. Recognizing that each protein design CSP has many solutions, we train this network on millions of real protein sequences corresponding to thousands of protein structures. We show that our method rapidly designs novel protein sequences and perform a variety of in silico and in vitro validations suggesting that our designed proteins adopt the predetermined structures. One Sentence Summary A neural network optimized using Sudoku puzzles designs protein sequences that adopt predetermined structures.",
    "vllm_relevant": false,
    "openrouter_relevant": true,
    "models_agree": false
  },
  {
    "paperId": "75002268982fd7138e3df075ccd1ee90b44e53db",
    "url": "https://www.semanticscholar.org/paper/75002268982fd7138e3df075ccd1ee90b44e53db",
    "title": "Designing real novel proteins using deep graph neural networks",
    "year": 2019,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "146198684",
        "name": "Alexey Strokach"
      },
      {
        "authorId": "2064549370",
        "name": "David Becerra"
      },
      {
        "authorId": "30195625",
        "name": "Carles Corb\u00c3\u00ad"
      },
      {
        "authorId": "1806601",
        "name": "Philip M. Kim"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6a74efe6cf4526058d1a7dd2289e1b3d4fbb418e",
    "url": "https://www.semanticscholar.org/paper/6a74efe6cf4526058d1a7dd2289e1b3d4fbb418e",
    "title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2307.04895",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2307.04895, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2729091",
        "name": "Zhun Yang"
      },
      {
        "authorId": "51161337",
        "name": "Adam Ishay"
      },
      {
        "authorId": "46664110",
        "name": "Joohyung Lee"
      }
    ],
    "abstract": "Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that Transformer extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformer to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "14f5283035ae92e82c79e5603b1ebb484e3c1c6e",
    "url": "https://www.semanticscholar.org/paper/14f5283035ae92e82c79e5603b1ebb484e3c1c6e",
    "title": "Graph convolutional neural networks for the travelling salesman problem",
    "year": 2019,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "38009979",
        "name": "Chaitanya K. Joshi"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "b98ae5f7a9987173e067e5b5d497f2b4779d0e9e",
    "url": "https://www.semanticscholar.org/paper/b98ae5f7a9987173e067e5b5d497f2b4779d0e9e",
    "title": "Solving Constraint-Satisfaction Problems with Distributed Neocortical-Like Neuronal Networks",
    "year": 2018,
    "openAccessPdf": {
      "url": "https://direct.mit.edu/neco/article-pdf/30/5/1359/1036992/neco_a_01074.pdf",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/1801.04515, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "48774107",
        "name": "Ueli Rutishauser"
      },
      {
        "authorId": "1740591",
        "name": "J. Slotine"
      },
      {
        "authorId": "1742758",
        "name": "R. Douglas"
      }
    ],
    "abstract": "Finding actions that satisfy the constraints imposed by both external inputs and internal representations is central to decision making. We demonstrate that some important classes of constraint satisfaction problems (CSPs) can be solved by networks composed of homogeneous cooperative-competitive modules that have connectivity similar to motifs observed in the superficial layers of neocortex. The winner-take-all modules are sparsely coupled by programming neurons that embed the constraints onto the otherwise homogeneous modular computational substrate. We show rules that embed any instance of the CSP's planar four-color graph coloring, maximum independent set, and sudoku on this substrate and provide mathematical proofs that guarantee these graph coloring problems will convergence to a solution. The network is composed of nonsaturating linear threshold neurons. Their lack of right saturation allows the overall network to explore the problem space driven through the unstable dynamics generated by recurrent excitation. The direction of exploration is steered by the constraint neurons. While many problems can be solved using only linear inhibitory constraints, network performance on hard problems benefits significantly when these negative constraints are implemented by nonlinear multiplicative inhibition. Overall, our results demonstrate the importance of instability rather than stability in network computation and offer insight into the computational role of dual inhibitory mechanisms in neural circuits.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "51b27118d24aec80b9fe374fa252909e2f4583f6",
    "url": "https://www.semanticscholar.org/paper/51b27118d24aec80b9fe374fa252909e2f4583f6",
    "title": "Beyond-mean-field fluctuations for the solution of constraint satisfaction problems",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2507.10360, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2373408875",
        "name": "Niklas Foos"
      },
      {
        "authorId": "2144876069",
        "name": "Bastian Epping"
      },
      {
        "authorId": "2373409568",
        "name": "Jannik Grundler"
      },
      {
        "authorId": "2372566028",
        "name": "Alexandru Ciobanu"
      },
      {
        "authorId": "2333256242",
        "name": "Ajainderpal Singh"
      },
      {
        "authorId": "2373405879",
        "name": "Tim Bode"
      },
      {
        "authorId": "1775944",
        "name": "M. Helias"
      },
      {
        "authorId": "3361647",
        "name": "David Dahmen"
      }
    ],
    "abstract": "Constraint Satisfaction Problems (CSPs) lie at the heart of complexity theory and find application in a plethora of prominent tasks ranging from cryptography to genetics. Classical approaches use Hopfield networks to find approximate solutions while recently, modern machine-learning techniques like graph neural networks have become popular for this task. In this study, we employ the known mapping of MAX-2-SAT, a class of CSPs, to a spin-glass system from statistical physics, and use Glauber dynamics to approximately find its ground state, which corresponds to the optimal solution of the underlying problem. We show that Glauber dynamics outperforms the traditional Hopfield-network approach and can compete with state-of-the-art solvers. A systematic theoretical analysis uncovers the role of stochastic fluctuations in finding CSP solutions: even in the absense of thermal fluctuations at $T=0$ a significant portion of spins, which correspond to the CSP variables, attains an effective spin-dependent non-zero temperature. These spins form a subspace in which the stochastic Glauber dynamics continuously performs flips to eventually find better solutions. This is possible since the energy is degenerate, such that spin flips in this free-spin space do not require energy. Our theoretical analysis leads to new deterministic solvers that effectively account for such fluctuations, thereby reaching state-of-the-art performance.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "724e3c4e98bc9ac3281d5aef7d53ecfd4233c3fc",
    "url": "https://www.semanticscholar.org/paper/724e3c4e98bc9ac3281d5aef7d53ecfd4233c3fc",
    "title": "Neural Networks and Graph Algorithms with Next-Generation Processors",
    "year": 2018,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IPDPSW.2018.00184?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IPDPSW.2018.00184, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "13285913",
        "name": "Kathleen E. Hamilton"
      },
      {
        "authorId": "2318902",
        "name": "Catherine D. Schuman"
      },
      {
        "authorId": "144266132",
        "name": "Steven R. Young"
      },
      {
        "authorId": "1794961",
        "name": "N. Imam"
      },
      {
        "authorId": "2054708",
        "name": "T. Humble"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "5263a35cd0214b2dd5401e762abdab8525344004",
    "url": "https://www.semanticscholar.org/paper/5263a35cd0214b2dd5401e762abdab8525344004",
    "title": "Link2Link: A Robust Probabilistic Routing Algorithm via Edge-centric Graph Reinforcement Learning",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.23919/CNSM62983.2024.10814515?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/CNSM62983.2024.10814515, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2268748544",
        "name": "Jingli Zhou"
      },
      {
        "authorId": "2268722671",
        "name": "Yuqian Song"
      },
      {
        "authorId": "2243036428",
        "name": "Xinyuan Li"
      },
      {
        "authorId": "2264664329",
        "name": "Wenli Zhou"
      },
      {
        "authorId": "2243260776",
        "name": "Jun Liu"
      }
    ],
    "abstract": "As network services become more complex, efficient routing has become crucial for ensuring end-user satisfaction. To address this challenge, researchers are increasingly turning to routing algorithms that integrate Graph Neural Networks (GNNs) with Deep Reinforcement Learning (DRL), leveraging the natural graph structure of network topologies. However, a significant challenge with existing algorithms is their inability to generalize across different topologies without requiring retraining, a constraint that is impractical in real-world applications. To overcome this limitation, we propose a novel GNN-DRL-based routing algorithm, Link2Link, designed to decouple DRL-learned knowledge from specific network topologies by focusing on link-level features. Extensive experiments demonstrate that Link2Link achieves robust performance across diverse topologies, consistently outperforming OSPF without requiring retraining, making it a scalable and adaptable solution for modern network routing challenges.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "118638b8fa97595ac838bf8036c7f7b0b7f8982b",
    "url": "https://www.semanticscholar.org/paper/118638b8fa97595ac838bf8036c7f7b0b7f8982b",
    "title": "A graph-based immune-inspired constraint satisfaction search",
    "year": 2010,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s00521-010-0390-8?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s00521-010-0390-8, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1703584",
        "name": "M. Riff"
      },
      {
        "authorId": "2071953579",
        "name": "Marcos Z\u00c3\u00ba\u00c3\u00b1iga"
      },
      {
        "authorId": "144045668",
        "name": "Elizabeth Montero"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "8cb1eaa15d7d568b7b4bd7913072cedd28bfe63c",
    "url": "https://www.semanticscholar.org/paper/8cb1eaa15d7d568b7b4bd7913072cedd28bfe63c",
    "title": "Unification as Constraint Satisfaction in Structured Connectionist Networks",
    "year": 1989,
    "openAccessPdf": {
      "url": "http://www.icsi.berkeley.edu/ftp/global/pub/speech/stolcke/neuralcomp.pdf",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1162/neco.1989.1.4.559?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1162/neco.1989.1.4.559, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1762744",
        "name": "A. Stolcke"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "6ca05417564dcd7aa9541f85c79c1ff90354710e",
    "url": "https://www.semanticscholar.org/paper/6ca05417564dcd7aa9541f85c79c1ff90354710e",
    "title": "A linear constraint satisfaction approach to Bayesian networks",
    "year": 1999,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.1999.830878?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.1999.830878, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2572652",
        "name": "A. M. Abdelbar"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "427938c6eea116242a77862fcde7b8828071adf4",
    "url": "https://www.semanticscholar.org/paper/427938c6eea116242a77862fcde7b8828071adf4",
    "title": "Solving a near-maximal graph planarization problem using strictly digital neural networks with virtual slack-neurons",
    "year": 1994,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICNN.1994.375020?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICNN.1994.375020, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153358449",
        "name": "K. Murakami"
      },
      {
        "authorId": "144057931",
        "name": "T. Nakagawa"
      },
      {
        "authorId": "48116448",
        "name": "H. Kitagawa"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "9067703d3a32f7268d290e1f77f279ee900afe2e",
    "url": "https://www.semanticscholar.org/paper/9067703d3a32f7268d290e1f77f279ee900afe2e",
    "title": "Solving a graph layout problem using strictly digital neural networks with virtual slack-neurons",
    "year": 1999,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.1999.831581?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.1999.831581, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153358449",
        "name": "K. Murakami"
      },
      {
        "authorId": "144057931",
        "name": "T. Nakagawa"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "2edf0ee765486a09071f1d457b39f3f594e9e27c",
    "url": "https://www.semanticscholar.org/paper/2edf0ee765486a09071f1d457b39f3f594e9e27c",
    "title": "Unsupervised Learning of 3-colorings using Simplicial Higher-Order Neural Networks",
    "year": null,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "c5c02b5a10697435409fc8d76ec581fcddcdbe42",
    "url": "https://www.semanticscholar.org/paper/c5c02b5a10697435409fc8d76ec581fcddcdbe42",
    "title": "A constraint satisfaction network for matching 3D objects",
    "year": 1989,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.1989.118711?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.1989.118711, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "35170576",
        "name": "B. Parvin"
      },
      {
        "authorId": "3463966",
        "name": "G. Medioni"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1a0713f91167586174c72da8e59a9b6a11166cfe",
    "url": "https://www.semanticscholar.org/paper/1a0713f91167586174c72da8e59a9b6a11166cfe",
    "title": "Chip Floorplanning Optimization Using Deep Reinforcement Learning",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://doi.org/10.55524/ijircst.2024.12.5.14",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.55524/ijircst.2024.12.5.14?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.55524/ijircst.2024.12.5.14, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2315858658",
        "name": "Shikai Wang"
      },
      {
        "authorId": "2320722610",
        "name": "Haodong Zhang"
      },
      {
        "authorId": "2326543479",
        "name": "Shiji Zhou"
      },
      {
        "authorId": "2326645974",
        "name": "Jun Sun"
      },
      {
        "authorId": "2320874405",
        "name": "Qi Shen"
      }
    ],
    "abstract": "This paper presents a new method for chip floorplanning optimization using deep learning (DRL) combined with graph neural networks (GNNs). The plan addresses the challenges of traditional floor plans by applying AI to space design and intelligent space decisions. Three-head network architecture, including a policy network, cost network, and reconstruction head, is introduced to improve feature extraction and overall performance. GNNs are employed for state representation and feature extraction, enabling the capture of intricate topological information from chip netlists. A carefully designed reward function incorporating wire length minimization, area utilization, and timing constraint satisfaction guides the DRL agent toward high-quality floorplan solutions. An exploration bonus based on reconstruction error addresses the sparse reward problem. Extensive testing of the ISPD 2005 benchmarks demonstrated the effectiveness of the proposed approach, consistently operating on a state-of-the-art basis. Significant improvements include an average 31.4% reduction in half-perimeter wire length (HPWL) and a 34.2% reduction in breach time compared to the best baseline performance. The process scalability and robustness are evaluated, showing performance in various circuits and different perturbations. This research advances AI-driven electronic device design and paves the way for better chip design processes.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "78fa8e88333ef5a5972135ba3f2107616b46833f",
    "url": "https://www.semanticscholar.org/paper/78fa8e88333ef5a5972135ba3f2107616b46833f",
    "title": "Encoding logical constraints into neural network cost functions",
    "year": 1990,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.1990.137943?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.1990.137943, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2534366",
        "name": "Douglas A. Thomae"
      },
      {
        "authorId": "2445984",
        "name": "D. V. D. Bout"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "006d5994425930f04037eb3362a301f8e6cd7a29",
    "url": "https://www.semanticscholar.org/paper/006d5994425930f04037eb3362a301f8e6cd7a29",
    "title": "Optimization by reduction to maximum clique",
    "year": 1993,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICNN.1993.298783?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICNN.1993.298783, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "34719181",
        "name": "A. Jagota"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "e7bb1a1b6362d5dad798bdc7e0cf7564b9aa5128",
    "url": "https://www.semanticscholar.org/paper/e7bb1a1b6362d5dad798bdc7e0cf7564b9aa5128",
    "title": "Cooperative updating in the Hopfield model",
    "year": 2001,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/72.950153?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/72.950153, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2031529",
        "name": "T. Munehisa"
      },
      {
        "authorId": "152915633",
        "name": "Masaki Kobayashi"
      },
      {
        "authorId": "2067718455",
        "name": "Haruaki Yamazaki"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a2bc7e560a4e63b1d927e570d8f010345d668302",
    "url": "https://www.semanticscholar.org/paper/a2bc7e560a4e63b1d927e570d8f010345d668302",
    "title": "Learning and Intelligent Optimization, Third International Conference, LION 3, Trento, Italy, January 14-18, 2009. Selected Papers",
    "year": 2009,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/978-3-642-11169-3?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/978-3-642-11169-3, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1684799",
        "name": "T. St\u00c3\u00bctzle"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "2c105a0e1ad7a95dec9ffe23fb57facf589d717b",
    "url": "https://www.semanticscholar.org/paper/2c105a0e1ad7a95dec9ffe23fb57facf589d717b",
    "title": "IMPROVING GENET AND EGENET BY NEW VARIABLE ORDERING STRATEGIES",
    "year": 1998,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "144396500",
        "name": "V. Tam"
      },
      {
        "authorId": "1682747",
        "name": "Peter James Stuckey"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "88ede0b752b8ff22cbb2fe38d84b94fec07c86aa",
    "url": "https://www.semanticscholar.org/paper/88ede0b752b8ff22cbb2fe38d84b94fec07c86aa",
    "title": "Connectionist unification of feature-structures",
    "year": 1989,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/IJCNN.1989.118347?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/IJCNN.1989.118347, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1762744",
        "name": "A. Stolcke"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "c43ffb2b7751ef3f8193fbac94821cf3e1caf39e",
    "url": "https://www.semanticscholar.org/paper/c43ffb2b7751ef3f8193fbac94821cf3e1caf39e",
    "title": "Applying EGENET to solve continuous constrained optimization problems: a preliminary report",
    "year": 1999,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICIIS.1999.810233?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICIIS.1999.810233, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "144396500",
        "name": "V. Tam"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d932b9aee9270ef3c504361984025c50aa0a76dd",
    "url": "https://www.semanticscholar.org/paper/d932b9aee9270ef3c504361984025c50aa0a76dd",
    "title": "DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint Satisfaction",
    "year": 2023,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2303.01141",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2303.01141, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "153733980",
        "name": "Kshitij Goyal"
      },
      {
        "authorId": "3422854",
        "name": "Sebastijan Dumancic"
      },
      {
        "authorId": "1755851",
        "name": "H. Blockeel"
      }
    ],
    "abstract": "As machine learning models, specifically neural networks, are becoming increasingly popular, there are concerns regarding their trustworthiness, specially in safety-critical applications, e.g. actions of an autonomous vehicle must be safe. There are approaches that can train neural networks where such domain requirements are enforced as constraints, but they either cannot guarantee that the constraint will be satisfied by all possible predictions (even on unseen data) or they are limited in the type of constraints that can be enforced. In this paper, we present an approach to train neural networks which can enforce a wide variety of constraints and guarantee that the constraint is satisfied by all possible predictions. The approach builds on earlier work where learning linear models is formulated as a constraint satisfaction problem (CSP). To make this idea applicable to neural networks, two crucial new elements are added: constraint propagation over the network layers, and weight updates based on a mix of gradient descent and CSP solving. Evaluation on various machine learning tasks demonstrates that our approach is flexible enough to enforce a wide variety of domain constraints and is able to guarantee them in neural networks.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "5526a583bab0b28384f8305ff2def229c7f63513",
    "url": "https://www.semanticscholar.org/paper/5526a583bab0b28384f8305ff2def229c7f63513",
    "title": "Learning in stochastic neural networks for constraint satisfaction problems",
    "year": 1989,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "37994193",
        "name": "M. Johnston"
      },
      {
        "authorId": "96525129",
        "name": "H. Adorf"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "7228cbf184d4fee04b661e43abd981635fc4d8e1",
    "url": "https://www.semanticscholar.org/paper/7228cbf184d4fee04b661e43abd981635fc4d8e1",
    "title": "Learning Precedences for Scheduling Problems with Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.4230/LIPIcs.CP.2024.30?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.4230/LIPIcs.CP.2024.30, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2290852102",
        "name": "H\u00c3\u00a9l\u00c3\u00a8ne Verhaeghe"
      },
      {
        "authorId": "1907863",
        "name": "Quentin Cappart"
      },
      {
        "authorId": "2304559647",
        "name": "Gilles Pesant"
      },
      {
        "authorId": "2216890",
        "name": "Claude-Guy Quimper"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "0c2fecec1f72e4991f445771373e6403c996de3e",
    "url": "https://www.semanticscholar.org/paper/0c2fecec1f72e4991f445771373e6403c996de3e",
    "title": "Heterophilous Distribution Propagation for Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2405.20640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2170484925",
        "name": "Zhuonan Zheng"
      },
      {
        "authorId": "2282598613",
        "name": "Sheng Zhou"
      },
      {
        "authorId": "2170476701",
        "name": "Hongjia Xu"
      },
      {
        "authorId": "2283309613",
        "name": "Ming Gu"
      },
      {
        "authorId": "2304362412",
        "name": "Yilun Xu"
      },
      {
        "authorId": "2304374164",
        "name": "Ao Li"
      },
      {
        "authorId": "2304360489",
        "name": "Yuhong Li"
      },
      {
        "authorId": "2156226003",
        "name": "Jingjun Gu"
      },
      {
        "authorId": "2064698184",
        "name": "Jiajun Bu"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in various graph mining tasks by aggregating information from neighborhoods for representation learning. The success relies on the homophily assumption that nearby nodes exhibit similar behaviors, while it may be violated in many real-world graphs. Recently, heterophilous graph neural networks (HeterGNNs) have attracted increasing attention by modifying the neural message passing schema for heterophilous neighborhoods. However, they suffer from insufficient neighborhood partition and heterophily modeling, both of which are critical but challenging to break through. To tackle these challenges, in this paper, we propose heterophilous distribution propagation (HDP) for graph neural networks. Instead of aggregating information from all neighborhoods, HDP adaptively separates the neighbors into homophilous and heterophilous parts based on the pseudo assignments during training. The heterophilous neighborhood distribution is learned with orthogonality-oriented constraint via a trusted prototype contrastive learning paradigm. Both the homophilous and heterophilous patterns are propagated with a novel semantic-aware message-passing mechanism. We conduct extensive experiments on 9 benchmark datasets with different levels of homophily. Experimental results show that our method outperforms representative baselines on heterophilous datasets.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "29b9b7f16692df90282c2670c030a0b0bf2bdfa3",
    "url": "https://www.semanticscholar.org/paper/29b9b7f16692df90282c2670c030a0b0bf2bdfa3",
    "title": "xNet: Modeling Network Performance With Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNET.2023.3329357?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNET.2023.3329357, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2121631319",
        "name": "Sijiang Huang"
      },
      {
        "authorId": "2266098337",
        "name": "Yunze Wei"
      },
      {
        "authorId": "2265927786",
        "name": "Lingfeng Peng"
      },
      {
        "authorId": "2109018752",
        "name": "Mowei Wang"
      },
      {
        "authorId": "2171775182",
        "name": "Linbo Hui"
      },
      {
        "authorId": "2266015007",
        "name": "Peng Liu"
      },
      {
        "authorId": "2266203380",
        "name": "Zongpeng Du"
      },
      {
        "authorId": "2265948244",
        "name": "Zhenhua Liu"
      },
      {
        "authorId": "2149069358",
        "name": "Yong Cui"
      }
    ],
    "abstract": "Today\u00e2\u0080\u0099s network is notorious for its complexity and uncertainty. Network operators often rely on network models for efficient network planning, operation, and optimization. The network model is responsible for understanding the complex relationships between network performance metrics (e.g., delay and jitter) and network characteristics (e.g., traffic and configuration). However, we still lack a systematic approach to developing accurate and lightweight network models that are aware of the impact of network configurations (i.e., expressiveness) and provide fine-grained flow-level temporal predictions (i.e., granularity). In this paper, we propose xNet, a data-driven network modeling framework based on graph neural networks (GNN). It is worth noting that xNet is not a dedicated network model designed for a specific network scenario with constraint considerations. On the contrary, xNet provides a general approach to modeling the network characteristics of concern with relation graph representations and configurable GNN blocks. xNet learns the state transition functions between time steps and rolls them out to obtain the full fine-grained prediction trajectory. We implement and instantiate xNet with three use cases. The experimental results show that xNet can accurately predict different performance metrics (i.e. temporal and steady-state QoS) in different scenarios, with performance comparable to state-of-the-art domain-specific models. Compared with traditional packet-level simulators, xNet achieves a speed improvement of more than two orders of magnitude, demonstrating its promising application in real-time optimization of network configurations.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "5a62be0c6e98c92fb8d4e756568e6b62dbd085bc",
    "url": "https://www.semanticscholar.org/paper/5a62be0c6e98c92fb8d4e756568e6b62dbd085bc",
    "title": "Automated Physical Design Watermarking Leveraging Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2407.20544",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2407.20544, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2143418985",
        "name": "Ruisi Zhang"
      },
      {
        "authorId": "2042801642",
        "name": "Rachel Selina Rajarathnam"
      },
      {
        "authorId": "2298889265",
        "name": "David Z. Pan"
      },
      {
        "authorId": "3018662",
        "name": "F. Koushanfar"
      }
    ],
    "abstract": "This paper presents AutoMarks, an automated and transferable watermarking framework that leverages graph neural networks to reduce the watermark search overheads during the placement stage. AutoMarks\u00e2\u0080\u0099s novel automated watermark search is accomplished by (i) constructing novel graph and node features with physical, semantic, and design constraint-aware representation; (ii) designing a data-efficient sampling strategy for watermarking fidelity label collection; and (iii) leveraging a graph neural network to learn the connectivity between cells and predict the watermarking fidelity on unseen layouts. Extensive evaluations on ISPD\u00e2\u0080\u009915 and ISPD\u00e2\u0080\u009919 benchmarks demonstrate that our proposed automated methodology: (i) is capable of finding quality-preserving watermarks in a short time; and (ii) is transferable across various designs, i.e., AutoMarks trained on one layout is generalizable to other benchmark circuits. AutoMarks is also resilient against potential watermark removal and forging attacks.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "73c388d8ece7698e70ccd44d55259cb6f4d26fd7",
    "url": "https://www.semanticscholar.org/paper/73c388d8ece7698e70ccd44d55259cb6f4d26fd7",
    "title": "Graph Neural Networks as Ordering Heuristics for Parallel Graph Coloring",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2408.05054, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "16797155",
        "name": "Kenneth Langedal"
      },
      {
        "authorId": "2238357894",
        "name": "Fredrik Manne"
      }
    ],
    "abstract": "The graph coloring problem asks for an assignment of the minimum number of distinct colors to vertices in an undirected graph with the constraint that no pair of adjacent vertices share the same color. The problem is a thoroughly studied NP-hard combinatorial problem with several real-world applications. As such, a number of greedy heuristics have been suggested that strike a good balance between coloring quality, execution time, and also parallel scalability. In this work, we introduce a graph neural network (GNN) based ordering heuristic and demonstrate that it outperforms existing greedy ordering heuristics both on quality and performance. Previous results have demonstrated that GNNs can produce high-quality colorings but at the expense of excessive running time. The current paper is the first that brings the execution time down to compete with existing greedy heuristics. Our GNN model is trained using both supervised and unsupervised techniques. The experimental results show that a 2-layer GNN model can achieve execution times between the largest degree first (LF) and smallest degree last (SL) ordering heuristics while outperforming both on coloring quality. Increasing the number of layers improves the coloring quality further, and it is only at four layers that SL becomes faster than the GNN. Finally, our GNN-based coloring heuristic achieves superior scaling in the parallel setting compared to both SL and LF.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "c9e78d3057ef78d95e2161f2b9fd6a98f226c249",
    "url": "https://www.semanticscholar.org/paper/c9e78d3057ef78d95e2161f2b9fd6a98f226c249",
    "title": "Q'tron neural networks for constraint satisfaction",
    "year": 2004,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICHIS.2004.77?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICHIS.2004.77, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "50241660",
        "name": "T. Yue"
      },
      {
        "authorId": "2144237661",
        "name": "Mei-Ching Chen"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "68cb159826ab45deae65c74b3fcc3931b255c8c6",
    "url": "https://www.semanticscholar.org/paper/68cb159826ab45deae65c74b3fcc3931b255c8c6",
    "title": "Universal Symmetry Constraint Extraction for Analog and Mixed-Signal Circuits with Graph Neural Networks",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/dac18074.2021.9586211?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/dac18074.2021.9586211, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2149050523",
        "name": "Hao Chen"
      },
      {
        "authorId": "1471646837",
        "name": "Keren Zhu"
      },
      {
        "authorId": "1471681696",
        "name": "Mingjie Liu"
      },
      {
        "authorId": "2109653240",
        "name": "Xiyuan Tang"
      },
      {
        "authorId": "48000611",
        "name": "Nan Sun"
      },
      {
        "authorId": "1681705",
        "name": "D. Pan"
      }
    ],
    "abstract": "Recent research trends in analog layout synthesis aim for a fully automated netlist-to-GDSII design flow with minimum human efforts. Due to the sensitiveness of analog circuit layouts, symmetry matching between critical building blocks and devices can significantly impact the overall circuit performance. Therefore, providing accurate symmetry constraints for automated layout synthesis tools is crucial to achieving high-quality layouts. This paper presents a novel graph-learning-based framework leveraging unsupervised learning to recognize circuit matching structures by making the most of numerous unlabeled circuits. The proposed framework supports both system-level and device-level symmetry constraints extraction for various large-scale analog/mixed-signal systems. Experimental results show that our framework outperforms state-of-the-art symmetry constraint detection algorithms with remarkable accuracy and runtime improvement.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "7571d2883f725adc5754cad32bbb2358bd822558",
    "url": "https://www.semanticscholar.org/paper/7571d2883f725adc5754cad32bbb2358bd822558",
    "title": "A review on graph neural networks for predicting synergistic drug combinations",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s10462-023-10669-z.pdf",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s10462-023-10669-z?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s10462-023-10669-z, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2137655771",
        "name": "Milad Besharatifard"
      },
      {
        "authorId": "2284100985",
        "name": "Fatemeh Vafaee"
      }
    ],
    "abstract": "Combinational therapies with synergistic effects provide a powerful treatment strategy for tackling complex diseases, particularly malignancies. Discovering these synergistic combinations, often involving various compounds and structures, necessitates exploring a vast array of compound pairings. However, practical constraints such as cost, feasibility, and complexity hinder exhaustive in vivo and in vitro experimentation. In recent years, machine learning methods have made significant inroads in pharmacology. Among these, Graph Neural Networks (GNNs) have gained increasing attention in drug discovery due to their ability to represent complex molecular structures as networks, capture vital structural information, and seamlessly handle diverse data types. This review aims to provide a comprehensive overview of various GNN models developed for predicting effective drug combinations, examining the limitations and strengths of different models, and comparing their predictive performance. Additionally, we discuss the datasets used for drug synergism prediction and the extraction of drug-related information as predictive features. By summarizing the state-of-the-art GNN-driven drug combination prediction, this review aims to offer valuable insights into the promising field of computational pharmacotherapy.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1d71f1a5a2b6cdcf28a8e2ade666a8297a3c067b",
    "url": "https://www.semanticscholar.org/paper/1d71f1a5a2b6cdcf28a8e2ade666a8297a3c067b",
    "title": "Neural Networks for Constraint Satisfaction",
    "year": 1993,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/3-540-57292-9_48?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/3-540-57292-9_48, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2840865",
        "name": "A. Monfroglio"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1be7fc816143092690abd8aacd1a14141f1758e3",
    "url": "https://www.semanticscholar.org/paper/1be7fc816143092690abd8aacd1a14141f1758e3",
    "title": "Self-Consistent Graph Neural Networks for Semi-Supervised Node Classification",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TBDATA.2023.3266590?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TBDATA.2023.3266590, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3465997",
        "name": "Yanbei Liu"
      },
      {
        "authorId": "2157666845",
        "name": "Shichuan Zhao"
      },
      {
        "authorId": "2144552377",
        "name": "Xiao Wang"
      },
      {
        "authorId": "144072685",
        "name": "Lei Geng"
      },
      {
        "authorId": "1982147",
        "name": "Zhitao Xiao"
      },
      {
        "authorId": "38078886",
        "name": "Jerry Chun-Wei Lin"
      }
    ],
    "abstract": "Graph Neural Networks (GNNs), the powerful graph representation technique based on deep learning, have attracted great research interest in recent years. Although many GNNs have achieved the state-of-the-art accuracy on a set of standard benchmark datasets, they are still limited to traditional semi-supervised framework and lack of sufficient supervision information, especially for the large amount of unlabeled data. To overcome this issue, we propose a novel self-consistent graph neural networks (SCGNN) framework to enrich the supervision information from two aspects: the self-consistency of unlabeled data and the label information of labeled data. First, in order to extract the self-supervision information from the numerous unlabeled nodes, we perform graph data augmentation and leverage a self-consistent constraint to maximize the mutual information of the unlabeled nodes across different augmented graph views. The self-consistency can sufficiently utilize the intrinsic structural attributes of the graph to extract the self-supervision information from unlabeled data and improve the subsequent classification result. Second, to further extract supervision information from scarce labeled nodes, we introduce a fusion mechanism to obtain comprehensive node embeddings by fusing node representations of two positive graph views, and optimize the classification loss over labeled nodes to maximize the utilization of label information. We conduct comprehensive empirical studies on six public benchmark datasets in node classification task. In terms of accuracy, SCGNN improves by an average of 2.08% over the best baseline, and specifically by 5.8% on the Disease dataset.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d3483dd209fcbb5219790fa868ec383e00febe1b",
    "url": "https://www.semanticscholar.org/paper/d3483dd209fcbb5219790fa868ec383e00febe1b",
    "title": "Graph Neural Networks for Voltage Stability Margins With Topology Flexibilities",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/8784343/9999142/09962773.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/OAJPE.2022.3223962?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/OAJPE.2022.3223962, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2691522",
        "name": "K. Guddanti"
      },
      {
        "authorId": "2221471",
        "name": "Yang Weng"
      },
      {
        "authorId": "2792931",
        "name": "Antoine Marot"
      },
      {
        "authorId": "26384503",
        "name": "Benjamin Donnot"
      },
      {
        "authorId": "1741000",
        "name": "P. Panciatici"
      }
    ],
    "abstract": "High penetration of distributed energy resources (DERs) changes the flows in power grids causing thermal congestions which are managed by real-time corrective topology switching. It is crucial to consider voltage stability margin (VSM) as a constraint when modifying grid topology. However, it is nontrivial to exhaustively search using AC power flow (ACPF) for all control actions with desired VSM. Sensitivity methods are used to solve this issue of \u00e2\u0080\u009cpower flow-free VSM estimation\u00e2\u0080\u009d to screen candidate control actions. However, due to the volatile nature of DERs, sensitivity methods do not perform well near nonlinear operating regions which is overcome by solving ACPF. Here, we propose a new VSM estimation method that performs well at nonlinear operating regions without solving ACPF. We achieve this by formulating the learning of graph neural networks like the matrix-free power flow algorithms. We empirically demonstrate how this similarity bypasses the inaccuracy issues and performs well on unseen operating conditions and topologies without further re-training. The effectiveness is demonstrated on a power network with realistic load and generation profiles, various generation mix, and large control actions. The benefits are showcased in terms of speed, reliability to identify insecure controls, and adaptability to unseen scenarios and grid topologies.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "087b98d60d96d1d5166fafa8eff462dbf4f049d7",
    "url": "https://www.semanticscholar.org/paper/087b98d60d96d1d5166fafa8eff462dbf4f049d7",
    "title": "Matrix Completion of Adaptive Jumping Graph Neural Networks for Recommendation Systems",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10223037.pdf",
      "status": "GOLD",
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ACCESS.2023.3305945?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ACCESS.2023.3305945, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2117791468",
        "name": "Xiaodong Zhu"
      },
      {
        "authorId": "2232439563",
        "name": "Junyu Fu"
      },
      {
        "authorId": "40262099",
        "name": "Cheng Chen"
      }
    ],
    "abstract": "Using graph neural networks to model recommendation scenarios can effectively capture high-order relationship features between objects, thereby helping the model better handle recommendation problems. However, the over-smoothing phenomenon poses a performance constraint for recommendation algorithms based on graph convolutional node aggregation. In realistic recommendation scenarios that involve social relationships, the imbalance of node degrees can deepen the impact of over-smoothing on recommendation accuracy. To address these issues, we propose an adaptive matrix completion algorithm for collaborative filtering recommendation, which is based on the aggregation rules of relational graph convolutional networks, and introduces jumping knowledge connection for adaptive selection of user-item feature aggregation results of deep graph convolutional networks. And in order to overcome the limitations of existing interlayer aggregation mechanisms, we design a self-attention-based aggregation mechanism to integrate the output of each layer and enhance the generalization ability of the model. In addition, we introduce normalization in the process of data transmission between layers to ensure the distinguishability between nodes. Finally, we conduct experiments on three real recommendation datasets to compare the algorithm\u00e2\u0080\u0099s performance and perform ablation analysis. Our model achieves RMSEs of 0.9058, 0.8346 and 0.7176 on the three datasets respectively. The results show that the recommendation performance of our model achieves a leading level when compared with current state-of-the-art algorithms and verifies the influence of node degree distribution on the recommendation process.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "bc41762eac59dbada40bac457b02af1cc02ca920",
    "url": "https://www.semanticscholar.org/paper/bc41762eac59dbada40bac457b02af1cc02ca920",
    "title": "Graph Neural Networks to Predict Customer Satisfaction Following Interactions with a Corporate Call Center",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2102.00420, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "66479836",
        "name": "Teja Kanchinadam"
      },
      {
        "authorId": "8745352",
        "name": "Zihang Meng"
      },
      {
        "authorId": "2009082",
        "name": "Joseph Bockhorst"
      },
      {
        "authorId": "144711711",
        "name": "Vikas Singh"
      },
      {
        "authorId": "2064481572",
        "name": "G. Fung"
      }
    ],
    "abstract": "Customer satisfaction is an important factor in creating and maintaining long-term relationships with customers. Near real-time identification of potentially dissatisfied customers following phone calls can provide organizations the opportunity to take meaningful interventions and to foster ongoing customer satisfaction and loyalty. This work describes a fully operational system we have developed at a large US company for predicting customer satisfaction following incoming phone calls. The system takes as an input speech-to-text transcriptions of calls and predicts call satisfaction reported by customers on post-call surveys (scale from 1 to 10). Because of its ordinal, subjective, and often highly-skewed nature, predicting survey scores is not a trivial task and presents several modeling challenges. We introduce a graph neural network (GNN) approach that takes into account the comparative nature of the problem by considering the relative scores among batches, instead of only pairs of calls when training. This approach produces more accurate predictions than previous approaches including standard regression and classification models that directly fit the survey scores with call data. Our proposed approach can be easily generalized to other customer satisfaction prediction problems.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a3340cd6f24e4c83bec616c7bda719737492fe74",
    "url": "https://www.semanticscholar.org/paper/a3340cd6f24e4c83bec616c7bda719737492fe74",
    "title": "Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://dl.acm.org/doi/pdf/10.1145/3613904.3642822",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2404.13521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2283318301",
        "name": "Yue Jiang"
      },
      {
        "authorId": "2297830817",
        "name": "Changkong Zhou"
      },
      {
        "authorId": "2297771762",
        "name": "Vikas Garg"
      },
      {
        "authorId": "2063973671",
        "name": "A. Oulasvirta"
      }
    ],
    "abstract": "Present-day graphical user interfaces (GUIs) exhibit diverse arrangements of text, graphics, and interactive elements such as buttons and menus, but representations of GUIs have not kept up. They do not encapsulate both semantic and visuo-spatial relationships among elements. To seize machine learning\u00e2\u0080\u0099s potential for GUIs more efficiently, Graph4GUI exploits graph neural networks to capture individual elements\u00e2\u0080\u0099 properties and their semantic\u00e2\u0080\u0094visuo-spatial constraints in a layout. The learned representation demonstrated its effectiveness in multiple tasks, especially generating designs in a challenging GUI autocompletion task, which involved predicting the positions of remaining unplaced elements in a partially completed GUI. The new model\u00e2\u0080\u0099s suggestions showed alignment and visual appeal superior to the baseline method and received higher subjective ratings for preference. Furthermore, we demonstrate the practical benefits and efficiency advantages designers perceive when utilizing our model as an autocompletion plug-in.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a415ea4258b37bdd3b270c7ba7fefb552340a45b",
    "url": "https://www.semanticscholar.org/paper/a415ea4258b37bdd3b270c7ba7fefb552340a45b",
    "title": "Beyond-accuracy: a review on diversity, serendipity, and fairness in recommender systems based on graph neural networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://www.frontiersin.org/articles/10.3389/fdata.2023.1251072/pdf?isPublishedV2=False",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2310.02294, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "51119208",
        "name": "Tomislav Duricic"
      },
      {
        "authorId": "1803040",
        "name": "Dominik Kowald"
      },
      {
        "authorId": "2089715",
        "name": "Emanuel Laci\u00c4\u0087"
      },
      {
        "authorId": "3124784",
        "name": "E. Lex"
      }
    ],
    "abstract": "By providing personalized suggestions to users, recommender systems have become essential to numerous online platforms. Collaborative filtering, particularly graph-based approaches using Graph Neural Networks (GNNs), have demonstrated great results in terms of recommendation accuracy. However, accuracy may not always be the most important criterion for evaluating recommender systems' performance, since beyond-accuracy aspects such as recommendation diversity, serendipity, and fairness can strongly influence user engagement and satisfaction. This review paper focuses on addressing these dimensions in GNN-based recommender systems, going beyond the conventional accuracy-centric perspective. We begin by reviewing recent developments in approaches that improve not only the accuracy-diversity trade-off but also promote serendipity, and fairness in GNN-based recommender systems. We discuss different stages of model development including data preprocessing, graph construction, embedding initialization, propagation layers, embedding fusion, score computation, and training methodologies. Furthermore, we present a look into the practical difficulties encountered in assuring diversity, serendipity, and fairness, while retaining high accuracy. Finally, we discuss potential future research directions for developing more robust GNN-based recommender systems that go beyond the unidimensional perspective of focusing solely on accuracy. This review aims to provide researchers and practitioners with an in-depth understanding of the multifaceted issues that arise when designing GNN-based recommender systems, setting our work apart by offering a comprehensive exploration of beyond-accuracy dimensions.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "bf54547ca3d0c5f061474c9c07afbbb5479a1cd0",
    "url": "https://www.semanticscholar.org/paper/bf54547ca3d0c5f061474c9c07afbbb5479a1cd0",
    "title": "Graph neural networks-based spatiotemporal prediction of photovoltaic power: a comparative study",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s00521-024-10751-9?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s00521-024-10751-9, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2337453812",
        "name": "Dairi Abdelkader"
      },
      {
        "authorId": "2318038675",
        "name": "Harrou Fouzi"
      },
      {
        "authorId": "2337452048",
        "name": "Khaldi Belkacem"
      },
      {
        "authorId": "2318039783",
        "name": "Sun Ying"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "3e9b31689c3e53ff081a7814a1f621168aab7780",
    "url": "https://www.semanticscholar.org/paper/3e9b31689c3e53ff081a7814a1f621168aab7780",
    "title": "Bayesian Hierarchical Graph Neural Networks With Uncertainty Feedback for Trustworthy Fault Diagnosis of Industrial Processes",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TNNLS.2023.3319468?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TNNLS.2023.3319468, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "3228938",
        "name": "Dongyue Chen"
      },
      {
        "authorId": "30797404",
        "name": "Zongxia Xie"
      },
      {
        "authorId": "2259065993",
        "name": "Ruonan Liu"
      },
      {
        "authorId": "2158918469",
        "name": "Wenlong Yu"
      },
      {
        "authorId": "117110855",
        "name": "Qinghua Hu"
      },
      {
        "authorId": "2258943722",
        "name": "Xianling Li"
      },
      {
        "authorId": "2258937445",
        "name": "Steven X. Ding"
      }
    ],
    "abstract": "Deep learning (DL) methods have been widely applied to intelligent fault diagnosis of industrial processes and achieved state-of-the-art performance. However, fault diagnosis with point estimate may provide untrustworthy decisions. Recently, Bayesian inference shows to be a promising approach to trustworthy fault diagnosis by quantifying the uncertainty of the decisions with a DL model. The uncertainty information is not involved in the training process, which does not help the learning of highly uncertain samples and has little effect on improving the fault diagnosis performance. To address this challenge, we propose a Bayesian hierarchical graph neural network (BHGNN) with an uncertainty feedback mechanism, which formulates a trustworthy fault diagnosis on the Bayesian DL (BDL) framework. Specifically, BHGNN captures the epistemic uncertainty and aleatoric uncertainty via a variational dropout approach and utilizes the uncertainty information of each sample to adjust the strength of the temporal consistency (TC) constraint for robust feature learning. Meanwhile, the BHGNN method models the process data as a hierarchical graph (HG) by leveraging the interaction-aware module and physical topology knowledge of the industrial process, which integrates data with domain knowledge to learn fault representation. Moreover, the experiments on a three-phase flow facility (TFF) and secure water treatment (SWaT) show superior and competitive performance in fault diagnosis and verify the trustworthiness of the proposed method.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1371b5dc3a2f1434b89d41a0bdc97f100d19a4c7",
    "url": "https://www.semanticscholar.org/paper/1371b5dc3a2f1434b89d41a0bdc97f100d19a4c7",
    "title": "Graph Neural Network Meets Sparse Representation: Graph Sparse Neural Networks via Exclusive Group Lasso",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TPAMI.2023.3285215?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TPAMI.2023.3285215, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "152390773",
        "name": "Bo Jiang"
      },
      {
        "authorId": "49292271",
        "name": "Beibei Wang"
      },
      {
        "authorId": "50358605",
        "name": "Sibao Chen"
      },
      {
        "authorId": "37864689",
        "name": "Jin Tang"
      },
      {
        "authorId": "2151264175",
        "name": "B. Luo"
      }
    ],
    "abstract": "Existing GNNs usually conduct the layer-wise message propagation via the \u00e2\u0080\u0098full\u00e2\u0080\u0099 aggregation of all neighborhood information which are usually sensitive to the structural noises existed in the graphs, such as incorrect or undesired redundant edge connections. To overcome this issue, we propose to exploit Sparse Representation (SR) theory into GNNs and propose Graph Sparse Neural Networks (GSNNs) which conduct sparse aggregation to select reliable neighbors for message aggregation. GSNNs problem contains discrete/sparse constraint which is difficult to be optimized. Thus, we then develop a tight continuous relaxation model Exclusive Group Lasso GNNs (EGLassoGNNs) for GSNNs. An effective algorithm is derived to optimize the proposed EGLassoGNNs model. Experimental results on several benchmark datasets demonstrate the better performance and robustness of the proposed EGLassoGNNs model.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "9ac5f02dff405b274f9c8b6580e432d690953d4b",
    "url": "https://www.semanticscholar.org/paper/9ac5f02dff405b274f9c8b6580e432d690953d4b",
    "title": "Minimum Topology Attacks for Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2403.02723, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "16003017",
        "name": "Mengmei Zhang"
      },
      {
        "authorId": "144129720",
        "name": "Xiao Wang"
      },
      {
        "authorId": "2151458697",
        "name": "Chuan Shi"
      },
      {
        "authorId": "145225199",
        "name": "Lingjuan Lyu"
      },
      {
        "authorId": "2800519",
        "name": "Tianchi Yang"
      },
      {
        "authorId": "8491162",
        "name": "Junping Du"
      }
    ],
    "abstract": "With the great popularity of Graph Neural Networks (GNNs), their robustness to adversarial topology attacks has received significant attention. Although many attack methods have been proposed, they mainly focus on fixed-budget attacks, aiming at finding the most adversarial perturbations within a fixed budget for target node. However, considering the varied robustness of each node, there is an inevitable dilemma caused by the fixed budget, i.e., no successful perturbation is found when the budget is relatively small, while if it is too large, the yielding redundant perturbations will hurt the invisibility. To break this dilemma, we propose a new type of topology attack, named minimum-budget topology attack, aiming to adaptively find the minimum perturbation sufficient for a successful attack on each node. To this end, we propose an attack model, named MiBTack, based on a dynamic projected gradient descent algorithm, which can effectively solve the involving non-convex constraint optimization on discrete topology. Extensive results on three GNNs and four real-world datasets show that MiBTack can successfully lead all target nodes misclassified with the minimum perturbation edges. Moreover, the obtained minimum budget can be used to measure node robustness, so we can explore the relationships of robustness, topology, and uncertainty for nodes, which is beyond what the current fixed-budget topology attacks can offer.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "224dfe570c6d9bcc308c68cd922602721e3ea6b1",
    "url": "https://www.semanticscholar.org/paper/224dfe570c6d9bcc308c68cd922602721e3ea6b1",
    "title": "Imperceptible graph injection attack on graph neural networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01200-6.pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1007/s40747-023-01200-6?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1007/s40747-023-01200-6, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "145906066",
        "name": "Yang Chen"
      },
      {
        "authorId": "2039532",
        "name": "Zhonglin Ye"
      },
      {
        "authorId": "2144714344",
        "name": "Zhaoyang Wang"
      },
      {
        "authorId": "2992334",
        "name": "Haixing Zhao"
      }
    ],
    "abstract": "In recent years, Graph Neural Networks (GNNs) have achieved excellent applications in classification or prediction tasks. Recent studies have demonstrated that GNNs are vulnerable to adversarial attacks. Graph Modification Attack (GMA) and Graph Injection Attack (GIA) are commonly attack strategies. Most graph adversarial attack methods are based on GMA, which has a clear drawback: the attacker needs high privileges to modify the original graph, making it difficult to execute in practice. GIA can perform attacks without modifying the original graph. However, many GIA models fail to take care of attack invisibility, i.e., fake nodes can be easily distinguished from the original nodes. To solve the above issue, we propose an imperceptible graph injection attack, named IMGIA. Specifically, IMGIA uses the normal distribution sampling and mask learning to generate fake node features and links respectively, and then uses the homophily unnoticeability constraint to improve the camouflage of the attack. Our extensive experiments on three benchmark datasets demonstrate that IMGIA performs better than the existing state-of-the-art GIA methods. As an example, IMGIA shows an improvement in performance with an average increase in effectiveness of 2%.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "1143dc0b4344b4f423e4c02e5a9975bb2eafda6e",
    "url": "https://www.semanticscholar.org/paper/1143dc0b4344b4f423e4c02e5a9975bb2eafda6e",
    "title": "Sheaf-based Positional Encodings for Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null
    },
    "authors": [
      {
        "authorId": "2376412100",
        "name": "Yu He"
      },
      {
        "authorId": "46195895",
        "name": "Cristian Bodnar"
      },
      {
        "authorId": "2378576891",
        "name": "Pietro Lio'"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "476201b1dd3134747c45c00e81cb089209f2ab22",
    "url": "https://www.semanticscholar.org/paper/476201b1dd3134747c45c00e81cb089209f2ab22",
    "title": "Generalizing Topological Graph Neural Networks with Paths",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2308.06838",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.48550/arXiv.2308.06838?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48550/arXiv.2308.06838, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2230067482",
        "name": "Quang Truong"
      },
      {
        "authorId": "2281043198",
        "name": "Peter Chin"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "d22d95c94705e45cd6b7e66900287cca624094a9",
    "url": "https://www.semanticscholar.org/paper/d22d95c94705e45cd6b7e66900287cca624094a9",
    "title": "Fast and Robust Resource-Constrained Scheduling with Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/ICAPS/article/download/27244/27017",
      "status": "BRONZE",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1609/icaps.v33i1.27244?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/icaps.v33i1.27244, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1403725425",
        "name": "F. Teichteil-K\u00c3\u00b6nigsbuch"
      },
      {
        "authorId": "1413176979",
        "name": "G. Pov\u00c3\u00a9da"
      },
      {
        "authorId": "2221196489",
        "name": "Guillermo Gonz\u00c3\u00a1lez de Garibay Barba"
      },
      {
        "authorId": "2181140104",
        "name": "Tim Luchterhand"
      },
      {
        "authorId": "1685896",
        "name": "S. Thi\u00c3\u00a9baux"
      }
    ],
    "abstract": "Resource-Constrained Project Scheduling Problems (RCPSPs) are NP-complete, which makes it challenging to efficiently solve large instances and robustify solutions in the presence of uncertainty. To remedy this, we learn to efficiently mimic the solutions produced by Constraint Programming (CP) solver, using a Graph Neural Network (GNN) architecture designed to capture the structure of RCPSPs. Since the GNN solution may violate constraints, we ensure schedule feasibility at inference time by extracting the task ordering from the GNN schedule and post-processing it with the well-known Schedule Generation Scheme (SGS). We find that SIREN, the resulting algorithm, produces schedules that are of higher quality than those produced by the CP solver within the same computation time budget. The speed and solution quality of SIREN make it suitable as a component of an on-line scenario-based optimisation procedure for RCPSPs with stochastic durations. This leads to the SERENE system, which robustly selects, in real-time, the best next tasks to start in order to minimise the average makespan over the scenarios. Empirically, SERENE achieves better average makespan over different realisations of uncertainty than deterministic algorithms that continuously reschedule on the basis of either the worst, best or average task durations.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "88223436841b7e83185a95282c3a21648957c068",
    "url": "https://www.semanticscholar.org/paper/88223436841b7e83185a95282c3a21648957c068",
    "title": "A Smart Home Demand Response System based on Artificial Neural Networks Augmented with Constraint Satisfaction Heuristic",
    "year": 2021,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.23919/ELECO54474.2021.9677670?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.23919/ELECO54474.2021.9677670, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1500391660",
        "name": "Mert Nak\u00c4\u00b1p"
      },
      {
        "authorId": "2150709894",
        "name": "Arda Asut"
      },
      {
        "authorId": "2150709680",
        "name": "Cennet Kocab\u00c4\u00b1y\u00c4\u00b1k"
      },
      {
        "authorId": "144540872",
        "name": "C. G\u00c3\u00bczel\u00c4\u00b1\u00cc\u0087\u00c5\u009f"
      }
    ],
    "abstract": "Distributing the peak load and alleviating grid stress by considering hourly electricity prices are some of the main research problems for current smart grid systems. This paper deals with the scheduling problem of home appliances' operating hours in smart grids, which aims to achieve minimum cost in user-defined operation intervals. To this end, scheduling via Artificial Neural Networks Augmented with Constraint Satisfaction Heuristic (ANN-AH) method that emulates the operation of the optimization for smart home demand response is developed. Our results show that a home demand response via ANN-AH achieves close to optimal performance with 10 times lower execution time than the optimal scheduling. These results suggest that the ANN-AH based demand response is highly successful and practical, and it is promising for future applications in micro-grid and decentralized renewable energy systems.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "4baa58be06e51cad72d3413ca90748b6f0c5a5eb",
    "url": "https://www.semanticscholar.org/paper/4baa58be06e51cad72d3413ca90748b6f0c5a5eb",
    "title": "Power Constrained Autotuning using Graph Neural Networks",
    "year": 2023,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2302.11467",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2302.11467, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2100306",
        "name": "Akashnil Dutta"
      },
      {
        "authorId": "1918561",
        "name": "JeeWhan Choi"
      },
      {
        "authorId": "1692563",
        "name": "Ali Jannesari"
      }
    ],
    "abstract": "Recent advances in multi and many-core processors have led to significant improvements in the performance of scientific computing applications. However, the addition of a large number of complex cores have also increased the overall power consumption, and power has become a first-order design constraint in modern processors. While we can limit power consumption by simply applying software-based power constraints, applying them blindly will lead to non-trivial performance degradation. To address the challenge of improving the performance, power, and energy efficiency of scientific applications on modern multi-core processors, we propose a novel Graph Neural Network based auto-tuning approach that (i) optimizes runtime performance at pre-defined power constraints, and (ii) simultaneously optimizes for runtime performance and energy efficiency by minimizing the energy-delay product. The key idea behind this approach lies in modeling parallel code regions as flow-aware code graphs to capture both semantic and structural code features. We demonstrate the efficacy of our approach by conducting an extensive evaluation on 30 benchmarks and proxy-/mini-applications with 68 OpenMP code regions. Our approach identifies OpenMP configurations at different power constraints that yield a geometric mean performance improvement of more than 25% and 13% over the default OpenMP configuration on a 32-core Skylake and a 16-core Haswell processor respectively. In addition, when we optimize for the energy-delay product, the OpenMP configurations selected by our auto-tuner demonstrate both performance improvement of 21% and 11% and energy reduction of 29% and 18% over the default OpenMP configuration at Thermal Design Power for the same Skylake and Haswell processors, respectively.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "86a2ff25f5259f324b53ef30d788adb100b2df5a",
    "url": "https://www.semanticscholar.org/paper/86a2ff25f5259f324b53ef30d788adb100b2df5a",
    "title": "Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Broad Physical Dynamics Learning",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3637528.3671957?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3637528.3671957, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2264209295",
        "name": "Zinan Zheng"
      },
      {
        "authorId": "2283057198",
        "name": "Yang Liu"
      },
      {
        "authorId": "2253848916",
        "name": "Jia Li"
      },
      {
        "authorId": "2305334345",
        "name": "Jianhua Yao"
      },
      {
        "authorId": "2253468526",
        "name": "Yu Rong"
      }
    ],
    "abstract": "Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive biases into graph neural networks has improved their generalization ability and data efficiency in unbounded physical dynamics modeling. However, in various scientific and engineering applications, the symmetries of dynamics are frequently discrete due to the boundary conditions. Thus, existing GNNs either over-look necessary symmetry, resulting in suboptimal representation ability, or impose excessive equivariance, which fails to generalize to unobserved symmetric dynamics. In this work, we propose a general Discrete Equivariant Graph Neural Network (DEGNN) that guarantees equivariance to a given discrete point group. Specifically, we show that such discrete equivariant message passing could be constructed by transforming geometric features into permutation-invariant embeddings. Through relaxing continuous equivariant constraints, DEGNN can employ more geometric feature combinations to approximate unobserved physical object interaction functions. Two implementation approaches of DEGNN are proposed based on ranking or pooling permutation-invariant functions. We apply DEGNN to various physical dynamics, ranging from particle, molecular, crowd to vehicle dynamics. In twenty scenarios, DEGNN significantly outperforms existing state-of-the-art approaches. Moreover, we show that DEGNN is data efficient, learning with less data, and can generalize across scenarios such as unobserved orientation.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "7189401cb3a6a6f8e0fe7b16fb05f2abe2ff9fc7",
    "url": "https://www.semanticscholar.org/paper/7189401cb3a6a6f8e0fe7b16fb05f2abe2ff9fc7",
    "title": "Data Augmented Graph Neural Networks for Personality Detection",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/27823/27676",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1609/aaai.v38i1.27823?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aaai.v38i1.27823, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1585297850",
        "name": "Yangfu Zhu"
      },
      {
        "authorId": "2293575349",
        "name": "Yue Xia"
      },
      {
        "authorId": "2260817111",
        "name": "Meiling Li"
      },
      {
        "authorId": "2260830134",
        "name": "Tingting Zhang"
      },
      {
        "authorId": "2243402915",
        "name": "Bin Wu"
      }
    ],
    "abstract": "Personality detection is a fundamental task for user psychology research. One of the biggest challenges in personality detection lies in the quantitative limitation of labeled data collected by completing the personality questionnaire, which is very time-consuming and labor-intensive. Most of the existing works are mainly devoted to learning the rich representations of posts based on labeled data. However, they still suffer from the inherent weakness of the amount limitation of labels, which potentially restricts the capability of the model to deal with unseen data. In this paper, we construct a heterogeneous personality graph for each labeled and unlabeled user and develop a novel psycholinguistic augmented graph neural network to detect personality in a semi-supervised manner, namely Semi-PerGCN. Specifically, our model first explores a supervised Personality Graph Neural Network (PGNN) to refine labeled user representation on the heterogeneous graph. For the remaining massive unlabeled users, we utilize the empirical psychological knowledge of the Linguistic Inquiry and Word Count (LIWC) lexicon for multi-view graph augmentation and perform unsupervised graph consistent constraints on the parameters shared PGNN. During the learning process of finite labeled users, noise-invariant learning on a large scale of unlabeled users is combined to enhance the generalization ability. Extensive experiments on three real-world datasets, Youtube, PAN2015, and MyPersonality demonstrate the effectiveness of our Semi-PerGCN in personality detection, especially in scenarios with limited labeled users.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "4a24fd88ab0dfb9be55222b28ae6557d961c94a4",
    "url": "https://www.semanticscholar.org/paper/4a24fd88ab0dfb9be55222b28ae6557d961c94a4",
    "title": "Federated reinforcement learning with constrained markov decision processes and graph neural networks for fair and grid-constrained coordination of large-scale electric vehicle charging networks",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": "CCBYNCND",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC12612063, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2383913488",
        "name": "Lixia Zhou"
      },
      {
        "authorId": "2392028327",
        "name": "Dawei Huo"
      },
      {
        "authorId": "2392427337",
        "name": "Jian Chen"
      },
      {
        "authorId": "2352086381",
        "name": "Bo Bo"
      },
      {
        "authorId": "2383840613",
        "name": "Hao Li"
      }
    ],
    "abstract": "The rapid proliferation of electric vehicles (EVs) and their spatially clustered charging behaviors have imposed unprecedented challenges on the stability, efficiency, and fairness of power distribution networks. Coordinating large-scale EV clusters across geographically distributed charging stations requires intelligent scheduling strategies that can simultaneously respect grid constraints, maximize user satisfaction, and enhance renewable energy utilization\u00e2\u0080\u0094all while safeguarding data privacy and computational scalability. This paper proposes a novel multi-agent cooperative dispatch framework based on Federated Deep Reinforcement Learning (FDRL) to optimize the real-time coordination between EVs, chargers, and the underlying power grid infrastructure. The model adopts a hierarchical structure where local agents independently train deep reinforcement learning policies tailored to site-specific dynamics, while a central aggregator synchronizes global model parameters using federated averaging enhanced by entropy-based reward normalization and fairness-aware weighting. The optimization problem is formulated as a multi-objective constrained Markov decision process (CMDP), featuring long-horizon coupling, grid-aware feasibility, and user-centric reward shaping. Our formulation explicitly integrates peak transformer loading limits, charging demand satisfaction, temporal renewable absorption, and inter-agent equity, thereby capturing the full complexity of EV\u00e2\u0080\u0093grid interactions. A realistic case study involving 1,200 EVs, 60 chargers, and a 33-bus feeder system over 24 hours shows that the proposed FDRL framework achieves a 13.6% reduction in grid operating cost, a 21.4% increase in renewable absorption, and fairness with Jain\u00e2\u0080\u0099s index consistently above 0.95, while reducing average state-of-charge (SoC) deviation to below 2.5%. These quantitative results highlight the effectiveness of the framework and confirm its promise as a privacy-preserving, scalable, and equitable solution for next-generation energy\u00e2\u0080\u0093cyber\u00e2\u0080\u0093physical systems.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "4f385d87011a5d4f4834955a9e25f954c1330080",
    "url": "https://www.semanticscholar.org/paper/4f385d87011a5d4f4834955a9e25f954c1330080",
    "title": "Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing Heterogeneous Temporal Dynamics",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2407.18691, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2294776811",
        "name": "Mengjie Zhao"
      },
      {
        "authorId": "2683590",
        "name": "C. Taal"
      },
      {
        "authorId": "2294718237",
        "name": "Stephan Baggerohr"
      },
      {
        "authorId": "2248130898",
        "name": "Olga Fink"
      }
    ],
    "abstract": "Real-time condition monitoring is crucial for the reliable and efficient operation of complex systems. However, relying solely on physical sensors can be limited due to their cost, placement constraints, or inability to directly measure certain critical parameters. Virtual sensing addresses these limitations by leveraging readily available sensor data and system knowledge to estimate inaccessible parameters or infer system states. The increasing complexity of industrial systems necessitates deployments of sensors with diverse modalities to provide a comprehensive understanding of system states. These sensors capture data at varying frequencies to monitor both rapid and slowly varying system dynamics, as well as local and global state evolutions of the systems. This leads to heterogeneous temporal dynamics, which, particularly under varying operational end environmental conditions, pose a significant challenge for accurate virtual sensing. To address this, we propose a Heterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly models signals from diverse sensors and integrates operating conditions into the model architecture. We evaluate HTGNN using two newly released datasets: a bearing dataset with diverse load conditions for bearing load prediction and a year-long simulated dataset for predicting bridge live loads. Our results demonstrate that HTGNN significantly outperforms established baseline methods in both tasks, particularly under highly varying operating conditions. These results highlight HTGNN's potential as a robust and accurate virtual sensing approach for complex systems, paving the way for improved monitoring, predictive maintenance, and enhanced system performance. Our code and data are available under https://github.com/EPFL-IMOS/htgnn.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "2164419bc74b265682fd67f3d5dfcbc3117188d2",
    "url": "https://www.semanticscholar.org/paper/2164419bc74b265682fd67f3d5dfcbc3117188d2",
    "title": "Spatio-temporal graph neural networks for missing data completion in traffic prediction",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1080/13658816.2024.2381221?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1080/13658816.2024.2381221, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2135668545",
        "name": "Jiahui Chen"
      },
      {
        "authorId": "2238610683",
        "name": "Lina Yang"
      },
      {
        "authorId": "2284629081",
        "name": "Yi Yang"
      },
      {
        "authorId": "2153141325",
        "name": "Ling Peng"
      },
      {
        "authorId": "30965047",
        "name": "Xingtong Ge"
      }
    ],
    "abstract": "Abstract Missing traffic data completion is a key part of the construction of a smart city. However, due to cost constraints and other reasons, many locations do not have sensors to record traffic data. Most research methods do not systematically consider filling in missing traffic data. This study explores a new spatio-temporal feature extraction layer that includes spatio-temporal feature fusion, graph learning on an adaptive adjacency matrix, and a gated recurrent unit with a mask for missing traffic data completion. This idea is based on a hypothesis: missing data can be inferred from the spatio-temporal features of other nearby recorded sensor nodes. Therefore, we propose an end-to-end traffic model dealing with missing data - missing traffic data completion graph neural networks (MTC-GNN). Experiments demonstrate that the proposed model can learn spatio-temporal patterns and fill in speed from traffic data with various missing ratios and outperform existing models.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "a22c9ff148fdeb9172dec181ab085c05e53040c6",
    "url": "https://www.semanticscholar.org/paper/a22c9ff148fdeb9172dec181ab085c05e53040c6",
    "title": "THGNets: Constrained Temporal Hypergraphs and Graph Neural Networks in Hyperbolic Space for Information Diffusion Prediction",
    "year": 2025,
    "openAccessPdf": {
      "url": "https://doi.org/10.1609/aaai.v39i12.33331",
      "status": "GOLD",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1609/aaai.v39i12.33331?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1609/aaai.v39i12.33331, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2329877846",
        "name": "Yanchao Liu"
      },
      {
        "authorId": "2272010378",
        "name": "Pengzhou Zhang"
      },
      {
        "authorId": "2152981072",
        "name": "Wenchao Song"
      },
      {
        "authorId": "2271556504",
        "name": "Yao Zheng"
      },
      {
        "authorId": "2330048103",
        "name": "Deyu Li"
      },
      {
        "authorId": "2355570505",
        "name": "Lei Shi"
      },
      {
        "authorId": "2152694",
        "name": "Junpeng Gong"
      }
    ],
    "abstract": "Information diffusion prediction aims to predict the next infected user in the information diffusion, which is a critical task to understand how information spreads on social platforms. Existing methods mainly focus on the sequences or topology structure in euclidean space. However, they fail to sufficiently consider the hierarchical structure or power-law structure of the underlying topology of information cascade graphs and social networks, resulting in distortion of user features. To tackle above issue, we propose an innovative Constrained Temporal Hypergraphs and Graph Neural Networks (THGNets) framework that is tailored for information diffusion prediction. Specifically, we introduce hyperbolic temporal hypergraphs neural network to alleviate the distortion of user features by hyperbolic hierarchical learning in information cascades. Additionally, it also captures high-order dynamic interaction patterns between users and further integrates the time-consistency constraint mechanism to mitigate the instability and non-smoothness of user features in latent space. In parallel, we apply the hyperbolic graph neural network to investigate the hierarchical structure and user homogeneity on social networks, enhancing our understanding of social relationships. Moreover, hyperbolic gated recurrent units are employed to capture the potential dependency relationships between contextual users. Experiments conducted on four public datasets demonstrate that the proposed THGNets significantly outperform the existing methods, thereby validating the superiority and rationality of our approach.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "de5048582d7803fdae72bf879d854f43640ba416",
    "url": "https://www.semanticscholar.org/paper/de5048582d7803fdae72bf879d854f43640ba416",
    "title": "Deep Reinforcement Learning Based Topology Independent Routing and Load-Balancing in QKD Networks using Graph Neural Networks",
    "year": 2025,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/ICTON67126.2025.11125037?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/ICTON67126.2025.11125037, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2283629967",
        "name": "Tim Johann"
      },
      {
        "authorId": "2048018133",
        "name": "S. K\u00c3\u00bchl"
      },
      {
        "authorId": "2293467710",
        "name": "S. Pachnicke"
      }
    ],
    "abstract": "Due to the unavailability of quantum repeaters, end-to-end secret keys need to be relayed in a hop-by-hop manner using so called trusted nodes in long-distance QKD networks. Therefore, a sufficient number of secret keys is required between all QKD devices along the path until the destination node is reached. As key generation rates are typically limited to a few kbps depending on link lengths, constraint-based routing algorithms considering key availability levels are desirable. We show that centralized routing based on Deep Reinforcement Learning (DRL) combined with Graph Neural Networks (GNNs) is able to reduce blockings and enhance load-balancing compared to conventional shortest path algorithms. Additionally, because of the training on random topologies, the agent is able to act in topologies unseen during training.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "4bf4d5356a2ef2dc1f4058114df43b0a801e05a1",
    "url": "https://www.semanticscholar.org/paper/4bf4d5356a2ef2dc1f4058114df43b0a801e05a1",
    "title": "OPF-HGNN: Generalizable Heterogeneous Graph Neural Networks for AC Optimal Power Flow",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/PESGM51994.2024.10688560?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/PESGM51994.2024.10688560, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2317087887",
        "name": "Salah Ghamizi"
      },
      {
        "authorId": "2268527754",
        "name": "Aoxiang Ma"
      },
      {
        "authorId": "2268640208",
        "name": "Jun Cao"
      },
      {
        "authorId": "2324116767",
        "name": "Pedro Rodriguez Cortes"
      }
    ],
    "abstract": "The precise solution of the Alternating Current Optimal Power Flow (AC-OPF) problem is a pivotal challenge in the domain of real-time electricity grid operations. This problem is notorious for its significant computational complexity, primarily attributable to its inherently nonlinear and nonconvex nature. Recently, there has been a growing interest in harnessing Graph Neural Networks (GNN) as a means to tackle this optimization task, leveraging the incorporation of grid topology within neural network models. Nonetheless, existing techniques fall short in accommodating the diverse array of components found in contemporary grid networks and restrict their scope to homogeneous graphs. Furthermore, the constraints imposed by the grid networks are often overlooked, resulting in suboptimal or even infeasible solutions. To address the generalization and effectiveness of existing end-to-end OPF learning solutions, we propose OPF-HGNN, a new graph neural network (GNN) architecture and training framework that leverages heterogeneous graph neural networks and incorporates the grid constraints in the node loss function using differentiable penalty regularization. We demonstrate that OPF-HGNN is robust and outperforms traditional GNN learning by two orders of magnitude traditional GNN learning across a large variety of real-world grid topologies and generalization settings.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "7af44b6549f4981453839d94a607b39d18787703",
    "url": "https://www.semanticscholar.org/paper/7af44b6549f4981453839d94a607b39d18787703",
    "title": "Graph Neural Networks for Parameterized Quantum Circuits Expressibility Estimation",
    "year": 2024,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2405.08100",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2405.08100, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "152377088",
        "name": "Shamminuj Aktar"
      },
      {
        "authorId": "2182221260",
        "name": "Andreas Bartschi"
      },
      {
        "authorId": "2265579996",
        "name": "Diane Oyen"
      },
      {
        "authorId": "1707687",
        "name": "S. Eidenbenz"
      },
      {
        "authorId": "3059326",
        "name": "Abdel-Hameed A. Badawy"
      }
    ],
    "abstract": "Parameterized quantum circuits (PQCs) are fundamental to quantum machine learning (QML), quantum optimization, and variational quantum algorithms (VQAs). The expressibility of PQCs is a measure that determines their capability to harness the full potential of the quantum state space. It is thus a crucial guidepost to know when selecting a particular PQC ansatz. However, the existing technique for expressibility computation through statistical estimation requires a large number of samples, which poses significant challenges due to time and computational resource constraints. This paper introduces a novel approach for expressibility estimation of PQCs using Graph Neural Networks (GNNs). We demonstrate the predictive power of our GNN model with a dataset consisting of 25,000 samples from the noiseless IBM QASM Simulator and 12,000 samples from three distinct noisy quantum backends. The model accurately estimates expressibility, with root mean square errors (RMSE) of 0.05 and 0.06 for the noiseless and noisy backends, respectively. We compare our model's predictions with reference circuits from Sim et al. and IBM Qiskit's hardware-efficient ansatz sets to further evaluate our model's performance. Our experimental evaluation in noiseless and noisy scenarios reveals a close alignment with ground truth expressibility values, highlighting the model's efficacy. Moreover, our model exhibits promising extrapolation capabilities, predicting expressibility values with low RMSE for out-of-range qubit circuits trained solely on only up to 5-qubit circuit sets. This work thus provides a reliable means of efficiently evaluating the expressibility of diverse PQCs on noiseless simulators and hardware.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "11a7c53c69cf3a77f027795c353b2880267366ce",
    "url": "https://www.semanticscholar.org/paper/11a7c53c69cf3a77f027795c353b2880267366ce",
    "title": "Scalable Primal Heuristics Using Graph Neural Networks for Combinatorial Optimization",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://jair.org/index.php/jair/article/download/14972/27041",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1613/jair.1.14972?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1613/jair.1.14972, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2120214763",
        "name": "Furkan Cant\u00c3\u00bcrk"
      },
      {
        "authorId": "2213502984",
        "name": "T. Varol"
      },
      {
        "authorId": "2060698",
        "name": "Reyhan Aydo\u00c4\u009fan"
      },
      {
        "authorId": "2827919",
        "name": "O. \u00c3\u0096. \u00c3\u0096zener"
      }
    ],
    "abstract": "By examining the patterns of solutions obtained for various instances, one can gain insights into the structure and behavior of combinatorial optimization (CO) problems and develop efficient algorithms for solving them. Machine learning techniques, especially Graph Neural Networks (GNNs), have shown promise in parametrizing and automating this laborious design process. The inductive bias of GNNs allows for learning solutions to mixed-integer programming (MIP) formulations of constrained CO problems with a relational representation of decision variables and constraints. The trained GNNs can be leveraged with primal heuristics to construct high-quality feasible solutions to CO problems quickly. However, current GNN-based end-to-end learning approaches have limitations for scalable training and generalization on larger-scale instances; therefore, they have been mostly evaluated over small-scale instances. Addressing this issue, our study builds on supervised learning of optimal solutions to the downscaled instances of given large-scale CO problems. We introduce several improvements on a recent GNN model for CO to generalize on instances of a larger scale than those used in training. We also propose a two-stage primal heuristic strategy based on uncertainty-quantification to automatically configure how solution search relies on the predicted decision values. Our models can generalize on 16x upscaled instances of commonly benchmarked five CO problems. Unlike the regressive performance of existing GNN-based CO approaches as the scale of problems increases, the CO pipelines using our models offer an incremental performance improvement relative to CPLEX. The proposed uncertainty-based primal heuristics provide 6-75% better optimality gap values and 45-99% better primal gap values for the 16x upscaled instances and brings immense speedup to obtain high-quality solutions. All these gains are achieved through a computationally efficient modeling approach without sacrificing solution quality.",
    "vllm_relevant": true,
    "openrouter_relevant": true,
    "models_agree": true
  },
  {
    "paperId": "e46aa831aac38520249dff35916937f0d094f32e",
    "url": "https://www.semanticscholar.org/paper/e46aa831aac38520249dff35916937f0d094f32e",
    "title": "Knowledge Enhanced Graph Neural Networks for Explainable Recommendation",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TKDE.2022.3142260?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TKDE.2022.3142260, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1920802076",
        "name": "Ziyu Lyu"
      },
      {
        "authorId": "46220633",
        "name": "Yue Wu"
      },
      {
        "authorId": "2212677118",
        "name": "Junjie Lai"
      },
      {
        "authorId": "2144399230",
        "name": "Min Yang"
      },
      {
        "authorId": "2145534529",
        "name": "Chengming Li"
      },
      {
        "authorId": "101829183",
        "name": "Wei Zhou"
      }
    ],
    "abstract": "Recently, explainable recommendation has attracted increasing attentions, which can make the recommender system more transparent and improve user satisfactions by recommending products with useful explanations. However, existing methods trend to trade-off between the recommendation accuracy and the interpretability of recommendation results. In this manuscript, we propose Knowledge Enhanced Graph Neural Networks (KEGNN) for explainable recommendation. Semantic knowledge from the external knowledge base is leveraged into representation learning of three sides, respectively user, items and user-item interactions, and the knowledge enhanced semantic embedding are exploited to initialize the user/item entities and user-item relations of one constructed user behavior graph. We design a graph neural networks based user behavior learning and reasoning model to perform both semantic and relational knowledge propagation and reasoning over the user behavior graph for comprehensive understanding of user behaviors. On the top of comprehensive representations of users/items and user-item interactions, hierarchical neural collaborative filtering layers are developed for precise rating prediction, and one generation-mode and copy-mode combined generator is devised for human-like semantic explanation generation by integrating the copy mechanism into gated recurrent neural networks. Quantitative and qualitative results demonstrate the superiority of KEGNN over the state-of-art methods, and the explainability and interpretability of our method.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "61073c402c40431ae9c1dd18de3662118c2b9a68",
    "url": "https://www.semanticscholar.org/paper/61073c402c40431ae9c1dd18de3662118c2b9a68",
    "title": "Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2404.16366, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2155460174",
        "name": "Yuan-Qi Bei"
      },
      {
        "authorId": "2156158437",
        "name": "Sheng Zhou"
      },
      {
        "authorId": "2298312030",
        "name": "Jinke Shi"
      },
      {
        "authorId": "2298690419",
        "name": "Yao Ma"
      },
      {
        "authorId": "2238917689",
        "name": "Haishuai Wang"
      },
      {
        "authorId": "2253457926",
        "name": "Jiajun Bu"
      }
    ],
    "abstract": "Unsupervised graph anomaly detection aims at identifying rare patterns that deviate from the majority in a graph without the aid of labels, which is important for a variety of real-world applications. Recent advances have utilized graph neural networks (GNNs) to learn effective node representations by aggregating information from neighborhoods. This is motivated by the hypothesis that nodes in the graph tend to exhibit consistent behaviors with their neighborhoods. However, such consistency can be disrupted by graph anomalies in multiple ways. Most existing methods directly employ GNNs to learn representations, disregarding the negative impact of graph anomalies on GNNs, resulting in suboptimal node representations and anomaly detection performance. While a few recent approaches have redesigned GNNs for graph anomaly detection under semi-supervised label guidance, how to address the adverse effects of graph anomalies on GNNs in unsupervised scenarios and learn effective representations for anomaly detection are still underexplored. To bridge this gap, in this article, we propose a simple, yet effective framework for guarding GNNs for unsupervised graph anomaly detection (G3AD). Specifically, G3AD first introduces two auxiliary networks along with correlation constraints to guard the GNNs against inconsistent information encoding. Furthermore, G3AD introduces an adaptive caching (AC) module to guard the GNNs from directly reconstructing the observed graph data that contains anomalies. Extensive experiments demonstrate that our G3AD can outperform 20 state-of-the-art methods on both synthetic and real-world graph anomaly datasets, with flexible generalization ability in different GNN backbones.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "32f320a17953901198de9f945356a5e99340f73a",
    "url": "https://www.semanticscholar.org/paper/32f320a17953901198de9f945356a5e99340f73a",
    "title": "Meta-Learning Empowered Graph Neural Networks for Radio Resource Management",
    "year": 2024,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2408.16239",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2408.16239, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2256137671",
        "name": "Kai Huang"
      },
      {
        "authorId": "144362942",
        "name": "Le Liang"
      },
      {
        "authorId": "2257043168",
        "name": "Xinping Yi"
      },
      {
        "authorId": "2279671803",
        "name": "Hao Ye"
      },
      {
        "authorId": "2257490459",
        "name": "Shi Jin"
      },
      {
        "authorId": "2189909175",
        "name": "Geoffrey Ye Li"
      }
    ],
    "abstract": "In this paper, we consider a radio resource management (RRM) problem in the dynamic wireless networks, comprising multiple communication links that share the same spectrum resource. To achieve high network throughput while ensuring fairness across all links, we formulate a resilient power optimization problem with per-user minimum-rate constraints. We obtain the corresponding Lagrangian dual problem and parameterize all variables with neural networks, which can be trained in an unsupervised manner due to the provably acceptable duality gap. We develop a meta-learning approach with graph neural networks (GNNs) as parameterization that exhibits fast adaptation and scalability to varying network configurations. We formulate the objective of meta-learning by amalgamating the Lagrangian functions of different network configurations and utilize a first-order meta-learning algorithm, called Reptile, to obtain the meta-parameters. Numerical results verify that our method can efficiently improve the overall throughput and ensure the minimum rate performance. We further demonstrate that using the meta-parameters as initialization, our method can achieve fast adaptation to new wireless network configurations and reduce the number of required training data samples.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "c9be87af90f3a5ccf11fb0349f6633154b91364b",
    "url": "https://www.semanticscholar.org/paper/c9be87af90f3a5ccf11fb0349f6633154b91364b",
    "title": "Thermodynamics-informed graph neural networks for real-time simulation of digital human twins",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2412.12034, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2367424573",
        "name": "Lucas Tes\u00c3\u00a1n"
      },
      {
        "authorId": "2272614457",
        "name": "David Gonz\u00c3\u00a1lez"
      },
      {
        "authorId": "2335670891",
        "name": "Pedro Martins"
      },
      {
        "authorId": "2226778277",
        "name": "El\u00c3\u00adas Cueto"
      }
    ],
    "abstract": "The growing importance of real-time simulation in the medical field has exposed the limitations and bottlenecks inherent in the digital representation of complex biological systems. This paper presents a novel methodology aimed at advancing current lines of research in soft tissue simulation. The proposed approach introduces a hybrid model that integrates the geometric bias of graph neural networks with the physical bias derived from the imposition of a metriplectic structure as soft and hard constrains in the architecture, being able to simulate hepatic tissue with dissipative properties. This approach provides an efficient solution capable of generating predictions at high feedback rate while maintaining a remarkable generalization ability for previously unseen anatomies. This makes these features particularly relevant in the context of precision medicine and haptic rendering. Furthermore, this work synthesizes two prominent concepts in recent years: the role of message passing as a geometric mechanism fundamental to graph neural networks, and the potential of thermodynamics-informed networks to enhance extrapolation capabilities beyond training scenarios. We develop a multi-graph interaction between the computational model of the liver and a surgical tool. A displacement imposed at the contact region initiates a controlled flow of information that propagates throughout the graph model, aiming to achieve a steady and more efficient exchange of information across the entire network. The physics bias is obtained by imposing a metriplectic structure, enforced via strong and soft constraints. This ensures that the network satisfies thermodynamic principles during inference, even for a previously unseen system. Based on the adopted methodologies, we propose a model that predicts human liver responses to traction and compression loads in as little as 7.3 milliseconds for optimized configurations and as fast as 1.65 milliseconds in the most efficient cases, all in the forward pass. The model achieves relative position errors below 0.15%, with stress tensor and velocity estimations maintaining relative errors under 7%. This demonstrates the robustness of the approach developed, which is capable of handling diverse load states and anatomies effectively. This work highlights the feasibility of integrating real-time simulation with patient-specific geometries through deep learning, paving the way for more robust digital human twins in medical applications.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "ae183fd06b660181099f0740456577dc9f52fdf7",
    "url": "https://www.semanticscholar.org/paper/ae183fd06b660181099f0740456577dc9f52fdf7",
    "title": "SE(3)-equivariant Graph Neural Networks for Learning Glassy Liquids Representations",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2211.03226",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'abstract'}. Paper or abstract available at https://api.unpaywall.org/v2/10.48550/arXiv.2211.03226?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.48550/arXiv.2211.03226, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2164340624",
        "name": "F. S. Pezzicoli"
      },
      {
        "authorId": "2249162871",
        "name": "Guillaume Charpiat"
      },
      {
        "authorId": "2257176538",
        "name": "Fran\u00c3\u00a7ois P. Landes"
      }
    ],
    "abstract": null,
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "b754eabdcbf695cae6eaaac8c5e50c996e19ba26",
    "url": "https://www.semanticscholar.org/paper/b754eabdcbf695cae6eaaac8c5e50c996e19ba26",
    "title": "Rotation-equivariant graph neural networks for learning glassy liquids representations",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://scipost.org/10.21468/SciPostPhys.16.5.136/pdf",
      "status": "GOLD",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2211.03226, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2164340624",
        "name": "F. S. Pezzicoli"
      },
      {
        "authorId": "1926165",
        "name": "G. Charpiat"
      },
      {
        "authorId": "2257176538",
        "name": "Fran\u00c3\u00a7ois P. Landes"
      }
    ],
    "abstract": "The difficult problem of relating the static structure of glassy liquids and their dynamics is a good target for Machine Learning, an approach which excels at finding complex patterns hidden in data. Indeed, this approach is currently a hot topic in the glassy liquids community, where the state of the art consists in Graph Neural Networks (GNNs), which have great expressive power but are heavy models and lack interpretability. Inspired by recent advances in the field of Machine Learning group-equivariant representations, we build a GNN that learns a robust representation of the glass\u00e2\u0080\u0099 static structure by constraining it to preserve the roto-translation (SE(3)) equivariance. We show that this constraint significantly improves the predictive power at comparable or reduced number of parameters but most importantly, improves the ability to generalize to unseen temperatures. While remaining a Deep network, our model has improved interpretability compared to other GNNs, as the action of our basic convolution layer relates directly to well-known rotation-invariant expert features. Through transfer-learning experiments displaying unprecedented performance, we demonstrate that our network learns a robust representation, which allows us to push forward the idea of a learned structural order parameter for glasses.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "4d74f9322af338b874ed1d29cdc2c3b43fe4c568",
    "url": "https://www.semanticscholar.org/paper/4d74f9322af338b874ed1d29cdc2c3b43fe4c568",
    "title": "No prejudice! Fair Federated Graph Neural Networks for Personalized Recommendation",
    "year": 2023,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2312.10080, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2217512952",
        "name": "Nimesh Agrawal"
      },
      {
        "authorId": "2275054431",
        "name": "Anuj Kumar Sirohi"
      },
      {
        "authorId": "2230346286",
        "name": "Jayadeva"
      },
      {
        "authorId": "2275226493",
        "name": "Sandeep Kumar"
      }
    ],
    "abstract": "Ensuring fairness in Recommendation Systems (RSs) across demographic groups is critical due to the increased integration of RSs in applications such as personalized healthcare, finance, and e-commerce. Graph-based RSs play a crucial role in capturing intricate higher-order interactions among entities. However, integrating these graph models into the Federated Learning (FL) paradigm with fairness constraints poses formidable challenges as this requires access to the entire interaction graph and sensitive user information (such as gender, age, etc.) at the central server. This paper addresses the pervasive issue of inherent bias within RSs for different demographic groups without compromising the privacy of sensitive user attributes in FL environment with the graph-based model. To address the group bias, we propose F2PGNN (Fair Federated Personalized Graph Neural Network), a novel framework that leverages the power of Personalized Graph Neural Network (GNN) coupled with fairness considerations. Additionally, we use differential privacy techniques to fortify privacy protection. Experimental evaluation on three publicly available datasets showcases the efficacy of F2PGNN in mitigating group unfairness by 47% \u00e2\u0088\u00bc 99% compared to the state-of-the-art while preserving privacy and maintaining the utility. The results validate the significance of our framework in achieving equitable and personalized recommendations using GNN within the FL landscape. Source code is at: https://github.com/nimeshagrawal/F2PGNN-AAAI24",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "8c78869a269ee3ade35da1853cd6908db9cd6370",
    "url": "https://www.semanticscholar.org/paper/8c78869a269ee3ade35da1853cd6908db9cd6370",
    "title": "Offline-Online Learning of Deformation Model for Cable Manipulation With Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2203.15004",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2203.15004, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2146408590",
        "name": "Changhao Wang"
      },
      {
        "authorId": "2155337190",
        "name": "Yuyou Zhang"
      },
      {
        "authorId": "2189313357",
        "name": "Xiang Zhang"
      },
      {
        "authorId": "2215892556",
        "name": "Zheng Wu"
      },
      {
        "authorId": "8362363",
        "name": "Xinghao Zhu"
      },
      {
        "authorId": "1491175308",
        "name": "Shiyu Jin"
      },
      {
        "authorId": "2534107",
        "name": "Te Tang"
      },
      {
        "authorId": "1680165",
        "name": "M. Tomizuka"
      }
    ],
    "abstract": "Manipulating deformable linear objects by robots has a wide range of applications, e.g., manufacturing and medical surgery. To complete such tasks, an accurate dynamics model for predicting the deformation is critical for robust control. In this letter, we deal with this challenge by proposing a hybrid offline-online method to learn the dynamics of cables in a robust and data-efficient manner. In the offline phase, we adopt Graph Neural Network (GNN) to learn the deformation dynamics purely from the simulation data. Then a linear residual model is learned in real-time to bridge the sim-to-real gap. The learned model is then utilized as the dynamics constraint of a trust region based Model Predictive Controller (MPC) to calculate the optimal robot movements. The online learning and MPC run in a closed-loop manner to robustly accomplish the task. Finally, comparative results with existing methods are provided to quantitatively show the effectiveness and robustness.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "dfc64d868b7b257a38e402896bb9b1c223864139",
    "url": "https://www.semanticscholar.org/paper/dfc64d868b7b257a38e402896bb9b1c223864139",
    "title": "Fine-Tuning Graph Neural Networks via Graph Topology induced Optimal Transport",
    "year": 2022,
    "openAccessPdf": {
      "url": "http://arxiv.org/pdf/2203.10453",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2203.10453, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2107966843",
        "name": "Jiying Zhang"
      },
      {
        "authorId": "2153019995",
        "name": "Xi Xiao"
      },
      {
        "authorId": "2957079",
        "name": "Long-Kai Huang"
      },
      {
        "authorId": "48537464",
        "name": "Yu Rong"
      },
      {
        "authorId": "2419616",
        "name": "Yatao Bian"
      }
    ],
    "abstract": "Recently, the pretrain-finetuning paradigm has attracted tons of attention in graph learning community due to its power of alleviating the lack of labels problem in many real-world applications. Current studies use existing techniques, such as weight constraint, representation constraint, which are derived from images or text data, to transfer the invariant knowledge from the pre-train stage to fine-tuning stage. However, these methods failed to preserve invariances from graph structure and Graph Neural Network (GNN) style models. In this paper, we present a novel optimal transport-based fine-tuning framework called GTOT-Tuning, namely, Graph Topology induced Optimal Transport fine-Tuning, for GNN style backbones. GTOT-Tuning is required to utilize the property of graph data to enhance the preservation of representation produced by fine-tuned networks. Toward this goal, we formulate graph local knowledge transfer as an Optimal Transport (OT) problem with a structural prior and construct the GTOT regularizer to constrain the fine-tuned model behaviors. By using the adjacency relationship amongst nodes, the GTOT regularizer achieves node-level optimal transport procedures and reduces redundant transport procedures, resulting in efficient knowledge transfer from the pre-trained models. We evaluate GTOT-Tuning on eight downstream tasks with various GNN backbones and demonstrate that it achieves state-of-the-art fine-tuning performance for GNNs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "99ec4cad0f17f25f5b3c1f9be7de25868901943b",
    "url": "https://www.semanticscholar.org/paper/99ec4cad0f17f25f5b3c1f9be7de25868901943b",
    "title": "Labeling Trick: A Theory of Using Graph Neural Networks for Multi-Node Representation Learning",
    "year": 2020,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2010.16103, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "1390814008",
        "name": "Muhan Zhang"
      },
      {
        "authorId": "1561672016",
        "name": "Pan Li"
      },
      {
        "authorId": "35846319",
        "name": "Yinglong Xia"
      },
      {
        "authorId": "2148897943",
        "name": "Kai Wang"
      },
      {
        "authorId": "2115288815",
        "name": "Long Jin"
      }
    ],
    "abstract": "In this paper, we provide a theory of using graph neural networks (GNNs) for multi-node representation learning (where we are interested in learning a representation for a set of more than one node, such as link). We know that GNN is designed to learn single-node representations. When we want to learn a node set representation involving multiple nodes, a common practice in previous works is to directly aggregate the single-node representations obtained by a GNN into a joint node set representation. In this paper, we show a fundamental constraint of such an approach, namely the inability to capture the dependence between nodes in the node set, and argue that directly aggregating individual node representations does not lead to an effective joint representation for multiple nodes. Then, we notice that a few previous successful works for multi-node representation learning, including SEAL, Distance Encoding, and ID-GNN, all used node labeling. These methods first label nodes in the graph according to their relationships with the target node set before applying a GNN. Then, the node representations obtained in the labeled graph are aggregated into a node set representation. By investigating their inner mechanisms, we unify these node labeling techniques into a single and most general form -- labeling trick. We prove that with labeling trick a sufficiently expressive GNN learns the most expressive node set representations, thus in principle solves any joint learning tasks over node sets. Experiments on one important two-node representation learning task, link prediction, verified our theory. Our work explains the superior performance of previous node-labeling-based methods, and establishes a theoretical foundation of using GNNs for multi-node representation learning.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "9412ccb10351cd62f3cebc35f3847b5514885d96",
    "url": "https://www.semanticscholar.org/paper/9412ccb10351cd62f3cebc35f3847b5514885d96",
    "title": "Unsupervised Optimal Power Flow Using Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "https://arxiv.org/pdf/2210.09277",
      "status": "GREEN",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2210.09277, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "73773424",
        "name": "Damian Owerko"
      },
      {
        "authorId": "145682863",
        "name": "Fernando Gama"
      },
      {
        "authorId": "152551711",
        "name": "Alejandro Ribeiro"
      }
    ],
    "abstract": "Optimal power flow is a critical optimization problem that allocates power to the generators in order to satisfy the demand at a minimum cost. This is a non-convex problem shown to be NP-hard. We use a graph neural network to learn a nonlinear function between the power demanded and the corresponding allocation. We learn the solution in an unsupervised manner, minimizing the cost directly. To consider the power system constraints, we propose a novel barrier method that is differentiable and works on initially infeasible points. We show through simulations that the use of graph neural networks in this unsupervised learning context leads to solutions comparable to standard solvers while being computationally efficient and avoiding constraint violations.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "5e9d280a24c196cbdd4031be6d12cde80b612a6e",
    "url": "https://www.semanticscholar.org/paper/5e9d280a24c196cbdd4031be6d12cde80b612a6e",
    "title": "Contaminant Transport Modeling and Source Attribution With Attention\u00e2\u0080\u0090Based Graph Neural Network",
    "year": 2024,
    "openAccessPdf": {
      "url": "https://doi.org/10.1029/2023wr035278",
      "status": "HYBRID",
      "license": "CCBY",
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1029/2023WR035278?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1029/2023WR035278, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2304606136",
        "name": "Min Pang"
      },
      {
        "authorId": "113652426",
        "name": "E. Du"
      },
      {
        "authorId": "2089142118",
        "name": "Chunmiao Zheng"
      }
    ],
    "abstract": "Groundwater contamination induced by anthropogenic activities has long been a global issue. Characterizing and modeling contaminant transport processes is crucial to groundwater protection and management. However, challenges still exist in process complexity, data constraint, and computational cost. In the era of big data, the growth of machine learning has led to new opportunities in studying contaminant transport in groundwater systems. In this work, we introduce a new attention\u00e2\u0080\u0090based graph neural network (aGNN) for modeling contaminant transport with limited monitoring data and quantifying causal connections between contaminant sources (drivers) and their spreading (outcomes). In five synthetic case studies that involve varying monitoring networks in heterogeneous aquifers, aGNN is shown to outperform LSTM\u00e2\u0080\u0090based (long\u00e2\u0080\u0090short term memory) and CNN\u00e2\u0080\u0090 based (convolutional neural network) methods in multistep predictions (i.e., transductive learning). It also demonstrates a high level of applicability in inferring observations for unmonitored sites (i.e., inductive learning). Furthermore, an explanatory analysis based on aGNN quantifies the influence of each contaminant source, which has been validated by a physics\u00e2\u0080\u0090based model with consistent outcomes with an R2 value exceeding 92%. The major advantage of aGNN is that it not only has a high level of predictive power in multiple scenario evaluations but also substantially reduces computational cost. Overall, this study shows that aGNN is efficient and robust for highly nonlinear spatiotemporal learning in subsurface contaminant transport, and provides a promising tool for groundwater management involving contaminant source attribution.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "786f1a4ae2b6037b0c66701e1881bb2ff5746082",
    "url": "https://www.semanticscholar.org/paper/786f1a4ae2b6037b0c66701e1881bb2ff5746082",
    "title": "xNet: Improving Expressiveness and Granularity for Network Modeling with Graph Neural Networks",
    "year": 2022,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/INFOCOM48880.2022.9796726?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/INFOCOM48880.2022.9796726, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2109018752",
        "name": "Mowei Wang"
      },
      {
        "authorId": "2171775182",
        "name": "Linbo Hui"
      },
      {
        "authorId": "2149069358",
        "name": "Yong Cui"
      },
      {
        "authorId": "121330209",
        "name": "Ru Liang"
      },
      {
        "authorId": "50851621",
        "name": "Zhen Liu"
      }
    ],
    "abstract": "Today\u00e2\u0080\u0099s network is notorious for its complexity and uncertainty. Network operators often rely on network models to achieve efficient network planning, operation, and optimization. The network model is responsible for understanding the complex relationships between the network performance metrics (e.g., latency) and the network characteristics (e.g., traffic). However, we still lack a systematic approach to developing accurate and lightweight network models that are aware of the impact of network configurations (i.e., expressiveness) and provide fine-grained flow-level temporal predictions (i.e., granularity).In this paper, we propose xNet, a data-driven network modeling framework based on graph neural networks (GNN). Unlike the previous proposals, xNet is not a dedicated network model designed for specific network scenarios with constraint considerations. On the contrary, xNet provides a general approach to modeling the network characteristics of concern with relation graph representations and configurable GNN blocks. xNet learns the state transition function between time steps and rolls it out to obtain the full fine-grained prediction trajectory. We implement and instantiate xNet with three use cases. The experiment results show that xNet can accurately predict different performance metrics while achieving over two orders of magnitude of speedup compared with the conventional packet-level simulator.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "8967cc60bb838327e450f11bd9ce07767ea541b5",
    "url": "https://www.semanticscholar.org/paper/8967cc60bb838327e450f11bd9ce07767ea541b5",
    "title": "Improving Expressive Power of Spectral Graph Neural Networks with Eigenvalue Correction",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2401.15603, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2281746766",
        "name": "Kangkang Lu"
      },
      {
        "authorId": "2281950230",
        "name": "Yanhua Yu"
      },
      {
        "authorId": "46959445",
        "name": "Hao Fei"
      },
      {
        "authorId": "2281758294",
        "name": "Xuan Li"
      },
      {
        "authorId": "2281790155",
        "name": "Zixuan Yang"
      },
      {
        "authorId": "2281799094",
        "name": "Zirui Guo"
      },
      {
        "authorId": "2281749687",
        "name": "Meiyu Liang"
      },
      {
        "authorId": "2184849566",
        "name": "Mengran Yin"
      },
      {
        "authorId": "2281747744",
        "name": "Tat-Seng Chua"
      }
    ],
    "abstract": "In recent years, spectral graph neural networks, characterized by polynomial filters, have garnered increasing attention and have achieved remarkable performance in tasks such as node classification. These models typically assume that eigenvalues for the normalized Laplacian matrix are distinct from each other, thus expecting a polynomial filter to have a high fitting ability. However, this paper empirically observes that normalized Laplacian matrices frequently possess repeated eigenvalues. Moreover, we theoretically establish that the number of distinguishable eigenvalues plays a pivotal role in determining the expressive power of spectral graph neural networks. In light of this observation, we propose an eigenvalue correction strategy that can free polynomial filters from the constraints of repeated eigenvalue inputs. Concretely, the proposed eigenvalue correction strategy enhances the uniform distribution of eigenvalues, thus mitigating repeated eigenvalues, and improving the fitting capacity and expressive power of polynomial filters. Extensive experimental results on both synthetic and real-world datasets demonstrate the superiority of our method.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f73a134981fb90080fbe07236c290e56c8ca44ca",
    "url": "https://www.semanticscholar.org/paper/f73a134981fb90080fbe07236c290e56c8ca44ca",
    "title": "AutoSGNN: Automatic Propagation Mechanism Discovery for Spectral Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2412.12483, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2335667914",
        "name": "Shibing Mo"
      },
      {
        "authorId": "2326813714",
        "name": "Kai Wu"
      },
      {
        "authorId": "2336015051",
        "name": "Qixuan Gao"
      },
      {
        "authorId": "152455987",
        "name": "Xiangyi Teng"
      },
      {
        "authorId": "2296488473",
        "name": "Jing Liu"
      }
    ],
    "abstract": "In real-world applications, spectral Graph Neural Networks (GNNs) are powerful tools for processing diverse types of graphs. However, a single GNN often struggles to handle different graph types-such as homogeneous and heterogeneous graphs-simultaneously. This challenge has led to the manual design of GNNs tailored to specific graph types, but these approaches are limited by the high cost of labor and the constraints of expert knowledge, which cannot keep up with the rapid growth of graph data. To overcome these challenges, we propose AutoSGNN, an automated framework for discovering propagation mechanisms in spectral GNNs. AutoSGNN unifies the search space for spectral GNNs by integrating large language models with evolutionary strategies to automatically generate architectures that adapt to various graph types. Extensive experiments on nine widely-used datasets, encompassing both homophilic and heterophilic graphs, demonstrate that AutoSGNN outperforms state-of-the-art spectral GNNs and graph neural architecture search methods in both performance and efficiency.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "56e9c89fcafa950a353b5c67a66ecba4541c613d",
    "url": "https://www.semanticscholar.org/paper/56e9c89fcafa950a353b5c67a66ecba4541c613d",
    "title": "Enhancing Locally Adaptive Smoothing of Graph Neural Networks Via Laplacian Node Disagreement",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/TKDE.2023.3303212?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/TKDE.2023.3303212, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2153607346",
        "name": "Yu Wang"
      },
      {
        "authorId": "2118847803",
        "name": "Liang Hu"
      },
      {
        "authorId": "48811990",
        "name": "Xiaofeng Cao"
      },
      {
        "authorId": "2112613807",
        "name": "Yi Chang"
      },
      {
        "authorId": "1807998",
        "name": "I. Tsang"
      }
    ],
    "abstract": "Graph neural networks (GNNs) are designed to perform inference on data described by graph-structured node features and topology information. From the perspective of graph signal denoising, the typical message passing schemes of GNNs act as a globally uniform smoothing that minimizes disagreements between embeddings of connected nodes. However, the level of smoothing over different regions of the graph should be different, especially for those inter-class regions. This deviation limits the expressiveness of GNNs, and then renders them fragile to over-smoothing, long-range dependencies, and non-homophily settings. In this paper, we find that the node disagreements of initial graph features can present more trustworthy constraints on node embeddings, thereby enhancing the locally adaptive smoothing of GNNs. To spread the inherent disagreements of nodes, we propose the Laplacian node disagreement to jointly measure the initial features and output embeddings. With such a measurement, we then present a new graph signal denoising objective deriving a more effective message passing scheme and further incorporate it into the GNN architecture, named Laplacian node disagreement-based GNN (LND-GNN). Learning from its output node representations, we integrate an auxiliary disagreement constraint into the overall classification loss. Experiments demonstrate the expressive ability of LND-GNN in the downstream semi-supervised node classification task.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "f4cc45ec72473a93c9393128370208b45d91b2b3",
    "url": "https://www.semanticscholar.org/paper/f4cc45ec72473a93c9393128370208b45d91b2b3",
    "title": "Phonon predictions with E(3)-equivariant graph neural networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2403.11347, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2283269138",
        "name": "Shiang Fang"
      },
      {
        "authorId": "2253522157",
        "name": "Mario Geiger"
      },
      {
        "authorId": "2252939384",
        "name": "J. G. Checkelsky"
      },
      {
        "authorId": "5485763",
        "name": "T. Smidt"
      }
    ],
    "abstract": "We present an equivariant neural network for predicting vibrational and phonon modes of molecules and periodic crystals, respectively. These predictions are made by evaluating the second derivative Hessian matrices of the learned energy model that is trained with the energy and force data. Using this method, we are able to efficiently predict phonon dispersion and the density of states for inorganic crystal materials. For molecules, we also derive the symmetry constraints for IR/Raman active modes by analyzing the phonon mode irreducible representations. Additionally, we demonstrate that using Hessian as a new type of higher-order training data improves energy models beyond models that only use lower-order energy and force data. With this second derivative approach, one can directly relate the energy models to the experimental observations for the vibrational properties. This approach further connects to a broader class of physical observables with a generalized energy model that includes external fields.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "73a5755392c52808ed18d3595227fff8f0dee82e",
    "url": "https://www.semanticscholar.org/paper/73a5755392c52808ed18d3595227fff8f0dee82e",
    "title": "Low Earth Orbit Satellite Network Routing Algorithm Based on Graph Neural Networks and Deep Q-Network",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.3390/app14093840?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.3390/app14093840, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2118759323",
        "name": "Yuan Shi"
      },
      {
        "authorId": "2299728687",
        "name": "Weian Wang"
      },
      {
        "authorId": "2261046072",
        "name": "Xiaorong Zhu"
      },
      {
        "authorId": "2237948264",
        "name": "Hongbo Zhu"
      }
    ],
    "abstract": "Low Earth orbit (LEO) satellite networks are characterized by rapid topological changes, numerous network nodes and varying states of node resource constraints, which have resulted in traditional routing algorithms no longer being suitable for LEO satellite network routing. Therefore, this paper proposes an inductive learning architecture based on Graph Sample and Aggregate (GraphSAGE), which can significantly reduce the number of topology nodes to be trained, thereby reducing the computational complexity of the nodes. Then deep reinforcement learning (DRL) is employed for the continuous learning optimization of routing algorithms, and its generalization is improved by selecting GraphSAGE to construct the DRL agent. In the proposed graph neural-network-based routing optimization algorithm for LEO satellite networks, each Deep Q-Network (DQN) agent independently generates the hidden states of the nodes through the GraphSAGE model and uses them as inputs to the DRL model to make routing decisions. After a simulation and comparison, the proposed algorithm not only improves the overall network throughput, but also reduces the average end-to-end delay. The average throughput of the proposed algorithm increases by 29.47% and 18.42% compared to that of Dijkstra and the DQN, respectively. The average end-to-end delay is reduced by 39.76% and 15.29%, respectively, and can also adapt to changing topologies.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "ec67e840b9deeff5a9f1ed7e103369a3b82d3131",
    "url": "https://www.semanticscholar.org/paper/ec67e840b9deeff5a9f1ed7e103369a3b82d3131",
    "title": "Digital Twin-Assisted Multiview Reconstruction Enhanced Domain Adaptation Graph Networks for Aero-Engine Gas Path Fault Diagnosis",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1109/JSEN.2024.3400249?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1109/JSEN.2024.3400249, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2218991030",
        "name": "Changyi Xu"
      },
      {
        "authorId": "2267050365",
        "name": "Xuecheng Gui"
      },
      {
        "authorId": "2302110873",
        "name": "Ying Zhao"
      }
    ],
    "abstract": "This article proposes a digital twin (DT)-assisted multiview reconstruction enhanced domain adaptation graph networks (MRDANs) to improve the diagnostic accuracy and adaptability to performance degradation of the aero-engines gas path system (AGPS). First, the DT model with sufficient multicondition data to lay the foundation for subsequent experiments is obtained. Then, convolutional neural networks (CNNs) are used to expand the view of multiple feature spaces. Further, a graph-based multiview reconstruction (MR) method is designed for feature extraction. This approach simultaneously considers the topology and node feature on the graph by constructing a learnable adjacency matrix to tune the topology in the reconstructed graph and placing random walk kernels on different graphs. Next, graph neural network (GNN) is used to perform feature extraction on the reconstructed graph, while the proposed feature harmonized constraint (FHC) is combined with domain adaptation. Finally, the comparison experiment is given, exhibiting that, the proposed framework performs better fault feature extraction ability and domain transfer ability in gas path fault diagnosis.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "165288c93cf6b1f9a7f19fa92b0a114b662e9733",
    "url": "https://www.semanticscholar.org/paper/165288c93cf6b1f9a7f19fa92b0a114b662e9733",
    "title": "On Representing Convex Quadratically Constrained Quadratic Programs via Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://arxiv.org/abs/2411.13805, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2331798569",
        "name": "Chenyang Wu"
      },
      {
        "authorId": "2304763598",
        "name": "Qian Chen"
      },
      {
        "authorId": "2327001725",
        "name": "Akang Wang"
      },
      {
        "authorId": "2287824247",
        "name": "Tian Ding"
      },
      {
        "authorId": "2324219295",
        "name": "Ruoyu Sun"
      },
      {
        "authorId": "2331796472",
        "name": "Wenguo Yang"
      },
      {
        "authorId": "2327325924",
        "name": "Qingjiang Shi"
      }
    ],
    "abstract": "Convex quadratically constrained quadratic programs (QCQPs) involve finding a solution within a convex feasible region defined by quadratic constraints while minimizing a convex quadratic objective function. These problems arise in various industrial applications, including power systems and signal processing. Traditional methods for solving convex QCQPs primarily rely on matrix factorization, which quickly becomes computationally prohibitive as the problem size increases. Recently, graph neural networks (GNNs) have gained attention for their potential in representing and solving various optimization problems such as linear programs and linearly constrained quadratic programs. In this work, we investigate the representation power of GNNs in the context of QCQP tasks. Specifically, we propose a new tripartite graph representation for general convex QCQPs and properly associate it with message-passing GNNs. We demonstrate that there exist GNNs capable of reliably representing key properties of convex QCQPs, including feasibility, optimal value, and optimal solution. Our result deepens the understanding of the connection between QCQPs and GNNs, paving the way for future machine learning approaches to efficiently solve QCQPs.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "4792cc41a599001e04e11a6789172852a45bbea1",
    "url": "https://www.semanticscholar.org/paper/4792cc41a599001e04e11a6789172852a45bbea1",
    "title": "Advancing 2D material predictions: superior work function estimation with atomistic line graph neural networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": null,
      "license": "CCBYNC",
      "disclaimer": "Notice: Paper or abstract available at https://pmc.ncbi.nlm.nih.gov/articles/PMC11605676, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2333065741",
        "name": "Harikrishnan Sibi"
      },
      {
        "authorId": "2310621784",
        "name": "Jovita Biju"
      },
      {
        "authorId": "2302312127",
        "name": "Chandra Chowdhury"
      }
    ],
    "abstract": "Despite the increased research and scholarly attention on two-dimensional (2D) materials, there is still a limited range of practical applications for these materials. This is because it is challenging to acquire properties that are usually obtained by experiments or first-principles predictions, which require substantial time and resources. Descriptor-based machine learning models frequently require further density functional theory (DFT) calculations to enhance prediction accuracy due to the intricate nature of the systems and the constraints of the descriptors employed. Unlike these models, research has demonstrated that graph neural networks (GNNs), which solely rely on the systems' coordinates for model description, greatly improve the ability to represent and simulate atomistic materials. Within this framework, we employed the Atomistic Line Graph Neural Network (ALIGNN) to predict the work function, a crucial material characteristic, for a diverse array of 2D materials sourced from the Computational 2D Materials Database (C2DB). We found that the ALIGNN algorithm shows superior performance compared to standard feature-based approaches. It attained a mean absolute error of 0.20 eV, whereas random forest models achieved 0.27 eV.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  },
  {
    "paperId": "96080034af6f0d846a080a8e1a37d61cf07aabfa",
    "url": "https://www.semanticscholar.org/paper/96080034af6f0d846a080a8e1a37d61cf07aabfa",
    "title": "Dynamic Service Function Chaining Provisioning with Reinforcement Learning Graph Neural Networks",
    "year": 2024,
    "openAccessPdf": {
      "url": "",
      "status": "CLOSED",
      "license": null,
      "disclaimer": "Notice: Paper or abstract available at https://api.unpaywall.org/v2/10.1145/3694811.3697824?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1145/3694811.3697824, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
    },
    "authors": [
      {
        "authorId": "2268686950",
        "name": "Brigitte Jaumard"
      },
      {
        "authorId": "2315149235",
        "name": "Charles Boudreau"
      },
      {
        "authorId": "2781285",
        "name": "Emil Janulewicz"
      }
    ],
    "abstract": "The Service Function Chain (SFC) provisioning problem in a 5G/B5G network corresponds to the routing of service requests through an ordered list of virtualized network functions (VNFs) while respecting network/computing resource, and delay/bandwidth constraints. This study proposes a solution to this problem through the use of Deep Reinforcement Learning (Deep-RL) and Graph Neural Networks (GNNs). The latter ones are first explored with Graph Convolutional Network (GCN) and then with Graph Attention Networks (GATs) which leverage attention mechanisms for feature learning on graphs. Experiments are conducted on large graphs with up to 200 nodes. GNN (both GCN and GAT) solutions compare very favorably to a similar agent employing a fully-connected network at its core, as they require less data to learn better and faster the topology, with GAT improving over GCN.",
    "vllm_relevant": false,
    "openrouter_relevant": false,
    "models_agree": true
  }
]