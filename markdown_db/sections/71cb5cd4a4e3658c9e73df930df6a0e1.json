{
  "sections": {
    "neural_approaches_to_sat_solving_design_choices_an": "## Introduction\n\n\nApart from the RNN- based update functions, we also experiment with LSTM- based update functions which have been used in the original Neuro SAT architecture Selsam et al. [2018]. The LSTM- based updates follow a similar pattern but maintain an additional cell state alongside the hidden state. In Section 5.2 we show that different update functions are suitable for different settings. After each update step, we apply L2 normalization to all node embeddings to stabilize training: \\[\\mathbf{h}_{i}^{(t)} = \\frac{\\mathbf{h}_{i}^{(t)}}{\\|\\mathbf{h}_{i}^{(t)}\\|_{2}} \\quad (11)\\] Node classification After \\(T\\) iterations of message passing, we use the final node embeddings to predict variable assignments. For the variable- clause graph, we apply a linear layer to each variable embedding to produce two logits (representing scores for value true and false): \\(\\mathbf{y}_{v} = \\mathbf{W}\\mathbf{h}_{v}^{(T)} + \\mathbf{b}\\) . The assignment is then determined by applying softmax and taking the argmax: \\(\\hat{a}_{v} = \\arg \\max_{i}(\\mathrm{softmax}(\\mathbf{y}_{v})_{i})\\) . For the literal- clause graph, we focus on the embeddings of positive literals only, as they directly correspond to variables. During training, we use cross- entropy loss between these predicted assignments and the ground truth assignments. For satisfiability prediction, we can determine whether a formula is satisfiable by checking if the predicted assignment satisfies all clauses. The model is thus trained to find assignments that minimize the number of unsatisfied clauses, effectively solving the Max SAT problem even when trained only with assignment supervision. ### 4.3 Supervision Tasks and Objectives There are several obvious supervision objectives and prediction tasks which can be used to train the model. The original Neuro SAT model was trained to predict the satisfiability status of a given formula using binary cross- entropy. Later, several authors tried different training tasks and objectives which have been summarized in a review paper by Li et al. Li et al. [2023]. We reimplement these objective and task for our setup and also introduce a novel training objective which in certain settings results in significant improvements of the model performance. These objective are briefly described below. Satisfiability Classification This is the task which was used by Selsam et al. [2018] for training the original Neuro SAT architecture. The model is trained to predict whether the formula is satisfiable or not through graph- level embedding aggregation using global mean pooling. The loss is computed by binary cross- entropy between the prediction \\(\\hat{y}\\) and ground truth \\(y\\in \\{0,1\\}\\) .. \\(\\mathcal{L}_{\\mathrm{sat}} = -(y\\log \\hat{y} +(1 - y)\\log (1 - \\hat{y}))\\) Unsupervised Training For unsupervised training, we define the loss using clause validity Ozolins et al. [2022], where \\(\\hat{x}_{i}\\) represents the model's predicted continuous probability of a variable being true: \\[V_{c}(\\hat{x}) = 1 - \\prod_{i\\in c^{+}}(1 - \\hat{x}_{i})\\prod_{i\\in c^{-}}\\hat{x}_{i},\\quad \\mathcal{L}_{\\phi}(\\hat{x}) = -\\sum_{c\\in \\phi}\\log (V_{c}(\\hat{x})), \\quad (12)\\] where \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in clause \\(c\\) in positive and negative form respectively. This loss reaches its minimum only when the prediction \\(\\hat{x}\\) is a satisfying assignment. We note that alternative unsupervised formulations exist Amizadeh et al. [2018], and comprehensive evaluations reported by Li et al. Li et al. [2023] suggest that these two different\n\napproaches perform similarly in practice. Another training option would be to directly optimize a convex loss function derived from SDP relaxation, but this approach is limited because SDP formulations work well for MAX- 2- SAT and can be extended to MAX- 3- SAT, but become increasingly difficult to formulate for general Max SAT problems with larger clauses. Assignment Prediction For satisfiable formulas, we can train the model to predict the satisfiable variable assignments directly. We tried to use either mean squared error or cross- entropy loss between the predicted assignments and the ground truth assignments: \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{MSE}} =\\) \\(\\| \\hat{a} - x\\|_{2}^{2}\\) and \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{CE}} = - \\sum_{i}x_{i}\\log \\hat{x}_{i} + (1 - x_{i})\\log (1 - \\hat{x}_{i})\\) where \\(x\\) is the ground truth assignment and \\(\\hat{a},\\hat{x}\\) are the predicted assignments which differ by application of softmax (i.e. \\(\\hat{a}\\) are just logits without a softmax applied). Closest Assignment Training One problem with assignment prediction is that satisfiable formulas can have a lot of solution and the network is penalized even if it predicts satisfiable solution which differs from the one which is used as a ground truth. We therefore introduce a novel supervision method which uses a Max SAT solver to always compute the solution which is closest to the solution predicted by the model. We then update then model with respect to this solution. In Section 5.2, we show that this method works particularly well when the solution space is large. For each formula in a batch, a valid assignments that minimize the Hamming distance to the model's current predictions is found by the RC2 Max SAT solver. For satisfiable formulas it finds an assignment that satisfies all clauses while being closest to current prediction. For unsatisfiable formulas, it finds an assignment that maximizes the number of satisfied clauses while minimizing distance to prediction. This approach allows the model to explore different regions of the solution space while maintaining valid solutions for SAT instances or optimal partial solutions for UNSAT instances. The supervision signal adapts to the model's current state rather than forcing it toward a single pre- determined assignment. The disadvantage of this method is that the computation of the loss is slower then with the precomputed solution. This could be solved by pre- computing solutions or by using an approximate Max SAT solver. SAT- Only Instance Filtering After initially training with both satisfiable and unsatisfiable instances, we experimented with formula- type specialization by restricting training to only satisfiable instances. In Table 3, we show that this filtering can lead to higher accuracy of the trained model. ### 4.4 Benchmarks and Data Generation We utilize two complementary benchmark generators for evaluating the tested variants: the SR generator and a 3- SAT generator with the ratio between variable and clauses set close to the phase transition point. SR Generator The SR generator by Selsam et al. [Selsam et al., 2018] produces pairs of satisfiable and unsatisfiable formulas that differ by negating only a single literal. This design specifically prevents models from exploiting superficial features for classification. Intuitively, it works by iteratively sampling random clauses and adding them to a formula. After each addition, a SAT solver checks if the formula remains satisfiable. When adding a clause that finally makes the formula unsatisfiable, the generator saves this instance and creates its satisfiable counterpart by flipping a single literal in the last clause. To create each clause, it samples a small integer \\(k\\) based on a mix of Bernoulli and geometric distributions, then randomly selects \\(k\\) variables without replacement, negating each with 0.5 probability. This solver- driven approach ensures\n\nthat satisfiability classification requires understanding the logical structure rather than statistical properties. As reported in the review by Li et al. Li et al. [2023], the models trained on problems from this generator transfer the best to other problem distributions. 3- SAT Generator We also employ a 3- SAT generator configured at the critical clause- to- variable ratio of 4.26, known as the phase transition point where SAT problems are empirically the most challenging to solve [Crawford and Auton, 1996]. At this ratio, approximately half of the generated instances are satisfiable. Each clause contains exactly 3 literals selected uniformly from the available variables, with each literal negated with 0.5 probability. Unlike the SR generator, 3- SAT focuses on generating naturally difficult problems rather than explicitly preventing superficial feature learning. ## 5 Experimental Results ### 5.1 Training and Evaluation Methodology For training, we generate 50,000 instances: 25,000 pairs for SR and 50,000 instances for 3- SAT. We annotate each dataset by the maximum number of variables appearing in the training formulas. For SR, we test two variations, SR40 for which the training examples are sampled with 3- 40 variables and SR100 for which the training examples contain 10- 100 variables. For 3- SAT, the training samples contain 10- 100 variables (3SAT100). The SR dataset is well suited for training SAT/UNSAT prediction models due to its design that prevents learning from superficial features, making it harder for models to exploit statistical shortcuts rather than learning true logical reasoning. We also create versions of training data which contain only satisfiable instances (denoted SAT only). The size of these datasets is half of the original datasets (i.e. 25000 examples). To evaluate generalization, we validate exclusively on problems with exactly the maximum number of variables in each category, therefore SR40 for evaluation means that the problems have always exactly 40 variables (not a range of 3- 40), SR100 test contains only problems with exactly 100 variables, and so on.1 Table 1 summarizes the key statistics of our evaluation datasets. Table 1: Statistics of benchmark test sets. SAT% indicates the percentage of satisfiable instances in each dataset. Avg. Gap represents the average number of unsatisfied clauses when using random variable assignments. SAT Gap and UNSAT Gap show this metric separated by instance satisfiability. SR datasets are generated using the SR generator with the indicated number of variables (e.g., SR40 contains instances with 40 variables), while 3SAT datasets contain instances near the phase transition point with the specified number of variables. All datasets maintain a balanced distribution of satisfiable and unsatisfiable instances. <table><tr><td>Dataset</td><td>SAT%</td><td>Avg. Gap</td><td>SAT Gap</td><td>UNSAT Gap</td><td>Avg. Clauses</td></tr><tr><td>SR40</td><td>50.0%</td><td>21.29</td><td>21.59</td><td>20.99</td><td>228.40</td></tr><tr><td>SR100</td><td>50.0%</td><td>51.31</td><td>50.64</td><td>51.98</td><td>547.49</td></tr><tr><td>SR200</td><td>50.0%</td><td>100.31</td><td>101.03</td><td>99.59</td><td>1083.81</td></tr><tr><td>SR400</td><td>50.0%</td><td>198.74</td><td>198.53</td><td>198.95</td><td>2152.32</td></tr><tr><td>3SAT100</td><td>53.5%</td><td>52.78</td><td>53.00</td><td>52.54</td><td>426.00</td></tr><tr><td>3SAT200</td><td>55.5%</td><td>107.65</td><td>107.45</td><td>107.90</td><td>852.00</td></tr></table> The Gap metric represents the average number of unsatisfied clauses when using random\n\nvariable assignments. This metric has the same definition for both SAT and UNSAT instances; it simply counts how many clauses remain unsatisfied with random assignments on average. Larger gaps indicate more challenging problems where random guessing performs poorly. ### 5.2 Quantitative Evaluation We conducted a comprehensive evaluation that compares different architectural choices and supervision methods. Our evaluation focuses on five key performance metrics: - Average Gap: The average number of unsatisfied clauses across all test instances. Lower values indicate better performance, with 0 representing perfect satisfaction (i.e., no unsatisfied clauses) on satisfiable instances. For unsatisfiable instances, this metric reflects how close the model gets to minimizing unsatisfied clauses.- Gap on SAT: The average number of unsatisfied clauses computed only over satisfiable instances.- Gap on UNSAT: The average number of unsatisfied clauses computed only over unsatisfiable instances.- SAT Accuracy: The percentage of satisfiable instances for which the model correctly finds a satisfying assignment, computed only over satisfiable instances.- Decision Accuracy: The percentage of instances for which the model correctly predicts whether the formula is satisfiable. Since our approach does not formally refute unsatisfiable instances, we classify an instance as unsatisfiable when the model fails to find a satisfying assignment. This means unsatisfiable instances are always classified correctly under this assumption. This applies specifically in the case of assignment-based evaluation. #### 5.2.1 Comparison of Graph Representations, Update Functions and Training Methods Table 2 presents a comprehensive comparison of different architectural configurations trained exclusively on the SR40 dataset. This comparison includes different graph representations (Literal Clause Graph vs. Variable- Clause Graph), update functions (RNN vs. LSTM), and supervision approaches (SAT/UNSAT classification, assignment supervision, and unsupervised objective training), all evaluated on instances with 40 variables. All models were evaluated using Exponential Moving Average (EMA) of parameters during validation only, as detailed in A.1.2, which helps reduce fluctuations in validation metrics and provide more reliable model selection. Importantly, curriculum learning ( A.1.1) was employed only for training models with SAT/UNSAT classification objectives, as it proved unnecessary for models trained with assignment prediction or unsupervised learning approaches. Graph Representation Impact: Our results demonstrate that Literal- Clause Graph (LCG) and Variable- Clause Graph (VCG) representations exhibit different strengths. VCG shows better performance for assignment- based training with RNN updates, achieving a SAT accuracy of 68.8% compared to 48.6% for LCG. Additionally, VCG's more compact representation (using one node per variable rather than two for positive and negative literals) provides computational advantages for larger formulas, making it our preferred choice for scaling to more complex problems.\n\nMessage Passing Mechanism: While LSTM- based message passing shows advantages in some configurations, particularly for unsupervised training, we found that RNN- based approaches offer a better balance of performance and interpretability for assignment- based training. RNN updates with VCG representation achieved higher results for finding satisfying assignments, with \\(68.8\\%\\) SAT accuracy and \\(84.4\\%\\) decision accuracy. The simpler RNN structure also facilitates better analysis of the model's internal reasoning process. However, we found training RNN- based models for SAT/UNSAT classification particularly challenging, with LSTM being more stable for this specific task. Supervision Approach: Our experiments reveal distinct advantages for different supervision approaches: 1. Assignment-based supervision shows better performance for finding satisfying assignments, especially with VCG+RNN configuration (68.8% SAT accuracy, 84.4% decision accuracy). 2. Unsupervised learning achieves the lowest average gaps across configurations (as low as 0.91 for VCG+RNN and 0.84 for VCG+LSTM). This makes unsupervised training useful for applications where minimizing unsatisfied clauses is the priority. 3. SAT/UNSAT classification training, while challenging with RNN, enables an interesting property: models trained only for classification develop an implicit ability to separate embeddings for positive and negative literals. This separation allows for retrieving satisfying assignments through clustering techniques, despite the model not being explicitly trained for assignment prediction. Based on the results reported in Table 2, we identify the VCG+RNN+Assignment configuration as our most effective approach, offering a good balance between assignment accuracy and computational efficiency. This configuration forms the foundation for our further experiments and analysis in subsequent sections. Assignment Training Refinements: Table 3 highlights the impact of a novel training method we introduce, here called \"closest assignment\", with the VCG+RNN configuration across multiple datasets. This method computes assignments that minimize Hamming distance to the model's current predictions, showing improvements over training with precalculated assignments, especially for formulas with more variables. For SR100, using the closest assignment approach reduces the average gap from 3.81 to 1.43 for SAT+UNSAT training and improves SAT accuracy from 44.8% to 53.2%. This improvement correlates with the number of possible solutions in the benchmarks (SR10- 100 has a median of 16 solutions per formula compared to SR3- 40's median of 7), supporting our hypothesis that for formulas with larger solution spaces, guiding the model with dynamically selected assignments that align with its current predictions yields better generalization than using fixed predetermined assignments. The computational challenges of calculating closest assignments during training are noteworthy, particularly for larger benchmarks like 3SAT+UNSAT, where this approach became impractical and we therefore omit this experiment and leave the last row of Table 3 empty. It also highlights an opportunity for future work on more efficient approximation methods for finding near- optimal assignments. Training Data Composition: Our results also indicate that training exclusively on SAT instances (SAT only) improves performance for finding satisfying assignments. For SR40, this approach with closest assignment training achieves our highest SAT accuracy of 76% and decision accuracy of 88%. However, models trained on both SAT and UNSAT instances (SAT+UNSAT)\n\nwith closest assignment supervision demonstrate better gap minimization, achieving an average gap of 0.98 versus 2.68 for SAT- only training on SR40. Table 2: Performance comparison of GNN architectures for SAT solving on the SR40 dataset.The table compares Literal-Clause Graph (LCG) and Variable-Clause Graph (VCG) repre-sentations, RNN and LSTM update mechanisms, and different training objectives. Metrics include average gap (number of unsatisfied clauses) across all instances and separated by sat-isfiability status (lower is better), SAT accuracy (percentage of satisfiable instances solved by finding assignment), and decision accuracy (percentage of correct satisfiability predictions). No-table findings include: unsupervised training consistently achieves lowest gaps; VCG+RNN with assignment prediction shows highest SAT accuracy (68.8%); and RNN-based models with SAT/UNSAT classification proved challenging to train effectively (indicated by dashes). As-terisks (*) indicate results obtained through clustering of node embeddings rather than direct prediction. This model combination was particularly hard to train in our setup. We found that both for VCG and LCG RNN is very sensitive to hyper-parameter selection. As the model failed to get generalized in our final unified experimental setup we do not include this result (close to random performance) now. <table><tr><td>Graph</td><td>Update</td><td>Loss Function</td><td>Avg. Gap\u2193</td><td>Gap on SAT\u2193</td><td>Gap on UNSAT\u2193</td><td>SAT Acc.\u2191</td><td>Dec. Acc.\u2191</td></tr><tr><td rowspan=\"6\">LCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Assignment</td><td>1.83</td><td>1.25</td><td>2.41</td><td>48.6%</td><td>72.8%</td></tr><tr><td>Unsup</td><td>0.93</td><td>0.59</td><td>1.26</td><td>51.4%</td><td>75.7%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>1.96*</td><td>1.27*</td><td>2.62*</td><td>59.2%</td><td>83.9/79.6%</td></tr><tr><td>Assignment</td><td>1.82</td><td>1.06</td><td>2.58</td><td>56.8%</td><td>78.4%</td></tr><tr><td>Unsup</td><td>0.81</td><td>0.45</td><td>1.16</td><td>62%</td><td>81%</td></tr><tr><td rowspan=\"6\">VCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>3.62*</td><td>1.9*</td><td>5.34*</td><td>56.6%</td><td>80/78.3%</td></tr><tr><td>Assignment</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8%</td><td>84.4%</td></tr><tr><td>Unsup</td><td>0.91</td><td>0.58</td><td>1.23</td><td>51.6%</td><td>75.8%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>2.33*</td><td>1.57</td><td>3.08</td><td>52.2%</td><td>81.9/76.1%</td></tr><tr><td>Assignment</td><td>2.05</td><td>0.96</td><td>3.14</td><td>66.4%</td><td>83.2%</td></tr><tr><td>Unsup</td><td>0.84</td><td>0.51</td><td>1.17</td><td>56.4%</td><td>78.2%</td></tr></table> # 5.3 Test-time Scaling A key property of our recurrent GNN architecture for SAT solving is the ability to adjust computational effort at inference time. Unlike standard GNNs with fixed number of layers,the weight-shared recurrent design enables flexible scaling through additional iterations and resampling. ## 5.3.1 Iteration and Resampling Effects Figure 2 demonstrates how increasing message-passing iterations improves the percentage of solved SAT instances. Similarly, Figure 3 shows how the average gap decreases across iterations for various benchmarks. The heat maps in Figure 4 provide a comprehensive view of how performance metrics improve with both increased iterations and resampling attempts. For the model trained on SR40, several observations are notable: \u00b7Iteration benefits: Increasing iterations from 25 to 125 consistently improves all metrics across benchmarks. \u00b7Resampling effects: Multiple inference attempts with different random initializations of node feature vectors further enhance performance. For SR40, decision accuracy improves from 84% with one sample to 93% with five samples at 125 iterations.\n\nTable 3: Performance analysis of VCG+RNN with assignment prediction across different datasets and training methodologies. Our novel \"Closest\" supervision method (which dynamically selects assignments closest to current model predictions) consistently outperforms training with precalculated assignments. For SR40, SAT-only training with closest assignment supervision achieves the highest SAT accuracy (76%), while SAT+UNSAT training with closest assignment supervision yields the lowest average gap (0.98). The missing data for 3SAT100 with SAT+UNSAT closest supervision is due to prohibitive computational costs. Bold values indicate best results per dataset. <table><tr><td>Dataset</td><td>Training Mode</td><td>Assignment Type</td><td>Avg. Gap \u2193</td><td>Gap on SAT \u2193</td><td>Gap on UNSAT \u2193</td><td>SAT Acc. \u2191</td><td>Dec. Acc. \u2191</td></tr><tr><td rowspan=\"4\">SR40</td><td>SAT only</td><td>Precalculated</td><td>2.93</td><td>1.11</td><td>4.75</td><td>68.2 %</td><td>84.1 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>2.68</td><td>0.88</td><td>4.48</td><td>76 %</td><td>88 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8 %</td><td>84.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>0.98</td><td>0.48</td><td>1.49</td><td>71.2 %</td><td>85.6 %</td></tr><tr><td rowspan=\"4\">SR100</td><td>SAT only</td><td>Precalculated</td><td>4.42</td><td>2.36</td><td>6.48</td><td>47.4 %</td><td>73.7 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>3.57</td><td>1.67</td><td>5.48</td><td>59.6 %</td><td>79.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>3.81</td><td>2.34</td><td>5.28</td><td>44.8 %</td><td>72.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>1.43</td><td>0.92</td><td>1.94</td><td>53.2 %</td><td>76.6 %</td></tr><tr><td rowspan=\"4\">3SAT100</td><td>SAT only</td><td>Precalculated</td><td>5.93</td><td>3.40</td><td>9.27</td><td>25.7 %</td><td>57.2 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>5.23</td><td>2.33</td><td>9.11</td><td>48.4 %</td><td>70 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>4.22</td><td>2.84</td><td>6.00</td><td>23.9 %</td><td>55.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td></tr></table> - Cross-distribution applicability: The model trained on SR40 maintains reasonable effectiveness on SR100 and 3SAT100, though with expected performance decrease. This aligns with findings from Li et al. Li et al. [2023], who demonstrated that models trained on SR distributions generally transfer well to other SAT problem structures. #### 5.3.2 Train-time vs Test-time Scaling Tables 4 and 5 present the performance of models trained on SR40 and SR100 distributions when evaluated across benchmarks of varying sizes. The SR40- trained model achieves reasonable generalization to larger instances, though with decreasing effectiveness as problem size increases. For SR100, the model achieves 74.2% decision accuracy despite being trained on smaller instances, showing good generalization capabilities. The SR100- trained model demonstrates better performance on larger instances compared to the SR40- trained model, as expected. On SR200, it achieves 83.0% decision accuracy compared to 58.5% for the SR40 model. This suggests that while test- time scaling can improve performance on larger problems, there are limits to this approach, and training models on larger instances might be necessary for optimal performance on very large problems. These results highlight that recurrent GNN architectures allow for a flexible computation- performance tradeoff that can be adjusted at inference time based on available computational resources and desired solution quality. ### 5.4 Diffusion Model Extension As we mentioned in Section 3.4.4, one can use the GNN as a function approximator \\(f_{\\theta}(\\cdot)\\) inside a diffusion model. This enables another way of scaling the test- time compute. We adapt the diffusion model used by Sun et al. Sun and Yang [2023] where the function approximator is trained to predict the ground truth solution \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t},t)\\) conditioned on a sample \\(\\mathbf{x_t}\\) at time \\(t\\) . The predicted assignment is then used to obtain a sample at time \\(t - 1\\) and this process is repeated again \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_{t - 1}},t - 1)\\) until we reach \\(t = 0\\) . One application of the function approximator together with the sampling is called a diffusion step. The number of diffusion steps \\(T\\) used for inference is a parameter which can be adapted after the model was already\n\nTable 4: Performance of a model trained on SR40 (VCG+RNN with closest assignment supervision) when tested across various benchmarks with a maximum of 100 message-passing iterations and early stopping. The model maintains reasonable performance on SR100 ( \\(74.2\\%\\) decision accuracy) but degrades on larger instances. \"UNSAT Instances (gap \\(= =1\\) )\" shows the percentage of UNSAT instances where the model achieved a gap of 1, which is always optimal for SR datasets but not always achievable for 3SAT instances. \"Steps\" columns indicate average/median iterations required to reach solutions, demonstrating the model's efficiency. <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>89.5%</td><td>79.0%</td><td>95.6%</td><td>16.17/13.0</td><td>13.33/10.0</td></tr><tr><td>SR100</td><td>74.2%</td><td>48.3%</td><td>91.3%</td><td>24.93/21.0</td><td>23.47/19.0</td></tr><tr><td>SR200</td><td>58.5%</td><td>17.0%</td><td>64.5%</td><td>32.44/30.0</td><td>33.98/28.0</td></tr><tr><td>SR400</td><td>51.5%</td><td>3.0%</td><td>16.0%</td><td>41.33/34.0</td><td>52.06/44.5</td></tr><tr><td>3SAT100</td><td>74.8%</td><td>52.8%</td><td>64.0%</td><td>25.63/22.0</td><td>29.66/24.0</td></tr><tr><td>3SAT200</td><td>54.0%</td><td>17.1%</td><td>22.5%</td><td>33.21/25.0</td><td>35.10/31.5</td></tr></table> Table 5: Performance of a model trained on SR100 (VCG+RNN with closest assignment supervision) when tested on SR benchmarks with a maximum of 100 message-passing iterations and early stopping. Given that the SR40-trained model achieved only \\(3\\%\\) SAT accuracy on SR400 (see Table 4), we focused on evaluating how training on larger instances improves scaling. The results show dramatic improvement on larger benchmarks ( \\(36.5\\%\\) vs \\(3\\%\\) on SR400), demonstrating that training on larger problems significantly enhances generalization capacity. The \"Steps\" metrics confirm the SR100-trained model requires fewer iterations on larger problems (e.g., 30.68 vs 41.33 average iterations for SAT instances on SR400). <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>90.6%</td><td>81.2%</td><td>90.0%</td><td>14.57/12.0</td><td>16.21/12.0</td></tr><tr><td>SR100</td><td>79.3%</td><td>58.7%</td><td>85.7%</td><td>22.16/18.0</td><td>22.64/19.0</td></tr><tr><td>SR200</td><td>83.0%</td><td>68.2%</td><td>60.2%</td><td>22.29/20.0</td><td>27.12/22.0</td></tr><tr><td>SR400</td><td>68.2%</td><td>36.5%</td><td>78.0%</td><td>30.68/26.0</td><td>33.13/28.0</td></tr></table>\n\n<center>Figure 2: Percentage of SAT instances solved as message passing iterations increase for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Performance on SR100, showing rapid initial improvement. Right: Comparison across benchmarks, demonstrating effectiveness decreases with problem size but benefits from additional iterations, highlighting the recurrent architecture's inference-time scaling capability. </center> <center>Figure 3: Average gap (unsatisfied clauses) reduction with increasing message passing iterations for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Comparison across benchmarks showing extremely rapid gap reduction in early iterations for all problem sizes, with all benchmarks achieving remarkably low average gaps despite varying SAT-solving performance. Right: Individual instance trajectories revealing different convergence patterns between SAT and UNSAT instances, with occasional fluctuations suggesting potential benefit from monitoring solution quality during inference. </center> trained and therefore, in this setting we have two types of iterations. One is the number of message- passing iterations and the second is the number of diffusion steps. In Table 6 we report the tradeoff between the number of message- passing steps (referred to as GNN_Steps) and the number of diffusion steps. The reported numbers correspond to the dataset SR100 with 100 variables in each problem. The model was trained on the SR40 distribution and the tested combinations use around 300 iterations in total distributed between the two types of steps. The experiments revealed a consistent trend: increasing the number of message- passing steps is generally more important for improving metrics such as Accuracy and Avg. Gap. #### 5.4.1 Connection to Assignment Prediction Training We also report an interesting finding which allows to simplify the function approximator used in the diffusion model. Notice that in the expression \\(\\mathbf{x}_0 = f_\\theta (\\mathbf{x}_t, t)\\) it is also conditioned on the timestep \\(t\\) . This conditioning is dictated by the theory of diffusion models Nakkiran et al. [2024] and most of the models, including the one by Sun et al. Sun and Yang [2023] blindly follow this design choice. In our experiments, we found out that this conditioning is not needed and that the model sometimes works even better without it. Therefore, in all reported results, the\n\n<center>Figure 4: Performance heatmaps for a model trained on SR40 with SAT+UNSAT closest assignment supervision, showing how metrics improve with both increased iterations (columns) and resampling attempts (rows). Testing on SR40 (top), SR100 (middle), and 3SAT100 (bottom) demonstrates significant gains from both scaling dimensions\u2014e.g., SR40 decision accuracy improves from 84% (1 sample, 25 iterations) to 93% (5 samples, 125 iterations). This two-dimensional inference-time scaling capability is consistent across benchmarks but with decreasing returns on larger problems. </center> model is trained to predict the solution \\(\\mathbf{x_0}\\) only from the sample at timestep \\(t\\) ( \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t})\\) ). Concurrently to us, this fact was also discovered by Sun et al. Sun et al. [2025] (the same surname is a coincidence) and it's possible that many of the reported experiments which blindly use this conditioning would result in better values without it. In this simplified setup, the training examples \\((\\mathbf{x_0},\\mathbf{x_t})\\) are sampled by taking a solution of a formula \\((\\mathbf{x_0})\\) , sampling a random \\(t\\) from the diffusion schedule and obtaining a corrupted version of the solution at time \\(t\\) ( \\(\\mathbf{x_t}\\) ). The model is trained to predict \\(\\mathbf{x_0}\\) from \\(\\mathbf{x_t}\\) . The GNN is the same as in the case of assignment prediction except that it also contains a learnable embedding layer which embeds the Boolean values in the assignment \\(\\mathbf{x_t}\\) into a vector space to obtain the initial embeddings of variables (or literals) for the first pass of message- passing. The only difference from the model trained for assignment prediction is therefore that the initial embeddings are not sampled randomly but obtained by embedding the perturbed assignment \\(\\mathbf{x_t}\\) . This also means that during test time, these two approaches differ only by rounding, i.e. running the model trained for assignment prediction for 100 steps and after every 20 steps rounding the variable embeddings to vectors representing True and False is same as running the diffusion model for 5 diffusion steps where each step has 20 message- passing iterations.\n\ntheir performance and on the theoretical side, understanding how a GNN can solve a CNF formula could help us to elucidate the reasoning ability of Transformers Vaswani et al. [2017] because Transformers can be viewed as GNNs in which the graph connectivity is given by the attention map and is learned from data Cai et al. [2023]. Our aim in this contribution is to provide an experimental evaluation of different design choices for GNNs in the context of Boolean satisfiability together with an intuitive explanation of the inner workings of these models. Our main contributions are as follows: - We provide an experimental comparison of different architectures and training regimes.- We introduce a novel supervision method based on the closest assignment, resulting in significant improvements.- We demonstrate that these architectures scale well at test time.- We extend the graph neural network to a diffusion model and show how it relates to the base model.- We provide an intuitive explanation for the inner workings of these models. The rest of the text has the following structure: Section 3 (Relevant Background) provides the necessary context on Boolean satisfiability problems, SAT solving approaches, graph neural networks, theoretical connection to approximation algorithms, and diffusion models. Section 4 (Experimental Setup) describes our methodology, including data representation choices, architecture variants, supervision methods, and benchmark generation. Section 5 (Experimental Results) presents our comprehensive evaluation, comparing different graph representations and training methods (Section 5.2), demonstrating test- time scaling capabilities (Section 5.3), and introducing our diffusion model extension (Section 5.4). Section 6 (Interpreting the Trained Model) offers analysis of the embedding space and explains the networks' behavior through the lens of approximation algorithms based on continuous relaxation. Section 2 (Related Work) positions our contribution within the broader research landscape, and Section 7 contains a discussion of our findings and directions for future research. We conclude in Section 8. Additional implementation details and mathematical derivations are provided in the Appendix. ## 2 Related Work Our research builds directly upon Neuro SAT Selsam et al. [2018], which introduced the first end- to- end neural approach for SAT solving using a recurrent message- passing architecture. While we maintain the core iterative design of Neuro SAT (allowing variable numbers of message- passing iterations through weight sharing), we explore simplified variants using RNNs and LSTMs and incorporate techniques like curriculum learning to improve training efficiency. Several other works have explored different directions in neural SAT solving. Li et al. Li et al. [2023] developed G4SATBench to benchmark various GNN architectures (GCN, GGNN, GIN) across different graph representations and supervision objectives. Unlike their broader exploration across architecture types, our work focuses on the recurrent message- passing paradigm from Neuro SAT and investigates how different training objectives and graph representations affect performance within this specific framework. We also mention the work by Warde et al. Warde- Farley et al. [2023] who developed a recurrent architecture based on a Restricted Boltzmann Machine. Hybrid approaches that integrate neural networks with traditional solvers include Neuro Core by Selsam and Bjorner Selsam and Bjorner [2019], which uses neural predictions to guide variable branching in CDCL solvers. Similarly, Wang et al. Wang et al. [2021] proposed Neuro Comb to enhance CDCL solvers through GNN- based identification of important variables and clauses.\n\nTable 6: Performance Metrics for Different GNN and Diffusion Step Configurations. Variable names shown in parentheses in the original data source are omitted here for brevity. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Dec. Acc. (%)</td><td>Single-Step Avg. Gap</td><td>Single-Step Dec. Acc (%)</td></tr><tr><td>20</td><td>15</td><td>1.09</td><td>68.7</td><td>3.26</td><td>60.2</td></tr><tr><td>23</td><td>13</td><td>1.05</td><td>70.4</td><td>2.80</td><td>63.1</td></tr><tr><td>27</td><td>11</td><td>0.96</td><td>73.6</td><td>2.44</td><td>64.7</td></tr><tr><td>31</td><td>9</td><td>0.98</td><td>73.8</td><td>2.11</td><td>68.2</td></tr><tr><td>35</td><td>8</td><td>0.93</td><td>75.4</td><td>1.96</td><td>69.5</td></tr><tr><td>38</td><td>7</td><td>0.92</td><td>76.3</td><td>1.83</td><td>70.2</td></tr><tr><td>42</td><td>7</td><td>0.90</td><td>76.7</td><td>1.70</td><td>71.6</td></tr><tr><td>46</td><td>6</td><td>0.95</td><td>76.8</td><td>1.64</td><td>72.1</td></tr><tr><td>50</td><td>6</td><td>0.94</td><td>76.2</td><td>1.52</td><td>73.0</td></tr></table> #### 5.4.2 Interleaving Diffusion Steps with Unit Propagation The fact that for each diffusion step, the model outputs probabilities for two possible values, allows us to obtain a partial solution and then run a unit propagation to deduce assignment to other variables. The partial assignment can be obtained by fixing a threshold and then assigning only variables for which one of the values has a predicted probability higher than this threshold. The lower the threshold, the more variables will be fixed and the higher the probability that it will not be possible to complete the partial assignment to a satisfiable assignment. We therefore design a tree- search- like algorithm which first tries a low threshold in each diffusion step and if it does not find a satisfiable assignment it backtracks and increases the threshold to obtain a new partial assignment. The details of this algorithm are described in A.3 and the experimental results are reported in Table 7. As can be seen, interleaving the diffusion steps with unit propagation results in additional improvements over the base diffusion model (approximately \\(10\\%\\) ). We explicitly mention that this experiment is provided only to show a possible avenue for further improvements and the algorithm in its current form is not optimized for speed. Table 7: Performance with Unit Propagation. Here we compare the performance with (U.P. Acc.) and without (Dec. Acc.) Unit Propagation, and report the computational cost of Unit Propagation, listing the average number of total recursive function calls, the average number of recursive calls in solved problems, and the average number of recursive calls in unsolved problems. <table><tr><td>Problems</td><td>Dec. Acc. (%)</td><td>U.P. Acc. (%)</td><td>Total Rec. Calls</td><td>Solved Rec. Calls</td><td>Unsolved Rec. Calls</td></tr><tr><td>SR40</td><td>88.4</td><td>94.2</td><td>32.864</td><td>6.701</td><td>53.546</td></tr><tr><td>SR50</td><td>86.6</td><td>93.7</td><td>29.539</td><td>6.995</td><td>47.038</td></tr><tr><td>SR60</td><td>83.3</td><td>92.2</td><td>26.414</td><td>7.526</td><td>40.204</td></tr><tr><td>SR70</td><td>79.5</td><td>89.5</td><td>24.162</td><td>6.752</td><td>35.505</td></tr><tr><td>SR80</td><td>77.6</td><td>88.0</td><td>22.604</td><td>6.917</td><td>32.219</td></tr><tr><td>SR90</td><td>74.0</td><td>85.1</td><td>22.140</td><td>7.274</td><td>30.151</td></tr><tr><td>SR100</td><td>73.4</td><td>83.7</td><td>20.363</td><td>7.129</td><td>27.074</td></tr><tr><td>SR150</td><td>63.2</td><td>75.1</td><td>17.388</td><td>7.828</td><td>20.592</td></tr><tr><td>SR200</td><td>58.0</td><td>67.5</td><td>16.270</td><td>8.710</td><td>17.868</td></tr></table>\n\n## 6 Interpreting the Trained Model ### 6.1 Embedding Space Analysis Our analysis of variable embeddings reveals patterns that explain how GNNs learn to solve SAT problems. When visualizing these embeddings using dimensionality reduction Mc Innes et al. [2018], we observe that they form distinct clusters corresponding to optimal variable assignments. As shown in Figure 5, variable embeddings start randomly distributed but gradually organize into two clusters through message passing iterations. By applying k- means clustering ( \\(k = 2\\) ) to these embeddings, we can recover variable assignments that approximate optimal solutions, even from networks trained only to predict satisfiability status. ### 6.2 Iterative Optimization Behavior By tracking clause satisfaction across iterations, we observe that GNNs solve SAT problems through progressive local refinement. The gap (number of unsatisfied clauses) decreases following a trajectory typical of iterative optimization methods: rapid initial improvement followed by gradual refinement. This behavior supports the interpretation that GNNs implicitly learn to perform continuous optimization in a high- dimensional space similar to SDP relaxations for SAT. The effectiveness of additional message passing iterations during inference further strengthens this connection. A difference from the SDP relaxation is that the objective function which the GNN implicitely optimizes is non- convex because we observed that it can get stuck in local optima or converge to different solutions when initialized multiple times by different random embeddings. Figure 3 illustrates how the average gap decreases with increasing iterations. The trajectory suggests a rapid improvement phase followed by more gradual refinement. Individual instance trajectories reveal that while most instances show steady improvement toward optimal solutions, some exhibit fluctuations, particularly unsatisfiable instances. This observation supports the potential value of early stopping techniques, as in rare cases, the gap at later iterations might be higher than a previously achieved minimum gap. The bi- level optimization perspective\u2014where message passing performs an inner optimization loop (finding variable assignments) guided by network parameters optimized at the outer level (during training)\u2014helps explain the network's ability to generalize to novel problem instances and larger problems than those seen during training. In Section 7, we discuss more details about a possibility of manual derivation of the GNN equations from and explicit objective function. ## 7 Discussion In this section, we discuss the limitations of our work along with an outlook for future research. The primary limitation of the methods presented here is that they are not competitive with state- of- the- art SAT solvers on benchmarks derived from real- world problems. Current SAT solvers can handle formulas with millions of variables, which is not feasible for the GNN in its current form. However, as mentioned in the introduction, our motivation for studying these models is to better understand the reasoning capabilities of neural networks in a simplified context. The test- time scaling experiments clearly demonstrate that the GNNs can successfully generalize beyond their training distribution and do not merely learn superficial statistical patterns. The qualitative results presented in Section 6 further suggest that it is possible to fully understand the mechanisms by which the GNN solves a given formula. Figure 3 illustrates that the trained GNN functions as an implicit Max SAT solver, incrementally maximizing the number\n\n<center>Figure 5: Evolution of variable embeddings during message passing iterations for a satisfiable SR40 instance. The visualization shows 2D projections at different stages (Initial through Iteration 25), colored k-means algorithm in each iteration (green/red). Initially random, embeddings gradually organize into two distinct clusters often corresponding to optimal variable assignments. This clustering behavior was observed across different model architectures and training objectives\u2014notably, even models trained solely for SAT/UNSAT classification (without explicit assignment supervision) develop this embedding separation. This phenomenon supports our interpretation that GNNs implicitly perform continuous optimization similar to SDP relaxation for SAT problems. </center>\n\nof satisfied clauses at each step. These local updates occur in continuous space and can therefore be viewed as gradient updates with respect to an implicit objective function measuring clause satisfaction. Variables are also represented in a high- dimensional vector space, similar to semi- definite programming as explained in B. From this perspective, Equations 6, 7, and 11 can be interpreted as a gradient descent algorithm searching for an optimal assignment over a high- dimensional unit sphere (due to unit normalization), while the final classification layer corresponds to a rounding step to Boolean values. In future work, we aim to manually derive these equations from a trained GNN using a primal- dual approach, interleaving gradient updates of primal and dual variables associated with constraints. We believe that by utilizing suitable proximal operators and an appropriate metric in the relaxed solution space, the GNN can be effectively interpreted as a primal- dual algorithm optimizing a continuous relaxation of the Max SAT objective in a high- dimensional space. This points out to another major advantage of using the RNN update function because its simple form is suitable for such derivation. Deriving equations for such algorithms applicable to arbitrary combinatorial optimization problems would be highly beneficial in practice, allowing these equations to be parameterized by learnable matrices and fine- tuned for specific problem distributions. Such data- driven solvers would be analogous to physics- informed neural networks Cai et al. [2021], where substantial domain knowledge is embedded within the model, followed by fine- tuning to approximate the dynamics of a particular physical system. This approach results in fast numerical solvers tailored to specific domains. We believe that the development of data- drive numerical solvers represents an exciting future direction for combinatorial optimization research. To make these numerical solvers practical, it will still be necessary to integrate them into more complex systems, where they would function as guessing or bounding heuristic. Another limitation of our work is that the model was tested exclusively on random problems. This decision is justified by the findings of Li et al. Li et al. [2023], who demonstrated that models trained on random problem instances exhibit superior generalization to other distributions. Since Li et al. already provided experimental results demonstrating the transferability of models across different problem distributions, we chose not to repeat those experiments here. ## 8 Conclusion This work provides a comprehensive analysis of graph neural networks for Boolean satisfiability problems. Our evaluation identified key design choices that enhance performance: variable- clause graph representation with RNN updates offers an effective balance of accuracy and efficiency, while our novel closest assignment supervision method significantly improves performance on problems with large solution spaces. The recurrent architecture enables flexible scaling during inference through additional message- passing iterations and resampling. Our diffusion model extension demonstrates another approach to inference- time adaptation, with further improvements possible by integrating classical techniques like unit propagation. Our analysis of embedding space patterns and optimization trajectories supports the interpretation that these models implicitly implement continuous relaxation algorithms for Max SAT, explaining their ability to generalize to novel problem instances. This connection provides a theoretical framework for understanding neural reasoning capabilities in structured domains, with implications for the design of hybrid solving approaches. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit- sat: An unsupervised differentiable approach. In International conference on learning representations, 2018.\n\nJacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state- spaces. Advances in neural information processing systems, 34:17981- 17993, 2021. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisfiability, volume 185. IOS press, 2009. Sally C Brailsford, Chris N Potts, and Barbara M Smith. Constraint satisfaction problems: Algorithms and applications. European journal of operational research, 119(3):557- 581, 1999. Chen Cai, Truong Son Hy, Rose Yu, and Yusu Wang. On the connection between mpnn and graph transformer. In International conference on machine learning, pages 3408- 3430. PMLR, 2023. Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics- informed neural networks (pinns) for fluid mechanics: A review. Acta Mechanica Sinica, 37 (12):1727- 1738, 2021. James M Crawford and Larry D Auton. Experimental results on the crossover point in random 3- sat. Artificial intelligence, 81(1- 2):31- 57, 1996. Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1- 2):3- 71, 1988. Zhaohui Fu and Sharad Malik. On solving the partial max- sat problem. In International Conference on Theory and Applications of Satisfiability Testing, pages 252- 265. Springer, 2006. Bernd G\u00e4rtner and Jiri Matousek. Approximation algorithms and semidefinite programming. Springer Science & Business Media, 2012. Michel X Goemans and David P Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. Journal of the ACM (JACM), 42(6):1115- 1145, 1995. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek- r1: Incentivizing reasoning capability in llms via reinforcement learning. ar Xiv preprint ar Xiv:2501.12948, 2025. Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840- 6851, 2020. Abdelrahman Hosny and Sherief Reda. torchmsat: A gpu- accelerated approximation to the maximum satisfiability problem. ar Xiv preprint ar Xiv:2402.03640, 2024. Jan Hula, David Moj\u017e\u00ed\u0161ek, and Mikol\u00e1\u0161 Janota. Understanding gnns for boolean satisfiability through approximation algorithms. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pages 953- 961, 2024. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El- Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. ar Xiv preprint ar Xiv:2412.16720, 2024. Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Vardi, and Zhiwei Zhang. Fourier sat: A fourier expansion- based algebraic framework for solving hybrid boolean constraints. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 1552- 1560, 2020.\n\nZhaoyu Li and Xujie Si. Nsnet: A general neural probabilistic framework for satisfiability problems. Advances in Neural Information Processing Systems, 35:25573- 25585, 2022. Zhaoyu Li, Jinpei Guo, and Xujie Si. G4satbench: Benchmarking and advancing sat solving with graph neural networks. ar Xiv preprint ar Xiv:2309.16941, 2023. Gary Marcus. Deep learning: A critical appraisal. ar Xiv preprint ar Xiv:1801.00631, 2018. Gary F Marcus. The algebraic mind: Integrating connectionism and cognitive science. MIT press, 2003. Leland Mc Innes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for dimension reduction. ar Xiv preprint ar Xiv:1802.03426, 2018. Preetum Nakkiran, Arwen Bradley, Hattie Zhou, and Madhu Advani. Step- by- step diffusion: An elementary tutorial. ar Xiv preprint ar Xiv:2406.08929, 2024. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural sat solver. In 2022 International joint conference on neural networks (IJCNN), pages 1- 8. IEEE, 2022. Motakuri Ramana and Alan J Goldman. Some geometric results in semidefinite programming. Journal of Global Optimization, 7(1):33- 50, 1995. Bart Selman, Henry A Kautz, Bram Cohen, et al. Local search strategies for satisfiability testing. Cliques, coloring, and satisfiability, 26:521- 532, 1993. Daniel Selsam and Nikolaj Bjorner. Guiding high- performance sat solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing- SAT 2019: 22nd International Conference, SAT 2019, Lisbon, Portugal, July 9- 12, 2019, Proceedings 22, pages 336- 353. Springer, 2019. Daniel Selsam, Matthew Lamm, Benedikt Binz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a sat solver from single- bit supervision. ar Xiv preprint ar Xiv:1802.03685, 2018. Qiao Sun, Zhicheng Jiang, Hanhong Zhao, and Kaiming He. Is noise conditioning necessary for denoising generative models? ar Xiv preprint ar Xiv:2502.13129, 2025. Zhiqing Sun and Yiming Yang. Difusco: Graph- based diffusion solvers for combinatorial optimization. Advances in neural information processing systems, 36:3706- 3731, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. W Wang, Y Hu, M Tiwari, S Khurshid, KL Mc Millan, and R Miikkulainen. Neurocomb: improving sat solving with graph neural networks, 2021. David Warde- Farley, Vinod Nair, Yujia Li, Ivan Lobov, Felix Gimeno, and Simon Osindero. Solving maxsat with matrix multiplication. ar Xiv preprint ar Xiv:2311.02101, 2023. Morris Yau, Nikolaos Karalias, Eric Lu, Jessica Xu, and Stefanie Jegelka. Are graph neural networks optimal approximation algorithms? Advances in Neural Information Processing Systems, 37:73124- 73181, 2024. Emre Yolcu and Barnabas P\u00f3czos. Learning local search heuristics for boolean satisfiability. Advances in Neural Information Processing Systems, 32, 2019.\n\n<center>Figure 6: Validation accuracy during training. Our model with a curriculum achieves reaches \\(85\\%\\) in approximately 30 minutes, whereas the original Neuro SAT implementation needs over 5 hours. For comparison, we also add our implementation trained on the same data, but without a curriculum. The training of each model stops once it achieves an accuracy of \\(85\\%\\) on a validation set. </center> ## A Appendix ## A.1 Training Tricks and Information ## A.1.1 Curriculum Learning We implement a curriculum learning strategy to improve training efficiency and generalization. The key insight is that starting with simpler (smaller) formulas and gradually increasing complexity allows the model to learn basic logical reasoning patterns before tackling more complex instances. Our curriculum proceeds as follows: 1. Start training with small formulas (5 variables) 2. Set a validation accuracy threshold for each formula size (starting at \\(65\\%\\) for the smallest size and increasing to \\(85\\%\\) for the largest) 3. Once the model reaches the threshold accuracy on the current size or reaches a maximum number of epochs (100), increase the formula size by 2 variables 4. When introducing a new size, include formulas from the four previous sizes to prevent catastrophic forgetting 5. Continue until reaching the maximum formula size (40 variables) This curriculum approach significantly accelerates training compared to starting with the full distribution of formula sizes. Our previous experiments showed that the curriculum- trained model reaches \\(85\\%\\) validation accuracy in approximately 30 minutes, compared to over 5 hours for the non- curriculum approach. ## A.1.2 Exponential Moving Average (EMA) We employ Exponential Moving Average (EMA) for model parameter updates during training. EMA maintains a shadow copy of the model parameters that is updated after each training\n\nbatch: \\[\\theta_{\\mathrm{EMA}}\\leftarrow \\beta \\theta_{\\mathrm{EMA}} + (1 - \\beta)\\theta_{\\mathrm{current}} \\quad (13)\\] where \\(\\beta\\) is the decay rate (we use \\(\\beta = 0.999\\) ). During validation and testing, we use the EMA parameters instead of the current parameters. This technique significantly stabilizes training and improves generalization, especially in the early stages of training. Our experiments show that EMA provides a smooth validation accuracy curve, while the validation accuracy of the non- EMA model exhibits high variance and jumps of up to \\(10\\%\\) . #### A.1.3 Learning Rate Schedule We implement a custom learning rate schedule that combines cosine annealing for the first half of training and a constant minimum learning rate for the second half: \\[\\eta (t) = \\left\\{ \\begin{array}{ll}\\eta_{\\mathrm{min}} + (\\eta_{0} - \\eta_{\\mathrm{min}})\\frac{1 + \\cos(\\pi t / t_{\\mathrm{half}})}{2} & \\mathrm{if} t< t_{\\mathrm{half}}\\\\ \\eta_{\\mathrm{min}} & \\mathrm{otherwise} \\end{array} \\right. \\quad (14)\\] where \\(\\eta_{0}\\) is the initial learning rate, \\(\\eta_{\\mathrm{min}}\\) is the minimum learning rate (set to \\(10^{- 5}\\) ), \\(t\\) is the current epoch, and \\(t_{\\mathrm{half}}\\) is half of the maximum number of epochs. This schedule helps the model converge to a good solution in the first half of training and then fine- tune in the second half without disrupting the learned representations. ## A.1.4 Impact of hidden dimension on GNN Performance The dimensionality of the hidden representations, here denoted as d_model, specifies the size of the embedding vectors of variables and the hidden state dimension used during the message passing and update phases within the GNN architecture. The choice of d_model directly influences the model's capacity to learn complex patterns and relationships within the graph structure and node features. It also impacts computational resource requirements, such as memory usage and training time. Understanding how performance metrics vary with different d_model values is therefore crucial for effective model design and hyperparameter tuning. Our evaluation in table 8 generally shows that increasing the d_model leads to improved model performance, likely due to the enhanced representational capacity allowing the model to capture more intricate features. However, we observed that this trend exhibits diminishing returns; while significant performance gains are noticeable as the dimension increases up to 64, further increases yield smaller improvements in accuracy relative to the growing computational cost (e.g., peak accuracy at d_model=256 came with significantly longer training time). This suggests that, considering the marginal benefits, a dimension around 64 still presents a practical optimum, offering a good balance between performance and model complexity/efficiency for this specific setup. ## A.2 Diffusion Model Extensions ## A.3 Using Unit Propagation for Problem Simplification in the Diffusion Process In the diffusion process, each iteration provides a belief for every variable, which can be leveraged to continuously simplify the problem via a unit propagation algorithm until it converges to an empty problem, thereby obtaining a solution. The overall solving process is recursive, and its main steps are described as follows:\n\nTable 8: Experimental results demonstrating the impact of hidden dimension size (d_model) on model performance and training duration. \u2018Embedding Size (d_model)\u2019 refers to the dimensionality of the hidden representations within the GNN. \u2018Accuracy\u2019 indicates the performance metric achieved by the model. \u2018Time (hours)\u2019 specifies the total time required to train the model for each corresponding dimension size. <table><tr><td>Embedding Size (d_model)</td><td>Accuracy</td><td>Time (hours)</td></tr><tr><td>16</td><td>0.782</td><td>1.62</td></tr><tr><td>32</td><td>0.852</td><td>1.66</td></tr><tr><td>48</td><td>0.860</td><td>1.70</td></tr><tr><td>64</td><td>0.869</td><td>1.87</td></tr><tr><td>96</td><td>0.861</td><td>2.32</td></tr><tr><td>128</td><td>0.864</td><td>2.99</td></tr><tr><td>256</td><td>0.877</td><td>7.55</td></tr></table> ## 1. Partial Assignment Extraction and Local Unit Propagation In each diffusion step, a belief value between 0 and 1 is calculated for every variable. A value closer to 1 indicates a stronger inclination toward being true, and vice versa. We set a threshold to select variables with high belief and assign them accordingly to obtain a partial assignment. This partial assignment is then used to perform unit propagation for clause simplification. The unit propagation algorithm works as follows: If a clause contains a literal that is already satisfied by the current assignment, the clause is marked as satisfied. If all literals in a clause have been assigned but none satisfy it, a conflict signal is returned. For clauses that are not fully assigned, the unassigned literals are retained to form a simplified clause set. For unit clauses obtained during the simplification process (i.e., clauses containing only a single literal), the corresponding unassigned variable is directly assigned the appropriate value, further advancing the local solving process. ## 2. Multi-Threshold Strategy and Recursive Solving In the partial assignment extraction step, setting a lower threshold allows for the selection of as many assignments as possible at each step, thereby greatly simplifying the problem; however, it is more likely to select unreliable assignments that may lead to contradictions. To balance this, we adopt a multi- threshold list, starting from the lowest threshold. For each given threshold, if a new partial assignment is obtained, unit propagation is used to update the clauses and evaluate: If the simplified clause set becomes empty, all clauses are satisfied and the final solution is directly returned. If a conflict occurs or the recursive call at the next level fails, the threshold is raised; if the highest threshold is reached, the process moves to the next recursive level and performs another diffusion step. If unit propagation succeeds but the problem is not yet completely solved, the process recurses to the next level, performing a diffusion step on the updated clauses. If the recursion reaches a preset maximum depth and the clauses still cannot be satisfied, the recursion at that level fails.\n\nTable 9: Performance on SR100 for Different Diffusion Step and Fixed GNN Step. Note that the Performance is no longer Significantly Improved when Diffusion Steps Larger than 8. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>25</td><td>4</td><td>0.991</td><td>69.9</td></tr><tr><td>25</td><td>5</td><td>0.901</td><td>71.2</td></tr><tr><td>25</td><td>6</td><td>0.798</td><td>72.7</td></tr><tr><td>25</td><td>8</td><td>0.705</td><td>73.0</td></tr><tr><td>25</td><td>10</td><td>0.728</td><td>72.1</td></tr><tr><td>25</td><td>20</td><td>0.662</td><td>73.3</td></tr><tr><td>25</td><td>30</td><td>0.676</td><td>72.3</td></tr><tr><td>25</td><td>40</td><td>0.655</td><td>73.3</td></tr><tr><td>25</td><td>50</td><td>0.663</td><td>73.0</td></tr></table> Table 10: Performance on SR100 for Different GNN Step and Fixed Diffusion Step. Note that the Performance is no longer Significantly Improved when GNN Steps Larger than 50. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>10</td><td>10</td><td>2.028</td><td>55.0</td></tr><tr><td>20</td><td>10</td><td>0.846</td><td>68.6</td></tr><tr><td>30</td><td>10</td><td>0.622</td><td>74.4</td></tr><tr><td>40</td><td>10</td><td>0.578</td><td>75.5</td></tr><tr><td>50</td><td>10</td><td>0.533</td><td>77.6</td></tr><tr><td>60</td><td>10</td><td>0.518</td><td>77.2</td></tr><tr><td>70</td><td>10</td><td>0.500</td><td>78.6</td></tr><tr><td>80</td><td>10</td><td>0.521</td><td>77.9</td></tr><tr><td>90</td><td>10</td><td>0.512</td><td>77.6</td></tr><tr><td>100</td><td>10</td><td>0.522</td><td>77.4</td></tr></table> Table 7 shows the performance and computational cost after applying unit propagation. We tested a fixed model under the settings: GNN steps \\(= 25\\) , diffusion steps \\(= 10\\) , and multithreshold list \\(= [0.6, 0.75, 0.9]\\) . As shown, incorporating unit propagation improves accuracy by approximately \\(10\\%\\) across various problem settings. The last three columns of the table list the number of recursive function calls during the recursion process. Since each call involves one diffusion step, the computational cost incurred by the multi- threshold strategy is directly reflected. We observed that for harder problems, the computational cost of the multi- threshold strategy is actually lower, as unit propagation on partial assignments is more likely to encounter conflicts, thereby reducing the number of recursive branches. ## A.4 Influence of Number of Message-passing and Diffusion Steps For completeness, we also report evaluations in which the number of diffusion steps is fixed and the number of message- passing steps is changing (Table 10) and vice versa (Table 9). We observe that the expansion of the number of iterative steps does not always bring benefits: when the number of one kind of step is fixed, further increasing the number of another kind of step beyond a certain threshold will not lead to performance improvement.\n\nThese approaches differ from our end- to- end model but demonstrate alternative applications of neural methods to SAT solving. The connection between neural networks and continuous relaxations is particularly relevant to our work. Kyrillidis et al. Kyrillidis et al. [2020] introduced Fourier SAT, which transforms Boolean SAT problems into continuous optimization using the Walsh- Fourier transform. This approach provides a theoretical foundation for understanding how neural networks might implicitly convert discrete search problems into continuous optimization. Similar technique was introduced by Hosny et al. Hosny and Reda [2024] who develop GPU- accelerated approaches for Max SAT problems. Hula et al. Hula et al. [2024] and Yau et al. Yau et al. [2024] explore the connection between GNNs and semidefinite programming relaxations, demonstrating empirically and theoretically that message- passing can implement gradient- based optimization of SDP relaxations. In the broader domain of combinatorial optimization, Sun et al. Sun and Yang [2023] used diffusion models based on GNNs to solver problems such as traveling salesman. ## 3 Relevant Background ### 3.1 Boolean Satisfiability and Maximum Satisfiability #### 3.1.1 Boolean Satisfiability as a Constraint Satisfaction Problem Boolean satisfiability (SAT) is a fundamental problem in computer science that asks whether a given Boolean formula has a satisfying assignment. The formula is built from propositional variables \\(x_{1},x_{2},\\ldots\\) that can take values from \\(\\{0,1\\}\\) , representing false and true respectively, and logical connectives: conjunction \\((\\wedge)\\) , disjunction \\((\\vee)\\) , and negation \\((\\neg)\\) . While other connectives like implication \\((\\rightarrow)\\) and equivalence \\((\\leftrightarrow)\\) exist, they can be expressed using these basic operators. A literal is either a propositional variable \\(x\\) or its negation \\(\\neg x\\) . While Boolean formulas can take arbitrary form, the most common representation is the conjunctive normal form (CNF), where a formula is a conjunction of clauses, and each clause is a disjunction of literals. For example, \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) is a CNF formula with two clauses. We note that any Boolean formula can be transformed into an equisatisfiable CNF formula, albeit potentially requiring additional variables. An assignment \\(\\sigma\\) maps each propositional variable to either 0 or 1. We say \\(\\sigma\\) satisfies a CNF formula if at least one literal in each clause evaluates to true under \\(\\sigma\\) . For instance, the assignment \\(\\sigma (x_{1}) = 1,\\sigma (x_{2}) = 0,\\sigma (x_{3}) = 1\\) satisfies the formula \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) as both clauses contain a true literal. SAT is a special case of the more general Constraint Satisfaction Problem (CSP) framework Brailsford et al. [1999]. A CSP consists of a set of variables, each with a domain of possible values, and a set of constraints that specify allowed combinations of values for groups of variables. While SAT variables are restricted to Boolean values and constraints take the form of clauses, CSPs can accommodate richer variable domains and constraint types. #### 3.1.2 Max SAT: The Optimization Variant The Maximum Satisfiability problem (Max SAT) is the optimization version of SAT. Given a CNF formula \\(\\phi\\) , the goal is to find an assignment that maximizes the number of satisfied clauses. This formulation is particularly useful when a formula is unsatisfiable, as Max SAT still yields the best possible solution. Max SAT has several variations that differ in their expressiveness and the way they handle the importance of clauses. In unweighted Max SAT, all clauses have equal importance. Weighted Max SAT assigns a positive weight to each clause, with the objective being to maximize the sum\n\n## B SDP for MAX-2-SAT Semidefinite programming (SDP) is a mathematical optimization technique primarily used for problems involving positive semidefinite matrices. In SDP, a linear objective function is optimized over a feasible region given by a spectrahedron (an intersection of a convex cone formed by positive semidefinite matrices and an affine subspace) Ramana and Goldman [1995]. Along with the broad scope of applications, SDP has been used to design approximation algorithms for discrete NP- hard problems Gartner and Matousek [2012]. This is achieved by lifting variables of a problem to a vector space and optimizing a loss function expressed in terms of these vectors. In this section, we provide a detailed derivation of the SDP relaxation for MAX- 2- SAT. The goal is to write an objective function for 2- CNF formulae, which consist of clauses \\(c_{1},\\ldots ,c_{k}\\) over variables \\(x_{1},\\ldots ,x_{n}\\) with at most two literals per clause. ## B.1 Derivation of the SDP Relaxation For each Boolean variable \\(x_{i}\\) (where \\(i\\in \\{1,2,\\ldots ,n\\}\\) ), a new variable \\(y_{i}\\in \\{- 1,1\\}\\) is associated, and an additional variable \\(y_{0}\\in \\{- 1,1\\}\\) is introduced. This additional variable is introduced to unambiguously assign the truth value in the original problem from values of the relaxed problem. It is not possible to just assign True (False) to \\(x_{i}\\) if \\(y_{i} = 1(- 1)\\) because quadratic terms cannot distinguish between \\(y_{i}\\cdot y_{j}\\) and \\((- y_{i})\\cdot (- y_{j})\\) . Instead, the truth value of \\(x_{i}\\) is assigned by comparing \\(y_{i}\\) with \\(y_{0}\\) : \\(x_{i}\\) is True if and only if \\(y_{i} = y_{0}\\) , otherwise it is False. The assignment is therefore invariant to negating all variables. To determine the value of a formula, we sum the value of its clauses \\(c\\) which are given by the value function \\(v(c)\\) . Here are examples of the value function for different clauses: \\[\\begin{array}{c}{v(x_{i}) = \\frac{1 + y_{0}\\cdot y_{i}}{2}}\\\\ {v(\\neg x_{i}) = 1 - v(x_{i}) = \\frac{1 - y_{0}\\cdot y_{i}}{2}}\\\\ {v(x_{i}\\vee \\neg x_{j}) = 1 - v(\\neg x_{i}\\wedge x_{j})}\\\\ {= 1 - \\frac{1 - y_{0}\\cdot y_{i}}{2}\\cdot \\frac{1 + y_{0}\\cdot y_{j}}{2}}\\\\ {= \\frac{1}{4} (1 + y_{0}\\cdot y_{i}) + \\frac{1}{4} (1 - y_{0}\\cdot y_{j}) + \\frac{1}{4} (1 + y_{i}\\cdot y_{j})} \\end{array} \\quad (15)\\] By summing over all clauses \\(c\\) in the Boolean formula, the following integer quadratic program for MAX- 2- SAT is obtained: \\[\\begin{array}{r l} & {\\mathrm{Maximize:}\\quad \\sum_{c\\in C}v(c)}\\\\ & {\\mathrm{Subject~to:}\\quad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\mathrm{Subject~to:}\\quad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}j\\in \\{0,1,\\ldots ,n\\}} \\end{array} \\quad (21)\\] This can be rewritten by collecting coefficients of \\(y_{i}\\cdot y_{j}\\) for \\(i,j\\in \\{0,1,\\ldots ,n\\}\\) and putting them symmetrically into a \\((n + 1)\\times (n + 1)\\) coefficient matrix \\(W\\) . The terms \\(y_{i}\\cdot y_{j}\\) can be collected in a matrix \\(Y\\) with the same dimensions as \\(W\\) . The elements \\(Y_{ij}\\) correspond to \\(y_{i}\\cdot y_{j}\\) for \\(i,j\\in \\{0,1,\\ldots ,n\\}\\) . Both matrices are symmetric, hence the sum of all elements in their element- wise product (which is the objective function) can be compactly expressed by using the trace operation. This leads to the following version of the same integer program: \\[\\begin{array}{r l} & {\\mathrm{Maximize:}\\quad \\mathrm{Tr}(W Y)}\\\\ & {\\mathrm{Subject~to:}\\quad Y_{i i} = 1\\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad Y_{i j} = y_{i}\\cdot y_{j}\\mathrm{~for~all~}i,j\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}} \\end{array} \\quad (22)\\]\n\n## B.2 Relaxation to Semidefinite Programming To make the discrete program continuous, we first allow the value of the variables \\(y_{i}\\) to be any real number between \\(- 1\\) and 1. However, semidefinite programming goes further and allows variables to be \\((n + 1)\\) - dimensional unit vectors \\((y_{0},\\ldots ,y_{n})\\longrightarrow (\\mathbf{y}_{0},\\ldots ,\\mathbf{y}_{n})\\) , as schematically depicted in Figure 7. In this relaxation, the binary products \\(y_{i}\\cdot y_{j}\\) in the objective function are replaced by inner products \\(\\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) This can be compactly represented in matrix form by substituting each inner product \\(\\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) with a scalar \\(Y_{ij}\\) of a matrix \\(Y\\) . The fact that these scalars correspond to inner products is encoded by the restriction to positive- semidefinite matrices \\(Y\\succeq 0\\) . The SDP relaxation of MAX- 2- SAT can thus be formulated as: \\[\\begin{array}{rl} & {\\mathrm{Maximize:}\\quad \\mathrm{Tr}(W Y)}\\\\ & {\\mathrm{Subject~to:}\\quad Y_{i i} = 1\\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad Y\\succeq 0} \\end{array} \\quad (27)\\] Positive semidefiniteness of matrix \\(Y\\) ensures that it can be uniquely factorized as \\(Y =\\) \\(Y^{\\frac{1}{2}}(Y^{\\frac{1}{2}})^{T}\\) . We can then obtain real unit vectors \\(\\mathbf{y}_{i}\\) for all \\(i\\in \\{0,\\ldots ,n\\}\\) such that \\(Y_{ij} = \\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) for all \\(i,j\\in \\{0,\\ldots ,n\\}\\) . The constraints \\(Y_{ii} = 1\\) ensure that all vectors \\(\\mathbf{y}_{i}\\) lie on an \\((n + 1)\\) - dimensional unit sphere. <center>Figure 7: Lifting the variables to a higher dimension, demonstrated on variables \\(y_{1},y_{2},y_{3}\\) . Initially, only integer values of \\(-1\\) and 1 could be assigned to them (integer program). Next, constraints are relaxed, allowing variables to take any real value between \\(-1\\) and 1. Finally, it is permitted for them to be unit vectors in a high-dimensional space (here, 3 dimensions). The hyperplane in the last picture would be used for rounding the variables at the end. This hyperplane can be randomly selected, and truth values for variables \\(y_{1},y_{2},y_{3}\\) are determined based on which side of the hyperplane they land after continuous optimization. </center> ## B.3 Interpretation and Rounding The SDP solver optimizes the numbers in the matrix \\(Y\\) , but using the factorization, we can visualize what happens with the vectors \\(\\mathbf{y}_{1}\\) . The process starts with random unit vectors that are continuously updated to maximize the objective function. If we fix the position of the vector \\(\\mathbf{y}_{0}\\) (corresponding to the value true), we would see that the vectors of variables that will be set to true in the final assignment get closer to the vector \\(\\mathbf{y}_{0}\\) , while the vectors \\(\\mathbf{y}_{j}\\) of variables that will be set to false move away from it so that the inner product \\(\\langle \\mathbf{y}_{0},\\mathbf{y}_{j}\\rangle\\) is close to \\(- 1\\) . If the formula is satisfiable, the objective function drives the vectors to form two wellseparated clusters. However, if only a few clauses can be satisfied simultaneously, the vectors would end up being scattered. A simple way to round the resulting vectors \\((\\mathbf{y}_{1},\\ldots ,\\mathbf{y}_{n})\\) and get the assignment for the original Boolean variables is to compute the inner product \\(\\langle \\mathbf{y}_{0},\\mathbf{y}_{i}\\rangle\\) and assign the value according\n\nto its sign. It is also possible to assign the values by picking a random separating hyperplane, and it can be shown that this rounding gives a 0.8785- approximation of the integer program optimum Goemans and Williamson [1995]. Note that the expressions of the clauses reach their maximum at 1 (when a clause is satisfied by the assignment). This means that the whole formula is satisfiable if the objective function achieves a value equal to the number of clauses in the formula. Another way to check satisfiability is to plug the obtained solution into the formula and verify whether it is satisfied. Therefore, we can obtain an incomplete SAT solver from this SDP formulation. Similar SDPs can be obtained for different versions of MAX- SAT (with larger clauses). From empirical observation, the convergence threshold of the SDP solver needs to be decreased significantly compared to MAX- 2- SAT in order to obtain a good approximation for these more complicated versions.\n\nof weights of satisfied clauses. In some variants (Partial MAX- SAT Fu and Malik [2006]), clauses are categorized as hard or soft, where hard clauses must be satisfied (often with infinite weight), and soft clauses are those that can be violated but contribute to the objective based on their weight. While weighted variants exist, in this paper we focus exclusively on the unweighted formulation. Formally, for a CNF formula \\(\\phi = c_{1} \\wedge c_{2} \\wedge \\dots \\wedge c_{m}\\) with \\(m\\) clauses, the unweighted Max SAT problem seeks an assignment \\(\\sigma^{*}\\) such that: \\[\\sigma^{*} = \\arg \\max_{\\sigma}\\sum_{i = 1}^{m}\\mathbf{1}(\\sigma \\mathrm{~satisfies~}c_{i}) \\quad (1)\\] where \\(\\mathbf{1}(\\cdot)\\) is the indicator function. ### 3.2 SAT Solving Approaches SAT solving algorithms are generally categorized into complete and incomplete approaches, each with distinct characteristics and applications. Complete Solvers Complete solvers theoretically guarantee definitive answers: either finding a satisfying assignment or proving that none exists. The Davis- Putnam- Logemann- Loveland (DPLL) algorithm forms the foundation for most modern complete solvers Biere et al. [2009]. It systematically explores the search space through backtracking while employing unit propagation to deduce logical consequences. Conflict- Driven Clause Learning (CDCL) extends DPLL by analyzing conflicts to learn new clauses, which helps prune large portions of the search space. When a conflict occurs, the solver identifies the \"reasons\" for the conflict and adds a new clause that prevents similar conflicts in the future. Modern CDCL solvers incorporate sophisticated heuristics for variable selection, restart strategies, and efficient data structures to improve performance. Incomplete Solvers Incomplete solvers focus on finding satisfying assignments but cannot prove unsatisfiability. These algorithms are particularly effective for large satisfiable instances where complete methods might be inefficient. Local search algorithms, such as Walk SAT Selman et al. [1993], start with a random assignment and iteratively modify it to satisfy more clauses. These methods employ heuristics to decide which variables to flip at each step, balancing between greedy choices and random moves to escape local optima. For Max SAT, local search algorithms often use scoring functions that prioritize flipping variables that maximize the increase in satisfied clauses. Stochastic algorithms including simulated annealing and genetic algorithms have also been applied to SAT and Max SAT problems. These approaches can effectively explore search spaces in certain problem classes where deterministic methods struggle. #### 3.2.1 Continuous Relaxations A specific type incomplete solvers that have been explored in recent research Kyrillidis et al. [2020], Hosny and Reda [2024] are explored continuous relaxations of Max SAT, that transform the discrete problem into a continuous optimization task. These methods map Boolean variables to continuous domains, enabling the application of gradient- based optimization techniques. The Fourier- SAT method Kyrillidis et al. [2020], for instance, transforms Boolean formulas into multilinear polynomials through Walsh- Fourier transform and then optimize the continuous variables w.r.t. the resulting polynomial. Continuous relaxations can also be obtained by making the objective function convex as often done when designing approximation algorithms which provide guarantees for their performance.\n\nThe guarantees can be improved by lifting the variables into a high- dimensional vector space and optimizing vectors instead of scalar values. The optimized vectors are finally rounded to discrete values. Semidefinite Programming (SDP) relaxation, particularly for MAX- 2- SAT or MAX- 3- SAT, illustrates this approach elegantly. In SDP relaxation, Boolean variables \\(x_{i} \\in \\{0,1\\}\\) are transformed into unit vectors \\(\\mathbf{y}_{i}\\) in a high- dimensional space. An additional vector \\(\\mathbf{y}_{0}\\) is introduced to represent the value \"true.\" The Boolean variable \\(x_{i}\\) is considered true if \\(\\mathbf{y}_{i}\\) is close to \\(\\mathbf{y}_{0}\\) (positive inner product) and false if it is far from \\(\\mathbf{y}_{0}\\) (negative inner product). The optimization process for these vectors follows a pattern: 1. Initialize random unit vectors for each variable 2. Optimize these vectors to maximize the number of satisfied clauses, expressed as a function of inner products between vectors 3. Round the resulting vectors to discrete assignments (typically based on the sign of inner products with \\(\\mathbf{y}_{0}\\) ) This relaxation enables the application of powerful continuous optimization techniques while providing approximation guarantees. For MAX- 2- SAT, this approach yields an approximation ratio of 0.878, meaning the solution will satisfy at least 87.8% of the maximum possible number of clauses. #### 3.2.2 Learning-Based Approaches Machine learning (ML) is also being heavily utilized for SAT solving. Many approaches have been developed to guide traditional solvers Selsam and Bj\u00f8rner [2019], Yolcu and P\u00f3czos [2019] or to solve SAT problems directly Selsam et al. [2018], Li and Si [2022]. To guide a solver, a neural network can be used to replace heuristics such as variable selection or restart policies. Importantly, Graph Neural Networks (GNNs) can also be trained to solve SAT problems end- to- end without relying on traditional algorithmic solvers Amizadeh et al. [2018]. These GNN- based approaches can operate directly on the graph representation of Boolean formulas, with variables and clauses forming nodes in a bipartite graph, and learn to predict satisfiability or produce satisfying assignments Li et al. [2023]. In this work, we focus on variants of GNNs that are recurrent and this allows us to scale the computation during inference or adapt the number of iterations for each instance separately. In Section 6 we will show an evidence that one can view the end- to- end ML approaches as bi- level optimization methods because during inference, the GNN behaves as a continuous solver trying to maximize the number of satisfied clauses. Therefore, during training, the outer loop of the bi- level optimization optimizes the weights of the network which then runs an inner loop that optimizes the values of variables to maximize the number of satisfiable clauses. ### 3.3 Graph Neural Networks Graph Neural Networks (GNNs) extend deep learning to graph- structured data, enabling learning on irregular data structures that classical neural architectures cannot directly process. A graph \\(G = (V,E)\\) consists of nodes \\(V\\) and edges \\(E\\) , where each node \\(v\\in V\\) may have associated features \\(x_{v}\\) . GNNs compute node representations through message passing, where each node iteratively aggregates information from its neighbors and updates its features. Formally, at layer \\(l\\) , a node \\(v\\) updates its representation \\(h_{v}^{l}\\) , according to: \\[h_{v}^{l + 1} = \\mathrm{UPDATE}(h_{v}^{l},\\mathrm{AGGREGATE}(\\{h_{u}^{l}:u\\in \\mathcal{N}(v)\\}))\\]\n\n<center>Figure 1: LCG and VCG of the CNF formula \\((\\overline{x}_{1} \\vee x_{2}) \\wedge (x_{2} \\vee \\overline{x}_{3}) \\wedge (x_{1} \\vee x_{3})\\) . </center> where \\(\\mathcal{N}(v)\\) denotes the neighbors of node \\(v\\) . The UPDATE and AGGREGATE functions are typically neural networks, often implementing permutation- invariant operations like sum or max. Through multiple layers of message passing, GNNs can capture both local structure and longer- range dependencies in the graph, making them suitable for processing SAT formulas represented as bipartite graphs. ### 3.4 Diffusion-based Assignment Generation In Section 5.4 will show how the GNNs we use can be extended to diffusion models which have in recent years emerged as a powerful approach for generative modeling across domains Ho et al. [2020]. These models learn to transform a random noise distributions (such as multi- variate Gaussian distribution) to complex distributions behind the given domain (i.e., distribution of images of human faces). For practical applications, diffusion models are typically conditioned on an input so that the generated sample has specific characteristics. In our case, we will condition the model by the bipartite graph of the CNF formula. #### 3.4.1 Categorical Diffusion Process While continuous diffusion models have gained prominence in image generation and other domains, discrete diffusion processes well- suited for combinatorial optimization problems like MAX- SAT, where the state space is inherently discrete. Our approach presented in Section 5.4 leverages a discrete diffusion process with categorical noise to model the generation of variable assignments. We adapt a concrete form of discrete diffusion first presented by Austin et al. Austin et al. [2021] and later leveraged for combinatorial optimization with GNNs by Sun et al. Sun and Yang [2023]. On a high level, diffusion models are trained to denoise noisy version of the training samples. These noisy versions are obtained by running a forward diffusion process for several steps and the model is then trained to predict the original sample. For a SAT problem with \\(n\\) variables, we represent each variable assignment as a binary value and the vector of these binary values represent the sample. The diffusion process gradually corrupts this sample until it becomes pure noise. More concretely, the process that progressively adds noise to the initial assignment \\(\\mathbf{x}_{0} \\in \\{0, 1\\}^{n}\\) over \\(T\\) timesteps, produces a sequence of increasingly more corrupted assignments \\(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots , \\mathbf{x}_{T}\\) . For categorical diffusion, this corruption process is defined by a Markov chain with the following transition matrices: \\[\\mathbf{Q}_{t} = \\left( \\begin{array}{cc}1 - \\beta_{t} & \\beta_{t} \\\\ \\beta_{t} & 1 - \\beta_{t} \\end{array} \\right) \\quad (2)\\] where \\(\\beta_{t} \\in (0, 1)\\) represents the noise schedule, controlling how quickly the assignments become corrupted. The matrix \\(\\mathbf{Q}_{t}\\) defines the probability of transitioning between states at time \\(t\\) , with the property that as \\(t\\) approaches \\(T\\) , the distribution of \\(\\mathbf{x}_{t}\\) approaches a uniform distribution over all possible assignments.\n\nTo simplify inference, the cumulative transition matrices \\(\\overline{\\mathbf{Q}}_{t} = \\mathbf{Q}_{1}\\mathbf{Q}_{2}\\cdot \\cdot \\cdot \\mathbf{Q}_{t}\\) , which directly gives us \\(p(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\) are being used. For the Boolean case, this allows us to efficiently sample \\(\\mathbf{x}_{t}\\) given \\(\\mathbf{x}_{0}\\) using: \\[p(\\mathbf{x}_{t}|\\mathbf{x}_{0}) = \\mathrm{Cat}(\\mathbf{x}_{t};\\mathbf{p} = \\tilde{\\mathbf{x}}_{0}\\overline{\\mathbf{Q}}_{t}) \\quad (3)\\] where \\(\\tilde{\\mathbf{x}}_{0} \\in \\{0,1\\}^{n \\times 2}\\) is the one- hot encoding of \\(\\mathbf{x}_{0}\\) , with each variable represented by a vector \\((1,0)\\) for value 0 or \\((0,1)\\) for value 1. The Cat operation refers to the categorical distribution, which samples \\(\\mathbf{x}_{t}\\) based on the probability vector \\(\\mathbf{p}\\) . #### 3.4.2 Learning the Reverse Process The core idea of diffusion models is to learn the reverse process - how to gradually denoise a corrupted sample to recover the original data distribution. In our case, we train a GNN to progressively recover a satisfiable assignment \\(\\mathbf{x}_{0}\\) starting from a random initial assignment. The trained model is used to sample from a distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) which can be used to obtain a an assignment \\(\\mathbf{x}_{0}\\) from random assignment \\(\\mathbf{x}_{T}\\) as explained bellow. There are multiple ways of training the neural network used in the diffusion model. One can train it to directly model the distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) . In the method introduced by Austin et al. Austin et al. [2021], the network is trained to predict the original uncorrupted input \\(\\mathbf{x}_{0}\\) which is then used to sample from the the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) using Bayes' rule. This approach provides stronger learning signals during training, as the target \\(\\mathbf{x}_{0}\\) remains fixed regardless of a timestep and we use it within this work. #### 3.4.3 Categorical Posterior Sampling As mentioned above, our model is trained to predict \\(\\mathbf{x}_{0}\\) directly and we use this prediction during inference to sample \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) . This is accomplished through categorical posterior sampling, which uses the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) to compute the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})\\) . By applying Bayes' rule and the Markov property of the diffusion process, we can derive: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (4)\\] For the categorical case, this is computed using: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}\\frac{p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{0})p(\\mathbf{x}_{t}|\\mathbf{x}_{t - 1})}{p(\\mathbf{x}_{t}|\\mathbf{x}_{0})} p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (5)\\] The diffusion model replaces the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) with a function approximator (GNN in our case) \\(f_{\\theta}(\\mathbf{x}_{t},t)\\) Therefore, we can train the model using a simple procedure (predicting \\(\\mathbf{x}_{0}\\) ) and during inference, we can use a sampling process (iteratively sampling \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) ), which tries to recover a uncorrupted input in several steps. A useful feature of diffusion models is that the number of sampling steps during inference can be chosen by the user after the model is already trained. #### 3.4.4 Inference Schedule During inference, we can accelerate the generation process by using fewer denoising steps than were used during training or use more denoising steps with the hope to increase the quality of outputs. The tuple of time steps used for inference \\((T,T - 1,\\ldots ,t_{0})\\) is called a schedule. The function approximator in the diffusion model is normally conditioned by the sample at a given time step and also the time step itself \\((f_{\\theta}(\\mathbf{x}_{t},t))\\) but as we show in Section 5.4.1, the time step conditioning is not needed. This means that in our case the schedule is defined only by the number of time steps used.\n\n## 4 Experimental Setup ### 4.1 Data Representation and Graph Structure Boolean formulas in CNF form can be naturally represented as bipartite graphs where clauses and variables (or literals) form two distinct sets of nodes. In this work, we explore two different graph representations: Literal- Clause Graph (LCG) In the literal- clause graph representation, each literal (both positive and negative polarity of a variable) is represented as a separate node. For a formula with \\(n\\) variables, this results in \\(2n\\) literal nodes. Each literal node is connected to all clause nodes containing that literal. Formally, for a CNF formula \\(\\phi\\) with variables \\(x_{1},\\ldots ,x_{n}\\) and clauses \\(c_{1},\\ldots ,c_{m}\\) , we construct a bipartite graph \\(G_{LC} = (L\\cup C,E)\\) where: - \\(L = \\{l_{1},\\ldots ,l_{n},\\bar{l}_{1},\\ldots ,\\bar{l}_{n}\\}\\) is the set of literal nodes - \\(C = \\{c_{1},\\ldots ,c_{m}\\}\\) is the set of clause nodes - \\((l_{i},c_{j})\\in E\\) if and only if literal \\(l_{i}\\) appears in clause \\(c_{j}\\) Variable- Clause Graph (VCG) In the variable- clause graph representation, each variable (rather than each literal) is represented as a node. For a formula with \\(n\\) variables, this results in exactly \\(n\\) variable nodes. Each variable node is connected to all clause nodes containing either the positive or negative literal of that variable. To retain information about the polarity of literals, we assign edge features \\(p_{ij}\\in \\{- 1,1\\}\\) to each edge \\((x_{i},c_{j})\\) , where \\(p_{ij} = 1\\) if the positive literal \\(x_{i}\\) appears in clause \\(c_{j}\\) , and \\(p_{ij} = - 1\\) if the negative literal \\(\\overline{{x}}_{i}\\) appears in clause \\(c_{j}\\) . Formally, we construct a bipartite graph \\(G_{VC} = (V\\cup C,E,P)\\) where: - \\(V = \\{x_{1},\\ldots ,x_{n}\\}\\) is the set of variable nodes- \\(C = \\{c_{1},\\ldots ,c_{m}\\}\\) is the set of clause nodes- \\((x_{i},c_{j})\\in E\\) if and only if variable \\(x_{i}\\) appears in clause \\(c_{j}\\) (in either polarity)- \\(P:E\\to \\{-1,1\\}\\) maps each edge to its corresponding polarity Both graph representations capture the structure of the Boolean formula, but they differ in how they handle variable polarity. The literal- clause graph explicitly represents both polarities as separate nodes, which increases the number of nodes but simplifies the message passing process of the GNN. The variable- clause graph is more compact but requires handling polarity information through edge features. For the GNNs we use, the variable- clause graph representation is more computationally efficient than the literal- clause graph, reducing both memory requirements and processing time. This efficiency comes from having half as many variable nodes (compared to literal nodes) and avoiding an expensive operation during message passing as will be described in Section 4.2. In our experiments, we compare both representations together with different message passing operations and different training regimes. ### 4.2 Architecture Variants Our GNN architecture variants are derived from the Neuro SAT architecture Selsam et al. [2018] which demonstrated the possibility of using GNNs for SAT solving. The main advantage of this architecture is that it is recurrent and therefore the number of message passing iterations is theoretically not limited. This is not the case for the non- recurrent alternatives with fixed number of layers. We will demonstrate the usefulness of this feature in Section (5.3).\n\nNode Embeddings Each node in the bi- partite graph of the formula is associated with a \\(d\\) - dimensional embedding vector ( \\(d = 64\\) in most of our experiments as a conclusion from an experiment in A.1.4). We initialize these embeddings randomly from a standard normal distribution. For a formula with \\(n\\) variables and \\(m\\) clauses, we have: In the literal-clause graph: \\(2n\\) literal embeddings \\(\\mathbf{l}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) In the variable- clause graph: \\(n\\) variable embeddings \\(\\mathbf{v}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) Message Passing Mechanism The core of our architecture is a two- phase message passing procedure that alternates between updating clause representations and unknown node representations (literals or variables, depending on the graph type). This process is repeated for a configurable number of iterations \\(T\\) . We primarily use an RNN- based update mechanism, where the node embeddings are the hidden states of the RNN that evolve through message passing iterations. For the variable- clause graph, the message passing at iteration \\(t\\) is defined as: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{v\\in \\mathcal{N}(c)}\\mathbf{M}_{v c}(\\mathbf{h}_{v}^{(t - 1)},p_{v c}),\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{v}^{(t)} = \\mathrm{RNN}_{v}\\left(\\sum_{c\\in \\mathcal{N}(v)}\\mathbf{M}_{c v}(\\mathbf{h}_{c}^{(t)},p_{v c}),\\mathbf{h}_{v}^{(t - 1)}\\right)} \\end{array} \\quad (6)\\] Here, \\(\\mathbf{h}_{c}^{(t)}\\) and \\(\\mathbf{h}_{v}^{(t)}\\) are the hidden states that serve as the actual clause and variable node embeddings for clause nodes and variable nodes respectively. \\(\\mathbf{M}_{v c}\\) and \\(\\mathbf{M}_{c v}\\) are the message transformation functions that operate on the source node embedding and the edge polarity. For the variable- clause graph, we implement these transformation functions as two MLPs that process positive and negative edges differently: \\[\\mathbf{M}_{v c}(\\mathbf{h}_{v},p) = \\left\\{ \\begin{array}{ll}\\mathrm{MLP}_{\\mathrm{pos}}(\\mathbf{h}_{v}) & \\mathrm{if} p > 0\\\\ \\mathrm{MLP}_{\\mathrm{neg}}(\\mathbf{h}_{v}) & \\mathrm{if} p< 0 \\end{array} \\right. \\quad (8)\\] For the literal- clause graph, the message passing mechanism also uses operation, called \"Flip\" bellow, that enforces the logical relationship between complementary literals: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{l\\in \\mathcal{N}(c)}\\mathbf{h}_{l}^{(t - 1)},\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{l}^{(t)} = \\mathrm{RNN}_{l}\\left(\\left[\\sum_{c\\in \\mathcal{N}(l)}\\mathbf{h}_{c}^{(t)},\\mathrm{Flip}(\\mathbf{h}_{l}^{(t - 1)})\\right],\\mathbf{h}_{l}^{(t - 1)}\\right)} \\end{array} \\quad (10)\\] where \\([\\cdot ,\\cdot ]\\) denotes vector concatenation. The \\(\\mathrm{Flip}(\\cdot)\\) operation exchanges the embeddings of positive literals with their corresponding negative literals and vice versa. The update function for a given literal embedding can therefore take into account the embedding of the complementary literal. We note, that the \\(\\mathrm{Flip}(\\cdot)\\) operation incurs a significant computational cost, particularly for large formulas. In contrast, the variable- clause graph representation eliminates this expensive operation by dedicating only one node for each variable and directly encoding its polarity in edge features. This efficiency makes the variable- clause approach particularly well- suited for larger formulas where computational demands become a critical factor.",
    "introduction": "Apart from the RNN- based update functions, we also experiment with LSTM- based update functions which have been used in the original Neuro SAT architecture Selsam et al. [2018]. The LSTM- based updates follow a similar pattern but maintain an additional cell state alongside the hidden state. In Section 5.2 we show that different update functions are suitable for different settings. After each update step, we apply L2 normalization to all node embeddings to stabilize training: \\[\\mathbf{h}_{i}^{(t)} = \\frac{\\mathbf{h}_{i}^{(t)}}{\\|\\mathbf{h}_{i}^{(t)}\\|_{2}} \\quad (11)\\] Node classification After \\(T\\) iterations of message passing, we use the final node embeddings to predict variable assignments. For the variable- clause graph, we apply a linear layer to each variable embedding to produce two logits (representing scores for value true and false): \\(\\mathbf{y}_{v} = \\mathbf{W}\\mathbf{h}_{v}^{(T)} + \\mathbf{b}\\) . The assignment is then determined by applying softmax and taking the argmax: \\(\\hat{a}_{v} = \\arg \\max_{i}(\\mathrm{softmax}(\\mathbf{y}_{v})_{i})\\) . For the literal- clause graph, we focus on the embeddings of positive literals only, as they directly correspond to variables. During training, we use cross- entropy loss between these predicted assignments and the ground truth assignments. For satisfiability prediction, we can determine whether a formula is satisfiable by checking if the predicted assignment satisfies all clauses. The model is thus trained to find assignments that minimize the number of unsatisfied clauses, effectively solving the Max SAT problem even when trained only with assignment supervision. ### 4.3 Supervision Tasks and Objectives There are several obvious supervision objectives and prediction tasks which can be used to train the model. The original Neuro SAT model was trained to predict the satisfiability status of a given formula using binary cross- entropy. Later, several authors tried different training tasks and objectives which have been summarized in a review paper by Li et al. Li et al. [2023]. We reimplement these objective and task for our setup and also introduce a novel training objective which in certain settings results in significant improvements of the model performance. These objective are briefly described below. Satisfiability Classification This is the task which was used by Selsam et al. [2018] for training the original Neuro SAT architecture. The model is trained to predict whether the formula is satisfiable or not through graph- level embedding aggregation using global mean pooling. The loss is computed by binary cross- entropy between the prediction \\(\\hat{y}\\) and ground truth \\(y\\in \\{0,1\\}\\) .. \\(\\mathcal{L}_{\\mathrm{sat}} = -(y\\log \\hat{y} +(1 - y)\\log (1 - \\hat{y}))\\) Unsupervised Training For unsupervised training, we define the loss using clause validity Ozolins et al. [2022], where \\(\\hat{x}_{i}\\) represents the model's predicted continuous probability of a variable being true: \\[V_{c}(\\hat{x}) = 1 - \\prod_{i\\in c^{+}}(1 - \\hat{x}_{i})\\prod_{i\\in c^{-}}\\hat{x}_{i},\\quad \\mathcal{L}_{\\phi}(\\hat{x}) = -\\sum_{c\\in \\phi}\\log (V_{c}(\\hat{x})), \\quad (12)\\] where \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in clause \\(c\\) in positive and negative form respectively. This loss reaches its minimum only when the prediction \\(\\hat{x}\\) is a satisfying assignment. We note that alternative unsupervised formulations exist Amizadeh et al. [2018], and comprehensive evaluations reported by Li et al. Li et al. [2023] suggest that these two different\n\napproaches perform similarly in practice. Another training option would be to directly optimize a convex loss function derived from SDP relaxation, but this approach is limited because SDP formulations work well for MAX- 2- SAT and can be extended to MAX- 3- SAT, but become increasingly difficult to formulate for general Max SAT problems with larger clauses. Assignment Prediction For satisfiable formulas, we can train the model to predict the satisfiable variable assignments directly. We tried to use either mean squared error or cross- entropy loss between the predicted assignments and the ground truth assignments: \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{MSE}} =\\) \\(\\| \\hat{a} - x\\|_{2}^{2}\\) and \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{CE}} = - \\sum_{i}x_{i}\\log \\hat{x}_{i} + (1 - x_{i})\\log (1 - \\hat{x}_{i})\\) where \\(x\\) is the ground truth assignment and \\(\\hat{a},\\hat{x}\\) are the predicted assignments which differ by application of softmax (i.e. \\(\\hat{a}\\) are just logits without a softmax applied). Closest Assignment Training One problem with assignment prediction is that satisfiable formulas can have a lot of solution and the network is penalized even if it predicts satisfiable solution which differs from the one which is used as a ground truth. We therefore introduce a novel supervision method which uses a Max SAT solver to always compute the solution which is closest to the solution predicted by the model. We then update then model with respect to this solution. In Section 5.2, we show that this method works particularly well when the solution space is large. For each formula in a batch, a valid assignments that minimize the Hamming distance to the model's current predictions is found by the RC2 Max SAT solver. For satisfiable formulas it finds an assignment that satisfies all clauses while being closest to current prediction. For unsatisfiable formulas, it finds an assignment that maximizes the number of satisfied clauses while minimizing distance to prediction. This approach allows the model to explore different regions of the solution space while maintaining valid solutions for SAT instances or optimal partial solutions for UNSAT instances. The supervision signal adapts to the model's current state rather than forcing it toward a single pre- determined assignment. The disadvantage of this method is that the computation of the loss is slower then with the precomputed solution. This could be solved by pre- computing solutions or by using an approximate Max SAT solver. SAT- Only Instance Filtering After initially training with both satisfiable and unsatisfiable instances, we experimented with formula- type specialization by restricting training to only satisfiable instances. In Table 3, we show that this filtering can lead to higher accuracy of the trained model. ### 4.4 Benchmarks and Data Generation We utilize two complementary benchmark generators for evaluating the tested variants: the SR generator and a 3- SAT generator with the ratio between variable and clauses set close to the phase transition point. SR Generator The SR generator by Selsam et al. [Selsam et al., 2018] produces pairs of satisfiable and unsatisfiable formulas that differ by negating only a single literal. This design specifically prevents models from exploiting superficial features for classification. Intuitively, it works by iteratively sampling random clauses and adding them to a formula. After each addition, a SAT solver checks if the formula remains satisfiable. When adding a clause that finally makes the formula unsatisfiable, the generator saves this instance and creates its satisfiable counterpart by flipping a single literal in the last clause. To create each clause, it samples a small integer \\(k\\) based on a mix of Bernoulli and geometric distributions, then randomly selects \\(k\\) variables without replacement, negating each with 0.5 probability. This solver- driven approach ensures\n\nthat satisfiability classification requires understanding the logical structure rather than statistical properties. As reported in the review by Li et al. Li et al. [2023], the models trained on problems from this generator transfer the best to other problem distributions. 3- SAT Generator We also employ a 3- SAT generator configured at the critical clause- to- variable ratio of 4.26, known as the phase transition point where SAT problems are empirically the most challenging to solve [Crawford and Auton, 1996]. At this ratio, approximately half of the generated instances are satisfiable. Each clause contains exactly 3 literals selected uniformly from the available variables, with each literal negated with 0.5 probability. Unlike the SR generator, 3- SAT focuses on generating naturally difficult problems rather than explicitly preventing superficial feature learning. ## 5 Experimental Results ### 5.1 Training and Evaluation Methodology For training, we generate 50,000 instances: 25,000 pairs for SR and 50,000 instances for 3- SAT. We annotate each dataset by the maximum number of variables appearing in the training formulas. For SR, we test two variations, SR40 for which the training examples are sampled with 3- 40 variables and SR100 for which the training examples contain 10- 100 variables. For 3- SAT, the training samples contain 10- 100 variables (3SAT100). The SR dataset is well suited for training SAT/UNSAT prediction models due to its design that prevents learning from superficial features, making it harder for models to exploit statistical shortcuts rather than learning true logical reasoning. We also create versions of training data which contain only satisfiable instances (denoted SAT only). The size of these datasets is half of the original datasets (i.e. 25000 examples). To evaluate generalization, we validate exclusively on problems with exactly the maximum number of variables in each category, therefore SR40 for evaluation means that the problems have always exactly 40 variables (not a range of 3- 40), SR100 test contains only problems with exactly 100 variables, and so on.1 Table 1 summarizes the key statistics of our evaluation datasets. Table 1: Statistics of benchmark test sets. SAT% indicates the percentage of satisfiable instances in each dataset. Avg. Gap represents the average number of unsatisfied clauses when using random variable assignments. SAT Gap and UNSAT Gap show this metric separated by instance satisfiability. SR datasets are generated using the SR generator with the indicated number of variables (e.g., SR40 contains instances with 40 variables), while 3SAT datasets contain instances near the phase transition point with the specified number of variables. All datasets maintain a balanced distribution of satisfiable and unsatisfiable instances. <table><tr><td>Dataset</td><td>SAT%</td><td>Avg. Gap</td><td>SAT Gap</td><td>UNSAT Gap</td><td>Avg. Clauses</td></tr><tr><td>SR40</td><td>50.0%</td><td>21.29</td><td>21.59</td><td>20.99</td><td>228.40</td></tr><tr><td>SR100</td><td>50.0%</td><td>51.31</td><td>50.64</td><td>51.98</td><td>547.49</td></tr><tr><td>SR200</td><td>50.0%</td><td>100.31</td><td>101.03</td><td>99.59</td><td>1083.81</td></tr><tr><td>SR400</td><td>50.0%</td><td>198.74</td><td>198.53</td><td>198.95</td><td>2152.32</td></tr><tr><td>3SAT100</td><td>53.5%</td><td>52.78</td><td>53.00</td><td>52.54</td><td>426.00</td></tr><tr><td>3SAT200</td><td>55.5%</td><td>107.65</td><td>107.45</td><td>107.90</td><td>852.00</td></tr></table> The Gap metric represents the average number of unsatisfied clauses when using random\n\nvariable assignments. This metric has the same definition for both SAT and UNSAT instances; it simply counts how many clauses remain unsatisfied with random assignments on average. Larger gaps indicate more challenging problems where random guessing performs poorly. ### 5.2 Quantitative Evaluation We conducted a comprehensive evaluation that compares different architectural choices and supervision methods. Our evaluation focuses on five key performance metrics: - Average Gap: The average number of unsatisfied clauses across all test instances. Lower values indicate better performance, with 0 representing perfect satisfaction (i.e., no unsatisfied clauses) on satisfiable instances. For unsatisfiable instances, this metric reflects how close the model gets to minimizing unsatisfied clauses.- Gap on SAT: The average number of unsatisfied clauses computed only over satisfiable instances.- Gap on UNSAT: The average number of unsatisfied clauses computed only over unsatisfiable instances.- SAT Accuracy: The percentage of satisfiable instances for which the model correctly finds a satisfying assignment, computed only over satisfiable instances.- Decision Accuracy: The percentage of instances for which the model correctly predicts whether the formula is satisfiable. Since our approach does not formally refute unsatisfiable instances, we classify an instance as unsatisfiable when the model fails to find a satisfying assignment. This means unsatisfiable instances are always classified correctly under this assumption. This applies specifically in the case of assignment-based evaluation. #### 5.2.1 Comparison of Graph Representations, Update Functions and Training Methods Table 2 presents a comprehensive comparison of different architectural configurations trained exclusively on the SR40 dataset. This comparison includes different graph representations (Literal Clause Graph vs. Variable- Clause Graph), update functions (RNN vs. LSTM), and supervision approaches (SAT/UNSAT classification, assignment supervision, and unsupervised objective training), all evaluated on instances with 40 variables. All models were evaluated using Exponential Moving Average (EMA) of parameters during validation only, as detailed in A.1.2, which helps reduce fluctuations in validation metrics and provide more reliable model selection. Importantly, curriculum learning ( A.1.1) was employed only for training models with SAT/UNSAT classification objectives, as it proved unnecessary for models trained with assignment prediction or unsupervised learning approaches. Graph Representation Impact: Our results demonstrate that Literal- Clause Graph (LCG) and Variable- Clause Graph (VCG) representations exhibit different strengths. VCG shows better performance for assignment- based training with RNN updates, achieving a SAT accuracy of 68.8% compared to 48.6% for LCG. Additionally, VCG's more compact representation (using one node per variable rather than two for positive and negative literals) provides computational advantages for larger formulas, making it our preferred choice for scaling to more complex problems.\n\nMessage Passing Mechanism: While LSTM- based message passing shows advantages in some configurations, particularly for unsupervised training, we found that RNN- based approaches offer a better balance of performance and interpretability for assignment- based training. RNN updates with VCG representation achieved higher results for finding satisfying assignments, with \\(68.8\\%\\) SAT accuracy and \\(84.4\\%\\) decision accuracy. The simpler RNN structure also facilitates better analysis of the model's internal reasoning process. However, we found training RNN- based models for SAT/UNSAT classification particularly challenging, with LSTM being more stable for this specific task. Supervision Approach: Our experiments reveal distinct advantages for different supervision approaches: 1. Assignment-based supervision shows better performance for finding satisfying assignments, especially with VCG+RNN configuration (68.8% SAT accuracy, 84.4% decision accuracy). 2. Unsupervised learning achieves the lowest average gaps across configurations (as low as 0.91 for VCG+RNN and 0.84 for VCG+LSTM). This makes unsupervised training useful for applications where minimizing unsatisfied clauses is the priority. 3. SAT/UNSAT classification training, while challenging with RNN, enables an interesting property: models trained only for classification develop an implicit ability to separate embeddings for positive and negative literals. This separation allows for retrieving satisfying assignments through clustering techniques, despite the model not being explicitly trained for assignment prediction. Based on the results reported in Table 2, we identify the VCG+RNN+Assignment configuration as our most effective approach, offering a good balance between assignment accuracy and computational efficiency. This configuration forms the foundation for our further experiments and analysis in subsequent sections. Assignment Training Refinements: Table 3 highlights the impact of a novel training method we introduce, here called \"closest assignment\", with the VCG+RNN configuration across multiple datasets. This method computes assignments that minimize Hamming distance to the model's current predictions, showing improvements over training with precalculated assignments, especially for formulas with more variables. For SR100, using the closest assignment approach reduces the average gap from 3.81 to 1.43 for SAT+UNSAT training and improves SAT accuracy from 44.8% to 53.2%. This improvement correlates with the number of possible solutions in the benchmarks (SR10- 100 has a median of 16 solutions per formula compared to SR3- 40's median of 7), supporting our hypothesis that for formulas with larger solution spaces, guiding the model with dynamically selected assignments that align with its current predictions yields better generalization than using fixed predetermined assignments. The computational challenges of calculating closest assignments during training are noteworthy, particularly for larger benchmarks like 3SAT+UNSAT, where this approach became impractical and we therefore omit this experiment and leave the last row of Table 3 empty. It also highlights an opportunity for future work on more efficient approximation methods for finding near- optimal assignments. Training Data Composition: Our results also indicate that training exclusively on SAT instances (SAT only) improves performance for finding satisfying assignments. For SR40, this approach with closest assignment training achieves our highest SAT accuracy of 76% and decision accuracy of 88%. However, models trained on both SAT and UNSAT instances (SAT+UNSAT)\n\nwith closest assignment supervision demonstrate better gap minimization, achieving an average gap of 0.98 versus 2.68 for SAT- only training on SR40. Table 2: Performance comparison of GNN architectures for SAT solving on the SR40 dataset.The table compares Literal-Clause Graph (LCG) and Variable-Clause Graph (VCG) repre-sentations, RNN and LSTM update mechanisms, and different training objectives. Metrics include average gap (number of unsatisfied clauses) across all instances and separated by sat-isfiability status (lower is better), SAT accuracy (percentage of satisfiable instances solved by finding assignment), and decision accuracy (percentage of correct satisfiability predictions). No-table findings include: unsupervised training consistently achieves lowest gaps; VCG+RNN with assignment prediction shows highest SAT accuracy (68.8%); and RNN-based models with SAT/UNSAT classification proved challenging to train effectively (indicated by dashes). As-terisks (*) indicate results obtained through clustering of node embeddings rather than direct prediction. This model combination was particularly hard to train in our setup. We found that both for VCG and LCG RNN is very sensitive to hyper-parameter selection. As the model failed to get generalized in our final unified experimental setup we do not include this result (close to random performance) now. <table><tr><td>Graph</td><td>Update</td><td>Loss Function</td><td>Avg. Gap\u2193</td><td>Gap on SAT\u2193</td><td>Gap on UNSAT\u2193</td><td>SAT Acc.\u2191</td><td>Dec. Acc.\u2191</td></tr><tr><td rowspan=\"6\">LCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Assignment</td><td>1.83</td><td>1.25</td><td>2.41</td><td>48.6%</td><td>72.8%</td></tr><tr><td>Unsup</td><td>0.93</td><td>0.59</td><td>1.26</td><td>51.4%</td><td>75.7%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>1.96*</td><td>1.27*</td><td>2.62*</td><td>59.2%</td><td>83.9/79.6%</td></tr><tr><td>Assignment</td><td>1.82</td><td>1.06</td><td>2.58</td><td>56.8%</td><td>78.4%</td></tr><tr><td>Unsup</td><td>0.81</td><td>0.45</td><td>1.16</td><td>62%</td><td>81%</td></tr><tr><td rowspan=\"6\">VCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>3.62*</td><td>1.9*</td><td>5.34*</td><td>56.6%</td><td>80/78.3%</td></tr><tr><td>Assignment</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8%</td><td>84.4%</td></tr><tr><td>Unsup</td><td>0.91</td><td>0.58</td><td>1.23</td><td>51.6%</td><td>75.8%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>2.33*</td><td>1.57</td><td>3.08</td><td>52.2%</td><td>81.9/76.1%</td></tr><tr><td>Assignment</td><td>2.05</td><td>0.96</td><td>3.14</td><td>66.4%</td><td>83.2%</td></tr><tr><td>Unsup</td><td>0.84</td><td>0.51</td><td>1.17</td><td>56.4%</td><td>78.2%</td></tr></table> # 5.3 Test-time Scaling A key property of our recurrent GNN architecture for SAT solving is the ability to adjust computational effort at inference time. Unlike standard GNNs with fixed number of layers,the weight-shared recurrent design enables flexible scaling through additional iterations and resampling. ## 5.3.1 Iteration and Resampling Effects Figure 2 demonstrates how increasing message-passing iterations improves the percentage of solved SAT instances. Similarly, Figure 3 shows how the average gap decreases across iterations for various benchmarks. The heat maps in Figure 4 provide a comprehensive view of how performance metrics improve with both increased iterations and resampling attempts. For the model trained on SR40, several observations are notable: \u00b7Iteration benefits: Increasing iterations from 25 to 125 consistently improves all metrics across benchmarks. \u00b7Resampling effects: Multiple inference attempts with different random initializations of node feature vectors further enhance performance. For SR40, decision accuracy improves from 84% with one sample to 93% with five samples at 125 iterations.\n\nTable 3: Performance analysis of VCG+RNN with assignment prediction across different datasets and training methodologies. Our novel \"Closest\" supervision method (which dynamically selects assignments closest to current model predictions) consistently outperforms training with precalculated assignments. For SR40, SAT-only training with closest assignment supervision achieves the highest SAT accuracy (76%), while SAT+UNSAT training with closest assignment supervision yields the lowest average gap (0.98). The missing data for 3SAT100 with SAT+UNSAT closest supervision is due to prohibitive computational costs. Bold values indicate best results per dataset. <table><tr><td>Dataset</td><td>Training Mode</td><td>Assignment Type</td><td>Avg. Gap \u2193</td><td>Gap on SAT \u2193</td><td>Gap on UNSAT \u2193</td><td>SAT Acc. \u2191</td><td>Dec. Acc. \u2191</td></tr><tr><td rowspan=\"4\">SR40</td><td>SAT only</td><td>Precalculated</td><td>2.93</td><td>1.11</td><td>4.75</td><td>68.2 %</td><td>84.1 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>2.68</td><td>0.88</td><td>4.48</td><td>76 %</td><td>88 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8 %</td><td>84.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>0.98</td><td>0.48</td><td>1.49</td><td>71.2 %</td><td>85.6 %</td></tr><tr><td rowspan=\"4\">SR100</td><td>SAT only</td><td>Precalculated</td><td>4.42</td><td>2.36</td><td>6.48</td><td>47.4 %</td><td>73.7 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>3.57</td><td>1.67</td><td>5.48</td><td>59.6 %</td><td>79.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>3.81</td><td>2.34</td><td>5.28</td><td>44.8 %</td><td>72.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>1.43</td><td>0.92</td><td>1.94</td><td>53.2 %</td><td>76.6 %</td></tr><tr><td rowspan=\"4\">3SAT100</td><td>SAT only</td><td>Precalculated</td><td>5.93</td><td>3.40</td><td>9.27</td><td>25.7 %</td><td>57.2 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>5.23</td><td>2.33</td><td>9.11</td><td>48.4 %</td><td>70 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>4.22</td><td>2.84</td><td>6.00</td><td>23.9 %</td><td>55.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td></tr></table> - Cross-distribution applicability: The model trained on SR40 maintains reasonable effectiveness on SR100 and 3SAT100, though with expected performance decrease. This aligns with findings from Li et al. Li et al. [2023], who demonstrated that models trained on SR distributions generally transfer well to other SAT problem structures. #### 5.3.2 Train-time vs Test-time Scaling Tables 4 and 5 present the performance of models trained on SR40 and SR100 distributions when evaluated across benchmarks of varying sizes. The SR40- trained model achieves reasonable generalization to larger instances, though with decreasing effectiveness as problem size increases. For SR100, the model achieves 74.2% decision accuracy despite being trained on smaller instances, showing good generalization capabilities. The SR100- trained model demonstrates better performance on larger instances compared to the SR40- trained model, as expected. On SR200, it achieves 83.0% decision accuracy compared to 58.5% for the SR40 model. This suggests that while test- time scaling can improve performance on larger problems, there are limits to this approach, and training models on larger instances might be necessary for optimal performance on very large problems. These results highlight that recurrent GNN architectures allow for a flexible computation- performance tradeoff that can be adjusted at inference time based on available computational resources and desired solution quality. ### 5.4 Diffusion Model Extension As we mentioned in Section 3.4.4, one can use the GNN as a function approximator \\(f_{\\theta}(\\cdot)\\) inside a diffusion model. This enables another way of scaling the test- time compute. We adapt the diffusion model used by Sun et al. Sun and Yang [2023] where the function approximator is trained to predict the ground truth solution \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t},t)\\) conditioned on a sample \\(\\mathbf{x_t}\\) at time \\(t\\) . The predicted assignment is then used to obtain a sample at time \\(t - 1\\) and this process is repeated again \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_{t - 1}},t - 1)\\) until we reach \\(t = 0\\) . One application of the function approximator together with the sampling is called a diffusion step. The number of diffusion steps \\(T\\) used for inference is a parameter which can be adapted after the model was already\n\nTable 4: Performance of a model trained on SR40 (VCG+RNN with closest assignment supervision) when tested across various benchmarks with a maximum of 100 message-passing iterations and early stopping. The model maintains reasonable performance on SR100 ( \\(74.2\\%\\) decision accuracy) but degrades on larger instances. \"UNSAT Instances (gap \\(= =1\\) )\" shows the percentage of UNSAT instances where the model achieved a gap of 1, which is always optimal for SR datasets but not always achievable for 3SAT instances. \"Steps\" columns indicate average/median iterations required to reach solutions, demonstrating the model's efficiency. <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>89.5%</td><td>79.0%</td><td>95.6%</td><td>16.17/13.0</td><td>13.33/10.0</td></tr><tr><td>SR100</td><td>74.2%</td><td>48.3%</td><td>91.3%</td><td>24.93/21.0</td><td>23.47/19.0</td></tr><tr><td>SR200</td><td>58.5%</td><td>17.0%</td><td>64.5%</td><td>32.44/30.0</td><td>33.98/28.0</td></tr><tr><td>SR400</td><td>51.5%</td><td>3.0%</td><td>16.0%</td><td>41.33/34.0</td><td>52.06/44.5</td></tr><tr><td>3SAT100</td><td>74.8%</td><td>52.8%</td><td>64.0%</td><td>25.63/22.0</td><td>29.66/24.0</td></tr><tr><td>3SAT200</td><td>54.0%</td><td>17.1%</td><td>22.5%</td><td>33.21/25.0</td><td>35.10/31.5</td></tr></table> Table 5: Performance of a model trained on SR100 (VCG+RNN with closest assignment supervision) when tested on SR benchmarks with a maximum of 100 message-passing iterations and early stopping. Given that the SR40-trained model achieved only \\(3\\%\\) SAT accuracy on SR400 (see Table 4), we focused on evaluating how training on larger instances improves scaling. The results show dramatic improvement on larger benchmarks ( \\(36.5\\%\\) vs \\(3\\%\\) on SR400), demonstrating that training on larger problems significantly enhances generalization capacity. The \"Steps\" metrics confirm the SR100-trained model requires fewer iterations on larger problems (e.g., 30.68 vs 41.33 average iterations for SAT instances on SR400). <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>90.6%</td><td>81.2%</td><td>90.0%</td><td>14.57/12.0</td><td>16.21/12.0</td></tr><tr><td>SR100</td><td>79.3%</td><td>58.7%</td><td>85.7%</td><td>22.16/18.0</td><td>22.64/19.0</td></tr><tr><td>SR200</td><td>83.0%</td><td>68.2%</td><td>60.2%</td><td>22.29/20.0</td><td>27.12/22.0</td></tr><tr><td>SR400</td><td>68.2%</td><td>36.5%</td><td>78.0%</td><td>30.68/26.0</td><td>33.13/28.0</td></tr></table>\n\n<center>Figure 2: Percentage of SAT instances solved as message passing iterations increase for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Performance on SR100, showing rapid initial improvement. Right: Comparison across benchmarks, demonstrating effectiveness decreases with problem size but benefits from additional iterations, highlighting the recurrent architecture's inference-time scaling capability. </center> <center>Figure 3: Average gap (unsatisfied clauses) reduction with increasing message passing iterations for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Comparison across benchmarks showing extremely rapid gap reduction in early iterations for all problem sizes, with all benchmarks achieving remarkably low average gaps despite varying SAT-solving performance. Right: Individual instance trajectories revealing different convergence patterns between SAT and UNSAT instances, with occasional fluctuations suggesting potential benefit from monitoring solution quality during inference. </center> trained and therefore, in this setting we have two types of iterations. One is the number of message- passing iterations and the second is the number of diffusion steps. In Table 6 we report the tradeoff between the number of message- passing steps (referred to as GNN_Steps) and the number of diffusion steps. The reported numbers correspond to the dataset SR100 with 100 variables in each problem. The model was trained on the SR40 distribution and the tested combinations use around 300 iterations in total distributed between the two types of steps. The experiments revealed a consistent trend: increasing the number of message- passing steps is generally more important for improving metrics such as Accuracy and Avg. Gap. #### 5.4.1 Connection to Assignment Prediction Training We also report an interesting finding which allows to simplify the function approximator used in the diffusion model. Notice that in the expression \\(\\mathbf{x}_0 = f_\\theta (\\mathbf{x}_t, t)\\) it is also conditioned on the timestep \\(t\\) . This conditioning is dictated by the theory of diffusion models Nakkiran et al. [2024] and most of the models, including the one by Sun et al. Sun and Yang [2023] blindly follow this design choice. In our experiments, we found out that this conditioning is not needed and that the model sometimes works even better without it. Therefore, in all reported results, the\n\n<center>Figure 4: Performance heatmaps for a model trained on SR40 with SAT+UNSAT closest assignment supervision, showing how metrics improve with both increased iterations (columns) and resampling attempts (rows). Testing on SR40 (top), SR100 (middle), and 3SAT100 (bottom) demonstrates significant gains from both scaling dimensions\u2014e.g., SR40 decision accuracy improves from 84% (1 sample, 25 iterations) to 93% (5 samples, 125 iterations). This two-dimensional inference-time scaling capability is consistent across benchmarks but with decreasing returns on larger problems. </center> model is trained to predict the solution \\(\\mathbf{x_0}\\) only from the sample at timestep \\(t\\) ( \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t})\\) ). Concurrently to us, this fact was also discovered by Sun et al. Sun et al. [2025] (the same surname is a coincidence) and it's possible that many of the reported experiments which blindly use this conditioning would result in better values without it. In this simplified setup, the training examples \\((\\mathbf{x_0},\\mathbf{x_t})\\) are sampled by taking a solution of a formula \\((\\mathbf{x_0})\\) , sampling a random \\(t\\) from the diffusion schedule and obtaining a corrupted version of the solution at time \\(t\\) ( \\(\\mathbf{x_t}\\) ). The model is trained to predict \\(\\mathbf{x_0}\\) from \\(\\mathbf{x_t}\\) . The GNN is the same as in the case of assignment prediction except that it also contains a learnable embedding layer which embeds the Boolean values in the assignment \\(\\mathbf{x_t}\\) into a vector space to obtain the initial embeddings of variables (or literals) for the first pass of message- passing. The only difference from the model trained for assignment prediction is therefore that the initial embeddings are not sampled randomly but obtained by embedding the perturbed assignment \\(\\mathbf{x_t}\\) . This also means that during test time, these two approaches differ only by rounding, i.e. running the model trained for assignment prediction for 100 steps and after every 20 steps rounding the variable embeddings to vectors representing True and False is same as running the diffusion model for 5 diffusion steps where each step has 20 message- passing iterations.\n\ntheir performance and on the theoretical side, understanding how a GNN can solve a CNF formula could help us to elucidate the reasoning ability of Transformers Vaswani et al. [2017] because Transformers can be viewed as GNNs in which the graph connectivity is given by the attention map and is learned from data Cai et al. [2023]. Our aim in this contribution is to provide an experimental evaluation of different design choices for GNNs in the context of Boolean satisfiability together with an intuitive explanation of the inner workings of these models. Our main contributions are as follows: - We provide an experimental comparison of different architectures and training regimes.- We introduce a novel supervision method based on the closest assignment, resulting in significant improvements.- We demonstrate that these architectures scale well at test time.- We extend the graph neural network to a diffusion model and show how it relates to the base model.- We provide an intuitive explanation for the inner workings of these models. The rest of the text has the following structure: Section 3 (Relevant Background) provides the necessary context on Boolean satisfiability problems, SAT solving approaches, graph neural networks, theoretical connection to approximation algorithms, and diffusion models. Section 4 (Experimental Setup) describes our methodology, including data representation choices, architecture variants, supervision methods, and benchmark generation. Section 5 (Experimental Results) presents our comprehensive evaluation, comparing different graph representations and training methods (Section 5.2), demonstrating test- time scaling capabilities (Section 5.3), and introducing our diffusion model extension (Section 5.4). Section 6 (Interpreting the Trained Model) offers analysis of the embedding space and explains the networks' behavior through the lens of approximation algorithms based on continuous relaxation. Section 2 (Related Work) positions our contribution within the broader research landscape, and Section 7 contains a discussion of our findings and directions for future research. We conclude in Section 8. Additional implementation details and mathematical derivations are provided in the Appendix. ## 2 Related Work Our research builds directly upon Neuro SAT Selsam et al. [2018], which introduced the first end- to- end neural approach for SAT solving using a recurrent message- passing architecture. While we maintain the core iterative design of Neuro SAT (allowing variable numbers of message- passing iterations through weight sharing), we explore simplified variants using RNNs and LSTMs and incorporate techniques like curriculum learning to improve training efficiency. Several other works have explored different directions in neural SAT solving. Li et al. Li et al. [2023] developed G4SATBench to benchmark various GNN architectures (GCN, GGNN, GIN) across different graph representations and supervision objectives. Unlike their broader exploration across architecture types, our work focuses on the recurrent message- passing paradigm from Neuro SAT and investigates how different training objectives and graph representations affect performance within this specific framework. We also mention the work by Warde et al. Warde- Farley et al. [2023] who developed a recurrent architecture based on a Restricted Boltzmann Machine. Hybrid approaches that integrate neural networks with traditional solvers include Neuro Core by Selsam and Bjorner Selsam and Bjorner [2019], which uses neural predictions to guide variable branching in CDCL solvers. Similarly, Wang et al. Wang et al. [2021] proposed Neuro Comb to enhance CDCL solvers through GNN- based identification of important variables and clauses.\n\nTable 6: Performance Metrics for Different GNN and Diffusion Step Configurations. Variable names shown in parentheses in the original data source are omitted here for brevity. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Dec. Acc. (%)</td><td>Single-Step Avg. Gap</td><td>Single-Step Dec. Acc (%)</td></tr><tr><td>20</td><td>15</td><td>1.09</td><td>68.7</td><td>3.26</td><td>60.2</td></tr><tr><td>23</td><td>13</td><td>1.05</td><td>70.4</td><td>2.80</td><td>63.1</td></tr><tr><td>27</td><td>11</td><td>0.96</td><td>73.6</td><td>2.44</td><td>64.7</td></tr><tr><td>31</td><td>9</td><td>0.98</td><td>73.8</td><td>2.11</td><td>68.2</td></tr><tr><td>35</td><td>8</td><td>0.93</td><td>75.4</td><td>1.96</td><td>69.5</td></tr><tr><td>38</td><td>7</td><td>0.92</td><td>76.3</td><td>1.83</td><td>70.2</td></tr><tr><td>42</td><td>7</td><td>0.90</td><td>76.7</td><td>1.70</td><td>71.6</td></tr><tr><td>46</td><td>6</td><td>0.95</td><td>76.8</td><td>1.64</td><td>72.1</td></tr><tr><td>50</td><td>6</td><td>0.94</td><td>76.2</td><td>1.52</td><td>73.0</td></tr></table> #### 5.4.2 Interleaving Diffusion Steps with Unit Propagation The fact that for each diffusion step, the model outputs probabilities for two possible values, allows us to obtain a partial solution and then run a unit propagation to deduce assignment to other variables. The partial assignment can be obtained by fixing a threshold and then assigning only variables for which one of the values has a predicted probability higher than this threshold. The lower the threshold, the more variables will be fixed and the higher the probability that it will not be possible to complete the partial assignment to a satisfiable assignment. We therefore design a tree- search- like algorithm which first tries a low threshold in each diffusion step and if it does not find a satisfiable assignment it backtracks and increases the threshold to obtain a new partial assignment. The details of this algorithm are described in A.3 and the experimental results are reported in Table 7. As can be seen, interleaving the diffusion steps with unit propagation results in additional improvements over the base diffusion model (approximately \\(10\\%\\) ). We explicitly mention that this experiment is provided only to show a possible avenue for further improvements and the algorithm in its current form is not optimized for speed. Table 7: Performance with Unit Propagation. Here we compare the performance with (U.P. Acc.) and without (Dec. Acc.) Unit Propagation, and report the computational cost of Unit Propagation, listing the average number of total recursive function calls, the average number of recursive calls in solved problems, and the average number of recursive calls in unsolved problems. <table><tr><td>Problems</td><td>Dec. Acc. (%)</td><td>U.P. Acc. (%)</td><td>Total Rec. Calls</td><td>Solved Rec. Calls</td><td>Unsolved Rec. Calls</td></tr><tr><td>SR40</td><td>88.4</td><td>94.2</td><td>32.864</td><td>6.701</td><td>53.546</td></tr><tr><td>SR50</td><td>86.6</td><td>93.7</td><td>29.539</td><td>6.995</td><td>47.038</td></tr><tr><td>SR60</td><td>83.3</td><td>92.2</td><td>26.414</td><td>7.526</td><td>40.204</td></tr><tr><td>SR70</td><td>79.5</td><td>89.5</td><td>24.162</td><td>6.752</td><td>35.505</td></tr><tr><td>SR80</td><td>77.6</td><td>88.0</td><td>22.604</td><td>6.917</td><td>32.219</td></tr><tr><td>SR90</td><td>74.0</td><td>85.1</td><td>22.140</td><td>7.274</td><td>30.151</td></tr><tr><td>SR100</td><td>73.4</td><td>83.7</td><td>20.363</td><td>7.129</td><td>27.074</td></tr><tr><td>SR150</td><td>63.2</td><td>75.1</td><td>17.388</td><td>7.828</td><td>20.592</td></tr><tr><td>SR200</td><td>58.0</td><td>67.5</td><td>16.270</td><td>8.710</td><td>17.868</td></tr></table>",
    "6_interpreting_the_trained_model_61_embedding_space_analysis_our_analysis_of_variable_embeddings_reveals_patterns_that_explain_how_gnns_learn_to_solve_sat_problems_when_visualizing_these_embeddings_using_dimensionality_reduction_mc_innes_et_al_2018_we_observe_that_they_form_distinct_clusters_corresponding_to_optimal_variable_assignments_as_shown_in_figure_5_variable_embeddings_start_randomly_distributed_but_gradually_organize_into_two_clusters_through_message_passing_iterations_by_applying_k-_means_clustering_k_2_to_these_embeddings_we_can_recover_variable_assignments_that_approximate_optimal_solutions_even_from_networks_trained_only_to_predict_satisfiability_status_62_iterative_optimization_behavior_by_tracking_clause_satisfaction_across_iterations_we_observe_that_gnns_solve_sat_problems_through_progressive_local_refinement_the_gap_number_of_unsatisfied_clauses_decreases_following_a_trajectory_typical_of_iterative_optimization_methods_rapid_initial_improvement_followed_by_gradual_refinement_this_behavior_supports_the_interpretation_that_gnns_implicitly_learn_to_perform_continuous_optimization_in_a_high-_dimensional_space_similar_to_sdp_relaxations_for_sat_the_effectiveness_of_additional_message_passing_iterations_during_inference_further_strengthens_this_connection_a_difference_from_the_sdp_relaxation_is_that_the_objective_function_which_the_gnn_implicitely_optimizes_is_non-_convex_because_we_observed_that_it_can_get_stuck_in_local_optima_or_converge_to_different_solutions_when_initialized_multiple_times_by_different_random_embeddings_figure_3_illustrates_how_the_average_gap_decreases_with_increasing_iterations_the_trajectory_suggests_a_rapid_improvement_phase_followed_by_more_gradual_refinement_individual_instance_trajectories_reveal_that_while_most_instances_show_steady_improvement_toward_optimal_solutions_some_exhibit_fluctuations_particularly_unsatisfiable_instances_this_observation_supports_the_potential_value_of_early_stopping_techniques_as_in_rare_cases_the_gap_at_later_iterations_might_be_higher_than_a_previously_achieved_minimum_gap_the_bi-_level_optimization_perspectivewhere_message_passing_performs_an_inner_optimization_loop_finding_variable_assignments_guided_by_network_parameters_optimized_at_the_outer_level_during_traininghelps_explain_the_networks_ability_to_generalize_to_novel_problem_instances_and_larger_problems_than_those_seen_during_training_in_section_7_we_discuss_more_details_about_a_possibility_of_manual_derivation_of_the_gnn_equations_from_and_explicit_objective_function_7_discussion_in_this_section_we_discuss_the_limitations_of_our_work_along_with_an_outlook_for_future_research_the_primary_limitation_of_the_methods_presented_here_is_that_they_are_not_competitive_with_state-_of-_the-_art_sat_solvers_on_benchmarks_derived_from_real-_world_problems_current_sat_solvers_can_handle_formulas_with_millions_of_variables_which_is_not_feasible_for_the_gnn_in_its_current_form_however_as_mentioned_in_the_introduction_our_motivation_for_studying_these_models_is_to_better_understand_the_reasoning_capabilities_of_neural_networks_in_a_simplified_context_the_test-_time_scaling_experiments_clearly_demonstrate_that_the_gnns_can_successfully_generalize_beyond_their_training_distribution_and_do_not_merely_learn_superficial_statistical_patterns_the_qualitative_results_presented_in_section_6_further_suggest_that_it_is_possible_to_fully_understand_the_mechanisms_by_which_the_gnn_solves_a_given_formula_figure_3_illustrates_that_the_trained_gnn_functions_as_an_implicit_max_sat_solver_incrementally_maximizing_the_number": "<center>Figure 5: Evolution of variable embeddings during message passing iterations for a satisfiable SR40 instance. The visualization shows 2D projections at different stages (Initial through Iteration 25), colored k-means algorithm in each iteration (green/red). Initially random, embeddings gradually organize into two distinct clusters often corresponding to optimal variable assignments. This clustering behavior was observed across different model architectures and training objectives\u2014notably, even models trained solely for SAT/UNSAT classification (without explicit assignment supervision) develop this embedding separation. This phenomenon supports our interpretation that GNNs implicitly perform continuous optimization similar to SDP relaxation for SAT problems. </center>\n\nof satisfied clauses at each step. These local updates occur in continuous space and can therefore be viewed as gradient updates with respect to an implicit objective function measuring clause satisfaction. Variables are also represented in a high- dimensional vector space, similar to semi- definite programming as explained in B. From this perspective, Equations 6, 7, and 11 can be interpreted as a gradient descent algorithm searching for an optimal assignment over a high- dimensional unit sphere (due to unit normalization), while the final classification layer corresponds to a rounding step to Boolean values. In future work, we aim to manually derive these equations from a trained GNN using a primal- dual approach, interleaving gradient updates of primal and dual variables associated with constraints. We believe that by utilizing suitable proximal operators and an appropriate metric in the relaxed solution space, the GNN can be effectively interpreted as a primal- dual algorithm optimizing a continuous relaxation of the Max SAT objective in a high- dimensional space. This points out to another major advantage of using the RNN update function because its simple form is suitable for such derivation. Deriving equations for such algorithms applicable to arbitrary combinatorial optimization problems would be highly beneficial in practice, allowing these equations to be parameterized by learnable matrices and fine- tuned for specific problem distributions. Such data- driven solvers would be analogous to physics- informed neural networks Cai et al. [2021], where substantial domain knowledge is embedded within the model, followed by fine- tuning to approximate the dynamics of a particular physical system. This approach results in fast numerical solvers tailored to specific domains. We believe that the development of data- drive numerical solvers represents an exciting future direction for combinatorial optimization research. To make these numerical solvers practical, it will still be necessary to integrate them into more complex systems, where they would function as guessing or bounding heuristic. Another limitation of our work is that the model was tested exclusively on random problems. This decision is justified by the findings of Li et al. Li et al. [2023], who demonstrated that models trained on random problem instances exhibit superior generalization to other distributions. Since Li et al. already provided experimental results demonstrating the transferability of models across different problem distributions, we chose not to repeat those experiments here. ## 8 Conclusion This work provides a comprehensive analysis of graph neural networks for Boolean satisfiability problems. Our evaluation identified key design choices that enhance performance: variable- clause graph representation with RNN updates offers an effective balance of accuracy and efficiency, while our novel closest assignment supervision method significantly improves performance on problems with large solution spaces. The recurrent architecture enables flexible scaling during inference through additional message- passing iterations and resampling. Our diffusion model extension demonstrates another approach to inference- time adaptation, with further improvements possible by integrating classical techniques like unit propagation. Our analysis of embedding space patterns and optimization trajectories supports the interpretation that these models implicitly implement continuous relaxation algorithms for Max SAT, explaining their ability to generalize to novel problem instances. This connection provides a theoretical framework for understanding neural reasoning capabilities in structured domains, with implications for the design of hybrid solving approaches. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit- sat: An unsupervised differentiable approach. In International conference on learning representations, 2018.\n\nJacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state- spaces. Advances in neural information processing systems, 34:17981- 17993, 2021. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisfiability, volume 185. IOS press, 2009. Sally C Brailsford, Chris N Potts, and Barbara M Smith. Constraint satisfaction problems: Algorithms and applications. European journal of operational research, 119(3):557- 581, 1999. Chen Cai, Truong Son Hy, Rose Yu, and Yusu Wang. On the connection between mpnn and graph transformer. In International conference on machine learning, pages 3408- 3430. PMLR, 2023. Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics- informed neural networks (pinns) for fluid mechanics: A review. Acta Mechanica Sinica, 37 (12):1727- 1738, 2021. James M Crawford and Larry D Auton. Experimental results on the crossover point in random 3- sat. Artificial intelligence, 81(1- 2):31- 57, 1996. Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1- 2):3- 71, 1988. Zhaohui Fu and Sharad Malik. On solving the partial max- sat problem. In International Conference on Theory and Applications of Satisfiability Testing, pages 252- 265. Springer, 2006. Bernd G\u00e4rtner and Jiri Matousek. Approximation algorithms and semidefinite programming. Springer Science & Business Media, 2012. Michel X Goemans and David P Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. Journal of the ACM (JACM), 42(6):1115- 1145, 1995. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek- r1: Incentivizing reasoning capability in llms via reinforcement learning. ar Xiv preprint ar Xiv:2501.12948, 2025. Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840- 6851, 2020. Abdelrahman Hosny and Sherief Reda. torchmsat: A gpu- accelerated approximation to the maximum satisfiability problem. ar Xiv preprint ar Xiv:2402.03640, 2024. Jan Hula, David Moj\u017e\u00ed\u0161ek, and Mikol\u00e1\u0161 Janota. Understanding gnns for boolean satisfiability through approximation algorithms. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pages 953- 961, 2024. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El- Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. ar Xiv preprint ar Xiv:2412.16720, 2024. Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Vardi, and Zhiwei Zhang. Fourier sat: A fourier expansion- based algebraic framework for solving hybrid boolean constraints. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 1552- 1560, 2020.\n\nZhaoyu Li and Xujie Si. Nsnet: A general neural probabilistic framework for satisfiability problems. Advances in Neural Information Processing Systems, 35:25573- 25585, 2022. Zhaoyu Li, Jinpei Guo, and Xujie Si. G4satbench: Benchmarking and advancing sat solving with graph neural networks. ar Xiv preprint ar Xiv:2309.16941, 2023. Gary Marcus. Deep learning: A critical appraisal. ar Xiv preprint ar Xiv:1801.00631, 2018. Gary F Marcus. The algebraic mind: Integrating connectionism and cognitive science. MIT press, 2003. Leland Mc Innes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for dimension reduction. ar Xiv preprint ar Xiv:1802.03426, 2018. Preetum Nakkiran, Arwen Bradley, Hattie Zhou, and Madhu Advani. Step- by- step diffusion: An elementary tutorial. ar Xiv preprint ar Xiv:2406.08929, 2024. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural sat solver. In 2022 International joint conference on neural networks (IJCNN), pages 1- 8. IEEE, 2022. Motakuri Ramana and Alan J Goldman. Some geometric results in semidefinite programming. Journal of Global Optimization, 7(1):33- 50, 1995. Bart Selman, Henry A Kautz, Bram Cohen, et al. Local search strategies for satisfiability testing. Cliques, coloring, and satisfiability, 26:521- 532, 1993. Daniel Selsam and Nikolaj Bjorner. Guiding high- performance sat solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing- SAT 2019: 22nd International Conference, SAT 2019, Lisbon, Portugal, July 9- 12, 2019, Proceedings 22, pages 336- 353. Springer, 2019. Daniel Selsam, Matthew Lamm, Benedikt Binz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a sat solver from single- bit supervision. ar Xiv preprint ar Xiv:1802.03685, 2018. Qiao Sun, Zhicheng Jiang, Hanhong Zhao, and Kaiming He. Is noise conditioning necessary for denoising generative models? ar Xiv preprint ar Xiv:2502.13129, 2025. Zhiqing Sun and Yiming Yang. Difusco: Graph- based diffusion solvers for combinatorial optimization. Advances in neural information processing systems, 36:3706- 3731, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. W Wang, Y Hu, M Tiwari, S Khurshid, KL Mc Millan, and R Miikkulainen. Neurocomb: improving sat solving with graph neural networks, 2021. David Warde- Farley, Vinod Nair, Yujia Li, Ivan Lobov, Felix Gimeno, and Simon Osindero. Solving maxsat with matrix multiplication. ar Xiv preprint ar Xiv:2311.02101, 2023. Morris Yau, Nikolaos Karalias, Eric Lu, Jessica Xu, and Stefanie Jegelka. Are graph neural networks optimal approximation algorithms? Advances in Neural Information Processing Systems, 37:73124- 73181, 2024. Emre Yolcu and Barnabas P\u00f3czos. Learning local search heuristics for boolean satisfiability. Advances in Neural Information Processing Systems, 32, 2019.\n\n<center>Figure 6: Validation accuracy during training. Our model with a curriculum achieves reaches \\(85\\%\\) in approximately 30 minutes, whereas the original Neuro SAT implementation needs over 5 hours. For comparison, we also add our implementation trained on the same data, but without a curriculum. The training of each model stops once it achieves an accuracy of \\(85\\%\\) on a validation set. </center> ## A Appendix ## A.1 Training Tricks and Information ## A.1.1 Curriculum Learning We implement a curriculum learning strategy to improve training efficiency and generalization. The key insight is that starting with simpler (smaller) formulas and gradually increasing complexity allows the model to learn basic logical reasoning patterns before tackling more complex instances. Our curriculum proceeds as follows: 1. Start training with small formulas (5 variables) 2. Set a validation accuracy threshold for each formula size (starting at \\(65\\%\\) for the smallest size and increasing to \\(85\\%\\) for the largest) 3. Once the model reaches the threshold accuracy on the current size or reaches a maximum number of epochs (100), increase the formula size by 2 variables 4. When introducing a new size, include formulas from the four previous sizes to prevent catastrophic forgetting 5. Continue until reaching the maximum formula size (40 variables) This curriculum approach significantly accelerates training compared to starting with the full distribution of formula sizes. Our previous experiments showed that the curriculum- trained model reaches \\(85\\%\\) validation accuracy in approximately 30 minutes, compared to over 5 hours for the non- curriculum approach. ## A.1.2 Exponential Moving Average (EMA) We employ Exponential Moving Average (EMA) for model parameter updates during training. EMA maintains a shadow copy of the model parameters that is updated after each training\n\nbatch: \\[\\theta_{\\mathrm{EMA}}\\leftarrow \\beta \\theta_{\\mathrm{EMA}} + (1 - \\beta)\\theta_{\\mathrm{current}} \\quad (13)\\] where \\(\\beta\\) is the decay rate (we use \\(\\beta = 0.999\\) ). During validation and testing, we use the EMA parameters instead of the current parameters. This technique significantly stabilizes training and improves generalization, especially in the early stages of training. Our experiments show that EMA provides a smooth validation accuracy curve, while the validation accuracy of the non- EMA model exhibits high variance and jumps of up to \\(10\\%\\) . #### A.1.3 Learning Rate Schedule We implement a custom learning rate schedule that combines cosine annealing for the first half of training and a constant minimum learning rate for the second half: \\[\\eta (t) = \\left\\{ \\begin{array}{ll}\\eta_{\\mathrm{min}} + (\\eta_{0} - \\eta_{\\mathrm{min}})\\frac{1 + \\cos(\\pi t / t_{\\mathrm{half}})}{2} & \\mathrm{if} t< t_{\\mathrm{half}}\\\\ \\eta_{\\mathrm{min}} & \\mathrm{otherwise} \\end{array} \\right. \\quad (14)\\] where \\(\\eta_{0}\\) is the initial learning rate, \\(\\eta_{\\mathrm{min}}\\) is the minimum learning rate (set to \\(10^{- 5}\\) ), \\(t\\) is the current epoch, and \\(t_{\\mathrm{half}}\\) is half of the maximum number of epochs. This schedule helps the model converge to a good solution in the first half of training and then fine- tune in the second half without disrupting the learned representations. ## A.1.4 Impact of hidden dimension on GNN Performance The dimensionality of the hidden representations, here denoted as d_model, specifies the size of the embedding vectors of variables and the hidden state dimension used during the message passing and update phases within the GNN architecture. The choice of d_model directly influences the model's capacity to learn complex patterns and relationships within the graph structure and node features. It also impacts computational resource requirements, such as memory usage and training time. Understanding how performance metrics vary with different d_model values is therefore crucial for effective model design and hyperparameter tuning. Our evaluation in table 8 generally shows that increasing the d_model leads to improved model performance, likely due to the enhanced representational capacity allowing the model to capture more intricate features. However, we observed that this trend exhibits diminishing returns; while significant performance gains are noticeable as the dimension increases up to 64, further increases yield smaller improvements in accuracy relative to the growing computational cost (e.g., peak accuracy at d_model=256 came with significantly longer training time). This suggests that, considering the marginal benefits, a dimension around 64 still presents a practical optimum, offering a good balance between performance and model complexity/efficiency for this specific setup. ## A.2 Diffusion Model Extensions ## A.3 Using Unit Propagation for Problem Simplification in the Diffusion Process In the diffusion process, each iteration provides a belief for every variable, which can be leveraged to continuously simplify the problem via a unit propagation algorithm until it converges to an empty problem, thereby obtaining a solution. The overall solving process is recursive, and its main steps are described as follows:\n\nTable 8: Experimental results demonstrating the impact of hidden dimension size (d_model) on model performance and training duration. \u2018Embedding Size (d_model)\u2019 refers to the dimensionality of the hidden representations within the GNN. \u2018Accuracy\u2019 indicates the performance metric achieved by the model. \u2018Time (hours)\u2019 specifies the total time required to train the model for each corresponding dimension size. <table><tr><td>Embedding Size (d_model)</td><td>Accuracy</td><td>Time (hours)</td></tr><tr><td>16</td><td>0.782</td><td>1.62</td></tr><tr><td>32</td><td>0.852</td><td>1.66</td></tr><tr><td>48</td><td>0.860</td><td>1.70</td></tr><tr><td>64</td><td>0.869</td><td>1.87</td></tr><tr><td>96</td><td>0.861</td><td>2.32</td></tr><tr><td>128</td><td>0.864</td><td>2.99</td></tr><tr><td>256</td><td>0.877</td><td>7.55</td></tr></table> ## 1. Partial Assignment Extraction and Local Unit Propagation In each diffusion step, a belief value between 0 and 1 is calculated for every variable. A value closer to 1 indicates a stronger inclination toward being true, and vice versa. We set a threshold to select variables with high belief and assign them accordingly to obtain a partial assignment. This partial assignment is then used to perform unit propagation for clause simplification. The unit propagation algorithm works as follows: If a clause contains a literal that is already satisfied by the current assignment, the clause is marked as satisfied. If all literals in a clause have been assigned but none satisfy it, a conflict signal is returned. For clauses that are not fully assigned, the unassigned literals are retained to form a simplified clause set. For unit clauses obtained during the simplification process (i.e., clauses containing only a single literal), the corresponding unassigned variable is directly assigned the appropriate value, further advancing the local solving process. ## 2. Multi-Threshold Strategy and Recursive Solving In the partial assignment extraction step, setting a lower threshold allows for the selection of as many assignments as possible at each step, thereby greatly simplifying the problem; however, it is more likely to select unreliable assignments that may lead to contradictions. To balance this, we adopt a multi- threshold list, starting from the lowest threshold. For each given threshold, if a new partial assignment is obtained, unit propagation is used to update the clauses and evaluate: If the simplified clause set becomes empty, all clauses are satisfied and the final solution is directly returned. If a conflict occurs or the recursive call at the next level fails, the threshold is raised; if the highest threshold is reached, the process moves to the next recursive level and performs another diffusion step. If unit propagation succeeds but the problem is not yet completely solved, the process recurses to the next level, performing a diffusion step on the updated clauses. If the recursion reaches a preset maximum depth and the clauses still cannot be satisfied, the recursion at that level fails.\n\nTable 9: Performance on SR100 for Different Diffusion Step and Fixed GNN Step. Note that the Performance is no longer Significantly Improved when Diffusion Steps Larger than 8. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>25</td><td>4</td><td>0.991</td><td>69.9</td></tr><tr><td>25</td><td>5</td><td>0.901</td><td>71.2</td></tr><tr><td>25</td><td>6</td><td>0.798</td><td>72.7</td></tr><tr><td>25</td><td>8</td><td>0.705</td><td>73.0</td></tr><tr><td>25</td><td>10</td><td>0.728</td><td>72.1</td></tr><tr><td>25</td><td>20</td><td>0.662</td><td>73.3</td></tr><tr><td>25</td><td>30</td><td>0.676</td><td>72.3</td></tr><tr><td>25</td><td>40</td><td>0.655</td><td>73.3</td></tr><tr><td>25</td><td>50</td><td>0.663</td><td>73.0</td></tr></table> Table 10: Performance on SR100 for Different GNN Step and Fixed Diffusion Step. Note that the Performance is no longer Significantly Improved when GNN Steps Larger than 50. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>10</td><td>10</td><td>2.028</td><td>55.0</td></tr><tr><td>20</td><td>10</td><td>0.846</td><td>68.6</td></tr><tr><td>30</td><td>10</td><td>0.622</td><td>74.4</td></tr><tr><td>40</td><td>10</td><td>0.578</td><td>75.5</td></tr><tr><td>50</td><td>10</td><td>0.533</td><td>77.6</td></tr><tr><td>60</td><td>10</td><td>0.518</td><td>77.2</td></tr><tr><td>70</td><td>10</td><td>0.500</td><td>78.6</td></tr><tr><td>80</td><td>10</td><td>0.521</td><td>77.9</td></tr><tr><td>90</td><td>10</td><td>0.512</td><td>77.6</td></tr><tr><td>100</td><td>10</td><td>0.522</td><td>77.4</td></tr></table> Table 7 shows the performance and computational cost after applying unit propagation. We tested a fixed model under the settings: GNN steps \\(= 25\\) , diffusion steps \\(= 10\\) , and multithreshold list \\(= [0.6, 0.75, 0.9]\\) . As shown, incorporating unit propagation improves accuracy by approximately \\(10\\%\\) across various problem settings. The last three columns of the table list the number of recursive function calls during the recursion process. Since each call involves one diffusion step, the computational cost incurred by the multi- threshold strategy is directly reflected. We observed that for harder problems, the computational cost of the multi- threshold strategy is actually lower, as unit propagation on partial assignments is more likely to encounter conflicts, thereby reducing the number of recursive branches. ## A.4 Influence of Number of Message-passing and Diffusion Steps For completeness, we also report evaluations in which the number of diffusion steps is fixed and the number of message- passing steps is changing (Table 10) and vice versa (Table 9). We observe that the expansion of the number of iterative steps does not always bring benefits: when the number of one kind of step is fixed, further increasing the number of another kind of step beyond a certain threshold will not lead to performance improvement.\n\nThese approaches differ from our end- to- end model but demonstrate alternative applications of neural methods to SAT solving. The connection between neural networks and continuous relaxations is particularly relevant to our work. Kyrillidis et al. Kyrillidis et al. [2020] introduced Fourier SAT, which transforms Boolean SAT problems into continuous optimization using the Walsh- Fourier transform. This approach provides a theoretical foundation for understanding how neural networks might implicitly convert discrete search problems into continuous optimization. Similar technique was introduced by Hosny et al. Hosny and Reda [2024] who develop GPU- accelerated approaches for Max SAT problems. Hula et al. Hula et al. [2024] and Yau et al. Yau et al. [2024] explore the connection between GNNs and semidefinite programming relaxations, demonstrating empirically and theoretically that message- passing can implement gradient- based optimization of SDP relaxations. In the broader domain of combinatorial optimization, Sun et al. Sun and Yang [2023] used diffusion models based on GNNs to solver problems such as traveling salesman. ## 3 Relevant Background ### 3.1 Boolean Satisfiability and Maximum Satisfiability #### 3.1.1 Boolean Satisfiability as a Constraint Satisfaction Problem Boolean satisfiability (SAT) is a fundamental problem in computer science that asks whether a given Boolean formula has a satisfying assignment. The formula is built from propositional variables \\(x_{1},x_{2},\\ldots\\) that can take values from \\(\\{0,1\\}\\) , representing false and true respectively, and logical connectives: conjunction \\((\\wedge)\\) , disjunction \\((\\vee)\\) , and negation \\((\\neg)\\) . While other connectives like implication \\((\\rightarrow)\\) and equivalence \\((\\leftrightarrow)\\) exist, they can be expressed using these basic operators. A literal is either a propositional variable \\(x\\) or its negation \\(\\neg x\\) . While Boolean formulas can take arbitrary form, the most common representation is the conjunctive normal form (CNF), where a formula is a conjunction of clauses, and each clause is a disjunction of literals. For example, \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) is a CNF formula with two clauses. We note that any Boolean formula can be transformed into an equisatisfiable CNF formula, albeit potentially requiring additional variables. An assignment \\(\\sigma\\) maps each propositional variable to either 0 or 1. We say \\(\\sigma\\) satisfies a CNF formula if at least one literal in each clause evaluates to true under \\(\\sigma\\) . For instance, the assignment \\(\\sigma (x_{1}) = 1,\\sigma (x_{2}) = 0,\\sigma (x_{3}) = 1\\) satisfies the formula \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) as both clauses contain a true literal. SAT is a special case of the more general Constraint Satisfaction Problem (CSP) framework Brailsford et al. [1999]. A CSP consists of a set of variables, each with a domain of possible values, and a set of constraints that specify allowed combinations of values for groups of variables. While SAT variables are restricted to Boolean values and constraints take the form of clauses, CSPs can accommodate richer variable domains and constraint types. #### 3.1.2 Max SAT: The Optimization Variant The Maximum Satisfiability problem (Max SAT) is the optimization version of SAT. Given a CNF formula \\(\\phi\\) , the goal is to find an assignment that maximizes the number of satisfied clauses. This formulation is particularly useful when a formula is unsatisfiable, as Max SAT still yields the best possible solution. Max SAT has several variations that differ in their expressiveness and the way they handle the importance of clauses. In unweighted Max SAT, all clauses have equal importance. Weighted Max SAT assigns a positive weight to each clause, with the objective being to maximize the sum",
    "b_sdp_for_max-2-sat_semidefinite_programming_sdp_is_a_mathematical_optimization_technique_primarily_used_for_problems_involving_positive_semidefinite_matrices_in_sdp_a_linear_objective_function_is_optimized_over_a_feasible_region_given_by_a_spectrahedron_an_intersection_of_a_convex_cone_formed_by_positive_semidefinite_matrices_and_an_affine_subspace_ramana_and_goldman_1995_along_with_the_broad_scope_of_applications_sdp_has_been_used_to_design_approximation_algorithms_for_discrete_np-_hard_problems_gartner_and_matousek_2012_this_is_achieved_by_lifting_variables_of_a_problem_to_a_vector_space_and_optimizing_a_loss_function_expressed_in_terms_of_these_vectors_in_this_section_we_provide_a_detailed_derivation_of_the_sdp_relaxation_for_max-_2-_sat_the_goal_is_to_write_an_objective_function_for_2-_cnf_formulae_which_consist_of_clauses_c_1ldots_c_k_over_variables_x_1ldots_x_n_with_at_most_two_literals_per_clause_b1_derivation_of_the_sdp_relaxation_for_each_boolean_variable_x_i_where_iin_12ldots_n_a_new_variable_y_iin_-_11_is_associated_and_an_additional_variable_y_0in_-_11_is_introduced_this_additional_variable_is_introduced_to_unambiguously_assign_the_truth_value_in_the_original_problem_from_values_of_the_relaxed_problem_it_is_not_possible_to_just_assign_true_false_to_x_i_if_y_i_1-_1_because_quadratic_terms_cannot_distinguish_between_y_icdot_y_j_and_-_y_icdot_-_y_j_instead_the_truth_value_of_x_i_is_assigned_by_comparing_y_i_with_y_0_x_i_is_true_if_and_only_if_y_i_y_0_otherwise_it_is_false_the_assignment_is_therefore_invariant_to_negating_all_variables_to_determine_the_value_of_a_formula_we_sum_the_value_of_its_clauses_c_which_are_given_by_the_value_function_vc_here_are_examples_of_the_value_function_for_different_clauses_beginarraycvx_i_frac1_y_0cdot_y_i2_vneg_x_i_1_-_vx_i_frac1_-_y_0cdot_y_i2_vx_ivee_neg_x_j_1_-_vneg_x_iwedge_x_j_1_-_frac1_-_y_0cdot_y_i2cdot_frac1_y_0cdot_y_j2_frac14_1_y_0cdot_y_i_frac14_1_-_y_0cdot_y_j_frac14_1_y_icdot_y_j_endarray_quad_15_by_summing_over_all_clauses_c_in_the_boolean_formula_the_following_integer_quadratic_program_for_max-_2-_sat_is_obtained_beginarrayr_l_mathrmmaximizequad_sum_cin_cvc_mathrmsubjecttoquad_y_iin_-11_mathrmforalliin_01ldots_n_mathrmsubjecttoquad_y_iin_-11_mathrmforalljin_01ldots_n_endarray_quad_21_this_can_be_rewritten_by_collecting_coefficients_of_y_icdot_y_j_for_ijin_01ldots_n_and_putting_them_symmetrically_into_a_n_1times_n_1_coefficient_matrix_w_the_terms_y_icdot_y_j_can_be_collected_in_a_matrix_y_with_the_same_dimensions_as_w_the_elements_y_ij_correspond_to_y_icdot_y_j_for_ijin_01ldots_n_both_matrices_are_symmetric_hence_the_sum_of_all_elements_in_their_element-_wise_product_which_is_the_objective_function_can_be_compactly_expressed_by_using_the_trace_operation_this_leads_to_the_following_version_of_the_same_integer_program_beginarrayr_l_mathrmmaximizequad_mathrmtrw_y_mathrmsubjecttoquad_y_i_i_1mathrmforalliin_01ldots_n_qquad_y_i_j_y_icdot_y_jmathrmforallijin_01ldots_n_qquad_y_iin_-11_mathrmforalliin_01ldots_n_endarray_quad_22": "",
    "b2_relaxation_to_semidefinite_programming_to_make_the_discrete_program_continuous_we_first_allow_the_value_of_the_variables_y_i_to_be_any_real_number_between_-_1_and_1_however_semidefinite_programming_goes_further_and_allows_variables_to_be_n_1_-_dimensional_unit_vectors_y_0ldots_y_nlongrightarrow_mathbfy_0ldots_mathbfy_n_as_schematically_depicted_in_figure_7_in_this_relaxation_the_binary_products_y_icdot_y_j_in_the_objective_function_are_replaced_by_inner_products_langle_mathbfy_imathbfy_jrangle_this_can_be_compactly_represented_in_matrix_form_by_substituting_each_inner_product_langle_mathbfy_imathbfy_jrangle_with_a_scalar_y_ij_of_a_matrix_y_the_fact_that_these_scalars_correspond_to_inner_products_is_encoded_by_the_restriction_to_positive-_semidefinite_matrices_ysucceq_0_the_sdp_relaxation_of_max-_2-_sat_can_thus_be_formulated_as_beginarrayrl_mathrmmaximizequad_mathrmtrw_y_mathrmsubjecttoquad_y_i_i_1mathrmforalliin_01ldots_n_qquad_ysucceq_0_endarray_quad_27_positive_semidefiniteness_of_matrix_y_ensures_that_it_can_be_uniquely_factorized_as_y_yfrac12yfrac12t_we_can_then_obtain_real_unit_vectors_mathbfy_i_for_all_iin_0ldots_n_such_that_y_ij_langle_mathbfy_imathbfy_jrangle_for_all_ijin_0ldots_n_the_constraints_y_ii_1_ensure_that_all_vectors_mathbfy_i_lie_on_an_n_1_-_dimensional_unit_sphere_centerfigure_7_lifting_the_variables_to_a_higher_dimension_demonstrated_on_variables_y_1y_2y_3_initially_only_integer_values_of_-1_and_1_could_be_assigned_to_them_integer_program_next_constraints_are_relaxed_allowing_variables_to_take_any_real_value_between_-1_and_1_finally_it_is_permitted_for_them_to_be_unit_vectors_in_a_high-dimensional_space_here_3_dimensions_the_hyperplane_in_the_last_picture_would_be_used_for_rounding_the_variables_at_the_end_this_hyperplane_can_be_randomly_selected_and_truth_values_for_variables_y_1y_2y_3_are_determined_based_on_which_side_of_the_hyperplane_they_land_after_continuous_optimization_center_b3_interpretation_and_rounding_the_sdp_solver_optimizes_the_numbers_in_the_matrix_y_but_using_the_factorization_we_can_visualize_what_happens_with_the_vectors_mathbfy_1_the_process_starts_with_random_unit_vectors_that_are_continuously_updated_to_maximize_the_objective_function_if_we_fix_the_position_of_the_vector_mathbfy_0_corresponding_to_the_value_true_we_would_see_that_the_vectors_of_variables_that_will_be_set_to_true_in_the_final_assignment_get_closer_to_the_vector_mathbfy_0_while_the_vectors_mathbfy_j_of_variables_that_will_be_set_to_false_move_away_from_it_so_that_the_inner_product_langle_mathbfy_0mathbfy_jrangle_is_close_to_-_1_if_the_formula_is_satisfiable_the_objective_function_drives_the_vectors_to_form_two_wellseparated_clusters_however_if_only_a_few_clauses_can_be_satisfied_simultaneously_the_vectors_would_end_up_being_scattered_a_simple_way_to_round_the_resulting_vectors_mathbfy_1ldots_mathbfy_n_and_get_the_assignment_for_the_original_boolean_variables_is_to_compute_the_inner_product_langle_mathbfy_0mathbfy_irangle_and_assign_the_value_according": "to its sign. It is also possible to assign the values by picking a random separating hyperplane, and it can be shown that this rounding gives a 0.8785- approximation of the integer program optimum Goemans and Williamson [1995]. Note that the expressions of the clauses reach their maximum at 1 (when a clause is satisfied by the assignment). This means that the whole formula is satisfiable if the objective function achieves a value equal to the number of clauses in the formula. Another way to check satisfiability is to plug the obtained solution into the formula and verify whether it is satisfied. Therefore, we can obtain an incomplete SAT solver from this SDP formulation. Similar SDPs can be obtained for different versions of MAX- SAT (with larger clauses). From empirical observation, the convergence threshold of the SDP solver needs to be decreased significantly compared to MAX- 2- SAT in order to obtain a good approximation for these more complicated versions.\n\nof weights of satisfied clauses. In some variants (Partial MAX- SAT Fu and Malik [2006]), clauses are categorized as hard or soft, where hard clauses must be satisfied (often with infinite weight), and soft clauses are those that can be violated but contribute to the objective based on their weight. While weighted variants exist, in this paper we focus exclusively on the unweighted formulation. Formally, for a CNF formula \\(\\phi = c_{1} \\wedge c_{2} \\wedge \\dots \\wedge c_{m}\\) with \\(m\\) clauses, the unweighted Max SAT problem seeks an assignment \\(\\sigma^{*}\\) such that: \\[\\sigma^{*} = \\arg \\max_{\\sigma}\\sum_{i = 1}^{m}\\mathbf{1}(\\sigma \\mathrm{~satisfies~}c_{i}) \\quad (1)\\] where \\(\\mathbf{1}(\\cdot)\\) is the indicator function. ### 3.2 SAT Solving Approaches SAT solving algorithms are generally categorized into complete and incomplete approaches, each with distinct characteristics and applications. Complete Solvers Complete solvers theoretically guarantee definitive answers: either finding a satisfying assignment or proving that none exists. The Davis- Putnam- Logemann- Loveland (DPLL) algorithm forms the foundation for most modern complete solvers Biere et al. [2009]. It systematically explores the search space through backtracking while employing unit propagation to deduce logical consequences. Conflict- Driven Clause Learning (CDCL) extends DPLL by analyzing conflicts to learn new clauses, which helps prune large portions of the search space. When a conflict occurs, the solver identifies the \"reasons\" for the conflict and adds a new clause that prevents similar conflicts in the future. Modern CDCL solvers incorporate sophisticated heuristics for variable selection, restart strategies, and efficient data structures to improve performance. Incomplete Solvers Incomplete solvers focus on finding satisfying assignments but cannot prove unsatisfiability. These algorithms are particularly effective for large satisfiable instances where complete methods might be inefficient. Local search algorithms, such as Walk SAT Selman et al. [1993], start with a random assignment and iteratively modify it to satisfy more clauses. These methods employ heuristics to decide which variables to flip at each step, balancing between greedy choices and random moves to escape local optima. For Max SAT, local search algorithms often use scoring functions that prioritize flipping variables that maximize the increase in satisfied clauses. Stochastic algorithms including simulated annealing and genetic algorithms have also been applied to SAT and Max SAT problems. These approaches can effectively explore search spaces in certain problem classes where deterministic methods struggle. #### 3.2.1 Continuous Relaxations A specific type incomplete solvers that have been explored in recent research Kyrillidis et al. [2020], Hosny and Reda [2024] are explored continuous relaxations of Max SAT, that transform the discrete problem into a continuous optimization task. These methods map Boolean variables to continuous domains, enabling the application of gradient- based optimization techniques. The Fourier- SAT method Kyrillidis et al. [2020], for instance, transforms Boolean formulas into multilinear polynomials through Walsh- Fourier transform and then optimize the continuous variables w.r.t. the resulting polynomial. Continuous relaxations can also be obtained by making the objective function convex as often done when designing approximation algorithms which provide guarantees for their performance.\n\nThe guarantees can be improved by lifting the variables into a high- dimensional vector space and optimizing vectors instead of scalar values. The optimized vectors are finally rounded to discrete values. Semidefinite Programming (SDP) relaxation, particularly for MAX- 2- SAT or MAX- 3- SAT, illustrates this approach elegantly. In SDP relaxation, Boolean variables \\(x_{i} \\in \\{0,1\\}\\) are transformed into unit vectors \\(\\mathbf{y}_{i}\\) in a high- dimensional space. An additional vector \\(\\mathbf{y}_{0}\\) is introduced to represent the value \"true.\" The Boolean variable \\(x_{i}\\) is considered true if \\(\\mathbf{y}_{i}\\) is close to \\(\\mathbf{y}_{0}\\) (positive inner product) and false if it is far from \\(\\mathbf{y}_{0}\\) (negative inner product). The optimization process for these vectors follows a pattern: 1. Initialize random unit vectors for each variable 2. Optimize these vectors to maximize the number of satisfied clauses, expressed as a function of inner products between vectors 3. Round the resulting vectors to discrete assignments (typically based on the sign of inner products with \\(\\mathbf{y}_{0}\\) ) This relaxation enables the application of powerful continuous optimization techniques while providing approximation guarantees. For MAX- 2- SAT, this approach yields an approximation ratio of 0.878, meaning the solution will satisfy at least 87.8% of the maximum possible number of clauses. #### 3.2.2 Learning-Based Approaches Machine learning (ML) is also being heavily utilized for SAT solving. Many approaches have been developed to guide traditional solvers Selsam and Bj\u00f8rner [2019], Yolcu and P\u00f3czos [2019] or to solve SAT problems directly Selsam et al. [2018], Li and Si [2022]. To guide a solver, a neural network can be used to replace heuristics such as variable selection or restart policies. Importantly, Graph Neural Networks (GNNs) can also be trained to solve SAT problems end- to- end without relying on traditional algorithmic solvers Amizadeh et al. [2018]. These GNN- based approaches can operate directly on the graph representation of Boolean formulas, with variables and clauses forming nodes in a bipartite graph, and learn to predict satisfiability or produce satisfying assignments Li et al. [2023]. In this work, we focus on variants of GNNs that are recurrent and this allows us to scale the computation during inference or adapt the number of iterations for each instance separately. In Section 6 we will show an evidence that one can view the end- to- end ML approaches as bi- level optimization methods because during inference, the GNN behaves as a continuous solver trying to maximize the number of satisfied clauses. Therefore, during training, the outer loop of the bi- level optimization optimizes the weights of the network which then runs an inner loop that optimizes the values of variables to maximize the number of satisfiable clauses. ### 3.3 Graph Neural Networks Graph Neural Networks (GNNs) extend deep learning to graph- structured data, enabling learning on irregular data structures that classical neural architectures cannot directly process. A graph \\(G = (V,E)\\) consists of nodes \\(V\\) and edges \\(E\\) , where each node \\(v\\in V\\) may have associated features \\(x_{v}\\) . GNNs compute node representations through message passing, where each node iteratively aggregates information from its neighbors and updates its features. Formally, at layer \\(l\\) , a node \\(v\\) updates its representation \\(h_{v}^{l}\\) , according to: \\[h_{v}^{l + 1} = \\mathrm{UPDATE}(h_{v}^{l},\\mathrm{AGGREGATE}(\\{h_{u}^{l}:u\\in \\mathcal{N}(v)\\}))\\]\n\n<center>Figure 1: LCG and VCG of the CNF formula \\((\\overline{x}_{1} \\vee x_{2}) \\wedge (x_{2} \\vee \\overline{x}_{3}) \\wedge (x_{1} \\vee x_{3})\\) . </center> where \\(\\mathcal{N}(v)\\) denotes the neighbors of node \\(v\\) . The UPDATE and AGGREGATE functions are typically neural networks, often implementing permutation- invariant operations like sum or max. Through multiple layers of message passing, GNNs can capture both local structure and longer- range dependencies in the graph, making them suitable for processing SAT formulas represented as bipartite graphs. ### 3.4 Diffusion-based Assignment Generation In Section 5.4 will show how the GNNs we use can be extended to diffusion models which have in recent years emerged as a powerful approach for generative modeling across domains Ho et al. [2020]. These models learn to transform a random noise distributions (such as multi- variate Gaussian distribution) to complex distributions behind the given domain (i.e., distribution of images of human faces). For practical applications, diffusion models are typically conditioned on an input so that the generated sample has specific characteristics. In our case, we will condition the model by the bipartite graph of the CNF formula. #### 3.4.1 Categorical Diffusion Process While continuous diffusion models have gained prominence in image generation and other domains, discrete diffusion processes well- suited for combinatorial optimization problems like MAX- SAT, where the state space is inherently discrete. Our approach presented in Section 5.4 leverages a discrete diffusion process with categorical noise to model the generation of variable assignments. We adapt a concrete form of discrete diffusion first presented by Austin et al. Austin et al. [2021] and later leveraged for combinatorial optimization with GNNs by Sun et al. Sun and Yang [2023]. On a high level, diffusion models are trained to denoise noisy version of the training samples. These noisy versions are obtained by running a forward diffusion process for several steps and the model is then trained to predict the original sample. For a SAT problem with \\(n\\) variables, we represent each variable assignment as a binary value and the vector of these binary values represent the sample. The diffusion process gradually corrupts this sample until it becomes pure noise. More concretely, the process that progressively adds noise to the initial assignment \\(\\mathbf{x}_{0} \\in \\{0, 1\\}^{n}\\) over \\(T\\) timesteps, produces a sequence of increasingly more corrupted assignments \\(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots , \\mathbf{x}_{T}\\) . For categorical diffusion, this corruption process is defined by a Markov chain with the following transition matrices: \\[\\mathbf{Q}_{t} = \\left( \\begin{array}{cc}1 - \\beta_{t} & \\beta_{t} \\\\ \\beta_{t} & 1 - \\beta_{t} \\end{array} \\right) \\quad (2)\\] where \\(\\beta_{t} \\in (0, 1)\\) represents the noise schedule, controlling how quickly the assignments become corrupted. The matrix \\(\\mathbf{Q}_{t}\\) defines the probability of transitioning between states at time \\(t\\) , with the property that as \\(t\\) approaches \\(T\\) , the distribution of \\(\\mathbf{x}_{t}\\) approaches a uniform distribution over all possible assignments.\n\nTo simplify inference, the cumulative transition matrices \\(\\overline{\\mathbf{Q}}_{t} = \\mathbf{Q}_{1}\\mathbf{Q}_{2}\\cdot \\cdot \\cdot \\mathbf{Q}_{t}\\) , which directly gives us \\(p(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\) are being used. For the Boolean case, this allows us to efficiently sample \\(\\mathbf{x}_{t}\\) given \\(\\mathbf{x}_{0}\\) using: \\[p(\\mathbf{x}_{t}|\\mathbf{x}_{0}) = \\mathrm{Cat}(\\mathbf{x}_{t};\\mathbf{p} = \\tilde{\\mathbf{x}}_{0}\\overline{\\mathbf{Q}}_{t}) \\quad (3)\\] where \\(\\tilde{\\mathbf{x}}_{0} \\in \\{0,1\\}^{n \\times 2}\\) is the one- hot encoding of \\(\\mathbf{x}_{0}\\) , with each variable represented by a vector \\((1,0)\\) for value 0 or \\((0,1)\\) for value 1. The Cat operation refers to the categorical distribution, which samples \\(\\mathbf{x}_{t}\\) based on the probability vector \\(\\mathbf{p}\\) . #### 3.4.2 Learning the Reverse Process The core idea of diffusion models is to learn the reverse process - how to gradually denoise a corrupted sample to recover the original data distribution. In our case, we train a GNN to progressively recover a satisfiable assignment \\(\\mathbf{x}_{0}\\) starting from a random initial assignment. The trained model is used to sample from a distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) which can be used to obtain a an assignment \\(\\mathbf{x}_{0}\\) from random assignment \\(\\mathbf{x}_{T}\\) as explained bellow. There are multiple ways of training the neural network used in the diffusion model. One can train it to directly model the distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) . In the method introduced by Austin et al. Austin et al. [2021], the network is trained to predict the original uncorrupted input \\(\\mathbf{x}_{0}\\) which is then used to sample from the the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) using Bayes' rule. This approach provides stronger learning signals during training, as the target \\(\\mathbf{x}_{0}\\) remains fixed regardless of a timestep and we use it within this work. #### 3.4.3 Categorical Posterior Sampling As mentioned above, our model is trained to predict \\(\\mathbf{x}_{0}\\) directly and we use this prediction during inference to sample \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) . This is accomplished through categorical posterior sampling, which uses the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) to compute the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})\\) . By applying Bayes' rule and the Markov property of the diffusion process, we can derive: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (4)\\] For the categorical case, this is computed using: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}\\frac{p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{0})p(\\mathbf{x}_{t}|\\mathbf{x}_{t - 1})}{p(\\mathbf{x}_{t}|\\mathbf{x}_{0})} p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (5)\\] The diffusion model replaces the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) with a function approximator (GNN in our case) \\(f_{\\theta}(\\mathbf{x}_{t},t)\\) Therefore, we can train the model using a simple procedure (predicting \\(\\mathbf{x}_{0}\\) ) and during inference, we can use a sampling process (iteratively sampling \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) ), which tries to recover a uncorrupted input in several steps. A useful feature of diffusion models is that the number of sampling steps during inference can be chosen by the user after the model is already trained. #### 3.4.4 Inference Schedule During inference, we can accelerate the generation process by using fewer denoising steps than were used during training or use more denoising steps with the hope to increase the quality of outputs. The tuple of time steps used for inference \\((T,T - 1,\\ldots ,t_{0})\\) is called a schedule. The function approximator in the diffusion model is normally conditioned by the sample at a given time step and also the time step itself \\((f_{\\theta}(\\mathbf{x}_{t},t))\\) but as we show in Section 5.4.1, the time step conditioning is not needed. This means that in our case the schedule is defined only by the number of time steps used.",
    "4_experimental_setup_41_data_representation_and_graph_structure_boolean_formulas_in_cnf_form_can_be_naturally_represented_as_bipartite_graphs_where_clauses_and_variables_or_literals_form_two_distinct_sets_of_nodes_in_this_work_we_explore_two_different_graph_representations_literal-_clause_graph_lcg_in_the_literal-_clause_graph_representation_each_literal_both_positive_and_negative_polarity_of_a_variable_is_represented_as_a_separate_node_for_a_formula_with_n_variables_this_results_in_2n_literal_nodes_each_literal_node_is_connected_to_all_clause_nodes_containing_that_literal_formally_for_a_cnf_formula_phi_with_variables_x_1ldots_x_n_and_clauses_c_1ldots_c_m_we_construct_a_bipartite_graph_g_lc_lcup_ce_where_-_l_l_1ldots_l_nbarl_1ldots_barl_n_is_the_set_of_literal_nodes_-_c_c_1ldots_c_m_is_the_set_of_clause_nodes_-_l_ic_jin_e_if_and_only_if_literal_l_i_appears_in_clause_c_j_variable-_clause_graph_vcg_in_the_variable-_clause_graph_representation_each_variable_rather_than_each_literal_is_represented_as_a_node_for_a_formula_with_n_variables_this_results_in_exactly_n_variable_nodes_each_variable_node_is_connected_to_all_clause_nodes_containing_either_the_positive_or_negative_literal_of_that_variable_to_retain_information_about_the_polarity_of_literals_we_assign_edge_features_p_ijin_-_11_to_each_edge_x_ic_j_where_p_ij_1_if_the_positive_literal_x_i_appears_in_clause_c_j_and_p_ij_-_1_if_the_negative_literal_overlinex_i_appears_in_clause_c_j_formally_we_construct_a_bipartite_graph_g_vc_vcup_cep_where_-_v_x_1ldots_x_n_is_the_set_of_variable_nodes-_c_c_1ldots_c_m_is_the_set_of_clause_nodes-_x_ic_jin_e_if_and_only_if_variable_x_i_appears_in_clause_c_j_in_either_polarity-_peto_-11_maps_each_edge_to_its_corresponding_polarity_both_graph_representations_capture_the_structure_of_the_boolean_formula_but_they_differ_in_how_they_handle_variable_polarity_the_literal-_clause_graph_explicitly_represents_both_polarities_as_separate_nodes_which_increases_the_number_of_nodes_but_simplifies_the_message_passing_process_of_the_gnn_the_variable-_clause_graph_is_more_compact_but_requires_handling_polarity_information_through_edge_features_for_the_gnns_we_use_the_variable-_clause_graph_representation_is_more_computationally_efficient_than_the_literal-_clause_graph_reducing_both_memory_requirements_and_processing_time_this_efficiency_comes_from_having_half_as_many_variable_nodes_compared_to_literal_nodes_and_avoiding_an_expensive_operation_during_message_passing_as_will_be_described_in_section_42_in_our_experiments_we_compare_both_representations_together_with_different_message_passing_operations_and_different_training_regimes_42_architecture_variants_our_gnn_architecture_variants_are_derived_from_the_neuro_sat_architecture_selsam_et_al_2018_which_demonstrated_the_possibility_of_using_gnns_for_sat_solving_the_main_advantage_of_this_architecture_is_that_it_is_recurrent_and_therefore_the_number_of_message_passing_iterations_is_theoretically_not_limited_this_is_not_the_case_for_the_non-_recurrent_alternatives_with_fixed_number_of_layers_we_will_demonstrate_the_usefulness_of_this_feature_in_section_53": "Node Embeddings Each node in the bi- partite graph of the formula is associated with a \\(d\\) - dimensional embedding vector ( \\(d = 64\\) in most of our experiments as a conclusion from an experiment in A.1.4). We initialize these embeddings randomly from a standard normal distribution. For a formula with \\(n\\) variables and \\(m\\) clauses, we have: In the literal-clause graph: \\(2n\\) literal embeddings \\(\\mathbf{l}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) In the variable- clause graph: \\(n\\) variable embeddings \\(\\mathbf{v}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) Message Passing Mechanism The core of our architecture is a two- phase message passing procedure that alternates between updating clause representations and unknown node representations (literals or variables, depending on the graph type). This process is repeated for a configurable number of iterations \\(T\\) . We primarily use an RNN- based update mechanism, where the node embeddings are the hidden states of the RNN that evolve through message passing iterations. For the variable- clause graph, the message passing at iteration \\(t\\) is defined as: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{v\\in \\mathcal{N}(c)}\\mathbf{M}_{v c}(\\mathbf{h}_{v}^{(t - 1)},p_{v c}),\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{v}^{(t)} = \\mathrm{RNN}_{v}\\left(\\sum_{c\\in \\mathcal{N}(v)}\\mathbf{M}_{c v}(\\mathbf{h}_{c}^{(t)},p_{v c}),\\mathbf{h}_{v}^{(t - 1)}\\right)} \\end{array} \\quad (6)\\] Here, \\(\\mathbf{h}_{c}^{(t)}\\) and \\(\\mathbf{h}_{v}^{(t)}\\) are the hidden states that serve as the actual clause and variable node embeddings for clause nodes and variable nodes respectively. \\(\\mathbf{M}_{v c}\\) and \\(\\mathbf{M}_{c v}\\) are the message transformation functions that operate on the source node embedding and the edge polarity. For the variable- clause graph, we implement these transformation functions as two MLPs that process positive and negative edges differently: \\[\\mathbf{M}_{v c}(\\mathbf{h}_{v},p) = \\left\\{ \\begin{array}{ll}\\mathrm{MLP}_{\\mathrm{pos}}(\\mathbf{h}_{v}) & \\mathrm{if} p > 0\\\\ \\mathrm{MLP}_{\\mathrm{neg}}(\\mathbf{h}_{v}) & \\mathrm{if} p< 0 \\end{array} \\right. \\quad (8)\\] For the literal- clause graph, the message passing mechanism also uses operation, called \"Flip\" bellow, that enforces the logical relationship between complementary literals: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{l\\in \\mathcal{N}(c)}\\mathbf{h}_{l}^{(t - 1)},\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{l}^{(t)} = \\mathrm{RNN}_{l}\\left(\\left[\\sum_{c\\in \\mathcal{N}(l)}\\mathbf{h}_{c}^{(t)},\\mathrm{Flip}(\\mathbf{h}_{l}^{(t - 1)})\\right],\\mathbf{h}_{l}^{(t - 1)}\\right)} \\end{array} \\quad (10)\\] where \\([\\cdot ,\\cdot ]\\) denotes vector concatenation. The \\(\\mathrm{Flip}(\\cdot)\\) operation exchanges the embeddings of positive literals with their corresponding negative literals and vice versa. The update function for a given literal embedding can therefore take into account the embedding of the complementary literal. We note, that the \\(\\mathrm{Flip}(\\cdot)\\) operation incurs a significant computational cost, particularly for large formulas. In contrast, the variable- clause graph representation eliminates this expensive operation by dedicating only one node for each variable and directly encoding its polarity in edge features. This efficiency makes the variable- clause approach particularly well- suited for larger formulas where computational demands become a critical factor."
  },
  "section_objects": [
    {
      "heading": "Neural Approaches to SAT Solving Design Choices an",
      "content": "## Introduction\n\n\nApart from the RNN- based update functions, we also experiment with LSTM- based update functions which have been used in the original Neuro SAT architecture Selsam et al. [2018]. The LSTM- based updates follow a similar pattern but maintain an additional cell state alongside the hidden state. In Section 5.2 we show that different update functions are suitable for different settings. After each update step, we apply L2 normalization to all node embeddings to stabilize training: \\[\\mathbf{h}_{i}^{(t)} = \\frac{\\mathbf{h}_{i}^{(t)}}{\\|\\mathbf{h}_{i}^{(t)}\\|_{2}} \\quad (11)\\] Node classification After \\(T\\) iterations of message passing, we use the final node embeddings to predict variable assignments. For the variable- clause graph, we apply a linear layer to each variable embedding to produce two logits (representing scores for value true and false): \\(\\mathbf{y}_{v} = \\mathbf{W}\\mathbf{h}_{v}^{(T)} + \\mathbf{b}\\) . The assignment is then determined by applying softmax and taking the argmax: \\(\\hat{a}_{v} = \\arg \\max_{i}(\\mathrm{softmax}(\\mathbf{y}_{v})_{i})\\) . For the literal- clause graph, we focus on the embeddings of positive literals only, as they directly correspond to variables. During training, we use cross- entropy loss between these predicted assignments and the ground truth assignments. For satisfiability prediction, we can determine whether a formula is satisfiable by checking if the predicted assignment satisfies all clauses. The model is thus trained to find assignments that minimize the number of unsatisfied clauses, effectively solving the Max SAT problem even when trained only with assignment supervision. ### 4.3 Supervision Tasks and Objectives There are several obvious supervision objectives and prediction tasks which can be used to train the model. The original Neuro SAT model was trained to predict the satisfiability status of a given formula using binary cross- entropy. Later, several authors tried different training tasks and objectives which have been summarized in a review paper by Li et al. Li et al. [2023]. We reimplement these objective and task for our setup and also introduce a novel training objective which in certain settings results in significant improvements of the model performance. These objective are briefly described below. Satisfiability Classification This is the task which was used by Selsam et al. [2018] for training the original Neuro SAT architecture. The model is trained to predict whether the formula is satisfiable or not through graph- level embedding aggregation using global mean pooling. The loss is computed by binary cross- entropy between the prediction \\(\\hat{y}\\) and ground truth \\(y\\in \\{0,1\\}\\) .. \\(\\mathcal{L}_{\\mathrm{sat}} = -(y\\log \\hat{y} +(1 - y)\\log (1 - \\hat{y}))\\) Unsupervised Training For unsupervised training, we define the loss using clause validity Ozolins et al. [2022], where \\(\\hat{x}_{i}\\) represents the model's predicted continuous probability of a variable being true: \\[V_{c}(\\hat{x}) = 1 - \\prod_{i\\in c^{+}}(1 - \\hat{x}_{i})\\prod_{i\\in c^{-}}\\hat{x}_{i},\\quad \\mathcal{L}_{\\phi}(\\hat{x}) = -\\sum_{c\\in \\phi}\\log (V_{c}(\\hat{x})), \\quad (12)\\] where \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in clause \\(c\\) in positive and negative form respectively. This loss reaches its minimum only when the prediction \\(\\hat{x}\\) is a satisfying assignment. We note that alternative unsupervised formulations exist Amizadeh et al. [2018], and comprehensive evaluations reported by Li et al. Li et al. [2023] suggest that these two different\n\napproaches perform similarly in practice. Another training option would be to directly optimize a convex loss function derived from SDP relaxation, but this approach is limited because SDP formulations work well for MAX- 2- SAT and can be extended to MAX- 3- SAT, but become increasingly difficult to formulate for general Max SAT problems with larger clauses. Assignment Prediction For satisfiable formulas, we can train the model to predict the satisfiable variable assignments directly. We tried to use either mean squared error or cross- entropy loss between the predicted assignments and the ground truth assignments: \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{MSE}} =\\) \\(\\| \\hat{a} - x\\|_{2}^{2}\\) and \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{CE}} = - \\sum_{i}x_{i}\\log \\hat{x}_{i} + (1 - x_{i})\\log (1 - \\hat{x}_{i})\\) where \\(x\\) is the ground truth assignment and \\(\\hat{a},\\hat{x}\\) are the predicted assignments which differ by application of softmax (i.e. \\(\\hat{a}\\) are just logits without a softmax applied). Closest Assignment Training One problem with assignment prediction is that satisfiable formulas can have a lot of solution and the network is penalized even if it predicts satisfiable solution which differs from the one which is used as a ground truth. We therefore introduce a novel supervision method which uses a Max SAT solver to always compute the solution which is closest to the solution predicted by the model. We then update then model with respect to this solution. In Section 5.2, we show that this method works particularly well when the solution space is large. For each formula in a batch, a valid assignments that minimize the Hamming distance to the model's current predictions is found by the RC2 Max SAT solver. For satisfiable formulas it finds an assignment that satisfies all clauses while being closest to current prediction. For unsatisfiable formulas, it finds an assignment that maximizes the number of satisfied clauses while minimizing distance to prediction. This approach allows the model to explore different regions of the solution space while maintaining valid solutions for SAT instances or optimal partial solutions for UNSAT instances. The supervision signal adapts to the model's current state rather than forcing it toward a single pre- determined assignment. The disadvantage of this method is that the computation of the loss is slower then with the precomputed solution. This could be solved by pre- computing solutions or by using an approximate Max SAT solver. SAT- Only Instance Filtering After initially training with both satisfiable and unsatisfiable instances, we experimented with formula- type specialization by restricting training to only satisfiable instances. In Table 3, we show that this filtering can lead to higher accuracy of the trained model. ### 4.4 Benchmarks and Data Generation We utilize two complementary benchmark generators for evaluating the tested variants: the SR generator and a 3- SAT generator with the ratio between variable and clauses set close to the phase transition point. SR Generator The SR generator by Selsam et al. [Selsam et al., 2018] produces pairs of satisfiable and unsatisfiable formulas that differ by negating only a single literal. This design specifically prevents models from exploiting superficial features for classification. Intuitively, it works by iteratively sampling random clauses and adding them to a formula. After each addition, a SAT solver checks if the formula remains satisfiable. When adding a clause that finally makes the formula unsatisfiable, the generator saves this instance and creates its satisfiable counterpart by flipping a single literal in the last clause. To create each clause, it samples a small integer \\(k\\) based on a mix of Bernoulli and geometric distributions, then randomly selects \\(k\\) variables without replacement, negating each with 0.5 probability. This solver- driven approach ensures\n\nthat satisfiability classification requires understanding the logical structure rather than statistical properties. As reported in the review by Li et al. Li et al. [2023], the models trained on problems from this generator transfer the best to other problem distributions. 3- SAT Generator We also employ a 3- SAT generator configured at the critical clause- to- variable ratio of 4.26, known as the phase transition point where SAT problems are empirically the most challenging to solve [Crawford and Auton, 1996]. At this ratio, approximately half of the generated instances are satisfiable. Each clause contains exactly 3 literals selected uniformly from the available variables, with each literal negated with 0.5 probability. Unlike the SR generator, 3- SAT focuses on generating naturally difficult problems rather than explicitly preventing superficial feature learning. ## 5 Experimental Results ### 5.1 Training and Evaluation Methodology For training, we generate 50,000 instances: 25,000 pairs for SR and 50,000 instances for 3- SAT. We annotate each dataset by the maximum number of variables appearing in the training formulas. For SR, we test two variations, SR40 for which the training examples are sampled with 3- 40 variables and SR100 for which the training examples contain 10- 100 variables. For 3- SAT, the training samples contain 10- 100 variables (3SAT100). The SR dataset is well suited for training SAT/UNSAT prediction models due to its design that prevents learning from superficial features, making it harder for models to exploit statistical shortcuts rather than learning true logical reasoning. We also create versions of training data which contain only satisfiable instances (denoted SAT only). The size of these datasets is half of the original datasets (i.e. 25000 examples). To evaluate generalization, we validate exclusively on problems with exactly the maximum number of variables in each category, therefore SR40 for evaluation means that the problems have always exactly 40 variables (not a range of 3- 40), SR100 test contains only problems with exactly 100 variables, and so on.1 Table 1 summarizes the key statistics of our evaluation datasets. Table 1: Statistics of benchmark test sets. SAT% indicates the percentage of satisfiable instances in each dataset. Avg. Gap represents the average number of unsatisfied clauses when using random variable assignments. SAT Gap and UNSAT Gap show this metric separated by instance satisfiability. SR datasets are generated using the SR generator with the indicated number of variables (e.g., SR40 contains instances with 40 variables), while 3SAT datasets contain instances near the phase transition point with the specified number of variables. All datasets maintain a balanced distribution of satisfiable and unsatisfiable instances. <table><tr><td>Dataset</td><td>SAT%</td><td>Avg. Gap</td><td>SAT Gap</td><td>UNSAT Gap</td><td>Avg. Clauses</td></tr><tr><td>SR40</td><td>50.0%</td><td>21.29</td><td>21.59</td><td>20.99</td><td>228.40</td></tr><tr><td>SR100</td><td>50.0%</td><td>51.31</td><td>50.64</td><td>51.98</td><td>547.49</td></tr><tr><td>SR200</td><td>50.0%</td><td>100.31</td><td>101.03</td><td>99.59</td><td>1083.81</td></tr><tr><td>SR400</td><td>50.0%</td><td>198.74</td><td>198.53</td><td>198.95</td><td>2152.32</td></tr><tr><td>3SAT100</td><td>53.5%</td><td>52.78</td><td>53.00</td><td>52.54</td><td>426.00</td></tr><tr><td>3SAT200</td><td>55.5%</td><td>107.65</td><td>107.45</td><td>107.90</td><td>852.00</td></tr></table> The Gap metric represents the average number of unsatisfied clauses when using random\n\nvariable assignments. This metric has the same definition for both SAT and UNSAT instances; it simply counts how many clauses remain unsatisfied with random assignments on average. Larger gaps indicate more challenging problems where random guessing performs poorly. ### 5.2 Quantitative Evaluation We conducted a comprehensive evaluation that compares different architectural choices and supervision methods. Our evaluation focuses on five key performance metrics: - Average Gap: The average number of unsatisfied clauses across all test instances. Lower values indicate better performance, with 0 representing perfect satisfaction (i.e., no unsatisfied clauses) on satisfiable instances. For unsatisfiable instances, this metric reflects how close the model gets to minimizing unsatisfied clauses.- Gap on SAT: The average number of unsatisfied clauses computed only over satisfiable instances.- Gap on UNSAT: The average number of unsatisfied clauses computed only over unsatisfiable instances.- SAT Accuracy: The percentage of satisfiable instances for which the model correctly finds a satisfying assignment, computed only over satisfiable instances.- Decision Accuracy: The percentage of instances for which the model correctly predicts whether the formula is satisfiable. Since our approach does not formally refute unsatisfiable instances, we classify an instance as unsatisfiable when the model fails to find a satisfying assignment. This means unsatisfiable instances are always classified correctly under this assumption. This applies specifically in the case of assignment-based evaluation. #### 5.2.1 Comparison of Graph Representations, Update Functions and Training Methods Table 2 presents a comprehensive comparison of different architectural configurations trained exclusively on the SR40 dataset. This comparison includes different graph representations (Literal Clause Graph vs. Variable- Clause Graph), update functions (RNN vs. LSTM), and supervision approaches (SAT/UNSAT classification, assignment supervision, and unsupervised objective training), all evaluated on instances with 40 variables. All models were evaluated using Exponential Moving Average (EMA) of parameters during validation only, as detailed in A.1.2, which helps reduce fluctuations in validation metrics and provide more reliable model selection. Importantly, curriculum learning ( A.1.1) was employed only for training models with SAT/UNSAT classification objectives, as it proved unnecessary for models trained with assignment prediction or unsupervised learning approaches. Graph Representation Impact: Our results demonstrate that Literal- Clause Graph (LCG) and Variable- Clause Graph (VCG) representations exhibit different strengths. VCG shows better performance for assignment- based training with RNN updates, achieving a SAT accuracy of 68.8% compared to 48.6% for LCG. Additionally, VCG's more compact representation (using one node per variable rather than two for positive and negative literals) provides computational advantages for larger formulas, making it our preferred choice for scaling to more complex problems.\n\nMessage Passing Mechanism: While LSTM- based message passing shows advantages in some configurations, particularly for unsupervised training, we found that RNN- based approaches offer a better balance of performance and interpretability for assignment- based training. RNN updates with VCG representation achieved higher results for finding satisfying assignments, with \\(68.8\\%\\) SAT accuracy and \\(84.4\\%\\) decision accuracy. The simpler RNN structure also facilitates better analysis of the model's internal reasoning process. However, we found training RNN- based models for SAT/UNSAT classification particularly challenging, with LSTM being more stable for this specific task. Supervision Approach: Our experiments reveal distinct advantages for different supervision approaches: 1. Assignment-based supervision shows better performance for finding satisfying assignments, especially with VCG+RNN configuration (68.8% SAT accuracy, 84.4% decision accuracy). 2. Unsupervised learning achieves the lowest average gaps across configurations (as low as 0.91 for VCG+RNN and 0.84 for VCG+LSTM). This makes unsupervised training useful for applications where minimizing unsatisfied clauses is the priority. 3. SAT/UNSAT classification training, while challenging with RNN, enables an interesting property: models trained only for classification develop an implicit ability to separate embeddings for positive and negative literals. This separation allows for retrieving satisfying assignments through clustering techniques, despite the model not being explicitly trained for assignment prediction. Based on the results reported in Table 2, we identify the VCG+RNN+Assignment configuration as our most effective approach, offering a good balance between assignment accuracy and computational efficiency. This configuration forms the foundation for our further experiments and analysis in subsequent sections. Assignment Training Refinements: Table 3 highlights the impact of a novel training method we introduce, here called \"closest assignment\", with the VCG+RNN configuration across multiple datasets. This method computes assignments that minimize Hamming distance to the model's current predictions, showing improvements over training with precalculated assignments, especially for formulas with more variables. For SR100, using the closest assignment approach reduces the average gap from 3.81 to 1.43 for SAT+UNSAT training and improves SAT accuracy from 44.8% to 53.2%. This improvement correlates with the number of possible solutions in the benchmarks (SR10- 100 has a median of 16 solutions per formula compared to SR3- 40's median of 7), supporting our hypothesis that for formulas with larger solution spaces, guiding the model with dynamically selected assignments that align with its current predictions yields better generalization than using fixed predetermined assignments. The computational challenges of calculating closest assignments during training are noteworthy, particularly for larger benchmarks like 3SAT+UNSAT, where this approach became impractical and we therefore omit this experiment and leave the last row of Table 3 empty. It also highlights an opportunity for future work on more efficient approximation methods for finding near- optimal assignments. Training Data Composition: Our results also indicate that training exclusively on SAT instances (SAT only) improves performance for finding satisfying assignments. For SR40, this approach with closest assignment training achieves our highest SAT accuracy of 76% and decision accuracy of 88%. However, models trained on both SAT and UNSAT instances (SAT+UNSAT)\n\nwith closest assignment supervision demonstrate better gap minimization, achieving an average gap of 0.98 versus 2.68 for SAT- only training on SR40. Table 2: Performance comparison of GNN architectures for SAT solving on the SR40 dataset.The table compares Literal-Clause Graph (LCG) and Variable-Clause Graph (VCG) repre-sentations, RNN and LSTM update mechanisms, and different training objectives. Metrics include average gap (number of unsatisfied clauses) across all instances and separated by sat-isfiability status (lower is better), SAT accuracy (percentage of satisfiable instances solved by finding assignment), and decision accuracy (percentage of correct satisfiability predictions). No-table findings include: unsupervised training consistently achieves lowest gaps; VCG+RNN with assignment prediction shows highest SAT accuracy (68.8%); and RNN-based models with SAT/UNSAT classification proved challenging to train effectively (indicated by dashes). As-terisks (*) indicate results obtained through clustering of node embeddings rather than direct prediction. This model combination was particularly hard to train in our setup. We found that both for VCG and LCG RNN is very sensitive to hyper-parameter selection. As the model failed to get generalized in our final unified experimental setup we do not include this result (close to random performance) now. <table><tr><td>Graph</td><td>Update</td><td>Loss Function</td><td>Avg. Gap\u2193</td><td>Gap on SAT\u2193</td><td>Gap on UNSAT\u2193</td><td>SAT Acc.\u2191</td><td>Dec. Acc.\u2191</td></tr><tr><td rowspan=\"6\">LCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Assignment</td><td>1.83</td><td>1.25</td><td>2.41</td><td>48.6%</td><td>72.8%</td></tr><tr><td>Unsup</td><td>0.93</td><td>0.59</td><td>1.26</td><td>51.4%</td><td>75.7%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>1.96*</td><td>1.27*</td><td>2.62*</td><td>59.2%</td><td>83.9/79.6%</td></tr><tr><td>Assignment</td><td>1.82</td><td>1.06</td><td>2.58</td><td>56.8%</td><td>78.4%</td></tr><tr><td>Unsup</td><td>0.81</td><td>0.45</td><td>1.16</td><td>62%</td><td>81%</td></tr><tr><td rowspan=\"6\">VCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>3.62*</td><td>1.9*</td><td>5.34*</td><td>56.6%</td><td>80/78.3%</td></tr><tr><td>Assignment</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8%</td><td>84.4%</td></tr><tr><td>Unsup</td><td>0.91</td><td>0.58</td><td>1.23</td><td>51.6%</td><td>75.8%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>2.33*</td><td>1.57</td><td>3.08</td><td>52.2%</td><td>81.9/76.1%</td></tr><tr><td>Assignment</td><td>2.05</td><td>0.96</td><td>3.14</td><td>66.4%</td><td>83.2%</td></tr><tr><td>Unsup</td><td>0.84</td><td>0.51</td><td>1.17</td><td>56.4%</td><td>78.2%</td></tr></table> # 5.3 Test-time Scaling A key property of our recurrent GNN architecture for SAT solving is the ability to adjust computational effort at inference time. Unlike standard GNNs with fixed number of layers,the weight-shared recurrent design enables flexible scaling through additional iterations and resampling. ## 5.3.1 Iteration and Resampling Effects Figure 2 demonstrates how increasing message-passing iterations improves the percentage of solved SAT instances. Similarly, Figure 3 shows how the average gap decreases across iterations for various benchmarks. The heat maps in Figure 4 provide a comprehensive view of how performance metrics improve with both increased iterations and resampling attempts. For the model trained on SR40, several observations are notable: \u00b7Iteration benefits: Increasing iterations from 25 to 125 consistently improves all metrics across benchmarks. \u00b7Resampling effects: Multiple inference attempts with different random initializations of node feature vectors further enhance performance. For SR40, decision accuracy improves from 84% with one sample to 93% with five samples at 125 iterations.\n\nTable 3: Performance analysis of VCG+RNN with assignment prediction across different datasets and training methodologies. Our novel \"Closest\" supervision method (which dynamically selects assignments closest to current model predictions) consistently outperforms training with precalculated assignments. For SR40, SAT-only training with closest assignment supervision achieves the highest SAT accuracy (76%), while SAT+UNSAT training with closest assignment supervision yields the lowest average gap (0.98). The missing data for 3SAT100 with SAT+UNSAT closest supervision is due to prohibitive computational costs. Bold values indicate best results per dataset. <table><tr><td>Dataset</td><td>Training Mode</td><td>Assignment Type</td><td>Avg. Gap \u2193</td><td>Gap on SAT \u2193</td><td>Gap on UNSAT \u2193</td><td>SAT Acc. \u2191</td><td>Dec. Acc. \u2191</td></tr><tr><td rowspan=\"4\">SR40</td><td>SAT only</td><td>Precalculated</td><td>2.93</td><td>1.11</td><td>4.75</td><td>68.2 %</td><td>84.1 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>2.68</td><td>0.88</td><td>4.48</td><td>76 %</td><td>88 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8 %</td><td>84.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>0.98</td><td>0.48</td><td>1.49</td><td>71.2 %</td><td>85.6 %</td></tr><tr><td rowspan=\"4\">SR100</td><td>SAT only</td><td>Precalculated</td><td>4.42</td><td>2.36</td><td>6.48</td><td>47.4 %</td><td>73.7 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>3.57</td><td>1.67</td><td>5.48</td><td>59.6 %</td><td>79.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>3.81</td><td>2.34</td><td>5.28</td><td>44.8 %</td><td>72.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>1.43</td><td>0.92</td><td>1.94</td><td>53.2 %</td><td>76.6 %</td></tr><tr><td rowspan=\"4\">3SAT100</td><td>SAT only</td><td>Precalculated</td><td>5.93</td><td>3.40</td><td>9.27</td><td>25.7 %</td><td>57.2 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>5.23</td><td>2.33</td><td>9.11</td><td>48.4 %</td><td>70 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>4.22</td><td>2.84</td><td>6.00</td><td>23.9 %</td><td>55.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td></tr></table> - Cross-distribution applicability: The model trained on SR40 maintains reasonable effectiveness on SR100 and 3SAT100, though with expected performance decrease. This aligns with findings from Li et al. Li et al. [2023], who demonstrated that models trained on SR distributions generally transfer well to other SAT problem structures. #### 5.3.2 Train-time vs Test-time Scaling Tables 4 and 5 present the performance of models trained on SR40 and SR100 distributions when evaluated across benchmarks of varying sizes. The SR40- trained model achieves reasonable generalization to larger instances, though with decreasing effectiveness as problem size increases. For SR100, the model achieves 74.2% decision accuracy despite being trained on smaller instances, showing good generalization capabilities. The SR100- trained model demonstrates better performance on larger instances compared to the SR40- trained model, as expected. On SR200, it achieves 83.0% decision accuracy compared to 58.5% for the SR40 model. This suggests that while test- time scaling can improve performance on larger problems, there are limits to this approach, and training models on larger instances might be necessary for optimal performance on very large problems. These results highlight that recurrent GNN architectures allow for a flexible computation- performance tradeoff that can be adjusted at inference time based on available computational resources and desired solution quality. ### 5.4 Diffusion Model Extension As we mentioned in Section 3.4.4, one can use the GNN as a function approximator \\(f_{\\theta}(\\cdot)\\) inside a diffusion model. This enables another way of scaling the test- time compute. We adapt the diffusion model used by Sun et al. Sun and Yang [2023] where the function approximator is trained to predict the ground truth solution \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t},t)\\) conditioned on a sample \\(\\mathbf{x_t}\\) at time \\(t\\) . The predicted assignment is then used to obtain a sample at time \\(t - 1\\) and this process is repeated again \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_{t - 1}},t - 1)\\) until we reach \\(t = 0\\) . One application of the function approximator together with the sampling is called a diffusion step. The number of diffusion steps \\(T\\) used for inference is a parameter which can be adapted after the model was already\n\nTable 4: Performance of a model trained on SR40 (VCG+RNN with closest assignment supervision) when tested across various benchmarks with a maximum of 100 message-passing iterations and early stopping. The model maintains reasonable performance on SR100 ( \\(74.2\\%\\) decision accuracy) but degrades on larger instances. \"UNSAT Instances (gap \\(= =1\\) )\" shows the percentage of UNSAT instances where the model achieved a gap of 1, which is always optimal for SR datasets but not always achievable for 3SAT instances. \"Steps\" columns indicate average/median iterations required to reach solutions, demonstrating the model's efficiency. <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>89.5%</td><td>79.0%</td><td>95.6%</td><td>16.17/13.0</td><td>13.33/10.0</td></tr><tr><td>SR100</td><td>74.2%</td><td>48.3%</td><td>91.3%</td><td>24.93/21.0</td><td>23.47/19.0</td></tr><tr><td>SR200</td><td>58.5%</td><td>17.0%</td><td>64.5%</td><td>32.44/30.0</td><td>33.98/28.0</td></tr><tr><td>SR400</td><td>51.5%</td><td>3.0%</td><td>16.0%</td><td>41.33/34.0</td><td>52.06/44.5</td></tr><tr><td>3SAT100</td><td>74.8%</td><td>52.8%</td><td>64.0%</td><td>25.63/22.0</td><td>29.66/24.0</td></tr><tr><td>3SAT200</td><td>54.0%</td><td>17.1%</td><td>22.5%</td><td>33.21/25.0</td><td>35.10/31.5</td></tr></table> Table 5: Performance of a model trained on SR100 (VCG+RNN with closest assignment supervision) when tested on SR benchmarks with a maximum of 100 message-passing iterations and early stopping. Given that the SR40-trained model achieved only \\(3\\%\\) SAT accuracy on SR400 (see Table 4), we focused on evaluating how training on larger instances improves scaling. The results show dramatic improvement on larger benchmarks ( \\(36.5\\%\\) vs \\(3\\%\\) on SR400), demonstrating that training on larger problems significantly enhances generalization capacity. The \"Steps\" metrics confirm the SR100-trained model requires fewer iterations on larger problems (e.g., 30.68 vs 41.33 average iterations for SAT instances on SR400). <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>90.6%</td><td>81.2%</td><td>90.0%</td><td>14.57/12.0</td><td>16.21/12.0</td></tr><tr><td>SR100</td><td>79.3%</td><td>58.7%</td><td>85.7%</td><td>22.16/18.0</td><td>22.64/19.0</td></tr><tr><td>SR200</td><td>83.0%</td><td>68.2%</td><td>60.2%</td><td>22.29/20.0</td><td>27.12/22.0</td></tr><tr><td>SR400</td><td>68.2%</td><td>36.5%</td><td>78.0%</td><td>30.68/26.0</td><td>33.13/28.0</td></tr></table>\n\n<center>Figure 2: Percentage of SAT instances solved as message passing iterations increase for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Performance on SR100, showing rapid initial improvement. Right: Comparison across benchmarks, demonstrating effectiveness decreases with problem size but benefits from additional iterations, highlighting the recurrent architecture's inference-time scaling capability. </center> <center>Figure 3: Average gap (unsatisfied clauses) reduction with increasing message passing iterations for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Comparison across benchmarks showing extremely rapid gap reduction in early iterations for all problem sizes, with all benchmarks achieving remarkably low average gaps despite varying SAT-solving performance. Right: Individual instance trajectories revealing different convergence patterns between SAT and UNSAT instances, with occasional fluctuations suggesting potential benefit from monitoring solution quality during inference. </center> trained and therefore, in this setting we have two types of iterations. One is the number of message- passing iterations and the second is the number of diffusion steps. In Table 6 we report the tradeoff between the number of message- passing steps (referred to as GNN_Steps) and the number of diffusion steps. The reported numbers correspond to the dataset SR100 with 100 variables in each problem. The model was trained on the SR40 distribution and the tested combinations use around 300 iterations in total distributed between the two types of steps. The experiments revealed a consistent trend: increasing the number of message- passing steps is generally more important for improving metrics such as Accuracy and Avg. Gap. #### 5.4.1 Connection to Assignment Prediction Training We also report an interesting finding which allows to simplify the function approximator used in the diffusion model. Notice that in the expression \\(\\mathbf{x}_0 = f_\\theta (\\mathbf{x}_t, t)\\) it is also conditioned on the timestep \\(t\\) . This conditioning is dictated by the theory of diffusion models Nakkiran et al. [2024] and most of the models, including the one by Sun et al. Sun and Yang [2023] blindly follow this design choice. In our experiments, we found out that this conditioning is not needed and that the model sometimes works even better without it. Therefore, in all reported results, the\n\n<center>Figure 4: Performance heatmaps for a model trained on SR40 with SAT+UNSAT closest assignment supervision, showing how metrics improve with both increased iterations (columns) and resampling attempts (rows). Testing on SR40 (top), SR100 (middle), and 3SAT100 (bottom) demonstrates significant gains from both scaling dimensions\u2014e.g., SR40 decision accuracy improves from 84% (1 sample, 25 iterations) to 93% (5 samples, 125 iterations). This two-dimensional inference-time scaling capability is consistent across benchmarks but with decreasing returns on larger problems. </center> model is trained to predict the solution \\(\\mathbf{x_0}\\) only from the sample at timestep \\(t\\) ( \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t})\\) ). Concurrently to us, this fact was also discovered by Sun et al. Sun et al. [2025] (the same surname is a coincidence) and it's possible that many of the reported experiments which blindly use this conditioning would result in better values without it. In this simplified setup, the training examples \\((\\mathbf{x_0},\\mathbf{x_t})\\) are sampled by taking a solution of a formula \\((\\mathbf{x_0})\\) , sampling a random \\(t\\) from the diffusion schedule and obtaining a corrupted version of the solution at time \\(t\\) ( \\(\\mathbf{x_t}\\) ). The model is trained to predict \\(\\mathbf{x_0}\\) from \\(\\mathbf{x_t}\\) . The GNN is the same as in the case of assignment prediction except that it also contains a learnable embedding layer which embeds the Boolean values in the assignment \\(\\mathbf{x_t}\\) into a vector space to obtain the initial embeddings of variables (or literals) for the first pass of message- passing. The only difference from the model trained for assignment prediction is therefore that the initial embeddings are not sampled randomly but obtained by embedding the perturbed assignment \\(\\mathbf{x_t}\\) . This also means that during test time, these two approaches differ only by rounding, i.e. running the model trained for assignment prediction for 100 steps and after every 20 steps rounding the variable embeddings to vectors representing True and False is same as running the diffusion model for 5 diffusion steps where each step has 20 message- passing iterations.\n\ntheir performance and on the theoretical side, understanding how a GNN can solve a CNF formula could help us to elucidate the reasoning ability of Transformers Vaswani et al. [2017] because Transformers can be viewed as GNNs in which the graph connectivity is given by the attention map and is learned from data Cai et al. [2023]. Our aim in this contribution is to provide an experimental evaluation of different design choices for GNNs in the context of Boolean satisfiability together with an intuitive explanation of the inner workings of these models. Our main contributions are as follows: - We provide an experimental comparison of different architectures and training regimes.- We introduce a novel supervision method based on the closest assignment, resulting in significant improvements.- We demonstrate that these architectures scale well at test time.- We extend the graph neural network to a diffusion model and show how it relates to the base model.- We provide an intuitive explanation for the inner workings of these models. The rest of the text has the following structure: Section 3 (Relevant Background) provides the necessary context on Boolean satisfiability problems, SAT solving approaches, graph neural networks, theoretical connection to approximation algorithms, and diffusion models. Section 4 (Experimental Setup) describes our methodology, including data representation choices, architecture variants, supervision methods, and benchmark generation. Section 5 (Experimental Results) presents our comprehensive evaluation, comparing different graph representations and training methods (Section 5.2), demonstrating test- time scaling capabilities (Section 5.3), and introducing our diffusion model extension (Section 5.4). Section 6 (Interpreting the Trained Model) offers analysis of the embedding space and explains the networks' behavior through the lens of approximation algorithms based on continuous relaxation. Section 2 (Related Work) positions our contribution within the broader research landscape, and Section 7 contains a discussion of our findings and directions for future research. We conclude in Section 8. Additional implementation details and mathematical derivations are provided in the Appendix. ## 2 Related Work Our research builds directly upon Neuro SAT Selsam et al. [2018], which introduced the first end- to- end neural approach for SAT solving using a recurrent message- passing architecture. While we maintain the core iterative design of Neuro SAT (allowing variable numbers of message- passing iterations through weight sharing), we explore simplified variants using RNNs and LSTMs and incorporate techniques like curriculum learning to improve training efficiency. Several other works have explored different directions in neural SAT solving. Li et al. Li et al. [2023] developed G4SATBench to benchmark various GNN architectures (GCN, GGNN, GIN) across different graph representations and supervision objectives. Unlike their broader exploration across architecture types, our work focuses on the recurrent message- passing paradigm from Neuro SAT and investigates how different training objectives and graph representations affect performance within this specific framework. We also mention the work by Warde et al. Warde- Farley et al. [2023] who developed a recurrent architecture based on a Restricted Boltzmann Machine. Hybrid approaches that integrate neural networks with traditional solvers include Neuro Core by Selsam and Bjorner Selsam and Bjorner [2019], which uses neural predictions to guide variable branching in CDCL solvers. Similarly, Wang et al. Wang et al. [2021] proposed Neuro Comb to enhance CDCL solvers through GNN- based identification of important variables and clauses.\n\nTable 6: Performance Metrics for Different GNN and Diffusion Step Configurations. Variable names shown in parentheses in the original data source are omitted here for brevity. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Dec. Acc. (%)</td><td>Single-Step Avg. Gap</td><td>Single-Step Dec. Acc (%)</td></tr><tr><td>20</td><td>15</td><td>1.09</td><td>68.7</td><td>3.26</td><td>60.2</td></tr><tr><td>23</td><td>13</td><td>1.05</td><td>70.4</td><td>2.80</td><td>63.1</td></tr><tr><td>27</td><td>11</td><td>0.96</td><td>73.6</td><td>2.44</td><td>64.7</td></tr><tr><td>31</td><td>9</td><td>0.98</td><td>73.8</td><td>2.11</td><td>68.2</td></tr><tr><td>35</td><td>8</td><td>0.93</td><td>75.4</td><td>1.96</td><td>69.5</td></tr><tr><td>38</td><td>7</td><td>0.92</td><td>76.3</td><td>1.83</td><td>70.2</td></tr><tr><td>42</td><td>7</td><td>0.90</td><td>76.7</td><td>1.70</td><td>71.6</td></tr><tr><td>46</td><td>6</td><td>0.95</td><td>76.8</td><td>1.64</td><td>72.1</td></tr><tr><td>50</td><td>6</td><td>0.94</td><td>76.2</td><td>1.52</td><td>73.0</td></tr></table> #### 5.4.2 Interleaving Diffusion Steps with Unit Propagation The fact that for each diffusion step, the model outputs probabilities for two possible values, allows us to obtain a partial solution and then run a unit propagation to deduce assignment to other variables. The partial assignment can be obtained by fixing a threshold and then assigning only variables for which one of the values has a predicted probability higher than this threshold. The lower the threshold, the more variables will be fixed and the higher the probability that it will not be possible to complete the partial assignment to a satisfiable assignment. We therefore design a tree- search- like algorithm which first tries a low threshold in each diffusion step and if it does not find a satisfiable assignment it backtracks and increases the threshold to obtain a new partial assignment. The details of this algorithm are described in A.3 and the experimental results are reported in Table 7. As can be seen, interleaving the diffusion steps with unit propagation results in additional improvements over the base diffusion model (approximately \\(10\\%\\) ). We explicitly mention that this experiment is provided only to show a possible avenue for further improvements and the algorithm in its current form is not optimized for speed. Table 7: Performance with Unit Propagation. Here we compare the performance with (U.P. Acc.) and without (Dec. Acc.) Unit Propagation, and report the computational cost of Unit Propagation, listing the average number of total recursive function calls, the average number of recursive calls in solved problems, and the average number of recursive calls in unsolved problems. <table><tr><td>Problems</td><td>Dec. Acc. (%)</td><td>U.P. Acc. (%)</td><td>Total Rec. Calls</td><td>Solved Rec. Calls</td><td>Unsolved Rec. Calls</td></tr><tr><td>SR40</td><td>88.4</td><td>94.2</td><td>32.864</td><td>6.701</td><td>53.546</td></tr><tr><td>SR50</td><td>86.6</td><td>93.7</td><td>29.539</td><td>6.995</td><td>47.038</td></tr><tr><td>SR60</td><td>83.3</td><td>92.2</td><td>26.414</td><td>7.526</td><td>40.204</td></tr><tr><td>SR70</td><td>79.5</td><td>89.5</td><td>24.162</td><td>6.752</td><td>35.505</td></tr><tr><td>SR80</td><td>77.6</td><td>88.0</td><td>22.604</td><td>6.917</td><td>32.219</td></tr><tr><td>SR90</td><td>74.0</td><td>85.1</td><td>22.140</td><td>7.274</td><td>30.151</td></tr><tr><td>SR100</td><td>73.4</td><td>83.7</td><td>20.363</td><td>7.129</td><td>27.074</td></tr><tr><td>SR150</td><td>63.2</td><td>75.1</td><td>17.388</td><td>7.828</td><td>20.592</td></tr><tr><td>SR200</td><td>58.0</td><td>67.5</td><td>16.270</td><td>8.710</td><td>17.868</td></tr></table>\n\n## 6 Interpreting the Trained Model ### 6.1 Embedding Space Analysis Our analysis of variable embeddings reveals patterns that explain how GNNs learn to solve SAT problems. When visualizing these embeddings using dimensionality reduction Mc Innes et al. [2018], we observe that they form distinct clusters corresponding to optimal variable assignments. As shown in Figure 5, variable embeddings start randomly distributed but gradually organize into two clusters through message passing iterations. By applying k- means clustering ( \\(k = 2\\) ) to these embeddings, we can recover variable assignments that approximate optimal solutions, even from networks trained only to predict satisfiability status. ### 6.2 Iterative Optimization Behavior By tracking clause satisfaction across iterations, we observe that GNNs solve SAT problems through progressive local refinement. The gap (number of unsatisfied clauses) decreases following a trajectory typical of iterative optimization methods: rapid initial improvement followed by gradual refinement. This behavior supports the interpretation that GNNs implicitly learn to perform continuous optimization in a high- dimensional space similar to SDP relaxations for SAT. The effectiveness of additional message passing iterations during inference further strengthens this connection. A difference from the SDP relaxation is that the objective function which the GNN implicitely optimizes is non- convex because we observed that it can get stuck in local optima or converge to different solutions when initialized multiple times by different random embeddings. Figure 3 illustrates how the average gap decreases with increasing iterations. The trajectory suggests a rapid improvement phase followed by more gradual refinement. Individual instance trajectories reveal that while most instances show steady improvement toward optimal solutions, some exhibit fluctuations, particularly unsatisfiable instances. This observation supports the potential value of early stopping techniques, as in rare cases, the gap at later iterations might be higher than a previously achieved minimum gap. The bi- level optimization perspective\u2014where message passing performs an inner optimization loop (finding variable assignments) guided by network parameters optimized at the outer level (during training)\u2014helps explain the network's ability to generalize to novel problem instances and larger problems than those seen during training. In Section 7, we discuss more details about a possibility of manual derivation of the GNN equations from and explicit objective function. ## 7 Discussion In this section, we discuss the limitations of our work along with an outlook for future research. The primary limitation of the methods presented here is that they are not competitive with state- of- the- art SAT solvers on benchmarks derived from real- world problems. Current SAT solvers can handle formulas with millions of variables, which is not feasible for the GNN in its current form. However, as mentioned in the introduction, our motivation for studying these models is to better understand the reasoning capabilities of neural networks in a simplified context. The test- time scaling experiments clearly demonstrate that the GNNs can successfully generalize beyond their training distribution and do not merely learn superficial statistical patterns. The qualitative results presented in Section 6 further suggest that it is possible to fully understand the mechanisms by which the GNN solves a given formula. Figure 3 illustrates that the trained GNN functions as an implicit Max SAT solver, incrementally maximizing the number\n\n<center>Figure 5: Evolution of variable embeddings during message passing iterations for a satisfiable SR40 instance. The visualization shows 2D projections at different stages (Initial through Iteration 25), colored k-means algorithm in each iteration (green/red). Initially random, embeddings gradually organize into two distinct clusters often corresponding to optimal variable assignments. This clustering behavior was observed across different model architectures and training objectives\u2014notably, even models trained solely for SAT/UNSAT classification (without explicit assignment supervision) develop this embedding separation. This phenomenon supports our interpretation that GNNs implicitly perform continuous optimization similar to SDP relaxation for SAT problems. </center>\n\nof satisfied clauses at each step. These local updates occur in continuous space and can therefore be viewed as gradient updates with respect to an implicit objective function measuring clause satisfaction. Variables are also represented in a high- dimensional vector space, similar to semi- definite programming as explained in B. From this perspective, Equations 6, 7, and 11 can be interpreted as a gradient descent algorithm searching for an optimal assignment over a high- dimensional unit sphere (due to unit normalization), while the final classification layer corresponds to a rounding step to Boolean values. In future work, we aim to manually derive these equations from a trained GNN using a primal- dual approach, interleaving gradient updates of primal and dual variables associated with constraints. We believe that by utilizing suitable proximal operators and an appropriate metric in the relaxed solution space, the GNN can be effectively interpreted as a primal- dual algorithm optimizing a continuous relaxation of the Max SAT objective in a high- dimensional space. This points out to another major advantage of using the RNN update function because its simple form is suitable for such derivation. Deriving equations for such algorithms applicable to arbitrary combinatorial optimization problems would be highly beneficial in practice, allowing these equations to be parameterized by learnable matrices and fine- tuned for specific problem distributions. Such data- driven solvers would be analogous to physics- informed neural networks Cai et al. [2021], where substantial domain knowledge is embedded within the model, followed by fine- tuning to approximate the dynamics of a particular physical system. This approach results in fast numerical solvers tailored to specific domains. We believe that the development of data- drive numerical solvers represents an exciting future direction for combinatorial optimization research. To make these numerical solvers practical, it will still be necessary to integrate them into more complex systems, where they would function as guessing or bounding heuristic. Another limitation of our work is that the model was tested exclusively on random problems. This decision is justified by the findings of Li et al. Li et al. [2023], who demonstrated that models trained on random problem instances exhibit superior generalization to other distributions. Since Li et al. already provided experimental results demonstrating the transferability of models across different problem distributions, we chose not to repeat those experiments here. ## 8 Conclusion This work provides a comprehensive analysis of graph neural networks for Boolean satisfiability problems. Our evaluation identified key design choices that enhance performance: variable- clause graph representation with RNN updates offers an effective balance of accuracy and efficiency, while our novel closest assignment supervision method significantly improves performance on problems with large solution spaces. The recurrent architecture enables flexible scaling during inference through additional message- passing iterations and resampling. Our diffusion model extension demonstrates another approach to inference- time adaptation, with further improvements possible by integrating classical techniques like unit propagation. Our analysis of embedding space patterns and optimization trajectories supports the interpretation that these models implicitly implement continuous relaxation algorithms for Max SAT, explaining their ability to generalize to novel problem instances. This connection provides a theoretical framework for understanding neural reasoning capabilities in structured domains, with implications for the design of hybrid solving approaches. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit- sat: An unsupervised differentiable approach. In International conference on learning representations, 2018.\n\nJacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state- spaces. Advances in neural information processing systems, 34:17981- 17993, 2021. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisfiability, volume 185. IOS press, 2009. Sally C Brailsford, Chris N Potts, and Barbara M Smith. Constraint satisfaction problems: Algorithms and applications. European journal of operational research, 119(3):557- 581, 1999. Chen Cai, Truong Son Hy, Rose Yu, and Yusu Wang. On the connection between mpnn and graph transformer. In International conference on machine learning, pages 3408- 3430. PMLR, 2023. Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics- informed neural networks (pinns) for fluid mechanics: A review. Acta Mechanica Sinica, 37 (12):1727- 1738, 2021. James M Crawford and Larry D Auton. Experimental results on the crossover point in random 3- sat. Artificial intelligence, 81(1- 2):31- 57, 1996. Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1- 2):3- 71, 1988. Zhaohui Fu and Sharad Malik. On solving the partial max- sat problem. In International Conference on Theory and Applications of Satisfiability Testing, pages 252- 265. Springer, 2006. Bernd G\u00e4rtner and Jiri Matousek. Approximation algorithms and semidefinite programming. Springer Science & Business Media, 2012. Michel X Goemans and David P Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. Journal of the ACM (JACM), 42(6):1115- 1145, 1995. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek- r1: Incentivizing reasoning capability in llms via reinforcement learning. ar Xiv preprint ar Xiv:2501.12948, 2025. Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840- 6851, 2020. Abdelrahman Hosny and Sherief Reda. torchmsat: A gpu- accelerated approximation to the maximum satisfiability problem. ar Xiv preprint ar Xiv:2402.03640, 2024. Jan Hula, David Moj\u017e\u00ed\u0161ek, and Mikol\u00e1\u0161 Janota. Understanding gnns for boolean satisfiability through approximation algorithms. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pages 953- 961, 2024. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El- Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. ar Xiv preprint ar Xiv:2412.16720, 2024. Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Vardi, and Zhiwei Zhang. Fourier sat: A fourier expansion- based algebraic framework for solving hybrid boolean constraints. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 1552- 1560, 2020.\n\nZhaoyu Li and Xujie Si. Nsnet: A general neural probabilistic framework for satisfiability problems. Advances in Neural Information Processing Systems, 35:25573- 25585, 2022. Zhaoyu Li, Jinpei Guo, and Xujie Si. G4satbench: Benchmarking and advancing sat solving with graph neural networks. ar Xiv preprint ar Xiv:2309.16941, 2023. Gary Marcus. Deep learning: A critical appraisal. ar Xiv preprint ar Xiv:1801.00631, 2018. Gary F Marcus. The algebraic mind: Integrating connectionism and cognitive science. MIT press, 2003. Leland Mc Innes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for dimension reduction. ar Xiv preprint ar Xiv:1802.03426, 2018. Preetum Nakkiran, Arwen Bradley, Hattie Zhou, and Madhu Advani. Step- by- step diffusion: An elementary tutorial. ar Xiv preprint ar Xiv:2406.08929, 2024. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural sat solver. In 2022 International joint conference on neural networks (IJCNN), pages 1- 8. IEEE, 2022. Motakuri Ramana and Alan J Goldman. Some geometric results in semidefinite programming. Journal of Global Optimization, 7(1):33- 50, 1995. Bart Selman, Henry A Kautz, Bram Cohen, et al. Local search strategies for satisfiability testing. Cliques, coloring, and satisfiability, 26:521- 532, 1993. Daniel Selsam and Nikolaj Bjorner. Guiding high- performance sat solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing- SAT 2019: 22nd International Conference, SAT 2019, Lisbon, Portugal, July 9- 12, 2019, Proceedings 22, pages 336- 353. Springer, 2019. Daniel Selsam, Matthew Lamm, Benedikt Binz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a sat solver from single- bit supervision. ar Xiv preprint ar Xiv:1802.03685, 2018. Qiao Sun, Zhicheng Jiang, Hanhong Zhao, and Kaiming He. Is noise conditioning necessary for denoising generative models? ar Xiv preprint ar Xiv:2502.13129, 2025. Zhiqing Sun and Yiming Yang. Difusco: Graph- based diffusion solvers for combinatorial optimization. Advances in neural information processing systems, 36:3706- 3731, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. W Wang, Y Hu, M Tiwari, S Khurshid, KL Mc Millan, and R Miikkulainen. Neurocomb: improving sat solving with graph neural networks, 2021. David Warde- Farley, Vinod Nair, Yujia Li, Ivan Lobov, Felix Gimeno, and Simon Osindero. Solving maxsat with matrix multiplication. ar Xiv preprint ar Xiv:2311.02101, 2023. Morris Yau, Nikolaos Karalias, Eric Lu, Jessica Xu, and Stefanie Jegelka. Are graph neural networks optimal approximation algorithms? Advances in Neural Information Processing Systems, 37:73124- 73181, 2024. Emre Yolcu and Barnabas P\u00f3czos. Learning local search heuristics for boolean satisfiability. Advances in Neural Information Processing Systems, 32, 2019.\n\n<center>Figure 6: Validation accuracy during training. Our model with a curriculum achieves reaches \\(85\\%\\) in approximately 30 minutes, whereas the original Neuro SAT implementation needs over 5 hours. For comparison, we also add our implementation trained on the same data, but without a curriculum. The training of each model stops once it achieves an accuracy of \\(85\\%\\) on a validation set. </center> ## A Appendix ## A.1 Training Tricks and Information ## A.1.1 Curriculum Learning We implement a curriculum learning strategy to improve training efficiency and generalization. The key insight is that starting with simpler (smaller) formulas and gradually increasing complexity allows the model to learn basic logical reasoning patterns before tackling more complex instances. Our curriculum proceeds as follows: 1. Start training with small formulas (5 variables) 2. Set a validation accuracy threshold for each formula size (starting at \\(65\\%\\) for the smallest size and increasing to \\(85\\%\\) for the largest) 3. Once the model reaches the threshold accuracy on the current size or reaches a maximum number of epochs (100), increase the formula size by 2 variables 4. When introducing a new size, include formulas from the four previous sizes to prevent catastrophic forgetting 5. Continue until reaching the maximum formula size (40 variables) This curriculum approach significantly accelerates training compared to starting with the full distribution of formula sizes. Our previous experiments showed that the curriculum- trained model reaches \\(85\\%\\) validation accuracy in approximately 30 minutes, compared to over 5 hours for the non- curriculum approach. ## A.1.2 Exponential Moving Average (EMA) We employ Exponential Moving Average (EMA) for model parameter updates during training. EMA maintains a shadow copy of the model parameters that is updated after each training\n\nbatch: \\[\\theta_{\\mathrm{EMA}}\\leftarrow \\beta \\theta_{\\mathrm{EMA}} + (1 - \\beta)\\theta_{\\mathrm{current}} \\quad (13)\\] where \\(\\beta\\) is the decay rate (we use \\(\\beta = 0.999\\) ). During validation and testing, we use the EMA parameters instead of the current parameters. This technique significantly stabilizes training and improves generalization, especially in the early stages of training. Our experiments show that EMA provides a smooth validation accuracy curve, while the validation accuracy of the non- EMA model exhibits high variance and jumps of up to \\(10\\%\\) . #### A.1.3 Learning Rate Schedule We implement a custom learning rate schedule that combines cosine annealing for the first half of training and a constant minimum learning rate for the second half: \\[\\eta (t) = \\left\\{ \\begin{array}{ll}\\eta_{\\mathrm{min}} + (\\eta_{0} - \\eta_{\\mathrm{min}})\\frac{1 + \\cos(\\pi t / t_{\\mathrm{half}})}{2} & \\mathrm{if} t< t_{\\mathrm{half}}\\\\ \\eta_{\\mathrm{min}} & \\mathrm{otherwise} \\end{array} \\right. \\quad (14)\\] where \\(\\eta_{0}\\) is the initial learning rate, \\(\\eta_{\\mathrm{min}}\\) is the minimum learning rate (set to \\(10^{- 5}\\) ), \\(t\\) is the current epoch, and \\(t_{\\mathrm{half}}\\) is half of the maximum number of epochs. This schedule helps the model converge to a good solution in the first half of training and then fine- tune in the second half without disrupting the learned representations. ## A.1.4 Impact of hidden dimension on GNN Performance The dimensionality of the hidden representations, here denoted as d_model, specifies the size of the embedding vectors of variables and the hidden state dimension used during the message passing and update phases within the GNN architecture. The choice of d_model directly influences the model's capacity to learn complex patterns and relationships within the graph structure and node features. It also impacts computational resource requirements, such as memory usage and training time. Understanding how performance metrics vary with different d_model values is therefore crucial for effective model design and hyperparameter tuning. Our evaluation in table 8 generally shows that increasing the d_model leads to improved model performance, likely due to the enhanced representational capacity allowing the model to capture more intricate features. However, we observed that this trend exhibits diminishing returns; while significant performance gains are noticeable as the dimension increases up to 64, further increases yield smaller improvements in accuracy relative to the growing computational cost (e.g., peak accuracy at d_model=256 came with significantly longer training time). This suggests that, considering the marginal benefits, a dimension around 64 still presents a practical optimum, offering a good balance between performance and model complexity/efficiency for this specific setup. ## A.2 Diffusion Model Extensions ## A.3 Using Unit Propagation for Problem Simplification in the Diffusion Process In the diffusion process, each iteration provides a belief for every variable, which can be leveraged to continuously simplify the problem via a unit propagation algorithm until it converges to an empty problem, thereby obtaining a solution. The overall solving process is recursive, and its main steps are described as follows:\n\nTable 8: Experimental results demonstrating the impact of hidden dimension size (d_model) on model performance and training duration. \u2018Embedding Size (d_model)\u2019 refers to the dimensionality of the hidden representations within the GNN. \u2018Accuracy\u2019 indicates the performance metric achieved by the model. \u2018Time (hours)\u2019 specifies the total time required to train the model for each corresponding dimension size. <table><tr><td>Embedding Size (d_model)</td><td>Accuracy</td><td>Time (hours)</td></tr><tr><td>16</td><td>0.782</td><td>1.62</td></tr><tr><td>32</td><td>0.852</td><td>1.66</td></tr><tr><td>48</td><td>0.860</td><td>1.70</td></tr><tr><td>64</td><td>0.869</td><td>1.87</td></tr><tr><td>96</td><td>0.861</td><td>2.32</td></tr><tr><td>128</td><td>0.864</td><td>2.99</td></tr><tr><td>256</td><td>0.877</td><td>7.55</td></tr></table> ## 1. Partial Assignment Extraction and Local Unit Propagation In each diffusion step, a belief value between 0 and 1 is calculated for every variable. A value closer to 1 indicates a stronger inclination toward being true, and vice versa. We set a threshold to select variables with high belief and assign them accordingly to obtain a partial assignment. This partial assignment is then used to perform unit propagation for clause simplification. The unit propagation algorithm works as follows: If a clause contains a literal that is already satisfied by the current assignment, the clause is marked as satisfied. If all literals in a clause have been assigned but none satisfy it, a conflict signal is returned. For clauses that are not fully assigned, the unassigned literals are retained to form a simplified clause set. For unit clauses obtained during the simplification process (i.e., clauses containing only a single literal), the corresponding unassigned variable is directly assigned the appropriate value, further advancing the local solving process. ## 2. Multi-Threshold Strategy and Recursive Solving In the partial assignment extraction step, setting a lower threshold allows for the selection of as many assignments as possible at each step, thereby greatly simplifying the problem; however, it is more likely to select unreliable assignments that may lead to contradictions. To balance this, we adopt a multi- threshold list, starting from the lowest threshold. For each given threshold, if a new partial assignment is obtained, unit propagation is used to update the clauses and evaluate: If the simplified clause set becomes empty, all clauses are satisfied and the final solution is directly returned. If a conflict occurs or the recursive call at the next level fails, the threshold is raised; if the highest threshold is reached, the process moves to the next recursive level and performs another diffusion step. If unit propagation succeeds but the problem is not yet completely solved, the process recurses to the next level, performing a diffusion step on the updated clauses. If the recursion reaches a preset maximum depth and the clauses still cannot be satisfied, the recursion at that level fails.\n\nTable 9: Performance on SR100 for Different Diffusion Step and Fixed GNN Step. Note that the Performance is no longer Significantly Improved when Diffusion Steps Larger than 8. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>25</td><td>4</td><td>0.991</td><td>69.9</td></tr><tr><td>25</td><td>5</td><td>0.901</td><td>71.2</td></tr><tr><td>25</td><td>6</td><td>0.798</td><td>72.7</td></tr><tr><td>25</td><td>8</td><td>0.705</td><td>73.0</td></tr><tr><td>25</td><td>10</td><td>0.728</td><td>72.1</td></tr><tr><td>25</td><td>20</td><td>0.662</td><td>73.3</td></tr><tr><td>25</td><td>30</td><td>0.676</td><td>72.3</td></tr><tr><td>25</td><td>40</td><td>0.655</td><td>73.3</td></tr><tr><td>25</td><td>50</td><td>0.663</td><td>73.0</td></tr></table> Table 10: Performance on SR100 for Different GNN Step and Fixed Diffusion Step. Note that the Performance is no longer Significantly Improved when GNN Steps Larger than 50. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>10</td><td>10</td><td>2.028</td><td>55.0</td></tr><tr><td>20</td><td>10</td><td>0.846</td><td>68.6</td></tr><tr><td>30</td><td>10</td><td>0.622</td><td>74.4</td></tr><tr><td>40</td><td>10</td><td>0.578</td><td>75.5</td></tr><tr><td>50</td><td>10</td><td>0.533</td><td>77.6</td></tr><tr><td>60</td><td>10</td><td>0.518</td><td>77.2</td></tr><tr><td>70</td><td>10</td><td>0.500</td><td>78.6</td></tr><tr><td>80</td><td>10</td><td>0.521</td><td>77.9</td></tr><tr><td>90</td><td>10</td><td>0.512</td><td>77.6</td></tr><tr><td>100</td><td>10</td><td>0.522</td><td>77.4</td></tr></table> Table 7 shows the performance and computational cost after applying unit propagation. We tested a fixed model under the settings: GNN steps \\(= 25\\) , diffusion steps \\(= 10\\) , and multithreshold list \\(= [0.6, 0.75, 0.9]\\) . As shown, incorporating unit propagation improves accuracy by approximately \\(10\\%\\) across various problem settings. The last three columns of the table list the number of recursive function calls during the recursion process. Since each call involves one diffusion step, the computational cost incurred by the multi- threshold strategy is directly reflected. We observed that for harder problems, the computational cost of the multi- threshold strategy is actually lower, as unit propagation on partial assignments is more likely to encounter conflicts, thereby reducing the number of recursive branches. ## A.4 Influence of Number of Message-passing and Diffusion Steps For completeness, we also report evaluations in which the number of diffusion steps is fixed and the number of message- passing steps is changing (Table 10) and vice versa (Table 9). We observe that the expansion of the number of iterative steps does not always bring benefits: when the number of one kind of step is fixed, further increasing the number of another kind of step beyond a certain threshold will not lead to performance improvement.\n\nThese approaches differ from our end- to- end model but demonstrate alternative applications of neural methods to SAT solving. The connection between neural networks and continuous relaxations is particularly relevant to our work. Kyrillidis et al. Kyrillidis et al. [2020] introduced Fourier SAT, which transforms Boolean SAT problems into continuous optimization using the Walsh- Fourier transform. This approach provides a theoretical foundation for understanding how neural networks might implicitly convert discrete search problems into continuous optimization. Similar technique was introduced by Hosny et al. Hosny and Reda [2024] who develop GPU- accelerated approaches for Max SAT problems. Hula et al. Hula et al. [2024] and Yau et al. Yau et al. [2024] explore the connection between GNNs and semidefinite programming relaxations, demonstrating empirically and theoretically that message- passing can implement gradient- based optimization of SDP relaxations. In the broader domain of combinatorial optimization, Sun et al. Sun and Yang [2023] used diffusion models based on GNNs to solver problems such as traveling salesman. ## 3 Relevant Background ### 3.1 Boolean Satisfiability and Maximum Satisfiability #### 3.1.1 Boolean Satisfiability as a Constraint Satisfaction Problem Boolean satisfiability (SAT) is a fundamental problem in computer science that asks whether a given Boolean formula has a satisfying assignment. The formula is built from propositional variables \\(x_{1},x_{2},\\ldots\\) that can take values from \\(\\{0,1\\}\\) , representing false and true respectively, and logical connectives: conjunction \\((\\wedge)\\) , disjunction \\((\\vee)\\) , and negation \\((\\neg)\\) . While other connectives like implication \\((\\rightarrow)\\) and equivalence \\((\\leftrightarrow)\\) exist, they can be expressed using these basic operators. A literal is either a propositional variable \\(x\\) or its negation \\(\\neg x\\) . While Boolean formulas can take arbitrary form, the most common representation is the conjunctive normal form (CNF), where a formula is a conjunction of clauses, and each clause is a disjunction of literals. For example, \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) is a CNF formula with two clauses. We note that any Boolean formula can be transformed into an equisatisfiable CNF formula, albeit potentially requiring additional variables. An assignment \\(\\sigma\\) maps each propositional variable to either 0 or 1. We say \\(\\sigma\\) satisfies a CNF formula if at least one literal in each clause evaluates to true under \\(\\sigma\\) . For instance, the assignment \\(\\sigma (x_{1}) = 1,\\sigma (x_{2}) = 0,\\sigma (x_{3}) = 1\\) satisfies the formula \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) as both clauses contain a true literal. SAT is a special case of the more general Constraint Satisfaction Problem (CSP) framework Brailsford et al. [1999]. A CSP consists of a set of variables, each with a domain of possible values, and a set of constraints that specify allowed combinations of values for groups of variables. While SAT variables are restricted to Boolean values and constraints take the form of clauses, CSPs can accommodate richer variable domains and constraint types. #### 3.1.2 Max SAT: The Optimization Variant The Maximum Satisfiability problem (Max SAT) is the optimization version of SAT. Given a CNF formula \\(\\phi\\) , the goal is to find an assignment that maximizes the number of satisfied clauses. This formulation is particularly useful when a formula is unsatisfiable, as Max SAT still yields the best possible solution. Max SAT has several variations that differ in their expressiveness and the way they handle the importance of clauses. In unweighted Max SAT, all clauses have equal importance. Weighted Max SAT assigns a positive weight to each clause, with the objective being to maximize the sum\n\n## B SDP for MAX-2-SAT Semidefinite programming (SDP) is a mathematical optimization technique primarily used for problems involving positive semidefinite matrices. In SDP, a linear objective function is optimized over a feasible region given by a spectrahedron (an intersection of a convex cone formed by positive semidefinite matrices and an affine subspace) Ramana and Goldman [1995]. Along with the broad scope of applications, SDP has been used to design approximation algorithms for discrete NP- hard problems Gartner and Matousek [2012]. This is achieved by lifting variables of a problem to a vector space and optimizing a loss function expressed in terms of these vectors. In this section, we provide a detailed derivation of the SDP relaxation for MAX- 2- SAT. The goal is to write an objective function for 2- CNF formulae, which consist of clauses \\(c_{1},\\ldots ,c_{k}\\) over variables \\(x_{1},\\ldots ,x_{n}\\) with at most two literals per clause. ## B.1 Derivation of the SDP Relaxation For each Boolean variable \\(x_{i}\\) (where \\(i\\in \\{1,2,\\ldots ,n\\}\\) ), a new variable \\(y_{i}\\in \\{- 1,1\\}\\) is associated, and an additional variable \\(y_{0}\\in \\{- 1,1\\}\\) is introduced. This additional variable is introduced to unambiguously assign the truth value in the original problem from values of the relaxed problem. It is not possible to just assign True (False) to \\(x_{i}\\) if \\(y_{i} = 1(- 1)\\) because quadratic terms cannot distinguish between \\(y_{i}\\cdot y_{j}\\) and \\((- y_{i})\\cdot (- y_{j})\\) . Instead, the truth value of \\(x_{i}\\) is assigned by comparing \\(y_{i}\\) with \\(y_{0}\\) : \\(x_{i}\\) is True if and only if \\(y_{i} = y_{0}\\) , otherwise it is False. The assignment is therefore invariant to negating all variables. To determine the value of a formula, we sum the value of its clauses \\(c\\) which are given by the value function \\(v(c)\\) . Here are examples of the value function for different clauses: \\[\\begin{array}{c}{v(x_{i}) = \\frac{1 + y_{0}\\cdot y_{i}}{2}}\\\\ {v(\\neg x_{i}) = 1 - v(x_{i}) = \\frac{1 - y_{0}\\cdot y_{i}}{2}}\\\\ {v(x_{i}\\vee \\neg x_{j}) = 1 - v(\\neg x_{i}\\wedge x_{j})}\\\\ {= 1 - \\frac{1 - y_{0}\\cdot y_{i}}{2}\\cdot \\frac{1 + y_{0}\\cdot y_{j}}{2}}\\\\ {= \\frac{1}{4} (1 + y_{0}\\cdot y_{i}) + \\frac{1}{4} (1 - y_{0}\\cdot y_{j}) + \\frac{1}{4} (1 + y_{i}\\cdot y_{j})} \\end{array} \\quad (15)\\] By summing over all clauses \\(c\\) in the Boolean formula, the following integer quadratic program for MAX- 2- SAT is obtained: \\[\\begin{array}{r l} & {\\mathrm{Maximize:}\\quad \\sum_{c\\in C}v(c)}\\\\ & {\\mathrm{Subject~to:}\\quad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\mathrm{Subject~to:}\\quad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}j\\in \\{0,1,\\ldots ,n\\}} \\end{array} \\quad (21)\\] This can be rewritten by collecting coefficients of \\(y_{i}\\cdot y_{j}\\) for \\(i,j\\in \\{0,1,\\ldots ,n\\}\\) and putting them symmetrically into a \\((n + 1)\\times (n + 1)\\) coefficient matrix \\(W\\) . The terms \\(y_{i}\\cdot y_{j}\\) can be collected in a matrix \\(Y\\) with the same dimensions as \\(W\\) . The elements \\(Y_{ij}\\) correspond to \\(y_{i}\\cdot y_{j}\\) for \\(i,j\\in \\{0,1,\\ldots ,n\\}\\) . Both matrices are symmetric, hence the sum of all elements in their element- wise product (which is the objective function) can be compactly expressed by using the trace operation. This leads to the following version of the same integer program: \\[\\begin{array}{r l} & {\\mathrm{Maximize:}\\quad \\mathrm{Tr}(W Y)}\\\\ & {\\mathrm{Subject~to:}\\quad Y_{i i} = 1\\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad Y_{i j} = y_{i}\\cdot y_{j}\\mathrm{~for~all~}i,j\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}} \\end{array} \\quad (22)\\]\n\n## B.2 Relaxation to Semidefinite Programming To make the discrete program continuous, we first allow the value of the variables \\(y_{i}\\) to be any real number between \\(- 1\\) and 1. However, semidefinite programming goes further and allows variables to be \\((n + 1)\\) - dimensional unit vectors \\((y_{0},\\ldots ,y_{n})\\longrightarrow (\\mathbf{y}_{0},\\ldots ,\\mathbf{y}_{n})\\) , as schematically depicted in Figure 7. In this relaxation, the binary products \\(y_{i}\\cdot y_{j}\\) in the objective function are replaced by inner products \\(\\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) This can be compactly represented in matrix form by substituting each inner product \\(\\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) with a scalar \\(Y_{ij}\\) of a matrix \\(Y\\) . The fact that these scalars correspond to inner products is encoded by the restriction to positive- semidefinite matrices \\(Y\\succeq 0\\) . The SDP relaxation of MAX- 2- SAT can thus be formulated as: \\[\\begin{array}{rl} & {\\mathrm{Maximize:}\\quad \\mathrm{Tr}(W Y)}\\\\ & {\\mathrm{Subject~to:}\\quad Y_{i i} = 1\\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad Y\\succeq 0} \\end{array} \\quad (27)\\] Positive semidefiniteness of matrix \\(Y\\) ensures that it can be uniquely factorized as \\(Y =\\) \\(Y^{\\frac{1}{2}}(Y^{\\frac{1}{2}})^{T}\\) . We can then obtain real unit vectors \\(\\mathbf{y}_{i}\\) for all \\(i\\in \\{0,\\ldots ,n\\}\\) such that \\(Y_{ij} = \\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) for all \\(i,j\\in \\{0,\\ldots ,n\\}\\) . The constraints \\(Y_{ii} = 1\\) ensure that all vectors \\(\\mathbf{y}_{i}\\) lie on an \\((n + 1)\\) - dimensional unit sphere. <center>Figure 7: Lifting the variables to a higher dimension, demonstrated on variables \\(y_{1},y_{2},y_{3}\\) . Initially, only integer values of \\(-1\\) and 1 could be assigned to them (integer program). Next, constraints are relaxed, allowing variables to take any real value between \\(-1\\) and 1. Finally, it is permitted for them to be unit vectors in a high-dimensional space (here, 3 dimensions). The hyperplane in the last picture would be used for rounding the variables at the end. This hyperplane can be randomly selected, and truth values for variables \\(y_{1},y_{2},y_{3}\\) are determined based on which side of the hyperplane they land after continuous optimization. </center> ## B.3 Interpretation and Rounding The SDP solver optimizes the numbers in the matrix \\(Y\\) , but using the factorization, we can visualize what happens with the vectors \\(\\mathbf{y}_{1}\\) . The process starts with random unit vectors that are continuously updated to maximize the objective function. If we fix the position of the vector \\(\\mathbf{y}_{0}\\) (corresponding to the value true), we would see that the vectors of variables that will be set to true in the final assignment get closer to the vector \\(\\mathbf{y}_{0}\\) , while the vectors \\(\\mathbf{y}_{j}\\) of variables that will be set to false move away from it so that the inner product \\(\\langle \\mathbf{y}_{0},\\mathbf{y}_{j}\\rangle\\) is close to \\(- 1\\) . If the formula is satisfiable, the objective function drives the vectors to form two wellseparated clusters. However, if only a few clauses can be satisfied simultaneously, the vectors would end up being scattered. A simple way to round the resulting vectors \\((\\mathbf{y}_{1},\\ldots ,\\mathbf{y}_{n})\\) and get the assignment for the original Boolean variables is to compute the inner product \\(\\langle \\mathbf{y}_{0},\\mathbf{y}_{i}\\rangle\\) and assign the value according\n\nto its sign. It is also possible to assign the values by picking a random separating hyperplane, and it can be shown that this rounding gives a 0.8785- approximation of the integer program optimum Goemans and Williamson [1995]. Note that the expressions of the clauses reach their maximum at 1 (when a clause is satisfied by the assignment). This means that the whole formula is satisfiable if the objective function achieves a value equal to the number of clauses in the formula. Another way to check satisfiability is to plug the obtained solution into the formula and verify whether it is satisfied. Therefore, we can obtain an incomplete SAT solver from this SDP formulation. Similar SDPs can be obtained for different versions of MAX- SAT (with larger clauses). From empirical observation, the convergence threshold of the SDP solver needs to be decreased significantly compared to MAX- 2- SAT in order to obtain a good approximation for these more complicated versions.\n\nof weights of satisfied clauses. In some variants (Partial MAX- SAT Fu and Malik [2006]), clauses are categorized as hard or soft, where hard clauses must be satisfied (often with infinite weight), and soft clauses are those that can be violated but contribute to the objective based on their weight. While weighted variants exist, in this paper we focus exclusively on the unweighted formulation. Formally, for a CNF formula \\(\\phi = c_{1} \\wedge c_{2} \\wedge \\dots \\wedge c_{m}\\) with \\(m\\) clauses, the unweighted Max SAT problem seeks an assignment \\(\\sigma^{*}\\) such that: \\[\\sigma^{*} = \\arg \\max_{\\sigma}\\sum_{i = 1}^{m}\\mathbf{1}(\\sigma \\mathrm{~satisfies~}c_{i}) \\quad (1)\\] where \\(\\mathbf{1}(\\cdot)\\) is the indicator function. ### 3.2 SAT Solving Approaches SAT solving algorithms are generally categorized into complete and incomplete approaches, each with distinct characteristics and applications. Complete Solvers Complete solvers theoretically guarantee definitive answers: either finding a satisfying assignment or proving that none exists. The Davis- Putnam- Logemann- Loveland (DPLL) algorithm forms the foundation for most modern complete solvers Biere et al. [2009]. It systematically explores the search space through backtracking while employing unit propagation to deduce logical consequences. Conflict- Driven Clause Learning (CDCL) extends DPLL by analyzing conflicts to learn new clauses, which helps prune large portions of the search space. When a conflict occurs, the solver identifies the \"reasons\" for the conflict and adds a new clause that prevents similar conflicts in the future. Modern CDCL solvers incorporate sophisticated heuristics for variable selection, restart strategies, and efficient data structures to improve performance. Incomplete Solvers Incomplete solvers focus on finding satisfying assignments but cannot prove unsatisfiability. These algorithms are particularly effective for large satisfiable instances where complete methods might be inefficient. Local search algorithms, such as Walk SAT Selman et al. [1993], start with a random assignment and iteratively modify it to satisfy more clauses. These methods employ heuristics to decide which variables to flip at each step, balancing between greedy choices and random moves to escape local optima. For Max SAT, local search algorithms often use scoring functions that prioritize flipping variables that maximize the increase in satisfied clauses. Stochastic algorithms including simulated annealing and genetic algorithms have also been applied to SAT and Max SAT problems. These approaches can effectively explore search spaces in certain problem classes where deterministic methods struggle. #### 3.2.1 Continuous Relaxations A specific type incomplete solvers that have been explored in recent research Kyrillidis et al. [2020], Hosny and Reda [2024] are explored continuous relaxations of Max SAT, that transform the discrete problem into a continuous optimization task. These methods map Boolean variables to continuous domains, enabling the application of gradient- based optimization techniques. The Fourier- SAT method Kyrillidis et al. [2020], for instance, transforms Boolean formulas into multilinear polynomials through Walsh- Fourier transform and then optimize the continuous variables w.r.t. the resulting polynomial. Continuous relaxations can also be obtained by making the objective function convex as often done when designing approximation algorithms which provide guarantees for their performance.\n\nThe guarantees can be improved by lifting the variables into a high- dimensional vector space and optimizing vectors instead of scalar values. The optimized vectors are finally rounded to discrete values. Semidefinite Programming (SDP) relaxation, particularly for MAX- 2- SAT or MAX- 3- SAT, illustrates this approach elegantly. In SDP relaxation, Boolean variables \\(x_{i} \\in \\{0,1\\}\\) are transformed into unit vectors \\(\\mathbf{y}_{i}\\) in a high- dimensional space. An additional vector \\(\\mathbf{y}_{0}\\) is introduced to represent the value \"true.\" The Boolean variable \\(x_{i}\\) is considered true if \\(\\mathbf{y}_{i}\\) is close to \\(\\mathbf{y}_{0}\\) (positive inner product) and false if it is far from \\(\\mathbf{y}_{0}\\) (negative inner product). The optimization process for these vectors follows a pattern: 1. Initialize random unit vectors for each variable 2. Optimize these vectors to maximize the number of satisfied clauses, expressed as a function of inner products between vectors 3. Round the resulting vectors to discrete assignments (typically based on the sign of inner products with \\(\\mathbf{y}_{0}\\) ) This relaxation enables the application of powerful continuous optimization techniques while providing approximation guarantees. For MAX- 2- SAT, this approach yields an approximation ratio of 0.878, meaning the solution will satisfy at least 87.8% of the maximum possible number of clauses. #### 3.2.2 Learning-Based Approaches Machine learning (ML) is also being heavily utilized for SAT solving. Many approaches have been developed to guide traditional solvers Selsam and Bj\u00f8rner [2019], Yolcu and P\u00f3czos [2019] or to solve SAT problems directly Selsam et al. [2018], Li and Si [2022]. To guide a solver, a neural network can be used to replace heuristics such as variable selection or restart policies. Importantly, Graph Neural Networks (GNNs) can also be trained to solve SAT problems end- to- end without relying on traditional algorithmic solvers Amizadeh et al. [2018]. These GNN- based approaches can operate directly on the graph representation of Boolean formulas, with variables and clauses forming nodes in a bipartite graph, and learn to predict satisfiability or produce satisfying assignments Li et al. [2023]. In this work, we focus on variants of GNNs that are recurrent and this allows us to scale the computation during inference or adapt the number of iterations for each instance separately. In Section 6 we will show an evidence that one can view the end- to- end ML approaches as bi- level optimization methods because during inference, the GNN behaves as a continuous solver trying to maximize the number of satisfied clauses. Therefore, during training, the outer loop of the bi- level optimization optimizes the weights of the network which then runs an inner loop that optimizes the values of variables to maximize the number of satisfiable clauses. ### 3.3 Graph Neural Networks Graph Neural Networks (GNNs) extend deep learning to graph- structured data, enabling learning on irregular data structures that classical neural architectures cannot directly process. A graph \\(G = (V,E)\\) consists of nodes \\(V\\) and edges \\(E\\) , where each node \\(v\\in V\\) may have associated features \\(x_{v}\\) . GNNs compute node representations through message passing, where each node iteratively aggregates information from its neighbors and updates its features. Formally, at layer \\(l\\) , a node \\(v\\) updates its representation \\(h_{v}^{l}\\) , according to: \\[h_{v}^{l + 1} = \\mathrm{UPDATE}(h_{v}^{l},\\mathrm{AGGREGATE}(\\{h_{u}^{l}:u\\in \\mathcal{N}(v)\\}))\\]\n\n<center>Figure 1: LCG and VCG of the CNF formula \\((\\overline{x}_{1} \\vee x_{2}) \\wedge (x_{2} \\vee \\overline{x}_{3}) \\wedge (x_{1} \\vee x_{3})\\) . </center> where \\(\\mathcal{N}(v)\\) denotes the neighbors of node \\(v\\) . The UPDATE and AGGREGATE functions are typically neural networks, often implementing permutation- invariant operations like sum or max. Through multiple layers of message passing, GNNs can capture both local structure and longer- range dependencies in the graph, making them suitable for processing SAT formulas represented as bipartite graphs. ### 3.4 Diffusion-based Assignment Generation In Section 5.4 will show how the GNNs we use can be extended to diffusion models which have in recent years emerged as a powerful approach for generative modeling across domains Ho et al. [2020]. These models learn to transform a random noise distributions (such as multi- variate Gaussian distribution) to complex distributions behind the given domain (i.e., distribution of images of human faces). For practical applications, diffusion models are typically conditioned on an input so that the generated sample has specific characteristics. In our case, we will condition the model by the bipartite graph of the CNF formula. #### 3.4.1 Categorical Diffusion Process While continuous diffusion models have gained prominence in image generation and other domains, discrete diffusion processes well- suited for combinatorial optimization problems like MAX- SAT, where the state space is inherently discrete. Our approach presented in Section 5.4 leverages a discrete diffusion process with categorical noise to model the generation of variable assignments. We adapt a concrete form of discrete diffusion first presented by Austin et al. Austin et al. [2021] and later leveraged for combinatorial optimization with GNNs by Sun et al. Sun and Yang [2023]. On a high level, diffusion models are trained to denoise noisy version of the training samples. These noisy versions are obtained by running a forward diffusion process for several steps and the model is then trained to predict the original sample. For a SAT problem with \\(n\\) variables, we represent each variable assignment as a binary value and the vector of these binary values represent the sample. The diffusion process gradually corrupts this sample until it becomes pure noise. More concretely, the process that progressively adds noise to the initial assignment \\(\\mathbf{x}_{0} \\in \\{0, 1\\}^{n}\\) over \\(T\\) timesteps, produces a sequence of increasingly more corrupted assignments \\(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots , \\mathbf{x}_{T}\\) . For categorical diffusion, this corruption process is defined by a Markov chain with the following transition matrices: \\[\\mathbf{Q}_{t} = \\left( \\begin{array}{cc}1 - \\beta_{t} & \\beta_{t} \\\\ \\beta_{t} & 1 - \\beta_{t} \\end{array} \\right) \\quad (2)\\] where \\(\\beta_{t} \\in (0, 1)\\) represents the noise schedule, controlling how quickly the assignments become corrupted. The matrix \\(\\mathbf{Q}_{t}\\) defines the probability of transitioning between states at time \\(t\\) , with the property that as \\(t\\) approaches \\(T\\) , the distribution of \\(\\mathbf{x}_{t}\\) approaches a uniform distribution over all possible assignments.\n\nTo simplify inference, the cumulative transition matrices \\(\\overline{\\mathbf{Q}}_{t} = \\mathbf{Q}_{1}\\mathbf{Q}_{2}\\cdot \\cdot \\cdot \\mathbf{Q}_{t}\\) , which directly gives us \\(p(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\) are being used. For the Boolean case, this allows us to efficiently sample \\(\\mathbf{x}_{t}\\) given \\(\\mathbf{x}_{0}\\) using: \\[p(\\mathbf{x}_{t}|\\mathbf{x}_{0}) = \\mathrm{Cat}(\\mathbf{x}_{t};\\mathbf{p} = \\tilde{\\mathbf{x}}_{0}\\overline{\\mathbf{Q}}_{t}) \\quad (3)\\] where \\(\\tilde{\\mathbf{x}}_{0} \\in \\{0,1\\}^{n \\times 2}\\) is the one- hot encoding of \\(\\mathbf{x}_{0}\\) , with each variable represented by a vector \\((1,0)\\) for value 0 or \\((0,1)\\) for value 1. The Cat operation refers to the categorical distribution, which samples \\(\\mathbf{x}_{t}\\) based on the probability vector \\(\\mathbf{p}\\) . #### 3.4.2 Learning the Reverse Process The core idea of diffusion models is to learn the reverse process - how to gradually denoise a corrupted sample to recover the original data distribution. In our case, we train a GNN to progressively recover a satisfiable assignment \\(\\mathbf{x}_{0}\\) starting from a random initial assignment. The trained model is used to sample from a distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) which can be used to obtain a an assignment \\(\\mathbf{x}_{0}\\) from random assignment \\(\\mathbf{x}_{T}\\) as explained bellow. There are multiple ways of training the neural network used in the diffusion model. One can train it to directly model the distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) . In the method introduced by Austin et al. Austin et al. [2021], the network is trained to predict the original uncorrupted input \\(\\mathbf{x}_{0}\\) which is then used to sample from the the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) using Bayes' rule. This approach provides stronger learning signals during training, as the target \\(\\mathbf{x}_{0}\\) remains fixed regardless of a timestep and we use it within this work. #### 3.4.3 Categorical Posterior Sampling As mentioned above, our model is trained to predict \\(\\mathbf{x}_{0}\\) directly and we use this prediction during inference to sample \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) . This is accomplished through categorical posterior sampling, which uses the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) to compute the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})\\) . By applying Bayes' rule and the Markov property of the diffusion process, we can derive: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (4)\\] For the categorical case, this is computed using: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}\\frac{p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{0})p(\\mathbf{x}_{t}|\\mathbf{x}_{t - 1})}{p(\\mathbf{x}_{t}|\\mathbf{x}_{0})} p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (5)\\] The diffusion model replaces the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) with a function approximator (GNN in our case) \\(f_{\\theta}(\\mathbf{x}_{t},t)\\) Therefore, we can train the model using a simple procedure (predicting \\(\\mathbf{x}_{0}\\) ) and during inference, we can use a sampling process (iteratively sampling \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) ), which tries to recover a uncorrupted input in several steps. A useful feature of diffusion models is that the number of sampling steps during inference can be chosen by the user after the model is already trained. #### 3.4.4 Inference Schedule During inference, we can accelerate the generation process by using fewer denoising steps than were used during training or use more denoising steps with the hope to increase the quality of outputs. The tuple of time steps used for inference \\((T,T - 1,\\ldots ,t_{0})\\) is called a schedule. The function approximator in the diffusion model is normally conditioned by the sample at a given time step and also the time step itself \\((f_{\\theta}(\\mathbf{x}_{t},t))\\) but as we show in Section 5.4.1, the time step conditioning is not needed. This means that in our case the schedule is defined only by the number of time steps used.\n\n## 4 Experimental Setup ### 4.1 Data Representation and Graph Structure Boolean formulas in CNF form can be naturally represented as bipartite graphs where clauses and variables (or literals) form two distinct sets of nodes. In this work, we explore two different graph representations: Literal- Clause Graph (LCG) In the literal- clause graph representation, each literal (both positive and negative polarity of a variable) is represented as a separate node. For a formula with \\(n\\) variables, this results in \\(2n\\) literal nodes. Each literal node is connected to all clause nodes containing that literal. Formally, for a CNF formula \\(\\phi\\) with variables \\(x_{1},\\ldots ,x_{n}\\) and clauses \\(c_{1},\\ldots ,c_{m}\\) , we construct a bipartite graph \\(G_{LC} = (L\\cup C,E)\\) where: - \\(L = \\{l_{1},\\ldots ,l_{n},\\bar{l}_{1},\\ldots ,\\bar{l}_{n}\\}\\) is the set of literal nodes - \\(C = \\{c_{1},\\ldots ,c_{m}\\}\\) is the set of clause nodes - \\((l_{i},c_{j})\\in E\\) if and only if literal \\(l_{i}\\) appears in clause \\(c_{j}\\) Variable- Clause Graph (VCG) In the variable- clause graph representation, each variable (rather than each literal) is represented as a node. For a formula with \\(n\\) variables, this results in exactly \\(n\\) variable nodes. Each variable node is connected to all clause nodes containing either the positive or negative literal of that variable. To retain information about the polarity of literals, we assign edge features \\(p_{ij}\\in \\{- 1,1\\}\\) to each edge \\((x_{i},c_{j})\\) , where \\(p_{ij} = 1\\) if the positive literal \\(x_{i}\\) appears in clause \\(c_{j}\\) , and \\(p_{ij} = - 1\\) if the negative literal \\(\\overline{{x}}_{i}\\) appears in clause \\(c_{j}\\) . Formally, we construct a bipartite graph \\(G_{VC} = (V\\cup C,E,P)\\) where: - \\(V = \\{x_{1},\\ldots ,x_{n}\\}\\) is the set of variable nodes- \\(C = \\{c_{1},\\ldots ,c_{m}\\}\\) is the set of clause nodes- \\((x_{i},c_{j})\\in E\\) if and only if variable \\(x_{i}\\) appears in clause \\(c_{j}\\) (in either polarity)- \\(P:E\\to \\{-1,1\\}\\) maps each edge to its corresponding polarity Both graph representations capture the structure of the Boolean formula, but they differ in how they handle variable polarity. The literal- clause graph explicitly represents both polarities as separate nodes, which increases the number of nodes but simplifies the message passing process of the GNN. The variable- clause graph is more compact but requires handling polarity information through edge features. For the GNNs we use, the variable- clause graph representation is more computationally efficient than the literal- clause graph, reducing both memory requirements and processing time. This efficiency comes from having half as many variable nodes (compared to literal nodes) and avoiding an expensive operation during message passing as will be described in Section 4.2. In our experiments, we compare both representations together with different message passing operations and different training regimes. ### 4.2 Architecture Variants Our GNN architecture variants are derived from the Neuro SAT architecture Selsam et al. [2018] which demonstrated the possibility of using GNNs for SAT solving. The main advantage of this architecture is that it is recurrent and therefore the number of message passing iterations is theoretically not limited. This is not the case for the non- recurrent alternatives with fixed number of layers. We will demonstrate the usefulness of this feature in Section (5.3).\n\nNode Embeddings Each node in the bi- partite graph of the formula is associated with a \\(d\\) - dimensional embedding vector ( \\(d = 64\\) in most of our experiments as a conclusion from an experiment in A.1.4). We initialize these embeddings randomly from a standard normal distribution. For a formula with \\(n\\) variables and \\(m\\) clauses, we have: In the literal-clause graph: \\(2n\\) literal embeddings \\(\\mathbf{l}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) In the variable- clause graph: \\(n\\) variable embeddings \\(\\mathbf{v}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) Message Passing Mechanism The core of our architecture is a two- phase message passing procedure that alternates between updating clause representations and unknown node representations (literals or variables, depending on the graph type). This process is repeated for a configurable number of iterations \\(T\\) . We primarily use an RNN- based update mechanism, where the node embeddings are the hidden states of the RNN that evolve through message passing iterations. For the variable- clause graph, the message passing at iteration \\(t\\) is defined as: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{v\\in \\mathcal{N}(c)}\\mathbf{M}_{v c}(\\mathbf{h}_{v}^{(t - 1)},p_{v c}),\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{v}^{(t)} = \\mathrm{RNN}_{v}\\left(\\sum_{c\\in \\mathcal{N}(v)}\\mathbf{M}_{c v}(\\mathbf{h}_{c}^{(t)},p_{v c}),\\mathbf{h}_{v}^{(t - 1)}\\right)} \\end{array} \\quad (6)\\] Here, \\(\\mathbf{h}_{c}^{(t)}\\) and \\(\\mathbf{h}_{v}^{(t)}\\) are the hidden states that serve as the actual clause and variable node embeddings for clause nodes and variable nodes respectively. \\(\\mathbf{M}_{v c}\\) and \\(\\mathbf{M}_{c v}\\) are the message transformation functions that operate on the source node embedding and the edge polarity. For the variable- clause graph, we implement these transformation functions as two MLPs that process positive and negative edges differently: \\[\\mathbf{M}_{v c}(\\mathbf{h}_{v},p) = \\left\\{ \\begin{array}{ll}\\mathrm{MLP}_{\\mathrm{pos}}(\\mathbf{h}_{v}) & \\mathrm{if} p > 0\\\\ \\mathrm{MLP}_{\\mathrm{neg}}(\\mathbf{h}_{v}) & \\mathrm{if} p< 0 \\end{array} \\right. \\quad (8)\\] For the literal- clause graph, the message passing mechanism also uses operation, called \"Flip\" bellow, that enforces the logical relationship between complementary literals: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{l\\in \\mathcal{N}(c)}\\mathbf{h}_{l}^{(t - 1)},\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{l}^{(t)} = \\mathrm{RNN}_{l}\\left(\\left[\\sum_{c\\in \\mathcal{N}(l)}\\mathbf{h}_{c}^{(t)},\\mathrm{Flip}(\\mathbf{h}_{l}^{(t - 1)})\\right],\\mathbf{h}_{l}^{(t - 1)}\\right)} \\end{array} \\quad (10)\\] where \\([\\cdot ,\\cdot ]\\) denotes vector concatenation. The \\(\\mathrm{Flip}(\\cdot)\\) operation exchanges the embeddings of positive literals with their corresponding negative literals and vice versa. The update function for a given literal embedding can therefore take into account the embedding of the complementary literal. We note, that the \\(\\mathrm{Flip}(\\cdot)\\) operation incurs a significant computational cost, particularly for large formulas. In contrast, the variable- clause graph representation eliminates this expensive operation by dedicating only one node for each variable and directly encoding its polarity in edge features. This efficiency makes the variable- clause approach particularly well- suited for larger formulas where computational demands become a critical factor.",
      "level": 1,
      "line_start": 1,
      "line_end": 67
    },
    {
      "heading": "Introduction",
      "content": "Apart from the RNN- based update functions, we also experiment with LSTM- based update functions which have been used in the original Neuro SAT architecture Selsam et al. [2018]. The LSTM- based updates follow a similar pattern but maintain an additional cell state alongside the hidden state. In Section 5.2 we show that different update functions are suitable for different settings. After each update step, we apply L2 normalization to all node embeddings to stabilize training: \\[\\mathbf{h}_{i}^{(t)} = \\frac{\\mathbf{h}_{i}^{(t)}}{\\|\\mathbf{h}_{i}^{(t)}\\|_{2}} \\quad (11)\\] Node classification After \\(T\\) iterations of message passing, we use the final node embeddings to predict variable assignments. For the variable- clause graph, we apply a linear layer to each variable embedding to produce two logits (representing scores for value true and false): \\(\\mathbf{y}_{v} = \\mathbf{W}\\mathbf{h}_{v}^{(T)} + \\mathbf{b}\\) . The assignment is then determined by applying softmax and taking the argmax: \\(\\hat{a}_{v} = \\arg \\max_{i}(\\mathrm{softmax}(\\mathbf{y}_{v})_{i})\\) . For the literal- clause graph, we focus on the embeddings of positive literals only, as they directly correspond to variables. During training, we use cross- entropy loss between these predicted assignments and the ground truth assignments. For satisfiability prediction, we can determine whether a formula is satisfiable by checking if the predicted assignment satisfies all clauses. The model is thus trained to find assignments that minimize the number of unsatisfied clauses, effectively solving the Max SAT problem even when trained only with assignment supervision. ### 4.3 Supervision Tasks and Objectives There are several obvious supervision objectives and prediction tasks which can be used to train the model. The original Neuro SAT model was trained to predict the satisfiability status of a given formula using binary cross- entropy. Later, several authors tried different training tasks and objectives which have been summarized in a review paper by Li et al. Li et al. [2023]. We reimplement these objective and task for our setup and also introduce a novel training objective which in certain settings results in significant improvements of the model performance. These objective are briefly described below. Satisfiability Classification This is the task which was used by Selsam et al. [2018] for training the original Neuro SAT architecture. The model is trained to predict whether the formula is satisfiable or not through graph- level embedding aggregation using global mean pooling. The loss is computed by binary cross- entropy between the prediction \\(\\hat{y}\\) and ground truth \\(y\\in \\{0,1\\}\\) .. \\(\\mathcal{L}_{\\mathrm{sat}} = -(y\\log \\hat{y} +(1 - y)\\log (1 - \\hat{y}))\\) Unsupervised Training For unsupervised training, we define the loss using clause validity Ozolins et al. [2022], where \\(\\hat{x}_{i}\\) represents the model's predicted continuous probability of a variable being true: \\[V_{c}(\\hat{x}) = 1 - \\prod_{i\\in c^{+}}(1 - \\hat{x}_{i})\\prod_{i\\in c^{-}}\\hat{x}_{i},\\quad \\mathcal{L}_{\\phi}(\\hat{x}) = -\\sum_{c\\in \\phi}\\log (V_{c}(\\hat{x})), \\quad (12)\\] where \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in clause \\(c\\) in positive and negative form respectively. This loss reaches its minimum only when the prediction \\(\\hat{x}\\) is a satisfying assignment. We note that alternative unsupervised formulations exist Amizadeh et al. [2018], and comprehensive evaluations reported by Li et al. Li et al. [2023] suggest that these two different\n\napproaches perform similarly in practice. Another training option would be to directly optimize a convex loss function derived from SDP relaxation, but this approach is limited because SDP formulations work well for MAX- 2- SAT and can be extended to MAX- 3- SAT, but become increasingly difficult to formulate for general Max SAT problems with larger clauses. Assignment Prediction For satisfiable formulas, we can train the model to predict the satisfiable variable assignments directly. We tried to use either mean squared error or cross- entropy loss between the predicted assignments and the ground truth assignments: \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{MSE}} =\\) \\(\\| \\hat{a} - x\\|_{2}^{2}\\) and \\(\\mathcal{L}_{\\mathrm{assign}}^{\\mathrm{CE}} = - \\sum_{i}x_{i}\\log \\hat{x}_{i} + (1 - x_{i})\\log (1 - \\hat{x}_{i})\\) where \\(x\\) is the ground truth assignment and \\(\\hat{a},\\hat{x}\\) are the predicted assignments which differ by application of softmax (i.e. \\(\\hat{a}\\) are just logits without a softmax applied). Closest Assignment Training One problem with assignment prediction is that satisfiable formulas can have a lot of solution and the network is penalized even if it predicts satisfiable solution which differs from the one which is used as a ground truth. We therefore introduce a novel supervision method which uses a Max SAT solver to always compute the solution which is closest to the solution predicted by the model. We then update then model with respect to this solution. In Section 5.2, we show that this method works particularly well when the solution space is large. For each formula in a batch, a valid assignments that minimize the Hamming distance to the model's current predictions is found by the RC2 Max SAT solver. For satisfiable formulas it finds an assignment that satisfies all clauses while being closest to current prediction. For unsatisfiable formulas, it finds an assignment that maximizes the number of satisfied clauses while minimizing distance to prediction. This approach allows the model to explore different regions of the solution space while maintaining valid solutions for SAT instances or optimal partial solutions for UNSAT instances. The supervision signal adapts to the model's current state rather than forcing it toward a single pre- determined assignment. The disadvantage of this method is that the computation of the loss is slower then with the precomputed solution. This could be solved by pre- computing solutions or by using an approximate Max SAT solver. SAT- Only Instance Filtering After initially training with both satisfiable and unsatisfiable instances, we experimented with formula- type specialization by restricting training to only satisfiable instances. In Table 3, we show that this filtering can lead to higher accuracy of the trained model. ### 4.4 Benchmarks and Data Generation We utilize two complementary benchmark generators for evaluating the tested variants: the SR generator and a 3- SAT generator with the ratio between variable and clauses set close to the phase transition point. SR Generator The SR generator by Selsam et al. [Selsam et al., 2018] produces pairs of satisfiable and unsatisfiable formulas that differ by negating only a single literal. This design specifically prevents models from exploiting superficial features for classification. Intuitively, it works by iteratively sampling random clauses and adding them to a formula. After each addition, a SAT solver checks if the formula remains satisfiable. When adding a clause that finally makes the formula unsatisfiable, the generator saves this instance and creates its satisfiable counterpart by flipping a single literal in the last clause. To create each clause, it samples a small integer \\(k\\) based on a mix of Bernoulli and geometric distributions, then randomly selects \\(k\\) variables without replacement, negating each with 0.5 probability. This solver- driven approach ensures\n\nthat satisfiability classification requires understanding the logical structure rather than statistical properties. As reported in the review by Li et al. Li et al. [2023], the models trained on problems from this generator transfer the best to other problem distributions. 3- SAT Generator We also employ a 3- SAT generator configured at the critical clause- to- variable ratio of 4.26, known as the phase transition point where SAT problems are empirically the most challenging to solve [Crawford and Auton, 1996]. At this ratio, approximately half of the generated instances are satisfiable. Each clause contains exactly 3 literals selected uniformly from the available variables, with each literal negated with 0.5 probability. Unlike the SR generator, 3- SAT focuses on generating naturally difficult problems rather than explicitly preventing superficial feature learning. ## 5 Experimental Results ### 5.1 Training and Evaluation Methodology For training, we generate 50,000 instances: 25,000 pairs for SR and 50,000 instances for 3- SAT. We annotate each dataset by the maximum number of variables appearing in the training formulas. For SR, we test two variations, SR40 for which the training examples are sampled with 3- 40 variables and SR100 for which the training examples contain 10- 100 variables. For 3- SAT, the training samples contain 10- 100 variables (3SAT100). The SR dataset is well suited for training SAT/UNSAT prediction models due to its design that prevents learning from superficial features, making it harder for models to exploit statistical shortcuts rather than learning true logical reasoning. We also create versions of training data which contain only satisfiable instances (denoted SAT only). The size of these datasets is half of the original datasets (i.e. 25000 examples). To evaluate generalization, we validate exclusively on problems with exactly the maximum number of variables in each category, therefore SR40 for evaluation means that the problems have always exactly 40 variables (not a range of 3- 40), SR100 test contains only problems with exactly 100 variables, and so on.1 Table 1 summarizes the key statistics of our evaluation datasets. Table 1: Statistics of benchmark test sets. SAT% indicates the percentage of satisfiable instances in each dataset. Avg. Gap represents the average number of unsatisfied clauses when using random variable assignments. SAT Gap and UNSAT Gap show this metric separated by instance satisfiability. SR datasets are generated using the SR generator with the indicated number of variables (e.g., SR40 contains instances with 40 variables), while 3SAT datasets contain instances near the phase transition point with the specified number of variables. All datasets maintain a balanced distribution of satisfiable and unsatisfiable instances. <table><tr><td>Dataset</td><td>SAT%</td><td>Avg. Gap</td><td>SAT Gap</td><td>UNSAT Gap</td><td>Avg. Clauses</td></tr><tr><td>SR40</td><td>50.0%</td><td>21.29</td><td>21.59</td><td>20.99</td><td>228.40</td></tr><tr><td>SR100</td><td>50.0%</td><td>51.31</td><td>50.64</td><td>51.98</td><td>547.49</td></tr><tr><td>SR200</td><td>50.0%</td><td>100.31</td><td>101.03</td><td>99.59</td><td>1083.81</td></tr><tr><td>SR400</td><td>50.0%</td><td>198.74</td><td>198.53</td><td>198.95</td><td>2152.32</td></tr><tr><td>3SAT100</td><td>53.5%</td><td>52.78</td><td>53.00</td><td>52.54</td><td>426.00</td></tr><tr><td>3SAT200</td><td>55.5%</td><td>107.65</td><td>107.45</td><td>107.90</td><td>852.00</td></tr></table> The Gap metric represents the average number of unsatisfied clauses when using random\n\nvariable assignments. This metric has the same definition for both SAT and UNSAT instances; it simply counts how many clauses remain unsatisfied with random assignments on average. Larger gaps indicate more challenging problems where random guessing performs poorly. ### 5.2 Quantitative Evaluation We conducted a comprehensive evaluation that compares different architectural choices and supervision methods. Our evaluation focuses on five key performance metrics: - Average Gap: The average number of unsatisfied clauses across all test instances. Lower values indicate better performance, with 0 representing perfect satisfaction (i.e., no unsatisfied clauses) on satisfiable instances. For unsatisfiable instances, this metric reflects how close the model gets to minimizing unsatisfied clauses.- Gap on SAT: The average number of unsatisfied clauses computed only over satisfiable instances.- Gap on UNSAT: The average number of unsatisfied clauses computed only over unsatisfiable instances.- SAT Accuracy: The percentage of satisfiable instances for which the model correctly finds a satisfying assignment, computed only over satisfiable instances.- Decision Accuracy: The percentage of instances for which the model correctly predicts whether the formula is satisfiable. Since our approach does not formally refute unsatisfiable instances, we classify an instance as unsatisfiable when the model fails to find a satisfying assignment. This means unsatisfiable instances are always classified correctly under this assumption. This applies specifically in the case of assignment-based evaluation. #### 5.2.1 Comparison of Graph Representations, Update Functions and Training Methods Table 2 presents a comprehensive comparison of different architectural configurations trained exclusively on the SR40 dataset. This comparison includes different graph representations (Literal Clause Graph vs. Variable- Clause Graph), update functions (RNN vs. LSTM), and supervision approaches (SAT/UNSAT classification, assignment supervision, and unsupervised objective training), all evaluated on instances with 40 variables. All models were evaluated using Exponential Moving Average (EMA) of parameters during validation only, as detailed in A.1.2, which helps reduce fluctuations in validation metrics and provide more reliable model selection. Importantly, curriculum learning ( A.1.1) was employed only for training models with SAT/UNSAT classification objectives, as it proved unnecessary for models trained with assignment prediction or unsupervised learning approaches. Graph Representation Impact: Our results demonstrate that Literal- Clause Graph (LCG) and Variable- Clause Graph (VCG) representations exhibit different strengths. VCG shows better performance for assignment- based training with RNN updates, achieving a SAT accuracy of 68.8% compared to 48.6% for LCG. Additionally, VCG's more compact representation (using one node per variable rather than two for positive and negative literals) provides computational advantages for larger formulas, making it our preferred choice for scaling to more complex problems.\n\nMessage Passing Mechanism: While LSTM- based message passing shows advantages in some configurations, particularly for unsupervised training, we found that RNN- based approaches offer a better balance of performance and interpretability for assignment- based training. RNN updates with VCG representation achieved higher results for finding satisfying assignments, with \\(68.8\\%\\) SAT accuracy and \\(84.4\\%\\) decision accuracy. The simpler RNN structure also facilitates better analysis of the model's internal reasoning process. However, we found training RNN- based models for SAT/UNSAT classification particularly challenging, with LSTM being more stable for this specific task. Supervision Approach: Our experiments reveal distinct advantages for different supervision approaches: 1. Assignment-based supervision shows better performance for finding satisfying assignments, especially with VCG+RNN configuration (68.8% SAT accuracy, 84.4% decision accuracy). 2. Unsupervised learning achieves the lowest average gaps across configurations (as low as 0.91 for VCG+RNN and 0.84 for VCG+LSTM). This makes unsupervised training useful for applications where minimizing unsatisfied clauses is the priority. 3. SAT/UNSAT classification training, while challenging with RNN, enables an interesting property: models trained only for classification develop an implicit ability to separate embeddings for positive and negative literals. This separation allows for retrieving satisfying assignments through clustering techniques, despite the model not being explicitly trained for assignment prediction. Based on the results reported in Table 2, we identify the VCG+RNN+Assignment configuration as our most effective approach, offering a good balance between assignment accuracy and computational efficiency. This configuration forms the foundation for our further experiments and analysis in subsequent sections. Assignment Training Refinements: Table 3 highlights the impact of a novel training method we introduce, here called \"closest assignment\", with the VCG+RNN configuration across multiple datasets. This method computes assignments that minimize Hamming distance to the model's current predictions, showing improvements over training with precalculated assignments, especially for formulas with more variables. For SR100, using the closest assignment approach reduces the average gap from 3.81 to 1.43 for SAT+UNSAT training and improves SAT accuracy from 44.8% to 53.2%. This improvement correlates with the number of possible solutions in the benchmarks (SR10- 100 has a median of 16 solutions per formula compared to SR3- 40's median of 7), supporting our hypothesis that for formulas with larger solution spaces, guiding the model with dynamically selected assignments that align with its current predictions yields better generalization than using fixed predetermined assignments. The computational challenges of calculating closest assignments during training are noteworthy, particularly for larger benchmarks like 3SAT+UNSAT, where this approach became impractical and we therefore omit this experiment and leave the last row of Table 3 empty. It also highlights an opportunity for future work on more efficient approximation methods for finding near- optimal assignments. Training Data Composition: Our results also indicate that training exclusively on SAT instances (SAT only) improves performance for finding satisfying assignments. For SR40, this approach with closest assignment training achieves our highest SAT accuracy of 76% and decision accuracy of 88%. However, models trained on both SAT and UNSAT instances (SAT+UNSAT)\n\nwith closest assignment supervision demonstrate better gap minimization, achieving an average gap of 0.98 versus 2.68 for SAT- only training on SR40. Table 2: Performance comparison of GNN architectures for SAT solving on the SR40 dataset.The table compares Literal-Clause Graph (LCG) and Variable-Clause Graph (VCG) repre-sentations, RNN and LSTM update mechanisms, and different training objectives. Metrics include average gap (number of unsatisfied clauses) across all instances and separated by sat-isfiability status (lower is better), SAT accuracy (percentage of satisfiable instances solved by finding assignment), and decision accuracy (percentage of correct satisfiability predictions). No-table findings include: unsupervised training consistently achieves lowest gaps; VCG+RNN with assignment prediction shows highest SAT accuracy (68.8%); and RNN-based models with SAT/UNSAT classification proved challenging to train effectively (indicated by dashes). As-terisks (*) indicate results obtained through clustering of node embeddings rather than direct prediction. This model combination was particularly hard to train in our setup. We found that both for VCG and LCG RNN is very sensitive to hyper-parameter selection. As the model failed to get generalized in our final unified experimental setup we do not include this result (close to random performance) now. <table><tr><td>Graph</td><td>Update</td><td>Loss Function</td><td>Avg. Gap\u2193</td><td>Gap on SAT\u2193</td><td>Gap on UNSAT\u2193</td><td>SAT Acc.\u2191</td><td>Dec. Acc.\u2191</td></tr><tr><td rowspan=\"6\">LCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Assignment</td><td>1.83</td><td>1.25</td><td>2.41</td><td>48.6%</td><td>72.8%</td></tr><tr><td>Unsup</td><td>0.93</td><td>0.59</td><td>1.26</td><td>51.4%</td><td>75.7%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>1.96*</td><td>1.27*</td><td>2.62*</td><td>59.2%</td><td>83.9/79.6%</td></tr><tr><td>Assignment</td><td>1.82</td><td>1.06</td><td>2.58</td><td>56.8%</td><td>78.4%</td></tr><tr><td>Unsup</td><td>0.81</td><td>0.45</td><td>1.16</td><td>62%</td><td>81%</td></tr><tr><td rowspan=\"6\">VCG</td><td rowspan=\"3\">RNN</td><td>SAT/UNSAT</td><td>3.62*</td><td>1.9*</td><td>5.34*</td><td>56.6%</td><td>80/78.3%</td></tr><tr><td>Assignment</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8%</td><td>84.4%</td></tr><tr><td>Unsup</td><td>0.91</td><td>0.58</td><td>1.23</td><td>51.6%</td><td>75.8%</td></tr><tr><td rowspan=\"3\">LSTM</td><td>SAT/UNSAT</td><td>2.33*</td><td>1.57</td><td>3.08</td><td>52.2%</td><td>81.9/76.1%</td></tr><tr><td>Assignment</td><td>2.05</td><td>0.96</td><td>3.14</td><td>66.4%</td><td>83.2%</td></tr><tr><td>Unsup</td><td>0.84</td><td>0.51</td><td>1.17</td><td>56.4%</td><td>78.2%</td></tr></table> # 5.3 Test-time Scaling A key property of our recurrent GNN architecture for SAT solving is the ability to adjust computational effort at inference time. Unlike standard GNNs with fixed number of layers,the weight-shared recurrent design enables flexible scaling through additional iterations and resampling. ## 5.3.1 Iteration and Resampling Effects Figure 2 demonstrates how increasing message-passing iterations improves the percentage of solved SAT instances. Similarly, Figure 3 shows how the average gap decreases across iterations for various benchmarks. The heat maps in Figure 4 provide a comprehensive view of how performance metrics improve with both increased iterations and resampling attempts. For the model trained on SR40, several observations are notable: \u00b7Iteration benefits: Increasing iterations from 25 to 125 consistently improves all metrics across benchmarks. \u00b7Resampling effects: Multiple inference attempts with different random initializations of node feature vectors further enhance performance. For SR40, decision accuracy improves from 84% with one sample to 93% with five samples at 125 iterations.\n\nTable 3: Performance analysis of VCG+RNN with assignment prediction across different datasets and training methodologies. Our novel \"Closest\" supervision method (which dynamically selects assignments closest to current model predictions) consistently outperforms training with precalculated assignments. For SR40, SAT-only training with closest assignment supervision achieves the highest SAT accuracy (76%), while SAT+UNSAT training with closest assignment supervision yields the lowest average gap (0.98). The missing data for 3SAT100 with SAT+UNSAT closest supervision is due to prohibitive computational costs. Bold values indicate best results per dataset. <table><tr><td>Dataset</td><td>Training Mode</td><td>Assignment Type</td><td>Avg. Gap \u2193</td><td>Gap on SAT \u2193</td><td>Gap on UNSAT \u2193</td><td>SAT Acc. \u2191</td><td>Dec. Acc. \u2191</td></tr><tr><td rowspan=\"4\">SR40</td><td>SAT only</td><td>Precalculated</td><td>2.93</td><td>1.11</td><td>4.75</td><td>68.2 %</td><td>84.1 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>2.68</td><td>0.88</td><td>4.48</td><td>76 %</td><td>88 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>1.95</td><td>0.8</td><td>3.05</td><td>68.8 %</td><td>84.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>0.98</td><td>0.48</td><td>1.49</td><td>71.2 %</td><td>85.6 %</td></tr><tr><td rowspan=\"4\">SR100</td><td>SAT only</td><td>Precalculated</td><td>4.42</td><td>2.36</td><td>6.48</td><td>47.4 %</td><td>73.7 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>3.57</td><td>1.67</td><td>5.48</td><td>59.6 %</td><td>79.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>3.81</td><td>2.34</td><td>5.28</td><td>44.8 %</td><td>72.4 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>1.43</td><td>0.92</td><td>1.94</td><td>53.2 %</td><td>76.6 %</td></tr><tr><td rowspan=\"4\">3SAT100</td><td>SAT only</td><td>Precalculated</td><td>5.93</td><td>3.40</td><td>9.27</td><td>25.7 %</td><td>57.2 %</td></tr><tr><td>SAT only</td><td>Closest</td><td>5.23</td><td>2.33</td><td>9.11</td><td>48.4 %</td><td>70 %</td></tr><tr><td>SAT+UNSAT</td><td>Precalculated</td><td>4.22</td><td>2.84</td><td>6.00</td><td>23.9 %</td><td>55.8 %</td></tr><tr><td>SAT+UNSAT</td><td>Closest</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td><td>\u2014</td></tr></table> - Cross-distribution applicability: The model trained on SR40 maintains reasonable effectiveness on SR100 and 3SAT100, though with expected performance decrease. This aligns with findings from Li et al. Li et al. [2023], who demonstrated that models trained on SR distributions generally transfer well to other SAT problem structures. #### 5.3.2 Train-time vs Test-time Scaling Tables 4 and 5 present the performance of models trained on SR40 and SR100 distributions when evaluated across benchmarks of varying sizes. The SR40- trained model achieves reasonable generalization to larger instances, though with decreasing effectiveness as problem size increases. For SR100, the model achieves 74.2% decision accuracy despite being trained on smaller instances, showing good generalization capabilities. The SR100- trained model demonstrates better performance on larger instances compared to the SR40- trained model, as expected. On SR200, it achieves 83.0% decision accuracy compared to 58.5% for the SR40 model. This suggests that while test- time scaling can improve performance on larger problems, there are limits to this approach, and training models on larger instances might be necessary for optimal performance on very large problems. These results highlight that recurrent GNN architectures allow for a flexible computation- performance tradeoff that can be adjusted at inference time based on available computational resources and desired solution quality. ### 5.4 Diffusion Model Extension As we mentioned in Section 3.4.4, one can use the GNN as a function approximator \\(f_{\\theta}(\\cdot)\\) inside a diffusion model. This enables another way of scaling the test- time compute. We adapt the diffusion model used by Sun et al. Sun and Yang [2023] where the function approximator is trained to predict the ground truth solution \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t},t)\\) conditioned on a sample \\(\\mathbf{x_t}\\) at time \\(t\\) . The predicted assignment is then used to obtain a sample at time \\(t - 1\\) and this process is repeated again \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_{t - 1}},t - 1)\\) until we reach \\(t = 0\\) . One application of the function approximator together with the sampling is called a diffusion step. The number of diffusion steps \\(T\\) used for inference is a parameter which can be adapted after the model was already\n\nTable 4: Performance of a model trained on SR40 (VCG+RNN with closest assignment supervision) when tested across various benchmarks with a maximum of 100 message-passing iterations and early stopping. The model maintains reasonable performance on SR100 ( \\(74.2\\%\\) decision accuracy) but degrades on larger instances. \"UNSAT Instances (gap \\(= =1\\) )\" shows the percentage of UNSAT instances where the model achieved a gap of 1, which is always optimal for SR datasets but not always achievable for 3SAT instances. \"Steps\" columns indicate average/median iterations required to reach solutions, demonstrating the model's efficiency. <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>89.5%</td><td>79.0%</td><td>95.6%</td><td>16.17/13.0</td><td>13.33/10.0</td></tr><tr><td>SR100</td><td>74.2%</td><td>48.3%</td><td>91.3%</td><td>24.93/21.0</td><td>23.47/19.0</td></tr><tr><td>SR200</td><td>58.5%</td><td>17.0%</td><td>64.5%</td><td>32.44/30.0</td><td>33.98/28.0</td></tr><tr><td>SR400</td><td>51.5%</td><td>3.0%</td><td>16.0%</td><td>41.33/34.0</td><td>52.06/44.5</td></tr><tr><td>3SAT100</td><td>74.8%</td><td>52.8%</td><td>64.0%</td><td>25.63/22.0</td><td>29.66/24.0</td></tr><tr><td>3SAT200</td><td>54.0%</td><td>17.1%</td><td>22.5%</td><td>33.21/25.0</td><td>35.10/31.5</td></tr></table> Table 5: Performance of a model trained on SR100 (VCG+RNN with closest assignment supervision) when tested on SR benchmarks with a maximum of 100 message-passing iterations and early stopping. Given that the SR40-trained model achieved only \\(3\\%\\) SAT accuracy on SR400 (see Table 4), we focused on evaluating how training on larger instances improves scaling. The results show dramatic improvement on larger benchmarks ( \\(36.5\\%\\) vs \\(3\\%\\) on SR400), demonstrating that training on larger problems significantly enhances generalization capacity. The \"Steps\" metrics confirm the SR100-trained model requires fewer iterations on larger problems (e.g., 30.68 vs 41.33 average iterations for SAT instances on SR400). <table><tr><td>Dataset</td><td>Decision Accuracy</td><td>SAT Instances Solved</td><td>UNSAT Instances (gap == 1)</td><td>SAT Steps (Avg/Med)</td><td>UNSAT Steps (Avg/Med)</td></tr><tr><td>SR40</td><td>90.6%</td><td>81.2%</td><td>90.0%</td><td>14.57/12.0</td><td>16.21/12.0</td></tr><tr><td>SR100</td><td>79.3%</td><td>58.7%</td><td>85.7%</td><td>22.16/18.0</td><td>22.64/19.0</td></tr><tr><td>SR200</td><td>83.0%</td><td>68.2%</td><td>60.2%</td><td>22.29/20.0</td><td>27.12/22.0</td></tr><tr><td>SR400</td><td>68.2%</td><td>36.5%</td><td>78.0%</td><td>30.68/26.0</td><td>33.13/28.0</td></tr></table>\n\n<center>Figure 2: Percentage of SAT instances solved as message passing iterations increase for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Performance on SR100, showing rapid initial improvement. Right: Comparison across benchmarks, demonstrating effectiveness decreases with problem size but benefits from additional iterations, highlighting the recurrent architecture's inference-time scaling capability. </center> <center>Figure 3: Average gap (unsatisfied clauses) reduction with increasing message passing iterations for a model trained on SR40 with SAT+UNSAT closest assignment supervision. Left: Comparison across benchmarks showing extremely rapid gap reduction in early iterations for all problem sizes, with all benchmarks achieving remarkably low average gaps despite varying SAT-solving performance. Right: Individual instance trajectories revealing different convergence patterns between SAT and UNSAT instances, with occasional fluctuations suggesting potential benefit from monitoring solution quality during inference. </center> trained and therefore, in this setting we have two types of iterations. One is the number of message- passing iterations and the second is the number of diffusion steps. In Table 6 we report the tradeoff between the number of message- passing steps (referred to as GNN_Steps) and the number of diffusion steps. The reported numbers correspond to the dataset SR100 with 100 variables in each problem. The model was trained on the SR40 distribution and the tested combinations use around 300 iterations in total distributed between the two types of steps. The experiments revealed a consistent trend: increasing the number of message- passing steps is generally more important for improving metrics such as Accuracy and Avg. Gap. #### 5.4.1 Connection to Assignment Prediction Training We also report an interesting finding which allows to simplify the function approximator used in the diffusion model. Notice that in the expression \\(\\mathbf{x}_0 = f_\\theta (\\mathbf{x}_t, t)\\) it is also conditioned on the timestep \\(t\\) . This conditioning is dictated by the theory of diffusion models Nakkiran et al. [2024] and most of the models, including the one by Sun et al. Sun and Yang [2023] blindly follow this design choice. In our experiments, we found out that this conditioning is not needed and that the model sometimes works even better without it. Therefore, in all reported results, the\n\n<center>Figure 4: Performance heatmaps for a model trained on SR40 with SAT+UNSAT closest assignment supervision, showing how metrics improve with both increased iterations (columns) and resampling attempts (rows). Testing on SR40 (top), SR100 (middle), and 3SAT100 (bottom) demonstrates significant gains from both scaling dimensions\u2014e.g., SR40 decision accuracy improves from 84% (1 sample, 25 iterations) to 93% (5 samples, 125 iterations). This two-dimensional inference-time scaling capability is consistent across benchmarks but with decreasing returns on larger problems. </center> model is trained to predict the solution \\(\\mathbf{x_0}\\) only from the sample at timestep \\(t\\) ( \\(\\mathbf{x_0} = f_{\\theta}(\\mathbf{x_t})\\) ). Concurrently to us, this fact was also discovered by Sun et al. Sun et al. [2025] (the same surname is a coincidence) and it's possible that many of the reported experiments which blindly use this conditioning would result in better values without it. In this simplified setup, the training examples \\((\\mathbf{x_0},\\mathbf{x_t})\\) are sampled by taking a solution of a formula \\((\\mathbf{x_0})\\) , sampling a random \\(t\\) from the diffusion schedule and obtaining a corrupted version of the solution at time \\(t\\) ( \\(\\mathbf{x_t}\\) ). The model is trained to predict \\(\\mathbf{x_0}\\) from \\(\\mathbf{x_t}\\) . The GNN is the same as in the case of assignment prediction except that it also contains a learnable embedding layer which embeds the Boolean values in the assignment \\(\\mathbf{x_t}\\) into a vector space to obtain the initial embeddings of variables (or literals) for the first pass of message- passing. The only difference from the model trained for assignment prediction is therefore that the initial embeddings are not sampled randomly but obtained by embedding the perturbed assignment \\(\\mathbf{x_t}\\) . This also means that during test time, these two approaches differ only by rounding, i.e. running the model trained for assignment prediction for 100 steps and after every 20 steps rounding the variable embeddings to vectors representing True and False is same as running the diffusion model for 5 diffusion steps where each step has 20 message- passing iterations.\n\ntheir performance and on the theoretical side, understanding how a GNN can solve a CNF formula could help us to elucidate the reasoning ability of Transformers Vaswani et al. [2017] because Transformers can be viewed as GNNs in which the graph connectivity is given by the attention map and is learned from data Cai et al. [2023]. Our aim in this contribution is to provide an experimental evaluation of different design choices for GNNs in the context of Boolean satisfiability together with an intuitive explanation of the inner workings of these models. Our main contributions are as follows: - We provide an experimental comparison of different architectures and training regimes.- We introduce a novel supervision method based on the closest assignment, resulting in significant improvements.- We demonstrate that these architectures scale well at test time.- We extend the graph neural network to a diffusion model and show how it relates to the base model.- We provide an intuitive explanation for the inner workings of these models. The rest of the text has the following structure: Section 3 (Relevant Background) provides the necessary context on Boolean satisfiability problems, SAT solving approaches, graph neural networks, theoretical connection to approximation algorithms, and diffusion models. Section 4 (Experimental Setup) describes our methodology, including data representation choices, architecture variants, supervision methods, and benchmark generation. Section 5 (Experimental Results) presents our comprehensive evaluation, comparing different graph representations and training methods (Section 5.2), demonstrating test- time scaling capabilities (Section 5.3), and introducing our diffusion model extension (Section 5.4). Section 6 (Interpreting the Trained Model) offers analysis of the embedding space and explains the networks' behavior through the lens of approximation algorithms based on continuous relaxation. Section 2 (Related Work) positions our contribution within the broader research landscape, and Section 7 contains a discussion of our findings and directions for future research. We conclude in Section 8. Additional implementation details and mathematical derivations are provided in the Appendix. ## 2 Related Work Our research builds directly upon Neuro SAT Selsam et al. [2018], which introduced the first end- to- end neural approach for SAT solving using a recurrent message- passing architecture. While we maintain the core iterative design of Neuro SAT (allowing variable numbers of message- passing iterations through weight sharing), we explore simplified variants using RNNs and LSTMs and incorporate techniques like curriculum learning to improve training efficiency. Several other works have explored different directions in neural SAT solving. Li et al. Li et al. [2023] developed G4SATBench to benchmark various GNN architectures (GCN, GGNN, GIN) across different graph representations and supervision objectives. Unlike their broader exploration across architecture types, our work focuses on the recurrent message- passing paradigm from Neuro SAT and investigates how different training objectives and graph representations affect performance within this specific framework. We also mention the work by Warde et al. Warde- Farley et al. [2023] who developed a recurrent architecture based on a Restricted Boltzmann Machine. Hybrid approaches that integrate neural networks with traditional solvers include Neuro Core by Selsam and Bjorner Selsam and Bjorner [2019], which uses neural predictions to guide variable branching in CDCL solvers. Similarly, Wang et al. Wang et al. [2021] proposed Neuro Comb to enhance CDCL solvers through GNN- based identification of important variables and clauses.\n\nTable 6: Performance Metrics for Different GNN and Diffusion Step Configurations. Variable names shown in parentheses in the original data source are omitted here for brevity. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Dec. Acc. (%)</td><td>Single-Step Avg. Gap</td><td>Single-Step Dec. Acc (%)</td></tr><tr><td>20</td><td>15</td><td>1.09</td><td>68.7</td><td>3.26</td><td>60.2</td></tr><tr><td>23</td><td>13</td><td>1.05</td><td>70.4</td><td>2.80</td><td>63.1</td></tr><tr><td>27</td><td>11</td><td>0.96</td><td>73.6</td><td>2.44</td><td>64.7</td></tr><tr><td>31</td><td>9</td><td>0.98</td><td>73.8</td><td>2.11</td><td>68.2</td></tr><tr><td>35</td><td>8</td><td>0.93</td><td>75.4</td><td>1.96</td><td>69.5</td></tr><tr><td>38</td><td>7</td><td>0.92</td><td>76.3</td><td>1.83</td><td>70.2</td></tr><tr><td>42</td><td>7</td><td>0.90</td><td>76.7</td><td>1.70</td><td>71.6</td></tr><tr><td>46</td><td>6</td><td>0.95</td><td>76.8</td><td>1.64</td><td>72.1</td></tr><tr><td>50</td><td>6</td><td>0.94</td><td>76.2</td><td>1.52</td><td>73.0</td></tr></table> #### 5.4.2 Interleaving Diffusion Steps with Unit Propagation The fact that for each diffusion step, the model outputs probabilities for two possible values, allows us to obtain a partial solution and then run a unit propagation to deduce assignment to other variables. The partial assignment can be obtained by fixing a threshold and then assigning only variables for which one of the values has a predicted probability higher than this threshold. The lower the threshold, the more variables will be fixed and the higher the probability that it will not be possible to complete the partial assignment to a satisfiable assignment. We therefore design a tree- search- like algorithm which first tries a low threshold in each diffusion step and if it does not find a satisfiable assignment it backtracks and increases the threshold to obtain a new partial assignment. The details of this algorithm are described in A.3 and the experimental results are reported in Table 7. As can be seen, interleaving the diffusion steps with unit propagation results in additional improvements over the base diffusion model (approximately \\(10\\%\\) ). We explicitly mention that this experiment is provided only to show a possible avenue for further improvements and the algorithm in its current form is not optimized for speed. Table 7: Performance with Unit Propagation. Here we compare the performance with (U.P. Acc.) and without (Dec. Acc.) Unit Propagation, and report the computational cost of Unit Propagation, listing the average number of total recursive function calls, the average number of recursive calls in solved problems, and the average number of recursive calls in unsolved problems. <table><tr><td>Problems</td><td>Dec. Acc. (%)</td><td>U.P. Acc. (%)</td><td>Total Rec. Calls</td><td>Solved Rec. Calls</td><td>Unsolved Rec. Calls</td></tr><tr><td>SR40</td><td>88.4</td><td>94.2</td><td>32.864</td><td>6.701</td><td>53.546</td></tr><tr><td>SR50</td><td>86.6</td><td>93.7</td><td>29.539</td><td>6.995</td><td>47.038</td></tr><tr><td>SR60</td><td>83.3</td><td>92.2</td><td>26.414</td><td>7.526</td><td>40.204</td></tr><tr><td>SR70</td><td>79.5</td><td>89.5</td><td>24.162</td><td>6.752</td><td>35.505</td></tr><tr><td>SR80</td><td>77.6</td><td>88.0</td><td>22.604</td><td>6.917</td><td>32.219</td></tr><tr><td>SR90</td><td>74.0</td><td>85.1</td><td>22.140</td><td>7.274</td><td>30.151</td></tr><tr><td>SR100</td><td>73.4</td><td>83.7</td><td>20.363</td><td>7.129</td><td>27.074</td></tr><tr><td>SR150</td><td>63.2</td><td>75.1</td><td>17.388</td><td>7.828</td><td>20.592</td></tr><tr><td>SR200</td><td>58.0</td><td>67.5</td><td>16.270</td><td>8.710</td><td>17.868</td></tr></table>",
      "level": 2,
      "line_start": 4,
      "line_end": 30
    },
    {
      "heading": "6 Interpreting the Trained Model ### 6.1 Embedding Space Analysis Our analysis of variable embeddings reveals patterns that explain how GNNs learn to solve SAT problems. When visualizing these embeddings using dimensionality reduction Mc Innes et al. [2018], we observe that they form distinct clusters corresponding to optimal variable assignments. As shown in Figure 5, variable embeddings start randomly distributed but gradually organize into two clusters through message passing iterations. By applying k- means clustering ( \\(k = 2\\) ) to these embeddings, we can recover variable assignments that approximate optimal solutions, even from networks trained only to predict satisfiability status. ### 6.2 Iterative Optimization Behavior By tracking clause satisfaction across iterations, we observe that GNNs solve SAT problems through progressive local refinement. The gap (number of unsatisfied clauses) decreases following a trajectory typical of iterative optimization methods: rapid initial improvement followed by gradual refinement. This behavior supports the interpretation that GNNs implicitly learn to perform continuous optimization in a high- dimensional space similar to SDP relaxations for SAT. The effectiveness of additional message passing iterations during inference further strengthens this connection. A difference from the SDP relaxation is that the objective function which the GNN implicitely optimizes is non- convex because we observed that it can get stuck in local optima or converge to different solutions when initialized multiple times by different random embeddings. Figure 3 illustrates how the average gap decreases with increasing iterations. The trajectory suggests a rapid improvement phase followed by more gradual refinement. Individual instance trajectories reveal that while most instances show steady improvement toward optimal solutions, some exhibit fluctuations, particularly unsatisfiable instances. This observation supports the potential value of early stopping techniques, as in rare cases, the gap at later iterations might be higher than a previously achieved minimum gap. The bi- level optimization perspective\u2014where message passing performs an inner optimization loop (finding variable assignments) guided by network parameters optimized at the outer level (during training)\u2014helps explain the network's ability to generalize to novel problem instances and larger problems than those seen during training. In Section 7, we discuss more details about a possibility of manual derivation of the GNN equations from and explicit objective function. ## 7 Discussion In this section, we discuss the limitations of our work along with an outlook for future research. The primary limitation of the methods presented here is that they are not competitive with state- of- the- art SAT solvers on benchmarks derived from real- world problems. Current SAT solvers can handle formulas with millions of variables, which is not feasible for the GNN in its current form. However, as mentioned in the introduction, our motivation for studying these models is to better understand the reasoning capabilities of neural networks in a simplified context. The test- time scaling experiments clearly demonstrate that the GNNs can successfully generalize beyond their training distribution and do not merely learn superficial statistical patterns. The qualitative results presented in Section 6 further suggest that it is possible to fully understand the mechanisms by which the GNN solves a given formula. Figure 3 illustrates that the trained GNN functions as an implicit Max SAT solver, incrementally maximizing the number",
      "content": "<center>Figure 5: Evolution of variable embeddings during message passing iterations for a satisfiable SR40 instance. The visualization shows 2D projections at different stages (Initial through Iteration 25), colored k-means algorithm in each iteration (green/red). Initially random, embeddings gradually organize into two distinct clusters often corresponding to optimal variable assignments. This clustering behavior was observed across different model architectures and training objectives\u2014notably, even models trained solely for SAT/UNSAT classification (without explicit assignment supervision) develop this embedding separation. This phenomenon supports our interpretation that GNNs implicitly perform continuous optimization similar to SDP relaxation for SAT problems. </center>\n\nof satisfied clauses at each step. These local updates occur in continuous space and can therefore be viewed as gradient updates with respect to an implicit objective function measuring clause satisfaction. Variables are also represented in a high- dimensional vector space, similar to semi- definite programming as explained in B. From this perspective, Equations 6, 7, and 11 can be interpreted as a gradient descent algorithm searching for an optimal assignment over a high- dimensional unit sphere (due to unit normalization), while the final classification layer corresponds to a rounding step to Boolean values. In future work, we aim to manually derive these equations from a trained GNN using a primal- dual approach, interleaving gradient updates of primal and dual variables associated with constraints. We believe that by utilizing suitable proximal operators and an appropriate metric in the relaxed solution space, the GNN can be effectively interpreted as a primal- dual algorithm optimizing a continuous relaxation of the Max SAT objective in a high- dimensional space. This points out to another major advantage of using the RNN update function because its simple form is suitable for such derivation. Deriving equations for such algorithms applicable to arbitrary combinatorial optimization problems would be highly beneficial in practice, allowing these equations to be parameterized by learnable matrices and fine- tuned for specific problem distributions. Such data- driven solvers would be analogous to physics- informed neural networks Cai et al. [2021], where substantial domain knowledge is embedded within the model, followed by fine- tuning to approximate the dynamics of a particular physical system. This approach results in fast numerical solvers tailored to specific domains. We believe that the development of data- drive numerical solvers represents an exciting future direction for combinatorial optimization research. To make these numerical solvers practical, it will still be necessary to integrate them into more complex systems, where they would function as guessing or bounding heuristic. Another limitation of our work is that the model was tested exclusively on random problems. This decision is justified by the findings of Li et al. Li et al. [2023], who demonstrated that models trained on random problem instances exhibit superior generalization to other distributions. Since Li et al. already provided experimental results demonstrating the transferability of models across different problem distributions, we chose not to repeat those experiments here. ## 8 Conclusion This work provides a comprehensive analysis of graph neural networks for Boolean satisfiability problems. Our evaluation identified key design choices that enhance performance: variable- clause graph representation with RNN updates offers an effective balance of accuracy and efficiency, while our novel closest assignment supervision method significantly improves performance on problems with large solution spaces. The recurrent architecture enables flexible scaling during inference through additional message- passing iterations and resampling. Our diffusion model extension demonstrates another approach to inference- time adaptation, with further improvements possible by integrating classical techniques like unit propagation. Our analysis of embedding space patterns and optimization trajectories supports the interpretation that these models implicitly implement continuous relaxation algorithms for Max SAT, explaining their ability to generalize to novel problem instances. This connection provides a theoretical framework for understanding neural reasoning capabilities in structured domains, with implications for the design of hybrid solving approaches. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit- sat: An unsupervised differentiable approach. In International conference on learning representations, 2018.\n\nJacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne Van Den Berg. Structured denoising diffusion models in discrete state- spaces. Advances in neural information processing systems, 34:17981- 17993, 2021. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisfiability, volume 185. IOS press, 2009. Sally C Brailsford, Chris N Potts, and Barbara M Smith. Constraint satisfaction problems: Algorithms and applications. European journal of operational research, 119(3):557- 581, 1999. Chen Cai, Truong Son Hy, Rose Yu, and Yusu Wang. On the connection between mpnn and graph transformer. In International conference on machine learning, pages 3408- 3430. PMLR, 2023. Shengze Cai, Zhiping Mao, Zhicheng Wang, Minglang Yin, and George Em Karniadakis. Physics- informed neural networks (pinns) for fluid mechanics: A review. Acta Mechanica Sinica, 37 (12):1727- 1738, 2021. James M Crawford and Larry D Auton. Experimental results on the crossover point in random 3- sat. Artificial intelligence, 81(1- 2):31- 57, 1996. Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1- 2):3- 71, 1988. Zhaohui Fu and Sharad Malik. On solving the partial max- sat problem. In International Conference on Theory and Applications of Satisfiability Testing, pages 252- 265. Springer, 2006. Bernd G\u00e4rtner and Jiri Matousek. Approximation algorithms and semidefinite programming. Springer Science & Business Media, 2012. Michel X Goemans and David P Williamson. Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming. Journal of the ACM (JACM), 42(6):1115- 1145, 1995. Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek- r1: Incentivizing reasoning capability in llms via reinforcement learning. ar Xiv preprint ar Xiv:2501.12948, 2025. Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840- 6851, 2020. Abdelrahman Hosny and Sherief Reda. torchmsat: A gpu- accelerated approximation to the maximum satisfiability problem. ar Xiv preprint ar Xiv:2402.03640, 2024. Jan Hula, David Moj\u017e\u00ed\u0161ek, and Mikol\u00e1\u0161 Janota. Understanding gnns for boolean satisfiability through approximation algorithms. In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pages 953- 961, 2024. Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El- Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. ar Xiv preprint ar Xiv:2412.16720, 2024. Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Vardi, and Zhiwei Zhang. Fourier sat: A fourier expansion- based algebraic framework for solving hybrid boolean constraints. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 1552- 1560, 2020.\n\nZhaoyu Li and Xujie Si. Nsnet: A general neural probabilistic framework for satisfiability problems. Advances in Neural Information Processing Systems, 35:25573- 25585, 2022. Zhaoyu Li, Jinpei Guo, and Xujie Si. G4satbench: Benchmarking and advancing sat solving with graph neural networks. ar Xiv preprint ar Xiv:2309.16941, 2023. Gary Marcus. Deep learning: A critical appraisal. ar Xiv preprint ar Xiv:1801.00631, 2018. Gary F Marcus. The algebraic mind: Integrating connectionism and cognitive science. MIT press, 2003. Leland Mc Innes, John Healy, and James Melville. Umap: Uniform manifold approximation and projection for dimension reduction. ar Xiv preprint ar Xiv:1802.03426, 2018. Preetum Nakkiran, Arwen Bradley, Hattie Zhou, and Madhu Advani. Step- by- step diffusion: An elementary tutorial. ar Xiv preprint ar Xiv:2406.08929, 2024. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural sat solver. In 2022 International joint conference on neural networks (IJCNN), pages 1- 8. IEEE, 2022. Motakuri Ramana and Alan J Goldman. Some geometric results in semidefinite programming. Journal of Global Optimization, 7(1):33- 50, 1995. Bart Selman, Henry A Kautz, Bram Cohen, et al. Local search strategies for satisfiability testing. Cliques, coloring, and satisfiability, 26:521- 532, 1993. Daniel Selsam and Nikolaj Bjorner. Guiding high- performance sat solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing- SAT 2019: 22nd International Conference, SAT 2019, Lisbon, Portugal, July 9- 12, 2019, Proceedings 22, pages 336- 353. Springer, 2019. Daniel Selsam, Matthew Lamm, Benedikt Binz, Percy Liang, Leonardo de Moura, and David L Dill. Learning a sat solver from single- bit supervision. ar Xiv preprint ar Xiv:1802.03685, 2018. Qiao Sun, Zhicheng Jiang, Hanhong Zhao, and Kaiming He. Is noise conditioning necessary for denoising generative models? ar Xiv preprint ar Xiv:2502.13129, 2025. Zhiqing Sun and Yiming Yang. Difusco: Graph- based diffusion solvers for combinatorial optimization. Advances in neural information processing systems, 36:3706- 3731, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. W Wang, Y Hu, M Tiwari, S Khurshid, KL Mc Millan, and R Miikkulainen. Neurocomb: improving sat solving with graph neural networks, 2021. David Warde- Farley, Vinod Nair, Yujia Li, Ivan Lobov, Felix Gimeno, and Simon Osindero. Solving maxsat with matrix multiplication. ar Xiv preprint ar Xiv:2311.02101, 2023. Morris Yau, Nikolaos Karalias, Eric Lu, Jessica Xu, and Stefanie Jegelka. Are graph neural networks optimal approximation algorithms? Advances in Neural Information Processing Systems, 37:73124- 73181, 2024. Emre Yolcu and Barnabas P\u00f3czos. Learning local search heuristics for boolean satisfiability. Advances in Neural Information Processing Systems, 32, 2019.\n\n<center>Figure 6: Validation accuracy during training. Our model with a curriculum achieves reaches \\(85\\%\\) in approximately 30 minutes, whereas the original Neuro SAT implementation needs over 5 hours. For comparison, we also add our implementation trained on the same data, but without a curriculum. The training of each model stops once it achieves an accuracy of \\(85\\%\\) on a validation set. </center> ## A Appendix ## A.1 Training Tricks and Information ## A.1.1 Curriculum Learning We implement a curriculum learning strategy to improve training efficiency and generalization. The key insight is that starting with simpler (smaller) formulas and gradually increasing complexity allows the model to learn basic logical reasoning patterns before tackling more complex instances. Our curriculum proceeds as follows: 1. Start training with small formulas (5 variables) 2. Set a validation accuracy threshold for each formula size (starting at \\(65\\%\\) for the smallest size and increasing to \\(85\\%\\) for the largest) 3. Once the model reaches the threshold accuracy on the current size or reaches a maximum number of epochs (100), increase the formula size by 2 variables 4. When introducing a new size, include formulas from the four previous sizes to prevent catastrophic forgetting 5. Continue until reaching the maximum formula size (40 variables) This curriculum approach significantly accelerates training compared to starting with the full distribution of formula sizes. Our previous experiments showed that the curriculum- trained model reaches \\(85\\%\\) validation accuracy in approximately 30 minutes, compared to over 5 hours for the non- curriculum approach. ## A.1.2 Exponential Moving Average (EMA) We employ Exponential Moving Average (EMA) for model parameter updates during training. EMA maintains a shadow copy of the model parameters that is updated after each training\n\nbatch: \\[\\theta_{\\mathrm{EMA}}\\leftarrow \\beta \\theta_{\\mathrm{EMA}} + (1 - \\beta)\\theta_{\\mathrm{current}} \\quad (13)\\] where \\(\\beta\\) is the decay rate (we use \\(\\beta = 0.999\\) ). During validation and testing, we use the EMA parameters instead of the current parameters. This technique significantly stabilizes training and improves generalization, especially in the early stages of training. Our experiments show that EMA provides a smooth validation accuracy curve, while the validation accuracy of the non- EMA model exhibits high variance and jumps of up to \\(10\\%\\) . #### A.1.3 Learning Rate Schedule We implement a custom learning rate schedule that combines cosine annealing for the first half of training and a constant minimum learning rate for the second half: \\[\\eta (t) = \\left\\{ \\begin{array}{ll}\\eta_{\\mathrm{min}} + (\\eta_{0} - \\eta_{\\mathrm{min}})\\frac{1 + \\cos(\\pi t / t_{\\mathrm{half}})}{2} & \\mathrm{if} t< t_{\\mathrm{half}}\\\\ \\eta_{\\mathrm{min}} & \\mathrm{otherwise} \\end{array} \\right. \\quad (14)\\] where \\(\\eta_{0}\\) is the initial learning rate, \\(\\eta_{\\mathrm{min}}\\) is the minimum learning rate (set to \\(10^{- 5}\\) ), \\(t\\) is the current epoch, and \\(t_{\\mathrm{half}}\\) is half of the maximum number of epochs. This schedule helps the model converge to a good solution in the first half of training and then fine- tune in the second half without disrupting the learned representations. ## A.1.4 Impact of hidden dimension on GNN Performance The dimensionality of the hidden representations, here denoted as d_model, specifies the size of the embedding vectors of variables and the hidden state dimension used during the message passing and update phases within the GNN architecture. The choice of d_model directly influences the model's capacity to learn complex patterns and relationships within the graph structure and node features. It also impacts computational resource requirements, such as memory usage and training time. Understanding how performance metrics vary with different d_model values is therefore crucial for effective model design and hyperparameter tuning. Our evaluation in table 8 generally shows that increasing the d_model leads to improved model performance, likely due to the enhanced representational capacity allowing the model to capture more intricate features. However, we observed that this trend exhibits diminishing returns; while significant performance gains are noticeable as the dimension increases up to 64, further increases yield smaller improvements in accuracy relative to the growing computational cost (e.g., peak accuracy at d_model=256 came with significantly longer training time). This suggests that, considering the marginal benefits, a dimension around 64 still presents a practical optimum, offering a good balance between performance and model complexity/efficiency for this specific setup. ## A.2 Diffusion Model Extensions ## A.3 Using Unit Propagation for Problem Simplification in the Diffusion Process In the diffusion process, each iteration provides a belief for every variable, which can be leveraged to continuously simplify the problem via a unit propagation algorithm until it converges to an empty problem, thereby obtaining a solution. The overall solving process is recursive, and its main steps are described as follows:\n\nTable 8: Experimental results demonstrating the impact of hidden dimension size (d_model) on model performance and training duration. \u2018Embedding Size (d_model)\u2019 refers to the dimensionality of the hidden representations within the GNN. \u2018Accuracy\u2019 indicates the performance metric achieved by the model. \u2018Time (hours)\u2019 specifies the total time required to train the model for each corresponding dimension size. <table><tr><td>Embedding Size (d_model)</td><td>Accuracy</td><td>Time (hours)</td></tr><tr><td>16</td><td>0.782</td><td>1.62</td></tr><tr><td>32</td><td>0.852</td><td>1.66</td></tr><tr><td>48</td><td>0.860</td><td>1.70</td></tr><tr><td>64</td><td>0.869</td><td>1.87</td></tr><tr><td>96</td><td>0.861</td><td>2.32</td></tr><tr><td>128</td><td>0.864</td><td>2.99</td></tr><tr><td>256</td><td>0.877</td><td>7.55</td></tr></table> ## 1. Partial Assignment Extraction and Local Unit Propagation In each diffusion step, a belief value between 0 and 1 is calculated for every variable. A value closer to 1 indicates a stronger inclination toward being true, and vice versa. We set a threshold to select variables with high belief and assign them accordingly to obtain a partial assignment. This partial assignment is then used to perform unit propagation for clause simplification. The unit propagation algorithm works as follows: If a clause contains a literal that is already satisfied by the current assignment, the clause is marked as satisfied. If all literals in a clause have been assigned but none satisfy it, a conflict signal is returned. For clauses that are not fully assigned, the unassigned literals are retained to form a simplified clause set. For unit clauses obtained during the simplification process (i.e., clauses containing only a single literal), the corresponding unassigned variable is directly assigned the appropriate value, further advancing the local solving process. ## 2. Multi-Threshold Strategy and Recursive Solving In the partial assignment extraction step, setting a lower threshold allows for the selection of as many assignments as possible at each step, thereby greatly simplifying the problem; however, it is more likely to select unreliable assignments that may lead to contradictions. To balance this, we adopt a multi- threshold list, starting from the lowest threshold. For each given threshold, if a new partial assignment is obtained, unit propagation is used to update the clauses and evaluate: If the simplified clause set becomes empty, all clauses are satisfied and the final solution is directly returned. If a conflict occurs or the recursive call at the next level fails, the threshold is raised; if the highest threshold is reached, the process moves to the next recursive level and performs another diffusion step. If unit propagation succeeds but the problem is not yet completely solved, the process recurses to the next level, performing a diffusion step on the updated clauses. If the recursion reaches a preset maximum depth and the clauses still cannot be satisfied, the recursion at that level fails.\n\nTable 9: Performance on SR100 for Different Diffusion Step and Fixed GNN Step. Note that the Performance is no longer Significantly Improved when Diffusion Steps Larger than 8. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>25</td><td>4</td><td>0.991</td><td>69.9</td></tr><tr><td>25</td><td>5</td><td>0.901</td><td>71.2</td></tr><tr><td>25</td><td>6</td><td>0.798</td><td>72.7</td></tr><tr><td>25</td><td>8</td><td>0.705</td><td>73.0</td></tr><tr><td>25</td><td>10</td><td>0.728</td><td>72.1</td></tr><tr><td>25</td><td>20</td><td>0.662</td><td>73.3</td></tr><tr><td>25</td><td>30</td><td>0.676</td><td>72.3</td></tr><tr><td>25</td><td>40</td><td>0.655</td><td>73.3</td></tr><tr><td>25</td><td>50</td><td>0.663</td><td>73.0</td></tr></table> Table 10: Performance on SR100 for Different GNN Step and Fixed Diffusion Step. Note that the Performance is no longer Significantly Improved when GNN Steps Larger than 50. <table><tr><td>GNN Steps</td><td>Diffusion Steps</td><td>Avg. Gap</td><td>Accuracy (%)</td></tr><tr><td>10</td><td>10</td><td>2.028</td><td>55.0</td></tr><tr><td>20</td><td>10</td><td>0.846</td><td>68.6</td></tr><tr><td>30</td><td>10</td><td>0.622</td><td>74.4</td></tr><tr><td>40</td><td>10</td><td>0.578</td><td>75.5</td></tr><tr><td>50</td><td>10</td><td>0.533</td><td>77.6</td></tr><tr><td>60</td><td>10</td><td>0.518</td><td>77.2</td></tr><tr><td>70</td><td>10</td><td>0.500</td><td>78.6</td></tr><tr><td>80</td><td>10</td><td>0.521</td><td>77.9</td></tr><tr><td>90</td><td>10</td><td>0.512</td><td>77.6</td></tr><tr><td>100</td><td>10</td><td>0.522</td><td>77.4</td></tr></table> Table 7 shows the performance and computational cost after applying unit propagation. We tested a fixed model under the settings: GNN steps \\(= 25\\) , diffusion steps \\(= 10\\) , and multithreshold list \\(= [0.6, 0.75, 0.9]\\) . As shown, incorporating unit propagation improves accuracy by approximately \\(10\\%\\) across various problem settings. The last three columns of the table list the number of recursive function calls during the recursion process. Since each call involves one diffusion step, the computational cost incurred by the multi- threshold strategy is directly reflected. We observed that for harder problems, the computational cost of the multi- threshold strategy is actually lower, as unit propagation on partial assignments is more likely to encounter conflicts, thereby reducing the number of recursive branches. ## A.4 Influence of Number of Message-passing and Diffusion Steps For completeness, we also report evaluations in which the number of diffusion steps is fixed and the number of message- passing steps is changing (Table 10) and vice versa (Table 9). We observe that the expansion of the number of iterative steps does not always bring benefits: when the number of one kind of step is fixed, further increasing the number of another kind of step beyond a certain threshold will not lead to performance improvement.\n\nThese approaches differ from our end- to- end model but demonstrate alternative applications of neural methods to SAT solving. The connection between neural networks and continuous relaxations is particularly relevant to our work. Kyrillidis et al. Kyrillidis et al. [2020] introduced Fourier SAT, which transforms Boolean SAT problems into continuous optimization using the Walsh- Fourier transform. This approach provides a theoretical foundation for understanding how neural networks might implicitly convert discrete search problems into continuous optimization. Similar technique was introduced by Hosny et al. Hosny and Reda [2024] who develop GPU- accelerated approaches for Max SAT problems. Hula et al. Hula et al. [2024] and Yau et al. Yau et al. [2024] explore the connection between GNNs and semidefinite programming relaxations, demonstrating empirically and theoretically that message- passing can implement gradient- based optimization of SDP relaxations. In the broader domain of combinatorial optimization, Sun et al. Sun and Yang [2023] used diffusion models based on GNNs to solver problems such as traveling salesman. ## 3 Relevant Background ### 3.1 Boolean Satisfiability and Maximum Satisfiability #### 3.1.1 Boolean Satisfiability as a Constraint Satisfaction Problem Boolean satisfiability (SAT) is a fundamental problem in computer science that asks whether a given Boolean formula has a satisfying assignment. The formula is built from propositional variables \\(x_{1},x_{2},\\ldots\\) that can take values from \\(\\{0,1\\}\\) , representing false and true respectively, and logical connectives: conjunction \\((\\wedge)\\) , disjunction \\((\\vee)\\) , and negation \\((\\neg)\\) . While other connectives like implication \\((\\rightarrow)\\) and equivalence \\((\\leftrightarrow)\\) exist, they can be expressed using these basic operators. A literal is either a propositional variable \\(x\\) or its negation \\(\\neg x\\) . While Boolean formulas can take arbitrary form, the most common representation is the conjunctive normal form (CNF), where a formula is a conjunction of clauses, and each clause is a disjunction of literals. For example, \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) is a CNF formula with two clauses. We note that any Boolean formula can be transformed into an equisatisfiable CNF formula, albeit potentially requiring additional variables. An assignment \\(\\sigma\\) maps each propositional variable to either 0 or 1. We say \\(\\sigma\\) satisfies a CNF formula if at least one literal in each clause evaluates to true under \\(\\sigma\\) . For instance, the assignment \\(\\sigma (x_{1}) = 1,\\sigma (x_{2}) = 0,\\sigma (x_{3}) = 1\\) satisfies the formula \\((x_{1}\\vee \\neg x_{2})\\wedge (x_{2}\\vee x_{3})\\) as both clauses contain a true literal. SAT is a special case of the more general Constraint Satisfaction Problem (CSP) framework Brailsford et al. [1999]. A CSP consists of a set of variables, each with a domain of possible values, and a set of constraints that specify allowed combinations of values for groups of variables. While SAT variables are restricted to Boolean values and constraints take the form of clauses, CSPs can accommodate richer variable domains and constraint types. #### 3.1.2 Max SAT: The Optimization Variant The Maximum Satisfiability problem (Max SAT) is the optimization version of SAT. Given a CNF formula \\(\\phi\\) , the goal is to find an assignment that maximizes the number of satisfied clauses. This formulation is particularly useful when a formula is unsatisfiable, as Max SAT still yields the best possible solution. Max SAT has several variations that differ in their expressiveness and the way they handle the importance of clauses. In unweighted Max SAT, all clauses have equal importance. Weighted Max SAT assigns a positive weight to each clause, with the objective being to maximize the sum",
      "level": 2,
      "line_start": 31,
      "line_end": 50
    },
    {
      "heading": "B SDP for MAX-2-SAT Semidefinite programming (SDP) is a mathematical optimization technique primarily used for problems involving positive semidefinite matrices. In SDP, a linear objective function is optimized over a feasible region given by a spectrahedron (an intersection of a convex cone formed by positive semidefinite matrices and an affine subspace) Ramana and Goldman [1995]. Along with the broad scope of applications, SDP has been used to design approximation algorithms for discrete NP- hard problems Gartner and Matousek [2012]. This is achieved by lifting variables of a problem to a vector space and optimizing a loss function expressed in terms of these vectors. In this section, we provide a detailed derivation of the SDP relaxation for MAX- 2- SAT. The goal is to write an objective function for 2- CNF formulae, which consist of clauses \\(c_{1},\\ldots ,c_{k}\\) over variables \\(x_{1},\\ldots ,x_{n}\\) with at most two literals per clause. ## B.1 Derivation of the SDP Relaxation For each Boolean variable \\(x_{i}\\) (where \\(i\\in \\{1,2,\\ldots ,n\\}\\) ), a new variable \\(y_{i}\\in \\{- 1,1\\}\\) is associated, and an additional variable \\(y_{0}\\in \\{- 1,1\\}\\) is introduced. This additional variable is introduced to unambiguously assign the truth value in the original problem from values of the relaxed problem. It is not possible to just assign True (False) to \\(x_{i}\\) if \\(y_{i} = 1(- 1)\\) because quadratic terms cannot distinguish between \\(y_{i}\\cdot y_{j}\\) and \\((- y_{i})\\cdot (- y_{j})\\) . Instead, the truth value of \\(x_{i}\\) is assigned by comparing \\(y_{i}\\) with \\(y_{0}\\) : \\(x_{i}\\) is True if and only if \\(y_{i} = y_{0}\\) , otherwise it is False. The assignment is therefore invariant to negating all variables. To determine the value of a formula, we sum the value of its clauses \\(c\\) which are given by the value function \\(v(c)\\) . Here are examples of the value function for different clauses: \\[\\begin{array}{c}{v(x_{i}) = \\frac{1 + y_{0}\\cdot y_{i}}{2}}\\\\ {v(\\neg x_{i}) = 1 - v(x_{i}) = \\frac{1 - y_{0}\\cdot y_{i}}{2}}\\\\ {v(x_{i}\\vee \\neg x_{j}) = 1 - v(\\neg x_{i}\\wedge x_{j})}\\\\ {= 1 - \\frac{1 - y_{0}\\cdot y_{i}}{2}\\cdot \\frac{1 + y_{0}\\cdot y_{j}}{2}}\\\\ {= \\frac{1}{4} (1 + y_{0}\\cdot y_{i}) + \\frac{1}{4} (1 - y_{0}\\cdot y_{j}) + \\frac{1}{4} (1 + y_{i}\\cdot y_{j})} \\end{array} \\quad (15)\\] By summing over all clauses \\(c\\) in the Boolean formula, the following integer quadratic program for MAX- 2- SAT is obtained: \\[\\begin{array}{r l} & {\\mathrm{Maximize:}\\quad \\sum_{c\\in C}v(c)}\\\\ & {\\mathrm{Subject~to:}\\quad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\mathrm{Subject~to:}\\quad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}j\\in \\{0,1,\\ldots ,n\\}} \\end{array} \\quad (21)\\] This can be rewritten by collecting coefficients of \\(y_{i}\\cdot y_{j}\\) for \\(i,j\\in \\{0,1,\\ldots ,n\\}\\) and putting them symmetrically into a \\((n + 1)\\times (n + 1)\\) coefficient matrix \\(W\\) . The terms \\(y_{i}\\cdot y_{j}\\) can be collected in a matrix \\(Y\\) with the same dimensions as \\(W\\) . The elements \\(Y_{ij}\\) correspond to \\(y_{i}\\cdot y_{j}\\) for \\(i,j\\in \\{0,1,\\ldots ,n\\}\\) . Both matrices are symmetric, hence the sum of all elements in their element- wise product (which is the objective function) can be compactly expressed by using the trace operation. This leads to the following version of the same integer program: \\[\\begin{array}{r l} & {\\mathrm{Maximize:}\\quad \\mathrm{Tr}(W Y)}\\\\ & {\\mathrm{Subject~to:}\\quad Y_{i i} = 1\\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad Y_{i j} = y_{i}\\cdot y_{j}\\mathrm{~for~all~}i,j\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad y_{i}\\in \\{-1,1\\} \\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}} \\end{array} \\quad (22)\\]",
      "content": "",
      "level": 2,
      "line_start": 51,
      "line_end": 52
    },
    {
      "heading": "B.2 Relaxation to Semidefinite Programming To make the discrete program continuous, we first allow the value of the variables \\(y_{i}\\) to be any real number between \\(- 1\\) and 1. However, semidefinite programming goes further and allows variables to be \\((n + 1)\\) - dimensional unit vectors \\((y_{0},\\ldots ,y_{n})\\longrightarrow (\\mathbf{y}_{0},\\ldots ,\\mathbf{y}_{n})\\) , as schematically depicted in Figure 7. In this relaxation, the binary products \\(y_{i}\\cdot y_{j}\\) in the objective function are replaced by inner products \\(\\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) This can be compactly represented in matrix form by substituting each inner product \\(\\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) with a scalar \\(Y_{ij}\\) of a matrix \\(Y\\) . The fact that these scalars correspond to inner products is encoded by the restriction to positive- semidefinite matrices \\(Y\\succeq 0\\) . The SDP relaxation of MAX- 2- SAT can thus be formulated as: \\[\\begin{array}{rl} & {\\mathrm{Maximize:}\\quad \\mathrm{Tr}(W Y)}\\\\ & {\\mathrm{Subject~to:}\\quad Y_{i i} = 1\\mathrm{~for~all~}i\\in \\{0,1,\\ldots ,n\\}}\\\\ & {\\qquad Y\\succeq 0} \\end{array} \\quad (27)\\] Positive semidefiniteness of matrix \\(Y\\) ensures that it can be uniquely factorized as \\(Y =\\) \\(Y^{\\frac{1}{2}}(Y^{\\frac{1}{2}})^{T}\\) . We can then obtain real unit vectors \\(\\mathbf{y}_{i}\\) for all \\(i\\in \\{0,\\ldots ,n\\}\\) such that \\(Y_{ij} = \\langle \\mathbf{y}_{i},\\mathbf{y}_{j}\\rangle\\) for all \\(i,j\\in \\{0,\\ldots ,n\\}\\) . The constraints \\(Y_{ii} = 1\\) ensure that all vectors \\(\\mathbf{y}_{i}\\) lie on an \\((n + 1)\\) - dimensional unit sphere. <center>Figure 7: Lifting the variables to a higher dimension, demonstrated on variables \\(y_{1},y_{2},y_{3}\\) . Initially, only integer values of \\(-1\\) and 1 could be assigned to them (integer program). Next, constraints are relaxed, allowing variables to take any real value between \\(-1\\) and 1. Finally, it is permitted for them to be unit vectors in a high-dimensional space (here, 3 dimensions). The hyperplane in the last picture would be used for rounding the variables at the end. This hyperplane can be randomly selected, and truth values for variables \\(y_{1},y_{2},y_{3}\\) are determined based on which side of the hyperplane they land after continuous optimization. </center> ## B.3 Interpretation and Rounding The SDP solver optimizes the numbers in the matrix \\(Y\\) , but using the factorization, we can visualize what happens with the vectors \\(\\mathbf{y}_{1}\\) . The process starts with random unit vectors that are continuously updated to maximize the objective function. If we fix the position of the vector \\(\\mathbf{y}_{0}\\) (corresponding to the value true), we would see that the vectors of variables that will be set to true in the final assignment get closer to the vector \\(\\mathbf{y}_{0}\\) , while the vectors \\(\\mathbf{y}_{j}\\) of variables that will be set to false move away from it so that the inner product \\(\\langle \\mathbf{y}_{0},\\mathbf{y}_{j}\\rangle\\) is close to \\(- 1\\) . If the formula is satisfiable, the objective function drives the vectors to form two wellseparated clusters. However, if only a few clauses can be satisfied simultaneously, the vectors would end up being scattered. A simple way to round the resulting vectors \\((\\mathbf{y}_{1},\\ldots ,\\mathbf{y}_{n})\\) and get the assignment for the original Boolean variables is to compute the inner product \\(\\langle \\mathbf{y}_{0},\\mathbf{y}_{i}\\rangle\\) and assign the value according",
      "content": "to its sign. It is also possible to assign the values by picking a random separating hyperplane, and it can be shown that this rounding gives a 0.8785- approximation of the integer program optimum Goemans and Williamson [1995]. Note that the expressions of the clauses reach their maximum at 1 (when a clause is satisfied by the assignment). This means that the whole formula is satisfiable if the objective function achieves a value equal to the number of clauses in the formula. Another way to check satisfiability is to plug the obtained solution into the formula and verify whether it is satisfied. Therefore, we can obtain an incomplete SAT solver from this SDP formulation. Similar SDPs can be obtained for different versions of MAX- SAT (with larger clauses). From empirical observation, the convergence threshold of the SDP solver needs to be decreased significantly compared to MAX- 2- SAT in order to obtain a good approximation for these more complicated versions.\n\nof weights of satisfied clauses. In some variants (Partial MAX- SAT Fu and Malik [2006]), clauses are categorized as hard or soft, where hard clauses must be satisfied (often with infinite weight), and soft clauses are those that can be violated but contribute to the objective based on their weight. While weighted variants exist, in this paper we focus exclusively on the unweighted formulation. Formally, for a CNF formula \\(\\phi = c_{1} \\wedge c_{2} \\wedge \\dots \\wedge c_{m}\\) with \\(m\\) clauses, the unweighted Max SAT problem seeks an assignment \\(\\sigma^{*}\\) such that: \\[\\sigma^{*} = \\arg \\max_{\\sigma}\\sum_{i = 1}^{m}\\mathbf{1}(\\sigma \\mathrm{~satisfies~}c_{i}) \\quad (1)\\] where \\(\\mathbf{1}(\\cdot)\\) is the indicator function. ### 3.2 SAT Solving Approaches SAT solving algorithms are generally categorized into complete and incomplete approaches, each with distinct characteristics and applications. Complete Solvers Complete solvers theoretically guarantee definitive answers: either finding a satisfying assignment or proving that none exists. The Davis- Putnam- Logemann- Loveland (DPLL) algorithm forms the foundation for most modern complete solvers Biere et al. [2009]. It systematically explores the search space through backtracking while employing unit propagation to deduce logical consequences. Conflict- Driven Clause Learning (CDCL) extends DPLL by analyzing conflicts to learn new clauses, which helps prune large portions of the search space. When a conflict occurs, the solver identifies the \"reasons\" for the conflict and adds a new clause that prevents similar conflicts in the future. Modern CDCL solvers incorporate sophisticated heuristics for variable selection, restart strategies, and efficient data structures to improve performance. Incomplete Solvers Incomplete solvers focus on finding satisfying assignments but cannot prove unsatisfiability. These algorithms are particularly effective for large satisfiable instances where complete methods might be inefficient. Local search algorithms, such as Walk SAT Selman et al. [1993], start with a random assignment and iteratively modify it to satisfy more clauses. These methods employ heuristics to decide which variables to flip at each step, balancing between greedy choices and random moves to escape local optima. For Max SAT, local search algorithms often use scoring functions that prioritize flipping variables that maximize the increase in satisfied clauses. Stochastic algorithms including simulated annealing and genetic algorithms have also been applied to SAT and Max SAT problems. These approaches can effectively explore search spaces in certain problem classes where deterministic methods struggle. #### 3.2.1 Continuous Relaxations A specific type incomplete solvers that have been explored in recent research Kyrillidis et al. [2020], Hosny and Reda [2024] are explored continuous relaxations of Max SAT, that transform the discrete problem into a continuous optimization task. These methods map Boolean variables to continuous domains, enabling the application of gradient- based optimization techniques. The Fourier- SAT method Kyrillidis et al. [2020], for instance, transforms Boolean formulas into multilinear polynomials through Walsh- Fourier transform and then optimize the continuous variables w.r.t. the resulting polynomial. Continuous relaxations can also be obtained by making the objective function convex as often done when designing approximation algorithms which provide guarantees for their performance.\n\nThe guarantees can be improved by lifting the variables into a high- dimensional vector space and optimizing vectors instead of scalar values. The optimized vectors are finally rounded to discrete values. Semidefinite Programming (SDP) relaxation, particularly for MAX- 2- SAT or MAX- 3- SAT, illustrates this approach elegantly. In SDP relaxation, Boolean variables \\(x_{i} \\in \\{0,1\\}\\) are transformed into unit vectors \\(\\mathbf{y}_{i}\\) in a high- dimensional space. An additional vector \\(\\mathbf{y}_{0}\\) is introduced to represent the value \"true.\" The Boolean variable \\(x_{i}\\) is considered true if \\(\\mathbf{y}_{i}\\) is close to \\(\\mathbf{y}_{0}\\) (positive inner product) and false if it is far from \\(\\mathbf{y}_{0}\\) (negative inner product). The optimization process for these vectors follows a pattern: 1. Initialize random unit vectors for each variable 2. Optimize these vectors to maximize the number of satisfied clauses, expressed as a function of inner products between vectors 3. Round the resulting vectors to discrete assignments (typically based on the sign of inner products with \\(\\mathbf{y}_{0}\\) ) This relaxation enables the application of powerful continuous optimization techniques while providing approximation guarantees. For MAX- 2- SAT, this approach yields an approximation ratio of 0.878, meaning the solution will satisfy at least 87.8% of the maximum possible number of clauses. #### 3.2.2 Learning-Based Approaches Machine learning (ML) is also being heavily utilized for SAT solving. Many approaches have been developed to guide traditional solvers Selsam and Bj\u00f8rner [2019], Yolcu and P\u00f3czos [2019] or to solve SAT problems directly Selsam et al. [2018], Li and Si [2022]. To guide a solver, a neural network can be used to replace heuristics such as variable selection or restart policies. Importantly, Graph Neural Networks (GNNs) can also be trained to solve SAT problems end- to- end without relying on traditional algorithmic solvers Amizadeh et al. [2018]. These GNN- based approaches can operate directly on the graph representation of Boolean formulas, with variables and clauses forming nodes in a bipartite graph, and learn to predict satisfiability or produce satisfying assignments Li et al. [2023]. In this work, we focus on variants of GNNs that are recurrent and this allows us to scale the computation during inference or adapt the number of iterations for each instance separately. In Section 6 we will show an evidence that one can view the end- to- end ML approaches as bi- level optimization methods because during inference, the GNN behaves as a continuous solver trying to maximize the number of satisfied clauses. Therefore, during training, the outer loop of the bi- level optimization optimizes the weights of the network which then runs an inner loop that optimizes the values of variables to maximize the number of satisfiable clauses. ### 3.3 Graph Neural Networks Graph Neural Networks (GNNs) extend deep learning to graph- structured data, enabling learning on irregular data structures that classical neural architectures cannot directly process. A graph \\(G = (V,E)\\) consists of nodes \\(V\\) and edges \\(E\\) , where each node \\(v\\in V\\) may have associated features \\(x_{v}\\) . GNNs compute node representations through message passing, where each node iteratively aggregates information from its neighbors and updates its features. Formally, at layer \\(l\\) , a node \\(v\\) updates its representation \\(h_{v}^{l}\\) , according to: \\[h_{v}^{l + 1} = \\mathrm{UPDATE}(h_{v}^{l},\\mathrm{AGGREGATE}(\\{h_{u}^{l}:u\\in \\mathcal{N}(v)\\}))\\]\n\n<center>Figure 1: LCG and VCG of the CNF formula \\((\\overline{x}_{1} \\vee x_{2}) \\wedge (x_{2} \\vee \\overline{x}_{3}) \\wedge (x_{1} \\vee x_{3})\\) . </center> where \\(\\mathcal{N}(v)\\) denotes the neighbors of node \\(v\\) . The UPDATE and AGGREGATE functions are typically neural networks, often implementing permutation- invariant operations like sum or max. Through multiple layers of message passing, GNNs can capture both local structure and longer- range dependencies in the graph, making them suitable for processing SAT formulas represented as bipartite graphs. ### 3.4 Diffusion-based Assignment Generation In Section 5.4 will show how the GNNs we use can be extended to diffusion models which have in recent years emerged as a powerful approach for generative modeling across domains Ho et al. [2020]. These models learn to transform a random noise distributions (such as multi- variate Gaussian distribution) to complex distributions behind the given domain (i.e., distribution of images of human faces). For practical applications, diffusion models are typically conditioned on an input so that the generated sample has specific characteristics. In our case, we will condition the model by the bipartite graph of the CNF formula. #### 3.4.1 Categorical Diffusion Process While continuous diffusion models have gained prominence in image generation and other domains, discrete diffusion processes well- suited for combinatorial optimization problems like MAX- SAT, where the state space is inherently discrete. Our approach presented in Section 5.4 leverages a discrete diffusion process with categorical noise to model the generation of variable assignments. We adapt a concrete form of discrete diffusion first presented by Austin et al. Austin et al. [2021] and later leveraged for combinatorial optimization with GNNs by Sun et al. Sun and Yang [2023]. On a high level, diffusion models are trained to denoise noisy version of the training samples. These noisy versions are obtained by running a forward diffusion process for several steps and the model is then trained to predict the original sample. For a SAT problem with \\(n\\) variables, we represent each variable assignment as a binary value and the vector of these binary values represent the sample. The diffusion process gradually corrupts this sample until it becomes pure noise. More concretely, the process that progressively adds noise to the initial assignment \\(\\mathbf{x}_{0} \\in \\{0, 1\\}^{n}\\) over \\(T\\) timesteps, produces a sequence of increasingly more corrupted assignments \\(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots , \\mathbf{x}_{T}\\) . For categorical diffusion, this corruption process is defined by a Markov chain with the following transition matrices: \\[\\mathbf{Q}_{t} = \\left( \\begin{array}{cc}1 - \\beta_{t} & \\beta_{t} \\\\ \\beta_{t} & 1 - \\beta_{t} \\end{array} \\right) \\quad (2)\\] where \\(\\beta_{t} \\in (0, 1)\\) represents the noise schedule, controlling how quickly the assignments become corrupted. The matrix \\(\\mathbf{Q}_{t}\\) defines the probability of transitioning between states at time \\(t\\) , with the property that as \\(t\\) approaches \\(T\\) , the distribution of \\(\\mathbf{x}_{t}\\) approaches a uniform distribution over all possible assignments.\n\nTo simplify inference, the cumulative transition matrices \\(\\overline{\\mathbf{Q}}_{t} = \\mathbf{Q}_{1}\\mathbf{Q}_{2}\\cdot \\cdot \\cdot \\mathbf{Q}_{t}\\) , which directly gives us \\(p(\\mathbf{x}_{t}|\\mathbf{x}_{0})\\) are being used. For the Boolean case, this allows us to efficiently sample \\(\\mathbf{x}_{t}\\) given \\(\\mathbf{x}_{0}\\) using: \\[p(\\mathbf{x}_{t}|\\mathbf{x}_{0}) = \\mathrm{Cat}(\\mathbf{x}_{t};\\mathbf{p} = \\tilde{\\mathbf{x}}_{0}\\overline{\\mathbf{Q}}_{t}) \\quad (3)\\] where \\(\\tilde{\\mathbf{x}}_{0} \\in \\{0,1\\}^{n \\times 2}\\) is the one- hot encoding of \\(\\mathbf{x}_{0}\\) , with each variable represented by a vector \\((1,0)\\) for value 0 or \\((0,1)\\) for value 1. The Cat operation refers to the categorical distribution, which samples \\(\\mathbf{x}_{t}\\) based on the probability vector \\(\\mathbf{p}\\) . #### 3.4.2 Learning the Reverse Process The core idea of diffusion models is to learn the reverse process - how to gradually denoise a corrupted sample to recover the original data distribution. In our case, we train a GNN to progressively recover a satisfiable assignment \\(\\mathbf{x}_{0}\\) starting from a random initial assignment. The trained model is used to sample from a distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) which can be used to obtain a an assignment \\(\\mathbf{x}_{0}\\) from random assignment \\(\\mathbf{x}_{T}\\) as explained bellow. There are multiple ways of training the neural network used in the diffusion model. One can train it to directly model the distribution \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) . In the method introduced by Austin et al. Austin et al. [2021], the network is trained to predict the original uncorrupted input \\(\\mathbf{x}_{0}\\) which is then used to sample from the the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\) using Bayes' rule. This approach provides stronger learning signals during training, as the target \\(\\mathbf{x}_{0}\\) remains fixed regardless of a timestep and we use it within this work. #### 3.4.3 Categorical Posterior Sampling As mentioned above, our model is trained to predict \\(\\mathbf{x}_{0}\\) directly and we use this prediction during inference to sample \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) . This is accomplished through categorical posterior sampling, which uses the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) to compute the posterior \\(p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})\\) . By applying Bayes' rule and the Markov property of the diffusion process, we can derive: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t},\\mathbf{x}_{0})p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (4)\\] For the categorical case, this is computed using: \\[p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{t})\\approx \\sum_{\\mathbf{x}_{0}}\\frac{p(\\mathbf{x}_{t - 1}|\\mathbf{x}_{0})p(\\mathbf{x}_{t}|\\mathbf{x}_{t - 1})}{p(\\mathbf{x}_{t}|\\mathbf{x}_{0})} p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t) \\quad (5)\\] The diffusion model replaces the distribution \\(p_{\\theta}(\\mathbf{x}_{0}|\\mathbf{x}_{t},t)\\) with a function approximator (GNN in our case) \\(f_{\\theta}(\\mathbf{x}_{t},t)\\) Therefore, we can train the model using a simple procedure (predicting \\(\\mathbf{x}_{0}\\) ) and during inference, we can use a sampling process (iteratively sampling \\(\\mathbf{x}_{t - 1}\\) given \\(\\mathbf{x}_{t}\\) ), which tries to recover a uncorrupted input in several steps. A useful feature of diffusion models is that the number of sampling steps during inference can be chosen by the user after the model is already trained. #### 3.4.4 Inference Schedule During inference, we can accelerate the generation process by using fewer denoising steps than were used during training or use more denoising steps with the hope to increase the quality of outputs. The tuple of time steps used for inference \\((T,T - 1,\\ldots ,t_{0})\\) is called a schedule. The function approximator in the diffusion model is normally conditioned by the sample at a given time step and also the time step itself \\((f_{\\theta}(\\mathbf{x}_{t},t))\\) but as we show in Section 5.4.1, the time step conditioning is not needed. This means that in our case the schedule is defined only by the number of time steps used.",
      "level": 2,
      "line_start": 53,
      "line_end": 64
    },
    {
      "heading": "4 Experimental Setup ### 4.1 Data Representation and Graph Structure Boolean formulas in CNF form can be naturally represented as bipartite graphs where clauses and variables (or literals) form two distinct sets of nodes. In this work, we explore two different graph representations: Literal- Clause Graph (LCG) In the literal- clause graph representation, each literal (both positive and negative polarity of a variable) is represented as a separate node. For a formula with \\(n\\) variables, this results in \\(2n\\) literal nodes. Each literal node is connected to all clause nodes containing that literal. Formally, for a CNF formula \\(\\phi\\) with variables \\(x_{1},\\ldots ,x_{n}\\) and clauses \\(c_{1},\\ldots ,c_{m}\\) , we construct a bipartite graph \\(G_{LC} = (L\\cup C,E)\\) where: - \\(L = \\{l_{1},\\ldots ,l_{n},\\bar{l}_{1},\\ldots ,\\bar{l}_{n}\\}\\) is the set of literal nodes - \\(C = \\{c_{1},\\ldots ,c_{m}\\}\\) is the set of clause nodes - \\((l_{i},c_{j})\\in E\\) if and only if literal \\(l_{i}\\) appears in clause \\(c_{j}\\) Variable- Clause Graph (VCG) In the variable- clause graph representation, each variable (rather than each literal) is represented as a node. For a formula with \\(n\\) variables, this results in exactly \\(n\\) variable nodes. Each variable node is connected to all clause nodes containing either the positive or negative literal of that variable. To retain information about the polarity of literals, we assign edge features \\(p_{ij}\\in \\{- 1,1\\}\\) to each edge \\((x_{i},c_{j})\\) , where \\(p_{ij} = 1\\) if the positive literal \\(x_{i}\\) appears in clause \\(c_{j}\\) , and \\(p_{ij} = - 1\\) if the negative literal \\(\\overline{{x}}_{i}\\) appears in clause \\(c_{j}\\) . Formally, we construct a bipartite graph \\(G_{VC} = (V\\cup C,E,P)\\) where: - \\(V = \\{x_{1},\\ldots ,x_{n}\\}\\) is the set of variable nodes- \\(C = \\{c_{1},\\ldots ,c_{m}\\}\\) is the set of clause nodes- \\((x_{i},c_{j})\\in E\\) if and only if variable \\(x_{i}\\) appears in clause \\(c_{j}\\) (in either polarity)- \\(P:E\\to \\{-1,1\\}\\) maps each edge to its corresponding polarity Both graph representations capture the structure of the Boolean formula, but they differ in how they handle variable polarity. The literal- clause graph explicitly represents both polarities as separate nodes, which increases the number of nodes but simplifies the message passing process of the GNN. The variable- clause graph is more compact but requires handling polarity information through edge features. For the GNNs we use, the variable- clause graph representation is more computationally efficient than the literal- clause graph, reducing both memory requirements and processing time. This efficiency comes from having half as many variable nodes (compared to literal nodes) and avoiding an expensive operation during message passing as will be described in Section 4.2. In our experiments, we compare both representations together with different message passing operations and different training regimes. ### 4.2 Architecture Variants Our GNN architecture variants are derived from the Neuro SAT architecture Selsam et al. [2018] which demonstrated the possibility of using GNNs for SAT solving. The main advantage of this architecture is that it is recurrent and therefore the number of message passing iterations is theoretically not limited. This is not the case for the non- recurrent alternatives with fixed number of layers. We will demonstrate the usefulness of this feature in Section (5.3).",
      "content": "Node Embeddings Each node in the bi- partite graph of the formula is associated with a \\(d\\) - dimensional embedding vector ( \\(d = 64\\) in most of our experiments as a conclusion from an experiment in A.1.4). We initialize these embeddings randomly from a standard normal distribution. For a formula with \\(n\\) variables and \\(m\\) clauses, we have: In the literal-clause graph: \\(2n\\) literal embeddings \\(\\mathbf{l}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) In the variable- clause graph: \\(n\\) variable embeddings \\(\\mathbf{v}_{i}\\in \\mathbb{R}^{d}\\) and \\(m\\) clause embeddings \\(\\mathbf{c}_{j}\\in \\mathbb{R}^{d}\\) Message Passing Mechanism The core of our architecture is a two- phase message passing procedure that alternates between updating clause representations and unknown node representations (literals or variables, depending on the graph type). This process is repeated for a configurable number of iterations \\(T\\) . We primarily use an RNN- based update mechanism, where the node embeddings are the hidden states of the RNN that evolve through message passing iterations. For the variable- clause graph, the message passing at iteration \\(t\\) is defined as: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{v\\in \\mathcal{N}(c)}\\mathbf{M}_{v c}(\\mathbf{h}_{v}^{(t - 1)},p_{v c}),\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{v}^{(t)} = \\mathrm{RNN}_{v}\\left(\\sum_{c\\in \\mathcal{N}(v)}\\mathbf{M}_{c v}(\\mathbf{h}_{c}^{(t)},p_{v c}),\\mathbf{h}_{v}^{(t - 1)}\\right)} \\end{array} \\quad (6)\\] Here, \\(\\mathbf{h}_{c}^{(t)}\\) and \\(\\mathbf{h}_{v}^{(t)}\\) are the hidden states that serve as the actual clause and variable node embeddings for clause nodes and variable nodes respectively. \\(\\mathbf{M}_{v c}\\) and \\(\\mathbf{M}_{c v}\\) are the message transformation functions that operate on the source node embedding and the edge polarity. For the variable- clause graph, we implement these transformation functions as two MLPs that process positive and negative edges differently: \\[\\mathbf{M}_{v c}(\\mathbf{h}_{v},p) = \\left\\{ \\begin{array}{ll}\\mathrm{MLP}_{\\mathrm{pos}}(\\mathbf{h}_{v}) & \\mathrm{if} p > 0\\\\ \\mathrm{MLP}_{\\mathrm{neg}}(\\mathbf{h}_{v}) & \\mathrm{if} p< 0 \\end{array} \\right. \\quad (8)\\] For the literal- clause graph, the message passing mechanism also uses operation, called \"Flip\" bellow, that enforces the logical relationship between complementary literals: \\[\\begin{array}{r l} & {\\mathbf{h}_{c}^{(t)} = \\mathrm{RNN}_{c}\\left(\\sum_{l\\in \\mathcal{N}(c)}\\mathbf{h}_{l}^{(t - 1)},\\mathbf{h}_{c}^{(t - 1)}\\right)}\\\\ & {\\mathbf{h}_{l}^{(t)} = \\mathrm{RNN}_{l}\\left(\\left[\\sum_{c\\in \\mathcal{N}(l)}\\mathbf{h}_{c}^{(t)},\\mathrm{Flip}(\\mathbf{h}_{l}^{(t - 1)})\\right],\\mathbf{h}_{l}^{(t - 1)}\\right)} \\end{array} \\quad (10)\\] where \\([\\cdot ,\\cdot ]\\) denotes vector concatenation. The \\(\\mathrm{Flip}(\\cdot)\\) operation exchanges the embeddings of positive literals with their corresponding negative literals and vice versa. The update function for a given literal embedding can therefore take into account the embedding of the complementary literal. We note, that the \\(\\mathrm{Flip}(\\cdot)\\) operation incurs a significant computational cost, particularly for large formulas. In contrast, the variable- clause graph representation eliminates this expensive operation by dedicating only one node for each variable and directly encoding its polarity in edge features. This efficiency makes the variable- clause approach particularly well- suited for larger formulas where computational demands become a critical factor.",
      "level": 2,
      "line_start": 65,
      "line_end": 67
    }
  ]
}