{
  "sections": {
    "g4satbench_benchmarking_and_advancing_sat_solving": "## Introduction\n\n\nprediction, we evaluate both Neuro SAT and GGNN using multiple- prediction decoding. Our evaluation focuses on three key aspects: (a) the number of distinct predicted assignments, (b) the number of flipped variables between two consecutive iterations, and (c) the number of unsatisfiable clauses associated with the predicted assignments. <center>Figure 5: Results on the predicted assignments with the increased message passing iteration \\(T\\) . Neuro SAT\\* refers to the model trained for satisfiability prediction. </center> As shown in Figure 5, all three GNN models initially generate a wide array of assignment predictions by flipping a considerable number of variables, resulting in a notable reduction in the number of unsatisfiable clauses. However, as the iterations progress, the number of flipped variables diminishes substantially, and most GNN models eventually converge towards predicting a specific assignment or making minimal changes to their predictions when there are no or very few unsatisfiable clauses remaining. This trend is reminiscent of the greedy solving strategy adopted by the LS solver GSAT (Selman et al., 1992), where changes are made to minimize the number of unsatisfied clauses in the new assignment. However, unlike GSAT's approach of flipping one variable at a time and incorporating random selection to break ties, GNN models simultaneously modify multiple variables and potentially converge to a particular unsatisfied assignment and find it challenging to deviate from such a prediction. It is also noteworthy that despite being trained for satisfiability prediction, Neuro SAT\\* demonstrates similar behavior to the GNN models trained for assignment prediction. This observation indicates that GNNs also learn to search for a satisfying assignment implicitly in the latent space while performing satisfiability prediction. To provide more insights into the strengths and limitations of GNN- based heuristics, we further conduct experiments to compare GNN- based SAT solvers against state- of- the- art CDCL and LS- based SAT solvers in Appendix D.2. ## 7 Discussions ### 7.1 Limitations and Future Work While G4SATBench represents a significant step in evaluating GNNs for SAT solving, there are still some limitations and potential future directions to consider. Firstly, G4SATBench primarily focuses on evaluating standalone neural SAT solvers, excluding the exploration of neural- guided SAT solvers that integrate GNNs with search- based SAT solvers. It also should be emphasized that the instances included in G4SATBench are considerably smaller compared to most practical instances found in real- world applications, where GNN models alone are not sufficient for solving such large- scale instances. The efficacy of GNN models in unsat- core prediction shows a promising avenue for combining GNNs with modern SAT solvers, and future research could explore more techniques to effectively leverage these neural- guided SAT solvers to scale up to real- world instances. Secondly, G4SATBench benchmarks general GNN models on the LCG\\* and VCG\\* graph representations for SAT solving, but does not consider sophisticated GNN models designed for specific graph constructions in certain domains, such as Circuit SAT problems. Investigating domain- specific GNN models tailored to the characteristics of specific problems could lead to improved performance in specialized instances. Lastly, all existing GNN- based SAT solvers in the literature are static GNNs, which have limited learning ability to capture the CDCL heuristic. Exploring dynamic GNN models that can effectively learn the CDCL heuristic is also a potential direction for future research.\n\n### 7.2 Conclusion 7.2 Conclusion In this work, we present G4SATBench, a benchmark study that comprehensively evaluates GNN models in SAT solving. G4SATBench offers curated synthetic SAT datasets sourced from various domains and difficulty levels and benchmarks a wide range of GNN- based SAT solvers under diverse settings. Our empirical analysis yields valuable insights into the performances of GNN- based SAT solvers and further provides a deeper understanding of their capabilities and limitations. We hope the proposed G4SATBench will serve as a solid foundation for GNN- based SAT solving and inspire future research in this exciting field. ## Acknowledgments Acknowledgments This work was supported, in part, by Individual Discovery Grants from the Natural Sciences and Engineering Research Council of Canada, and the Canada CIFAR AI Chair Program. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve Circuit- SAT: An unsupervised differentiable approach. In International Conference on Learning Representations (ICLR), 2019a. Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. PDP: A general neural framework for learning constraint satisfaction solvers. ar Xiv preprint ar Xiv:1903.01969, 2019b. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ar Xiv preprint ar Xiv:1607.06450, 2016. Adrian Balint and Andreas Fr\u00f6hlich. Improving stochastic local search for sat with a new probability distribution. In Theory and Applications of Satisfiability Testing- SAT 2010: 13th International Conference, SAT 2010, Edinburgh, UK, July 11- 14, 2010. Proceedings 13, pp. 10- 15. Springer, 2010. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of Satisfiability, volume 185. IOS press, 2009. B\u00e9la Bollob\u00e1s and Paul Erd\u0151s. Cliques in random graphs. In Mathematical Proceedings of the Cambridge Philosophical Society, 1976. Benedikt B\u00fcnz and Matthew Lamm. Graph neural networks and boolean satisfiability. ar Xiv preprint ar Xiv:1702.03592, 2017. Chris Cameron, Rex Chen, Jason Hartford, and Kevin Leyton- Brown. Predicting propositional satisfiability via end- to- end learning. In AAAI Conference on Artificial Intelligence (AAAI), 2020. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020. Ziliang Chen and Zhanfu Yang. Graph neural reasoning may fail in certifying boolean unsatisfiability. ar Xiv preprint ar Xiv:1909.11588, 2019. James M. Crawford and Larry D. Auton. Experimental results on the crossover point in random 3- SAT. Artificial Intelligence, 1996. Haonan Duan, Pashootan Vaezipoor, Max B. Paulus, Yangjun Ruan, and Chris J. Maddison. Augment with care: Contrastive learning for combinatorial problems. In International Conference on Machine Learning (ICML), 2022. Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. ar Xiv preprint ar Xiv:1903.02428, 2019. ABKFM Fleury and Maximilian Heisinger. Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020. SAT COMPETITION, 2020.\n\nJes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. A modularity- based random SAT instances generator. In International Joint Conference on Artificial Intelligence (IJCAI), 2015. Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. Locality in random SAT instances. In International Joint Conference on Artificial Intelligence (IJCAI), 2017. Wenxuan Guo, Junchi Yan, Hui- Ling Zhen, Xijun Li, Mingxuan Yuan, and Yaohui Jin. Machine learning methods in solving the boolean satisfiability problem. ar Xiv preprint ar Xiv:2203.04755, 2022. Jesse Michael Han. Enhancing SAT solvers with glue variable predictions. ar Xiv preprint ar Xiv:2007.02559, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human- level performance on imagenet classification. In IEEE International Conference on Computer Vision (ICCV), 2015. Sean B Holden et al. Machine learning for automated theorem proving: Learning to solve SAT and QSAT. Foundations and Trends\u00ae in Machine Learning, 14(6):807- 989, 2021. Holger H Hoos and Thomas St\u00fctzle. SATLIB: An online resource for research on SAT. Workshop on Satisfiability (SAT), 2000. Sebastian Jaszczur, Michal \u0141uszczyk, and Henryk Michalewski. Neural heuristics for SAT solving. ar Xiv preprint ar Xiv:2005.13406, 2020. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. Thomas N. Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q- learning with graph networks learn a generalizable branching heuristic for a SAT solver? In Advances in Neural Information Processing Systems (Neur IPS), 2020. Massimo Lauria, Jan Elffers, Jakob Nordstr\u00f6m, and Marc Vinyals. Cnfen: A generator of crafted benchmarks. In Theory and Applications of Satisfiability Testing (SAT), 2017. Min Li, Zhengyuan Shi, Qiuxia Lai, Sadaf Khan, Shaowei Cai, and Qiang Xu. On eda- driven learning for sat solving. In Design Automation Conference (DAC), 2023. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations (ICLR), 2016. Zhaoyu Li and Xujie Si. NSNet: A general neural probabilistic framework for satisfiability problems. In Advances in Neural Information Processing Systems (Neur IPS), 2022. Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning (ICML), 2010. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural SAT solver. In International Joint Conference on Neural Networks (IJCNN), 2022. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. Yang, Zachary De Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high- performance deep learning library. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Bart Selman, Hector J. Levesque, and David G. Mitchell. A new method for solving hard satisfiability problems. In National Conference on Artificial Intelligence (AAAI), 1992.\n\nDaniel Selsam and Nikolaj S. Bj\u00f8rner. Guiding high- performance SAT solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing (SAT), 2019. Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations (ICLR), 2019. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui- Ling Zhen, Mingxuan Yuan, and Qiang Xu. Sathermer: Transformer- based unsat core learning. In International Conference on Computer Aided Design (ICCAD), 2023. Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP: A search algorithm for propositional satisfiability. IEEE Transactions on Computers, 1999. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth Mc Millan, and Risto Miikkulainen. Neurocomb: Improving SAT solving with graph neural networks. ar Xiv preprint ar Xiv:2110.14053, 2021. Nathan Wetzler, Marijn Heule, and Warren A. Hunt Jr. Drat- trim: Efficient checking and trimming using expressive clausal proofs. In Theory and Applications of Satisfiability Testing (SAT), 2014. Ben Wieland and Anant P. Godbole. On the domination number of a random graph. The Electronic Journal of Combinatorics, 2001. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019. Zhiyuan Yan, Min Li, Zhengyuan Shi, Wenjie Zhang, Yingcong Chen, and Hongce Zhang. Addressing variable dependency in gnn- based SAT solving. ar Xiv preprint ar Xiv:2304.08738, 2023. Emre Yolcu and Barnab\u00e1s P\u00f3czos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong, and Lu Zhang. Nicolasat: Boosting local search with solution prediction. In International Joint Conference on Artificial Intelligence (IJCAI), 2020.\n\n## A Datasets Generators. To generate high- quality SAT datasets that do not contain trivial instances, we have employed a rigorous process of selecting appropriate parameters for each CNF generator in G4SATBench. Table 7 provides detailed information about the generators we have used. Table 7: Details of the synthetic generators employed in G4SATBench. <table><tr><td>Dataset</td><td>Description</td><td>Parameters</td><td>Notes</td></tr><tr><td>SR</td><td>The SR dataset is composed of pairs of satisfiable and unsatisfiable formulas, with the only difference between each pair being the polarity of a single literal. Given the number of variables n, the synthetic generator iteratively samples k = 1+Bernoulli(b)+Geometric(g) vari-ables uniformly at random without replacement and negates each one with independent probability 50% to build a clause. This procedure continues until the generated formula is unsatisfiable. The satisfiable instance is then constructed by negating the first literal in the last clause of the unsatisfiable one.</td><td>General: b = 0.3, g = 0.4, Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 400)</td><td>The sampling parameters are the same as the original paper (Selsam et al., 2019).</td></tr><tr><td>3-SAT</td><td>The 3-SAT dataset comprises CNF formulas at the phase transition, where the proportion of generated satisfiable and unsatisfiable formu- las is roughly equal. Given the number of variables n and clauses m, the synthetic generator iteratively samples three variables (and their polarities) uniformly at random until m clauses are obtained.</td><td>General: m = 4.258n + 58.26n-2/3, Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 300)</td><td>The parameter m is the same as the paper (Crawford &amp;amp; Auton, 1996)</td></tr><tr><td>CA</td><td>The CA dataset contains SAT instances that are designed to mimic the community structures and modularity features found in real-world industrial instances. Given variable number n, clause number m, clause size k, community number c, and modularity Q, the synthetic generator iteratively selects k literals in the same community uni- formly at random with probability P = Q + 1/c and selects k literals in the distinct community uniformly at random with probability 1-P to build a clause and repeat for m times to construct a CNF formula.</td><td>General: m ~ Uniform(13n, 15n), k ~ Uniform(4, 5), c ~ Uniform(3, 10), Q ~ Uniform(0.7, 0.9) Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 400)</td><td>The parameters are selected based on the experiments in the original paper (Gir\u00e1ldez-Cru &amp;amp; Levy, 2015) and our study to ensure that the generated SAT instances have a balance of satisfiability and unsatisfiability.</td></tr><tr><td>PS</td><td>PS dataset encompasses SAT instances with a power-law distribution in the number of variable occurrences (popularity), and good class- tering between them (similarity). Given variable number n, clause number m, and average clause size k, the synthetic generator first as- signs random angles \u03b8i, \u03b8j \u2208 [0, 2\u03c0] to each variable i and each clause j, and then randomly samples variable i in clause j with the proba- bility P = 1/(1+(i\u03b2j\u03b2i/R)T). Here, \u03b8ij = \u03c0-|\u03c0-|\u03b8i-|\u03b8j| is the angle between variable i and clause j. The exponent parameters \u03b2 and \u03b2\u2032 control the power-law distribution of variable occurrences and clause size respectively. The temperature parameter T controls the sharpness of the probability distribution, while R is an approximate normalization constant that ensures the average number of selected edges is km.</td><td>General: m ~ Uniform(6n, 8n), k ~ Uniform(4, 5), \u03b2 ~ Uniform(0, 1), \u03b2\u2032 = 1, c ~ Uniform(3, 10), T ~ Uniform(0.75, 1.5) Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 300)</td><td>The parameters are selected based on the experiments in the original paper (Gir\u00e1ldez-Cru &amp;amp; Levy, 2017) and our study to ensure that the generated SAT instances have a balance of satisfiability and unsatisfiability.</td></tr><tr><td>k-Clique</td><td>The k-Clique dataset includes SAT instances that encode the k-Clique problem, which involves determining whether there exists a clique (i.e., a subset of vertices that are all adjacent to each other) with v vertices in a given graph. Given the number of cliques k, the synthetic generator produces an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then transforms the corresponding k-Clique problem into a SAT instance.</td><td>General: p = (v)k-1/(v), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(3, 4), Medium dataset: v ~ Uniform(15, 20), k ~ Uniform(3, 5), Hard dataset: v ~ Uniform(20, 25), k ~ Uniform(4, 6)</td><td>The parameter p is selected based on the paper (Bollob\u00e1s &amp;amp; Erd\u0151s, 1976), making the expected number of k-Cliques in the generated graph equals 1.</td></tr><tr><td>k-Domset</td><td>The k-Domset dataset contains SAT instances that encode the k-Dominating Set problem. This problem is to determine whether there exists a dominating set (i.e., a subset of vertices such that every vertex in the graph is either in the subset or adjacent to a vertex in the sub- set) with at most k vertices in a given graph. Given the domination number k, the synthetic generator produces an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then transforms the corresponding k-Dominating Set problem into a SAT instance.</td><td>General: p = 1-(1-(v)k-1/(v)k), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(2, 3), Medium dataset: v ~ Uniform(15, 20), k ~ Uniform(3, 5), Hard dataset: v ~ Uniform(20, 25), k ~ Uniform(4, 6)</td><td>The parameter p is selected based on the paper (Wieland &amp;amp; Godbole, 2001), making the expected number of domination set with size k in the generated graph equals 1.</td></tr><tr><td>k-Vercov</td><td>The k-Vercov dataset consists of SAT instances that encode the k-Vercov problem, i.e., check whether there exists a set of k vertices in a graph such that every edge has at least one endpoint in this set. Given the vertex cover number k, the synthetic generator produces a complement graph of an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then converts the corresponding k-Vercov Cover problem into a SAT instance.</td><td>General: p = (v)k-1/(v), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(3, 5), Medium dataset: v ~ Uniform(10, 20), k ~ Uniform(6, 8), Hard dataset: v ~ Uniform(15, 25), k ~ Uniform(9, 10)</td><td>The generation process and the parameter are selected based on the relationship between k-Vercov Cover and k-Clique problems, making the size of the minimum vertex cover in the generated graph around k.</td></tr></table>\n\nStatistics. To provide a comprehensive understanding of our generated datasets, we compute several characteristics across three difficulty levels. These statistics include the average number of variables and clauses, as well as graph measures such as average clustering coefficient (in VIG) and modularity (in VIG, VCG, and LCG). The dataset statistics are summarized in Table 8. Table 8: Dataset statistics across difficulty levels in G4SATBench. <table><tr><td rowspan=\"2\">Dataset</td><td colspan=\"6\">Easy Difficulty</td><td colspan=\"6\">Medium Difficulty</td><td colspan=\"6\">Hard Difficulty</td></tr><tr><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td></tr><tr><td>SR</td><td>25.00</td><td>148.35</td><td>0.98</td><td>0.00</td><td>0.25</td><td>0.33</td><td>118.36</td><td>646.54</td><td>0.62</td><td>0.06</td><td>0.31</td><td>0.37</td><td>299.64</td><td>1613.86</td><td>0.32</td><td>0.09</td><td>0.32</td><td>0.37</td></tr><tr><td>3-SAT</td><td>25.05</td><td>113.69</td><td>0.72</td><td>0.06</td><td>0.36</td><td>0.46</td><td>120.00</td><td>513.14</td><td>0.27</td><td>0.16</td><td>0.43</td><td>0.51</td><td>250.44</td><td>1067.34</td><td>0.14</td><td>0.17</td><td>0.45</td><td>0.52</td></tr><tr><td>CA</td><td>31.66</td><td>303.48</td><td>0.65</td><td>0.19</td><td>0.73</td><td>0.73</td><td>120.27</td><td>1661.07</td><td>0.54</td><td>0.38</td><td>0.80</td><td>0.80</td><td>299.68</td><td>4195.50</td><td>0.59</td><td>0.57</td><td>0.80</td><td>0.80</td></tr><tr><td>PS</td><td>25.41</td><td>176.68</td><td>0.98</td><td>0.00</td><td>0.27</td><td>0.32</td><td>118.75</td><td>822.78</td><td>0.86</td><td>0.05</td><td>0.35</td><td>0.37</td><td>249.61</td><td>1728.34</td><td>0.77</td><td>0.08</td><td>0.38</td><td>0.28</td></tr><tr><td>A-Clique</td><td>34.85</td><td>592.89</td><td>0.90</td><td>0.03</td><td>0.45</td><td>0.49</td><td>69.56</td><td>2220.05</td><td>0.91</td><td>0.03</td><td>0.48</td><td>0.49</td><td>112.87</td><td>5543.26</td><td>0.88</td><td>0.04</td><td>0.49</td><td>0.50</td></tr><tr><td>k-Domest</td><td>41.90</td><td>369.40</td><td>0.70</td><td>0.26</td><td>0.47</td><td>0.53</td><td>90.64</td><td>1736.22</td><td>0.70</td><td>0.21</td><td>0.49</td><td>0.51</td><td>137.31</td><td>4022.48</td><td>0.70</td><td>0.20</td><td>0.49</td><td>0.51</td></tr><tr><td>k-Verox</td><td>45.41</td><td>484.28</td><td>0.66</td><td>0.16</td><td>0.48</td><td>0.53</td><td>107.40</td><td>2634.14</td><td>0.69</td><td>0.16</td><td>0.49</td><td>0.51</td><td>190.24</td><td>8190.94</td><td>0.69</td><td>0.16</td><td>0.50</td><td>0.51</td></tr></table> ## B GNN Models Message-passing schemes on VCG*. Recall that VCG* incorporates two distinct edge types, G4SATBench employs different functions to execute heterogeneous message-passing in each direction of each edge type. Formally, we define a d-dimensional embedding for each variable and clause node, denoted by \\(h_l\\) and \\(h_c\\), respectively. These embeddings are initialized to two learnable vectors \\(h_v^0\\) and \\(h_c^0\\), depending on the node type. At the \\(k\\)-th iteration of message passing, these hidden representations are updated as follows: \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^+ \\left(h_v^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^- \\left(h_v^{(k-1)}\\right)\\right\\}\\right), h_c^{(k-1)}\\right), \\quad (7)\\] \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^+ \\left(h_c^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^- \\left(h_c^{(k-1)}\\right)\\right\\}\\right), h_v^{(k-1)}\\right),\\] where \\(c^+\\) and \\(c^-\\) denote the sets of variable nodes that occur in the clause \\(c\\) with positive and negative polarity, respectively. Similarly, \\(v^+\\) and \\(v^-\\) denote the sets of clause nodes where variable \\(v\\) occurs in positive and negative form. \\(\\mathrm{MLP}_v^+\\), \\(\\mathrm{MLP}_v^-\\), \\(\\mathrm{MLP}_c^+\\), and \\(\\mathrm{MLP}_c^-\\) are four MLPs. \\(\\mathrm{UPD}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. GNN baselines. Table 9 summarizes the message-passing algorithms of the GNN models used in G4SATBench. We adopt heterogeneous versions of GCN (Kipf & Welling, 2017), GGNN (Li et al., 2016), and GIN (Xu et al., 2019) on both LCG* and VCG*, while maintaining the original Neuro SAT (Selsam et al., 2019) only on LCG*. ## C Benchmarking Evaluation ### C.1 Implementation Details In G4SATBench, we provide the ground truth of satisfiability and satisfying assignments by calling the state-of-the-art modern SAT solver Ca Di Ca L (Fleury & Heisinger, 2020) and generate the truth labels for unsat- core variables by invoking the proof checker DRAT-trim (Wetzler et al., 2014). All neural networks in our study are implemented using Py Torch (Paszke et al., 2019) and Py Torch Geometric (Fey & Lenssen, 2019). For all GNN models, we set the feature dimension \\(d\\) to 128 and the number of message passing iterations \\(T\\) to 32. The MLPs in the models consist of two hidden layers with the Re LU (Nair & Hinton, 2010) activation function. To select the optimal hyperparameters for each GNN baseline, we conduct a grid search over several settings. Specifically, we explore different learning rates from \\(\\{10^{-3}, 5 \\times 10^{-4}, 10^{-4}, 5 \\times 10^{-5}, 10^{-5}\\}\\), training epochs from \\(\\{50, 100, 200\\}\\), weight decay values from \\(\\{10^{-6}, 10^{-7}, 10^{-8}, 10^{-9}, 10^{-10}\\}\\), and gradient clipping norms from \\(\\{0.1, 0.5, 1\\}\\). We employ Adam (Kingma & Ba, 2015) as the optimizer and set the batch size to 128, 64, or 32 to fit within the maximum GPU memory (48G). For the parameters \\(\\tau\\) and \\(\\kappa\\) of the unsupervised loss in Equation 4 and Equation 5, we try the default settings (\\(\\tau = t^{-0.4}\\) and \\(\\kappa = 10\\), where \\(t\\) is the global step during training) as the original paper (Amizadeh et al., 2019a) as well as other values (\\(\\tau \\in \\{0.05, 0.1, 0.2, 0.5\\}\\), \\(\\kappa \\in \\{1, 2, 5\\}\\)) and empirically find \\(\\tau = 0.1\\), \\(\\kappa = 1\\) yield the best results. Furthermore,\n\nTable 9: Supported GNN models in G4SATBench. <table><tr><td>Graph</td><td>Method</td><td>Message-passing Algorithm</td><td>Notes</td></tr><tr><td rowspan=\"2\">Neuro SAT</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>s, s1 are the hidden states which are initialized to zero vectors.</td></tr><tr><td>h(c), s(c) = Layer Norm LSTM2</td><td>h(c), s(c) = Layer Norm LSTM2</td><td></td></tr><tr><td rowspan=\"2\">LCG*</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and literal node l in LCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">GGNN</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GCN</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and variable node v in VCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">VCG*</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = GIN</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = GIN</td><td></td></tr></table> it is important to note that we use three different random seeds to benchmark the performance of different GNN models and assess the generalization ability of Neuro SAT and GGNN using one seed for simplicity. ## C.2 Satisfiability Prediction Evaluation across different difficulty levels. The complete results of Neuro SAT and GGNN across different difficulty levels are presented in Figure 6. Consistent with the findings on the SR and 3- SAT datasets, both GNN models exhibit limited generalization ability to larger instances beyond their training data, while displaying relatively better performance on smaller instances. This observation suggests that training these models on more challenging instances could potentially enhance their generalization ability and improve their performance on larger instances. <center>Figure 6: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different message passing iterations. To investigate the impact of message-passing iterations on the performance of GNN models during training and testing, we conducted experiments with varying iteration values. Figure 7 presents the results of Neuro SAT and GGNN trained and evaluated with different message passing iterations. Remarkably, using a training iteration value of 32 consistently yielded the best performance for both models. Conversely, employing too small or too large iteration values during training resulted in decreased performance. Furthermore, the models trained with 32 iterations also demonstrated good generalization ability to testing iterations 16 and 64. These findings emphasize the critical importance of selecting an appropriate message-passing iteration to ensure optimal learning and reasoning within GNN models. <center>Figure 7: Classification accuracy of satisfiability across different message passing iterations \\(T\\) . The x-axis denotes testing iterations and the y-axis denotes training iterations. </center> ## C.3 Satisfying Assignment Prediction Evaluation with different training losses. Table 10 presents the complete results of each GNN baseline across three different training objectives. Like the results of Neuro SAT and GGNN, all other GNN models with unsupervised training outperform their supervised training counterparts. Table 10: Solving accuracy on identical distribution with different training losses. The top and bottom 7 rows represent the results for easy and medium datasets, respectively. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"3\">SR</td><td colspan=\"3\">3-SAT</td><td colspan=\"3\">CA</td><td colspan=\"3\">PS</td><td colspan=\"3\">k-Clique</td><td colspan=\"3\">k-Domest</td><td colspan=\"3\">k-Vercov</td></tr><tr><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>88.47</td><td>82.30</td><td>79.79</td><td>78.39</td><td>80.23</td><td>80.59</td><td>0.27</td><td>82.17</td><td>89.34</td><td>39.18</td><td>89.23</td><td>88.79</td><td>66.30</td><td>88.34</td><td>63.43</td><td>69.61</td><td>96.74</td><td>98.85</td><td>85.15</td><td>99.36</td><td>99.73</td></tr><tr><td>GCN</td><td>83.74</td><td>73.09</td><td>77.02</td><td>70.34</td><td>74.79</td><td>75.31</td><td>0.17</td><td>75.30</td><td>82.41</td><td>39.66</td><td>82.75</td><td>84.89</td><td>63.85</td><td>82.60</td><td>86.17</td><td>59.29</td><td>97.50</td><td>97.55</td><td>76.83</td><td>99.16</td><td>99.28</td></tr><tr><td>GGNN</td><td>84.13</td><td>76.39</td><td>78.75</td><td>72.87</td><td>76.55</td><td>76.42</td><td>0.29</td><td>78.13</td><td>84.08</td><td>38.82</td><td>84.44</td><td>86.29</td><td>60.80</td><td>84.60</td><td>87.12</td><td>68.36</td><td>97.49</td><td>98.06</td><td>82.06</td><td>-</td><td>99.34</td></tr><tr><td>GIN</td><td>83.81</td><td>81.45</td><td>80.39</td><td>73.99</td><td>78.47</td><td>76.24</td><td>0.20</td><td>78.44</td><td>85.15</td><td>39.13</td><td>85.31</td><td>85.43</td><td>56.85</td><td>84.48</td><td>85.11</td><td>68.93</td><td>96.99</td><td>97.43</td><td>81.49</td><td>99.28</td><td>99.38</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>83.38</td><td>84.19</td><td>78.00</td><td>76.60</td><td>84.42</td><td>79.23</td><td>14.98</td><td>76.64</td><td>83.79</td><td>51.48</td><td>85.88</td><td>83.06</td><td>56.27</td><td>85.28</td><td>86.91</td><td>66.32</td><td>97.62</td><td>96.74</td><td>78.67</td><td>-</td><td>93.51</td></tr><tr><td>GGNN</td><td>86.30</td><td>87.16</td><td>81.00</td><td>77.96</td><td>88.97</td><td>79.32</td><td>15.11</td><td>76.32</td><td>83.12</td><td>47.67</td><td>86.85</td><td>87.17</td><td>66.86</td><td>86.31</td><td>87.48</td><td>66.42</td><td>-</td><td>98.42</td><td>82.61</td><td>-</td><td>99.52</td></tr><tr><td>GIN</td><td>84.61</td><td>89.56</td><td>83.27</td><td>79.23</td><td>87.65</td><td>81.72</td><td>17.81</td><td>83.28</td><td>86.03</td><td>48.92</td><td>91.21</td><td>85.65</td><td>60.67</td><td>86.12</td><td>88.09</td><td>67.67</td><td>-</td><td>81.01</td><td>99.38</td><td>99.41</td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>34.97</td><td>25.00</td><td>37.25</td><td>20.07</td><td>30.40</td><td>41.61</td><td>0.00</td><td>35.45</td><td>70.83</td><td>3.64</td><td>60.28</td><td>71.03</td><td>56.61</td><td>41.45</td><td>-</td><td>52.09</td><td>95.06</td><td>96.18</td><td>74.77</td><td>67.44</td><td>95.99</td></tr><tr><td>GCN</td><td>13.19</td><td>13.76</td><td>19.21</td><td>8.87</td><td>20.50</td><td>24.58</td><td>0.00</td><td>30.20</td><td>54.04</td><td>14.45</td><td>45.16</td><td>56.29</td><td>55.36</td><td>61.82</td><td>66.33</td><td>43.50</td><td>92.86</td><td>94.89</td><td>67.83</td><td>-</td><td>93.84</td></tr><tr><td>GGNN</td><td>14.15</td><td>16.55</td><td>21.18</td><td>7.96</td><td>22.84</td><td>25.68</td><td>0.00</td><td>28.12</td><td>50.66</td><td>2.33</td><td>44.89</td><td>57.96</td><td>52.35</td><td>54.29</td><td>68.91</td><td>49.07</td><td>-</td><td>92.26</td><td>69.21</td><td>66.37</td><td>94.30</td></tr><tr><td>GIN</td><td>15.36</td><td>18.60</td><td>22.17</td><td>9.66</td><td>21.38</td><td>24.93</td><td>0.00</td><td>35.76</td><td>57.81</td><td>2.02</td><td>43.43</td><td>57.62</td><td>53.07</td><td>44.60</td><td>66.32</td><td>44.39</td><td>93.3</td><td>93.82</td><td>70.59</td><td>55.59</td><td>95.69</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>20.59</td><td>9.21</td><td>22.44</td><td>12.48</td><td>17.00</td><td>29.53</td><td>0.44</td><td>39.04</td><td>48.99</td><td>2.29</td><td>35.99</td><td>55.46</td><td>46.09</td><td>25.90</td><td>68.62</td><td>46.96</td><td>-</td><td>92.68</td><td>69.15</td><td>-</td><td>96.46</td></tr><tr><td>GGNN</td><td>28.04</td><td>27.72</td><td>33.37</td><td>16.46</td><td>29.65</td><td>35.95</td><td>0.56</td><td>48.13</td><td>49.93</td><td>3.12</td><td>51.73</td><td>65.11</td><td>44.26</td><td>48.92</td><td>56.43</td><td>51.01</td><td>-</td><td>71.97</td><td>-</td><td>95.23</td></tr><tr><td>GIN</td><td>26.73</td><td>26.48</td><td>31.97</td><td>14.64</td><td>26.86</td><td>35.81</td><td>0.64</td><td>44.06</td><td>63.84</td><td>3.38</td><td>58.03</td><td>64.66</td><td>55.47</td><td>56.97</td><td>67.78</td><td>46.98</td><td>-</td><td>95.28</td><td>69.40</td><td>-</td><td>96.96</td></tr></table> Evaluation across different difficulty levels. The performance of Neuro SAT across different difficulty levels is shown in Figure 8. Notably, training on medium datasets yields superior generalization performance compared to training on easy datasets. This suggests that training on more challenging SAT instances with larger sizes can enhance the model's ability to generalize to a wider range of problem complexities. <center>Figure 8: Solving accuracy of Neuro SAT across different difficulty levels (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different datasets. Figure 9 illustrates the performance of Neuro SAT across different datasets. For easy datasets, we observe that Neuro SAT demonstrates a strong generalization ability to other datasets when trained on the SR, 3- SAT, CA, and PS datasets. However, when trained on the \\(k\\) - Clique, \\(k\\) - Domset, and \\(k\\) - Vercov datasets, which involve specific graph structures inherent to their combinatorial problems, Neuro SAT struggles to generalize effectively. This observation indicates that the GNN model may overfit to leverage specific graph features associated with these combinatorial datasets, without developing a generalized solving strategy that can be applied to other problem domains for satisfying assignment prediction. For medium datasets, Neuro SAT also faces challenges in generalization, as its performance is relatively limited. This can be attributed to the difficulty of these datasets, where finding satisfying assignments is much harder than easy datasets. <center>Figure 9: Solving accuracy of Neuro SAT across different datasets (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation with different inference algorithms. Figure 10 illustrates the results of Neuro SAT using various decoding algorithms (with \\(\\mathrm{UNS}_2\\) as the training loss). Notably, all three decoding algorithms demonstrate similar performances across all datasets. This observation indicates that utilizing the standard readout after message passing is sufficient for predicting a satisfying assignment. Also, the GNN model has successfully learned to identify potential satisfying assignments within the latent space, which can be extracted by clustering the literal embeddings. <center>Figure 10: Solving accuracy of Neuro SAT with different inference algorithms. </center> ## Evaluation with unsatisfiable training in- Evaluation with unsatisfiable training instances. Following previous works (Amizadeh et al., 2019a;b; Ozolins et al., 2022), our evaluation of GNN models focuses solely on satisfiable instances. However, in practical scenarios, the satisfiability of instances may not be known before training. To address this gap, we explore the effectiveness of training Neuro SAT using the unsupervised loss \\(\\mathrm{UNS}_2\\) on noisy datasets that contain unsatisfiable instances. Table 11 presents the results of Neuro SAT when trained on such datasets, where \\(50\\%\\) of the instances are unsatisfiable. Interestingly, incorporating unsatisfiable instances for training does not significantly affect the performance of the GNN model. This finding highlights the potential utility of training GNN models using \\(\\mathrm{UNS}_2\\) loss on new datasets, irrespective of any prior knowledge regarding their satisfiability. Table 11: Solving accuracy of Neuro SAT when trained on noisy datasets. Values in parentheses indicate the performance difference compared to the model trained without unsatisfiable instances. The \\(k\\) -Clique dataset is excluded as Neuro SAT fails during training. <table><tr><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td></tr><tr><td>78.84<br>(-0.95)</td><td>80.48<br>(-0.11)</td><td>87.01<br>(-2.33)</td><td>88.66<br>(-0.13)</td><td>98.00<br>(-0.85)</td><td>95.24<br>(-4.49)</td><td>37.21<br>(-0.04)</td><td>41.75<br>(+0.14)</td><td>76.49<br>(+5.64)</td><td>72.52<br>(+1.46)</td><td>94.93<br>(-1.25)</td><td>96.18<br>(+0.19)</td></tr></table> ## C.4 Unsat-core Variable Prediction Evaluation across different difficulty levels. The results across different difficulty levels are presented in Figure 11. Remarkably, both Neuro SAT and GGNN exhibit a strong generalization ability when trained on easy or medium datasets. This suggests that GNN models can effectively learn and generalize from the\n\ncharacteristics and patterns present in these datasets, enabling them to perform well on a wide range of problem complexities. <center>Figure 11: Classification accuracy of unsat-core variables across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation across different datasets. Figure 12 shows the generalization results across different datasets. Both Neuro SAT and GGNN demonstrate good generalization performance to datasets that are different from their training data, except for the CA dataset. This discrepancy can be attributed to the specific characteristics of the CA dataset, where the number of unsat- core variables is significantly smaller compared to the number of variables not in the unsat core. In contrast, other datasets have a different distribution, where the number of unsat- core variables is much larger. This variation in distribution presents a challenge for the models' generalization ability on the CA dataset. <center>Figure 12: Classification accuracy of unsat-core variables across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> ## D Advancing Evaluation ## D.1 Implementation details To create the augmented datasets, we leverage Ca Di Ca L (Fleury & Heisinger, 2020) to generate a DART proof (Wetzler et al., 2014) for each SAT instance, which tracks the clause learning procedure and records all the learned clauses during the solving process. These learned clauses are then added to each instance, with a maximum limit of 1,000 clauses. For experiments on augmented datasets, we keep all training settings identical to those used for the original datasets. For contrastive pretraining experiments, we treat each original formula and its augmented counterpart as a positive pair and all other instances in a mini- batch as negative pairs. We use an MLP projection to map the graph embedding \\(z_{i}\\) of each formula to \\(m_{i}\\) and employ the Sim CLR's contrastive loss (Chen et al., 2020), where the loss function for a positive pair of examples \\((i,j)\\) in a mini- batch of size \\(2N\\) is defined as: \\[\\mathcal{L}_{i,j} = -\\log \\frac{\\exp(\\sin(m_{i},m_{j}) / \\tau)}{\\sum_{k = 1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\sin(m_{i},m_{k}) / \\tau)}. \\quad (8)\\]\n\npredicts marginal distributions of all satisfying solutions to solve the SAT problem. Moreover, most previous research has experimented on different datasets that vary in a range of settings (e.g., data distribution, instance size, and dataset size), which leads to a lack of unified and standardized datasets for training and evaluation. Additionally, some work (Amizadeh et al., 2019b; Shi et al., 2023; Yan et al., 2023) has noted the difficulty of re- implementing prior approaches as baselines, rendering it arduous to draw consistent conclusions about the performance of peer methods. All of these issues impede the development of GNN- based solvers for SAT solving. To systematically quantify the progress in this field and facilitate rapid, reproducible, and generalizable research, we propose G4SATBench, the first comprehensive benchmark study for SAT solving with GNNs. G4SATBench is characterized as follows: - First, we construct a large and diverse collection of SAT datasets that includes instances from distinct sources and difficulty levels. Specifically, our benchmark consists of 7 different datasets from 3 benchmark families, including random instances, pseudo-industrial instances, and combinatorial problems. It not only covers a wide range of prior datasets but also introduces 3 levels of difficulty for each dataset to enable fine-grained analyses. - Second, we re-implement various GNN-based SAT solvers with unified interfaces and configuration settings, establishing a general evaluation protocol for fair and comprehensive comparisons. Our framework allows for evaluating different GNN models in SAT solving with various prediction tasks, training objectives, and inference algorithms, encompassing the diverse learning frameworks employed in the existing literature. - Third, we present baseline results and conduct thorough analyses of GNN-based SAT solvers, providing a detailed reference of prior work and laying a solid foundation for future research. Our evaluations assess the performances of different choices of GNN models (e.g., graph constructions, message-passing schemes) with particular attention to some critical parameters (e.g., message-passing iterations), as well as their generalization ability across different distributions. - Lastly, we conduct a series of in-depth experiments to explore the learning abilities of GNN-based SAT solvers. Specifically, we compare the training and solving processes of GNNs with the heuristics employed in both CDCL and LS-based SAT solvers. Our experimental results reveal that GNNs tend to develop a solving heuristic similar to greedy local search to find a satisfying assignment but fail to effectively learn the CDCL heuristic in the latent space. We believe that G4SATBench will help the research community to make significant strides in understanding the capabilities and limitations of GNNs for solving SAT and facilitate further endeavors in this domain. ## 2 Related Work SAT solving with GNNs. Existing GNN- based SAT solvers can be broadly categorized into two branches (Holden et al., 2021; Guo et al., 2022): standalone neural solvers and neural- guided solvers. Standalone neural solvers utilize GNNs to solve SAT instances directly. For example, a stream of research (B\u00fcnz & Lamm, 2017; Selsam et al., 2019; Jaszczur et al., 2020; Cameron et al., 2020; Shi et al., 2023) focuses on predicting the satisfiability of a given formula, while several alternative approaches (Amizadeh et al., 2019a;b; Ozolins et al., 2022; Li et al., 2023; Yan et al., 2023) aim to construct a satisfying assignment. Neural- guided solvers, on the other hand, integrate GNNs with modern SAT solvers, trying to improve their search heuristics with the prediction of GNNs. These methods typically train GNN models using supervised learning on some tasks such as unsat- core variable prediction (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021), satisfying assignment prediction (Zhang et al., 2020), glue variable prediction (Han, 2020), and assignment marginal prediction (Li & Si, 2022), or through reinforcement learning (Yolcu & P\u00f3czos, 2019; Kurin et al., 2020) by modeling the entire search procedure as a Markov decision process. Despite the rich literature on SAT solving with GNNs, there is no benchmark study to evaluate and compare the performance of these GNN models. We hope the proposed G4SATBench would address this gap.\n\nHere, \\(\\mathbb{1}_{[k \\neq i]}\\) is an indicator function that evaluates to 1 if \\(k \\neq i\\) , \\(\\tau\\) is a temperature parameter, and \\(\\text{sim}(\\cdot , \\cdot)\\) is the similarity function defined as \\(\\text{sim}(m_i, m_j) = m_i^\\top m_j / \\|m_i\\| \\|m_j\\|\\) . The final loss is the average over all positive pairs. In our experiments, we set the temperature parameter to 0.5 and utilize a learning rate of \\(10^{- 4}\\) with a weight decay of \\(10^{- 8}\\) . The pretraining process is performed for a total of 100 epochs. Once the pretraining is completed, we keep the GNN model and remove the projection head for downstream tasks. For experiments involving random initialization, we utilize Kaiming Initialization (He et al., 2015) to initialize all literal/variable and clause embeddings during both training and testing. For the predicted assignments, we utilize 2- clustering decoding to construct two possible assignment predictions for Neuro SAT\\* at each iteration. When calculating the number of flipped variables and unsatisfiable clauses for Neuro SAT\\*, we only consider the better assignment prediction of the two at each iteration, which is the one that satisfies more clauses. All other experimental settings remain the same as in the benchmarking evaluation. ## D.2 Comparisons with State-of-the-art SAT Solvers We compare Neuro SAT with two advanced CDCL and LS solvers, Ca Di Ca L Fleury & Heisinger (2020) and Sparrow (Balint & Fr\u00f6hlich, 2010). To enable a fair comparison, we first configure Sparrow to generate the same number of assignments as Neuro SAT by setting its maximum flip number to 32, allowing for an apples- to- apples comparison of both solvers' accuracy and execution time. Subsequently, we allow Sparrow and Ca Di Ca L to run without constraints to solve the satisfiable instances in G4SATBench. Considering that Neuro SAT processes a batch of problems in parallel on GPUs, we calculate its per- instance runtime by dividing the total execution time by the number of testing instances. The results, summarized in Table 12, indicate that GNN- based heuristics could outperform modern local search solvers like Sparrow, generating more satisfying assignments extremely fast when constrained to output a limited number of solutions. However, once such a constraint is lifted, both Sparrow and Ca Di Ca L can traverse the solution space efficiently and solve all satisfiable instances in G4SATBench, while GNN models like Neuro SAT may find it challenging due to their limited exploration capacity as evidenced in Figure 5a. Nevertheless, it's crucial to recognize that while GNN models are hard to compete with Ca Di Ca L and Sparrow, their assignment predictions could still serve as good initializations in these solvers, potentially leading to better performance (Zhang et al., 2020; Li & Si, 2022). Table 12: Results of Neuro SAT, Sparrow, and Ca Di Ca L. The top 2 rows represent the solving accuracy (%), and the bottom 4 rows represent the running time (second) per instance. Sparrow\\\\* refers to Sparrow limited to a maximum of 32 flips. <table><tr><td rowspan=\"2\">Method</td><td colspan=\"7\">Easy Datasets</td><td colspan=\"7\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td>Neuro SAT</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.461</td><td>70.83</td><td>71.03</td><td>32.48</td><td>96.18</td><td>95.99</td></tr><tr><td>Sparrow*</td><td>56.03</td><td>52.09</td><td>85.48</td><td>77.25</td><td>53.68</td><td>37.15</td><td>31.61</td><td>1.64</td><td>1.85</td><td>12.68</td><td>10.72</td><td>12.99</td><td>1.27</td><td>0.53</td></tr><tr><td>Neuro SAT</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.003</td><td>0.002</td><td>0.003</td><td>0.008</td><td>0.006</td><td>0.009</td><td>0.010</td><td>0.009</td><td>0.006</td><td>0.007</td></tr><tr><td>Sparrow*</td><td>0.005</td><td>0.005</td><td>0.006</td><td>0.006</td><td>0.005</td><td>0.005</td><td>0.005</td><td>0.008</td><td>0.007</td><td>0.006</td><td>0.006</td><td>0.006</td><td>0.007</td><td>0.006</td></tr><tr><td>Sparrow</td><td>0.007</td><td>0.007</td><td>0.008</td><td>0.008</td><td>0.007</td><td>0.009</td><td>0.009</td><td>0.013</td><td>0.013</td><td>0.010</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td></tr><tr><td>Ca Di Ca L</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.043</td><td>0.016</td><td>0.018</td><td>0.015</td><td>0.013</td><td>0.012</td></tr></table>\n\nSAT datasets. Several established SAT benchmarks, including the prestigious SATLIB (Hoos & St\u00fctzle, 2000) and the SAT Competitions over the years, have provided a variety of practical instances to assess the performance of modern SAT solvers. Regrettably, these datasets are not particularly amenable for GNNs to learn from, given their relatively modest scale (less than 100 instances for a specific domain) or overly extensive instances (exceeding 10 million variables and clauses). To address this issue, researchers have turned to synthetic SAT instance generators (Gir\u00e1ldez- Cruz & Levy, 2015; 2017; Lauria et al., 2017; Selsam et al., 2019), which allow for the creation of a flexible number of instances with customizable settings. However, most of the existing datasets generated from these sources are limited to a few domains (less than 3 generators), small in size (less than 10k instances), or easy in difficulty (less than 40 variables within an instance), and there is no standardized dataset for evaluation. In G4SATBench, we include a variety of synthetic generators with carefully selected configurations, aiming to construct a broad collection of SAT datasets that are highly conducive for training and evaluating GNNs. ## 3 Preliminaries The SAT problem. In propositional logic, a Boolean formula is constructed from Boolean variables and logical operators such as conjunctions \\((\\wedge)\\) , disjunctions \\((\\vee)\\) , and negations \\((\\neg)\\) . It is typical to represent Boolean formulas in conjunctive normal form (CNF), expressed as a conjunction of clauses, where each clause is a disjunction of literals, which can be either a variable or its negation. Given a CNF formula, the SAT problem is to determine if there exists an assignment of boolean values to its variables such that the formula evaluates to true. If this is the case, the formula is called satisfiable; otherwise, it is unsatisfiable. For a satisfiable instance, one is expected to construct a satisfying assignment to prove its satisfiability. On the other hand, for an unsatisfiable formula, one can find a minimal subset of clauses whose conjunction is still unsatisfiable. Such a set of clauses is termed the unsat core, and variables in the unsat core are referred to as unsat- core variables. Graph representations of CNF formulas. Traditionally, a CNF formula can be represented using 4 types of graphs (Biere et al., 2009): Literal- Clause Graph (LCG), Variable- Clause Graph (VCG), Literal- Incidence Graph (LIG), and Variable- Incidence Graph (VIG). The LCG is a bipartite graph with literal and clause nodes connected by edges indicating the presence of a literal in a clause. The VCG is formed by merging the positive and negative literals of the same variables in LCG. The LIG, on the other hand, only consists of literal nodes, with edges indicating co- occurrence in a clause. Lastly, the VIG is derived from LIG using the same merging operation as VCG. ## 4 G4SATBench: A Benchmark Study on GNNs for SAT Solving The goal of G4SATBench is to establish a general framework that enables comprehensive comparisons and evaluations of various GNN- based SAT solvers. In this section, we will delve into the details of G4SATBench, including its datasets, GNN models, prediction tasks, as well as training and testing methodologies. The overview of the G4SATBench framework is shown in Figure 1. ### 4.1 Datasets G4SATBench is built on a diverse set of synthetic CNF generators. It currently consists of 7 datasets sourced from 3 distinct domain areas: random problems, pseudo- industrial problems, and combinatorial problems. Specifically, we utilize the SR generator in Neuro SAT (Selsam et al., 2019) and the 3- SAT generator in CNFGen (Lauria et al., 2017) to produce random CNF formulas. For pseudo- industrial problems, we employ the Community Attachment (CA) model (Gir\u00e1ldez- Cruz & Levy, 2015) and the Popularity- Similarity (PS) model (Gir\u00e1ldez- Cruz & Levy, 2017), which generate synthetic instances that exhibit similar statistical features, such as the community and the locality, to those observed in real- world industrial SAT instances. For combinatorics, we resort to 3 synthetic generators in CNFGen (Lauria et al., 2017) to create SAT instances derived from the translation of \\(k\\) - Clique, \\(k\\) - Dominating Set, and \\(k\\) - Vertex Cover problems.\n\n<center>Figure 1: Framework overview of G4SATBench. </center> In addition to the diversity of datasets, G4SATBench offers distinct difficulty levels for all datasets to enable fine- grained analyses. These levels include easy, medium, and hard, with the latter representing more complex problems with increased instance sizes. For example, the easy SR dataset contains instances with 10 to 40 variables, the medium SR dataset contains formulas with 40 to 200 variables, and the hard SR dataset consists of formulas with variables ranging from 200 to 400. For each easy and medium dataset, we generate 80k pairs of satisfiable and unsatisfiable instances for training, 10k pairs for validation, and 10k pairs for testing. For each hard dataset, we produce 10k testing pairs. It is also worth noting that the parameters for our synthetic generators are meticulously selected to avoid generating trivial cases. For instance, we produce random 3- SAT formulas at the phase- transition region where the relationship between the number of clauses \\((m)\\) and variables \\((n)\\) is \\(m = 4.258n + 58.26n^{- 2 / 3}\\) (Crawford & Auton, 1996), and utilize the \\(v\\) vertex Erd\u0151s- R\u00e9nyi graph with an edge probability of \\(p = \\binom{v}{k}^{- 1 / \\binom{v}{2}}\\) to generate \\(k\\) - Clique problems, making the expected number of \\(k\\) - Cliques in a graph equals 1 (Bollob\u00e1s & Erd\u0151s, 1976). To provide a detailed characterization of our generated datasets, we compute several statistics of the SAT instances across difficulty levels in G4SATBench. Please refer to Appendix A for more information about the datasets. ### 4.2 GNN Baselines Graph constructions. It is important to note that traditional graph representations of a CNF formula often lack the requisite details for optimally constructing GNNs. Specifically, the LIG and VIG exclude clause- specific information, while the LCG and VCG fail to differentiate between positive and negative literals of the same variable. To address these limitations, existing approaches typically build GNN models on the refined versions of the LCG and VCG encodings. In the LCG, a new type of edge is added between each literal and its negation, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. <center>Figure 2: LCG\\* and VCG\\* of the CNF formula \\((x_{1} \\vee \\neg x_{2}) \\wedge (x_{1} \\vee x_{3}) \\wedge (\\neg x_{1} \\vee x_{2} \\vee x_{3})\\) . </center> tion, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. Message- passing schemes. G4SATBench enables performing various heterogeneous message- passage algorithms between neighboring nodes on the LCG\\* or VCG\\* encodings of a CNF formula. For the sake of illustration, we will take GNN models on the LCG\\* as an example. We first define a \\(d\\) - dimensional embedding for every literal node and clause node, denoted by \\(h_{l}\\) and \\(h_{c}\\) respectively. Initially, all these embeddings are assigned to two learnable vectors \\(h_{l}^{0}\\) and \\(h_{c}^{0}\\) , depending on their node types. At the \\(k\\) - th iteration of\n\nmessage passing, these hidden representations are updated as: \\[\\begin{array}{r l} & {h_{c}^{(k)} = \\mathrm{UP D}\\left(\\underset {l\\in \\mathcal{N}(c)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{l}^{(k - 1)}\\right)\\right\\} \\right),h_{c}^{(k - 1)}\\right),}\\\\ & {h_{l}^{(k)} = \\mathrm{UP D}\\left(\\underset {c\\in \\mathcal{N}(l)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{c}^{(k - 1)}\\right)\\right\\} \\right),h_{-l}^{(k - 1)},h_{l}^{(k - 1)}\\right),} \\end{array} \\quad (1)\\] where \\(\\mathcal{N}(\\cdot)\\) denotes the set of neighbor nodes, MLP is the multi- layer perception, \\(\\mathrm{UP D}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. Most GNN models on \\(\\mathrm{LCG}^{*}\\) use Equation 1 with different choices of the update function and aggregation function. For instance, Neuro SAT employs Layer Norm L- STM (Ba et al., 2016) as the update function and summation as the aggregation function. In G4SATBench, we provide a diverse range of GNN models, including Neuro SAT (Selsam et al., 2019), Graph Convolutional Network (GCN) (Kipf & Welling, 2017), Gated Graph Neural Network (GGNN) (Li et al., 2016), and Graph Isomorphism Network (GIN) (Xu et al., 2019), on the both \\(\\mathrm{LCG}^{*}\\) and \\(\\mathrm{VCG}^{*}\\) . More details of these GNN models are included in Appendix B. ### 4.3 Supported Tasks, Training and Testing Settings Prediction tasks. In G4SATBench, we support three essential prediction tasks for SAT solving: satisfiability prediction, satisfying assignment prediction, and unsat- core variable prediction. These tasks are widely used in both standalone neural solvers and neural- guided solvers. Technically, we model satisfiability prediction as a binary graph classification task, where \\(1 / 0\\) denotes the given SAT instance \\(\\phi\\) is satisfiable/unsatisfiable. Here, we take GNN models on the \\(\\mathrm{LCG}^{*}\\) as an example. After \\(T\\) message passing iterations, we obtain the graph embedding by applying mean pooling on all literal embeddings, and then predict the satisfiability using an MLP followed by the sigmoid function \\(\\sigma\\) : \\[y_{\\phi} = \\sigma \\left(\\mathrm{MLP}\\left(\\mathrm{MEAN}\\left(\\{h_{l}^{(T)},l\\in \\phi \\}\\right)\\right)\\right). \\quad (2)\\] For satisfying assignment prediction and unsat- core variable prediction, we formulate them as binary node classification tasks, predicting the label for each variable in the given CNF formula \\(\\phi\\) . In the case of GNNs on the \\(\\mathrm{LCG}^{*}\\) , we concatenate the embeddings of each pair of literals \\(h_{l}\\) and \\(h_{- l}\\) to construct the variable embedding, and then readout using an MLP and the sigmoid function \\(\\sigma\\) : \\[y_{v} = \\sigma \\left(\\mathrm{MLP}\\left(\\left[h_{l}^{(T)},h_{-l}^{(T)}\\right]\\right)\\right). \\quad (3)\\] Training objectives. To train GNN models on the aforementioned tasks, one common approach is to minimize the binary cross- entropy loss between the predictions and the ground truth labels. In addition to supervised learning, G4SATBench supports two unsupervised training paradigms for satisfying assignment prediction (Amizadeh et al., 2019a; Ozolins et al., 2022). The first approach aims to differentiate and maximize the satisfiability value of a CNF formula (Amizadeh et al., 2019a). It replaces the \\(\\neg\\) operator with the function \\(N(x_{i}) = 1 - x_{i}\\) and uses smooth max and min functions to replace the \\(\\vee\\) and \\(\\wedge\\) operators. The smooth max and min functions are defined as follows: \\[S_{m a x}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{x_{i} / \\tau}},\\quad S_{m i n}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{-x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{-x_{i} / \\tau}}, \\quad (4)\\] where \\(\\tau \\geq 0\\) is the temperature parameter. Given a predicted assignment \\(x\\) , we apply the smoothing logical operators and substitute variables in a formula \\(\\phi\\) with the corresponding values from \\(x\\) to calculate its satisfiability value \\(S(x)\\) . Then we can minimize the following loss function: \\[\\mathcal{L}_{\\phi}(x) = \\frac{(1 - S(x))^{\\kappa}}{(1 - S(x))^{\\kappa} + S(x)^{\\kappa}}. \\quad (5)\\] The second unsupervised loss is defined as follows (Ozolins et al., 2022): \\[V_{c}(x) = 1 - \\prod_{i\\in c^{+}}(1 - x_{i})\\prod_{i\\in c^{-}}x_{i},\\quad \\mathcal{L}_{\\phi}(x) = -\\log \\Bigl (\\prod_{c\\in \\phi}V_{c}(x)\\Bigr) = -\\sum_{c\\in \\phi}\\log \\bigl (V_{c}(x)\\bigr), \\quad (6)\\]\n\nwhere \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in the clause \\(c\\) in positive and negative form respectively. Note that these two losses reach the minimum only when the prediction \\(x\\) is a satisfying assignment, thus minimizing such losses could help to construct a possible satisfying assignment. Inference algorithms. Beyond the standard readout process like training, G4SATBench offers two alternative inference algorithms for satisfying assignment prediction (Selsam et al., 2019; Amizadeh et al., 2019b). The first method performs 2- clustering on the literal embeddings to obtain two centers \\(\\Delta_{1}\\) and \\(\\Delta_{2}\\) and then partitions the positive and negative literals of each variable into distinct groups based on the predicate \\(||x_{i} - \\Delta_{1}||^{2} + ||\\neg x_{i} - \\Delta_{2}||^{2}< ||x_{i} - \\Delta_{2}||^{2} + ||\\neg x_{i} - \\Delta_{1}||^{2}\\) (Selsam et al., 2019). This allows the construction of two possible assignments by mapping one group of literals to true. The second approach is to employ the readout function at each iteration of message passing, resulting in multiple assignment predictions for a given instance (Amizadeh et al., 2019b). Evaluation metrics. For satisfiability prediction and unsat- core variable prediction, we report the classification accuracy of each GNN model in G4SATBench. For satisfying assignment prediction, we report the solving accuracy of the predicted assignments. If multiple assignments are predicted for a SAT instance, the instance is considered solved if any of the predictions satisfy the formula. ## 5 Benchmarking Evaluation on G4SATBench In this section, we present the benchmarking results of G4SATBench. To ensure a fair comparison, we conduct a grid search to tune the hyperparameters of each GNN baseline. The best checkpoint for each GNN model is selected based on its performance on the validation set. To mitigate the impact of randomness, we use 3 different random seeds to repeat the experiment in each setting and report the average performance. Each experiment is performed on a single RTX8000 GPU and 16 AMD EPYC 7502 CPU cores, and the total time cost is approximately 8,000 GPU hours. For detailed experimental setup and hyperparameters, please refer to Appendix C.1. ### 5.1 Satisfiability Prediction Evaluation on the same distribution. Table 1 shows the benchmarking results of each GNN baseline when trained and evaluated on datasets possessing identical distributions. All GNN models exhibit strong performance across most easy and medium datasets, except for the medium SR dataset. This difficulty can be attributed to the inherent characteristic of this dataset, which includes satisfiable and unsatisfiable pairs of medium- sized instances distinguished by just a single differing literal. Such a subtle difference presents a substantial challenge for GNN models in satisfiability classification. Among all GNN models, the different graph constructions do not seem to have a significant impact on the results, and Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) achieve the best overall performance. Table 1: Classification accuracy of satisfiability on identical distribution. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>96.00</td><td>96.33</td><td>98.83</td><td>96.59</td><td>97.92</td><td>99.77</td><td>99.99</td><td>78.02</td><td>84.90</td><td>99.57</td><td>96.81</td><td>89.39</td><td>99.67</td></tr><tr><td>GCN</td><td>94.43</td><td>94.47</td><td>98.79</td><td>97.53</td><td>98.24</td><td>99.59</td><td>99.98</td><td>69.39</td><td>82.67</td><td>99.53</td><td>96.16</td><td>85.72</td><td>99.16</td></tr><tr><td>GGNN</td><td>96.36</td><td>95.70</td><td>98.81</td><td>97.47</td><td>98.80</td><td>99.77</td><td>99.97</td><td>71.44</td><td>83.45</td><td>99.50</td><td>96.21</td><td>81.20</td><td>99.69</td></tr><tr><td>GIN</td><td>95.78</td><td>95.37</td><td>98.14</td><td>96.98</td><td>97.60</td><td>99.71</td><td>99.97</td><td>70.54</td><td>82.80</td><td>99.49</td><td>95.80</td><td>83.87</td><td>99.61</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>93.19</td><td>94.92</td><td>97.82</td><td>95.79</td><td>98.72</td><td>99.54</td><td>99.99</td><td>66.35</td><td>83.75</td><td>99.49</td><td>95.48</td><td>82.99</td><td>99.42</td></tr><tr><td>GGNN</td><td>96.75</td><td>96.25</td><td>98.77</td><td>96.44</td><td>98.88</td><td>99.68</td><td>99.98</td><td>77.12</td><td>85.11</td><td>99.57</td><td>96.48</td><td>83.63</td><td>99.62</td></tr><tr><td>GIN</td><td>96.04</td><td>95.71</td><td>98.47</td><td>96.95</td><td>97.33</td><td>99.59</td><td>99.98</td><td>73.56</td><td>85.26</td><td>99.49</td><td>96.55</td><td>89.41</td><td>99.38</td></tr></table> Evaluation across different distributions. To assess the generalization ability of GNN models, we evaluate the performance of Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) across different datasets and difficulty levels. As shown in Figure 3 and Figure 4, Neuro SAT and GGNN struggle to generalize effectively to datasets distinct from their training data in most cases. However, when trained on the SR dataset, they exhibit better generalization performance across different datasets. Furthermore, while both GNN models\n\ndemonstrate limited generalization to larger formulas beyond their training data, they perform relatively better on smaller instances. These observations suggest that the generalization performance of GNN models for satisfiability prediction is influenced by the distinct nature and complexity of its training data. Training on more challenging instances could potentially enhance their generalization ability. <center>Figure 3: Classification accuracy of satisfiability across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> <center>Figure 4: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Due to the limited space, Figure 4 exclusively displays the performance of Neuro SAT and GGNN on the SR and 3- SAT datasets. Comprehensive results on the other five datasets, as well as the experimental results on different massage passing iterations, are provided in Appendix C.2. ### 5.2 Satisfying Assignment Prediction Evaluation with different training losses. Table 2 presents the results of Neuro SAT (on \\(\\mathrm{LCG}^{*}\\) ) and GGNN (on \\(\\mathrm{VCG}^{*}\\) ) across three different training objectives. The results of other GNN models are listed in Table 10 in Appendix C.3. Interestingly, the unsupervised training methods outperform the supervised learning approach across the majority of datasets. We hypothesize that this is due to the presence of multiple satisfying assignments in most satisfiable instances. Supervised training tends to bias GNN models towards learning a specific satisfying solution, thereby neglecting the exploration of other feasible ones. This bias may compromise the models' ability to generalize effectively. Such limitations become increasingly apparent when the space of satisfying solutions is much larger, as seen in the medium CA and PS datasets. Additionally, it is noteworthy that employing \\(\\mathrm{UNS}_1\\) as the loss function can result in instability during the training of some GNN models, leading to a failure to converge in some cases. Conversely, using \\(\\mathrm{UNS}_2\\) loss demonstrates strong and stable performance across all datasets. In addition to evaluating the performance of GNN models under various training loss functions, we extend our analysis to explore how these models perform across different data distributions and under various inference algorithms. Furthermore, we assess the robustness of these GNN models when trained on noisy datasets that include unsatisfiable instances in an unsupervised fashion. For detailed results of these evaluations across different GNN baselines, please refer to Appendix C.3.\n\nTable 2: Solving accuracy on identical distribution with different training losses. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td rowspan=\"2\">Loss</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"3\">LCG*</td><td rowspan=\"3\">Neuro SAT</td><td>SUP</td><td>88.47</td><td>78.39</td><td>0.27</td><td>39.18</td><td>66.30</td><td>69.61</td><td>85.15</td><td>34.97</td><td>20.07</td><td>0.00</td><td>3.64</td><td>56.61</td><td>52.09</td></tr><tr><td>UNS1</td><td>82.30</td><td>80.23</td><td>82.17</td><td>89.23</td><td>88.34</td><td>96.74</td><td>99.36</td><td>25.00</td><td>30.40</td><td>35.45</td><td>60.28</td><td>41.45</td><td>95.06</td></tr><tr><td>UNS2</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.61</td><td>70.83</td><td>71.03</td><td>-</td><td>96.18</td><td>95.99</td></tr><tr><td rowspan=\"3\">VCG*</td><td rowspan=\"3\">GGNN</td><td>SUP</td><td>84.13</td><td>72.87</td><td>0.29</td><td>38.82</td><td>60.80</td><td>68.36</td><td>82.06</td><td>14.15</td><td>7.96</td><td>0.00</td><td>2.33</td><td>52.35</td><td>49.07</td></tr><tr><td>UNS1</td><td>76.39</td><td>76.55</td><td>78.13</td><td>84.44</td><td>84.60</td><td>97.49</td><td>-</td><td>16.55</td><td>22.84</td><td>28.12</td><td>44.89</td><td>54.29</td><td>-</td></tr><tr><td>UNS2</td><td>78.75</td><td>76.42</td><td>84.08</td><td>86.29</td><td>87.12</td><td>98.06</td><td>99.34</td><td>21.18</td><td>25.68</td><td>50.66</td><td>57.96</td><td>68.91</td><td>92.26</td><td>94.30</td></tr></table> ### 5.3 Unsat-core Variable Prediction Evaluation on the same distribution. The benchmarking results presented in Table 3 exhibit the superior performance of all GNN models on both easy and medium datasets, with Neuro SAT consistently achieving the best results across most datasets. It is important to note that the primary objective of predicting unsat- core variables is not to solve SAT problems directly but to provide valuable guidance for enhancing the backtracking search process. As such, even imperfect predictions - for instance, those with a classification accuracy of \\(90\\%\\) - have been demonstrated to be sufficiently effective in improving the search heuristics employed by modern CDCL- based SAT solvers, as indicated by previous studies (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021). Table 3: Classification accuracy of unsat-core variables on identical distribution. Only unsatisfiable instances are evaluated. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>90.76</td><td>94.43</td><td>83.69</td><td>86.20</td><td>99.93</td><td>95.80</td><td>94.47</td><td>90.07</td><td>99.65</td><td>85.73</td><td>88.53</td><td>99.97</td><td>97.90</td></tr><tr><td>GCN</td><td>89.17</td><td>94.35</td><td>82.89</td><td>85.32</td><td>99.93</td><td>95.74</td><td>94.43</td><td>88.11</td><td>99.65</td><td>85.71</td><td>87.70</td><td>99.96</td><td>97.89</td></tr><tr><td>GGNN</td><td>90.02</td><td>94.38</td><td>83.59</td><td>86.03</td><td>99.93</td><td>95.79</td><td>94.46</td><td>89.05</td><td>99.65</td><td>85.69</td><td>87.95</td><td>99.96</td><td>97.89</td></tr><tr><td>GIN</td><td>89.29</td><td>94.33</td><td>83.71</td><td>85.97</td><td>99.93</td><td>95.81</td><td>94.47</td><td>88.85</td><td>99.65</td><td>85.71</td><td>87.92</td><td>99.96</td><td>97.89</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>88.57</td><td>94.34</td><td>83.17</td><td>85.27</td><td>99.93</td><td>95.79</td><td>94.46</td><td>88.17</td><td>99.65</td><td>85.70</td><td>87.37</td><td>99.96</td><td>97.90</td></tr><tr><td>GGNN</td><td>89.57</td><td>94.37</td><td>83.50</td><td>85.84</td><td>99.93</td><td>95.81</td><td>94.49</td><td>88.84</td><td>99.65</td><td>85.68</td><td>88.03</td><td>99.98</td><td>97.90</td></tr><tr><td>GIN</td><td>89.50</td><td>94.35</td><td>83.23</td><td>85.69</td><td>99.93</td><td>95.79</td><td>94.47</td><td>89.51</td><td>99.65</td><td>85.72</td><td>88.13</td><td>99.96</td><td>97.89</td></tr></table> We also conduct experiments to evaluate the generalization ability of GNN models on unsat- core variable prediction. Please see appendix C.4 for details. ## 6 Advancing Evaluation on G4SATBench To gain deeper insights into how GNNs tackle the SAT problem, we conduct comprehensive comparative analyses between GNN- based SAT solvers and the CDCL and LS heuristics in this section. Since these search heuristics aim to solve a SAT instance directly, our focus only lies on the tasks of (T1) satisfiability prediction and (T2) satisfying assignment prediction (with \\(\\mathrm{UNS}_2\\) as the training loss). We employ Neuro SAT (on \\(\\mathrm{LCG}^*\\) ) and GGNN (on \\(\\mathrm{VCG}^*\\) ) as our GNN models and experiment on the SR and 3- SAT datasets. Detailed experimental settings are included in Appendix D.1. ### 6.1 Comparison with the CDCL Heuristic Evaluation on the clause- learning augmented instances. CDCL- based SAT solvers enhance backtracking search with conflict analysis and clause learning, enabling efficient exploration of the search space by iteratively adding \"learned clauses\" to avoid similar conflicts in future searches (Silva & Sakallah, 1999). To assess whether GNN- based SAT solvers can learn and benefit from the backtracking search (with CDCL) heuristic, we augment the original formulas in the datasets with learned clauses and evaluate GNN models on these clause- augmented instances.\n\nTable 4 shows the testing results on augmented SAT datasets. Notably, training on the augmented instances leads to significant improvements in both satisfiability prediction and satisfying assignment prediction. These improvements can be attributed to the presence of \"learned clauses\" that effectively modify the structure of the original formulas, thereby facilitating GNNs to solve with relative ease. However, despite the augmented instances being easily solvable using the backtracking search within a few search steps, GNN models fail to effectively handle these instances when trained on the original instances. These findings suggest that GNNs may not implicitly learn the CDCL heuristic when trained for satisfiability prediction or satisfying assignment prediction. Table 4: Results on augmented datasets. Values inside/outside parentheses denote the results of models trained on augmented/original instances. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>100.00 (96.78)</td><td>100.00 (96.06)</td><td>100.00 (84.57)</td><td>96.78 (84.85)</td></tr><tr><td>GGNN</td><td>100.00 (97.66)</td><td>100.00 (95.46)</td><td>100.00 (84.01)</td><td>96.29 (85.80)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>85.05 (83.28)</td><td>83.50 (81.04)</td><td>51.95 (45.51)</td><td>39.00 (16.52)</td></tr><tr><td>GGNN</td><td>85.35 (83.42)</td><td>81.56 (79.99)</td><td>44.18 (40.09)</td><td>34.67 (14.75)</td></tr></table> Table 5: Results using contrastive pretraining. Values in parentheses denote the difference between the results without pretraining. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>96.68 (+0.68)</td><td>96.23 (+0.10)</td><td>78.31 (+0.29)</td><td>85.02 (+0.12)</td></tr><tr><td>GGNN</td><td>96.46 (+0.29)</td><td>96.45 (+0.20)</td><td>76.34 (+0.78)</td><td>85.17 (+0.06)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>80.54 (+0.75)</td><td>79.71 (-0.88)</td><td>36.42 (-0.83)</td><td>41.23 (-0.38)</td></tr><tr><td>GGNN</td><td>80.66 (-0.34)</td><td>79.23 (-0.09)</td><td>33.44 (+0.07)</td><td>36.39 (+0.44)</td></tr></table> Evaluation with contrastive pretraining. Observing that GNN models exhibit superior performance on clause- learning augmented SAT instances, there is potential to improve the performance of GNNs by learning a latent representation of the original formula similar to its augmented counterpart. Motivated by this, we also experiment with a contrastive learning approach (i.e., Sim CLR (Chen et al., 2020)) to pretrain the representation of CNF formulas to be close to their augmented ones (Duan et al., 2022), trying to explicitly embed the CDCL heuristic in the latent space through representation learning. The results of contrastive pretraining are presented in Table 5. In contrast to the findings in Duan et al. (2022), our results show limited performance improvement through contrastive pretraining, indicating that GNN models still encounter difficulties in effectively learning the CDCL heuristic in the latent space. This observation aligns with the conclusions drawn in Chen & Yang (2019), which highlight that static GNNs may fail to exactly replicate the same search operations due to the dynamic changes in the graph structure introduced by the clause learning technique. ### 6.2 Comparison with the LS Heuristic Evaluation with random initialization. LS- based SAT solvers typically begin by randomly initializing an assignment and then iteratively flip variables guided by specific heuristics until reaching a satisfying assignment. To compare the behaviors of GNNs with this solving procedure, we first conduct an evaluation of GNN models with randomized initial embeddings in both training and testing, emulating the initialization of LS SAT solvers. The results presented in Table 6 demonstrate that using random initialization has a limited impact on the overall performances of GNN- based SAT solvers. This suggests that GNN models do not aim to learn a fixed latent representation of each formula for satisfiability prediction and satisfying assignment prediction. Instead, they have developed a solving strategy that effectively exploits the inherent graph structure of each SAT instance. Table 6: Results using random initialization. Values in parentheses denote the difference between the results with learned initialization. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>97.24 (+1.24)</td><td>96.44 (+0.11)</td><td>77.29 (-0.91)</td><td>84.85 (-0.05)</td></tr><tr><td>GGNN</td><td>96.78 (+0.03)</td><td>96.38 (+0.13)</td><td>76.97 (-0.15)</td><td>85.80 (+0.69)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>79.09 (-0.70)</td><td>80.79 (+0.20)</td><td>37.27 (+0.02)</td><td>40.75 (-0.86)</td></tr><tr><td>GGNN</td><td>80.10 (-0.90)</td><td>79.83 (+0.51)</td><td>32.85 (-0.52)</td><td>36.59 (+0.64)</td></tr></table> Evaluation on the predicted assignments. Under random initialization, we further analyze the solving strategies of GNNs by evaluating their predicted assignments decoded from the latent space. For the task of satisfiability prediction, we employ the 2- clustering decoding algorithm to extract the predicted assignments from the literal embeddings of Neuro SAT at each iteration of message passing. For satisfying assignment",
    "introduction": "prediction, we evaluate both Neuro SAT and GGNN using multiple- prediction decoding. Our evaluation focuses on three key aspects: (a) the number of distinct predicted assignments, (b) the number of flipped variables between two consecutive iterations, and (c) the number of unsatisfiable clauses associated with the predicted assignments. <center>Figure 5: Results on the predicted assignments with the increased message passing iteration \\(T\\) . Neuro SAT\\* refers to the model trained for satisfiability prediction. </center> As shown in Figure 5, all three GNN models initially generate a wide array of assignment predictions by flipping a considerable number of variables, resulting in a notable reduction in the number of unsatisfiable clauses. However, as the iterations progress, the number of flipped variables diminishes substantially, and most GNN models eventually converge towards predicting a specific assignment or making minimal changes to their predictions when there are no or very few unsatisfiable clauses remaining. This trend is reminiscent of the greedy solving strategy adopted by the LS solver GSAT (Selman et al., 1992), where changes are made to minimize the number of unsatisfied clauses in the new assignment. However, unlike GSAT's approach of flipping one variable at a time and incorporating random selection to break ties, GNN models simultaneously modify multiple variables and potentially converge to a particular unsatisfied assignment and find it challenging to deviate from such a prediction. It is also noteworthy that despite being trained for satisfiability prediction, Neuro SAT\\* demonstrates similar behavior to the GNN models trained for assignment prediction. This observation indicates that GNNs also learn to search for a satisfying assignment implicitly in the latent space while performing satisfiability prediction. To provide more insights into the strengths and limitations of GNN- based heuristics, we further conduct experiments to compare GNN- based SAT solvers against state- of- the- art CDCL and LS- based SAT solvers in Appendix D.2. ## 7 Discussions ### 7.1 Limitations and Future Work While G4SATBench represents a significant step in evaluating GNNs for SAT solving, there are still some limitations and potential future directions to consider. Firstly, G4SATBench primarily focuses on evaluating standalone neural SAT solvers, excluding the exploration of neural- guided SAT solvers that integrate GNNs with search- based SAT solvers. It also should be emphasized that the instances included in G4SATBench are considerably smaller compared to most practical instances found in real- world applications, where GNN models alone are not sufficient for solving such large- scale instances. The efficacy of GNN models in unsat- core prediction shows a promising avenue for combining GNNs with modern SAT solvers, and future research could explore more techniques to effectively leverage these neural- guided SAT solvers to scale up to real- world instances. Secondly, G4SATBench benchmarks general GNN models on the LCG\\* and VCG\\* graph representations for SAT solving, but does not consider sophisticated GNN models designed for specific graph constructions in certain domains, such as Circuit SAT problems. Investigating domain- specific GNN models tailored to the characteristics of specific problems could lead to improved performance in specialized instances. Lastly, all existing GNN- based SAT solvers in the literature are static GNNs, which have limited learning ability to capture the CDCL heuristic. Exploring dynamic GNN models that can effectively learn the CDCL heuristic is also a potential direction for future research.\n\n### 7.2 Conclusion 7.2 Conclusion In this work, we present G4SATBench, a benchmark study that comprehensively evaluates GNN models in SAT solving. G4SATBench offers curated synthetic SAT datasets sourced from various domains and difficulty levels and benchmarks a wide range of GNN- based SAT solvers under diverse settings. Our empirical analysis yields valuable insights into the performances of GNN- based SAT solvers and further provides a deeper understanding of their capabilities and limitations. We hope the proposed G4SATBench will serve as a solid foundation for GNN- based SAT solving and inspire future research in this exciting field. ## Acknowledgments Acknowledgments This work was supported, in part, by Individual Discovery Grants from the Natural Sciences and Engineering Research Council of Canada, and the Canada CIFAR AI Chair Program. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve Circuit- SAT: An unsupervised differentiable approach. In International Conference on Learning Representations (ICLR), 2019a. Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. PDP: A general neural framework for learning constraint satisfaction solvers. ar Xiv preprint ar Xiv:1903.01969, 2019b. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ar Xiv preprint ar Xiv:1607.06450, 2016. Adrian Balint and Andreas Fr\u00f6hlich. Improving stochastic local search for sat with a new probability distribution. In Theory and Applications of Satisfiability Testing- SAT 2010: 13th International Conference, SAT 2010, Edinburgh, UK, July 11- 14, 2010. Proceedings 13, pp. 10- 15. Springer, 2010. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of Satisfiability, volume 185. IOS press, 2009. B\u00e9la Bollob\u00e1s and Paul Erd\u0151s. Cliques in random graphs. In Mathematical Proceedings of the Cambridge Philosophical Society, 1976. Benedikt B\u00fcnz and Matthew Lamm. Graph neural networks and boolean satisfiability. ar Xiv preprint ar Xiv:1702.03592, 2017. Chris Cameron, Rex Chen, Jason Hartford, and Kevin Leyton- Brown. Predicting propositional satisfiability via end- to- end learning. In AAAI Conference on Artificial Intelligence (AAAI), 2020. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020. Ziliang Chen and Zhanfu Yang. Graph neural reasoning may fail in certifying boolean unsatisfiability. ar Xiv preprint ar Xiv:1909.11588, 2019. James M. Crawford and Larry D. Auton. Experimental results on the crossover point in random 3- SAT. Artificial Intelligence, 1996. Haonan Duan, Pashootan Vaezipoor, Max B. Paulus, Yangjun Ruan, and Chris J. Maddison. Augment with care: Contrastive learning for combinatorial problems. In International Conference on Machine Learning (ICML), 2022. Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. ar Xiv preprint ar Xiv:1903.02428, 2019. ABKFM Fleury and Maximilian Heisinger. Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020. SAT COMPETITION, 2020.\n\nJes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. A modularity- based random SAT instances generator. In International Joint Conference on Artificial Intelligence (IJCAI), 2015. Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. Locality in random SAT instances. In International Joint Conference on Artificial Intelligence (IJCAI), 2017. Wenxuan Guo, Junchi Yan, Hui- Ling Zhen, Xijun Li, Mingxuan Yuan, and Yaohui Jin. Machine learning methods in solving the boolean satisfiability problem. ar Xiv preprint ar Xiv:2203.04755, 2022. Jesse Michael Han. Enhancing SAT solvers with glue variable predictions. ar Xiv preprint ar Xiv:2007.02559, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human- level performance on imagenet classification. In IEEE International Conference on Computer Vision (ICCV), 2015. Sean B Holden et al. Machine learning for automated theorem proving: Learning to solve SAT and QSAT. Foundations and Trends\u00ae in Machine Learning, 14(6):807- 989, 2021. Holger H Hoos and Thomas St\u00fctzle. SATLIB: An online resource for research on SAT. Workshop on Satisfiability (SAT), 2000. Sebastian Jaszczur, Michal \u0141uszczyk, and Henryk Michalewski. Neural heuristics for SAT solving. ar Xiv preprint ar Xiv:2005.13406, 2020. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. Thomas N. Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q- learning with graph networks learn a generalizable branching heuristic for a SAT solver? In Advances in Neural Information Processing Systems (Neur IPS), 2020. Massimo Lauria, Jan Elffers, Jakob Nordstr\u00f6m, and Marc Vinyals. Cnfen: A generator of crafted benchmarks. In Theory and Applications of Satisfiability Testing (SAT), 2017. Min Li, Zhengyuan Shi, Qiuxia Lai, Sadaf Khan, Shaowei Cai, and Qiang Xu. On eda- driven learning for sat solving. In Design Automation Conference (DAC), 2023. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations (ICLR), 2016. Zhaoyu Li and Xujie Si. NSNet: A general neural probabilistic framework for satisfiability problems. In Advances in Neural Information Processing Systems (Neur IPS), 2022. Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning (ICML), 2010. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural SAT solver. In International Joint Conference on Neural Networks (IJCNN), 2022. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. Yang, Zachary De Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high- performance deep learning library. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Bart Selman, Hector J. Levesque, and David G. Mitchell. A new method for solving hard satisfiability problems. In National Conference on Artificial Intelligence (AAAI), 1992.\n\nDaniel Selsam and Nikolaj S. Bj\u00f8rner. Guiding high- performance SAT solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing (SAT), 2019. Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations (ICLR), 2019. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui- Ling Zhen, Mingxuan Yuan, and Qiang Xu. Sathermer: Transformer- based unsat core learning. In International Conference on Computer Aided Design (ICCAD), 2023. Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP: A search algorithm for propositional satisfiability. IEEE Transactions on Computers, 1999. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth Mc Millan, and Risto Miikkulainen. Neurocomb: Improving SAT solving with graph neural networks. ar Xiv preprint ar Xiv:2110.14053, 2021. Nathan Wetzler, Marijn Heule, and Warren A. Hunt Jr. Drat- trim: Efficient checking and trimming using expressive clausal proofs. In Theory and Applications of Satisfiability Testing (SAT), 2014. Ben Wieland and Anant P. Godbole. On the domination number of a random graph. The Electronic Journal of Combinatorics, 2001. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019. Zhiyuan Yan, Min Li, Zhengyuan Shi, Wenjie Zhang, Yingcong Chen, and Hongce Zhang. Addressing variable dependency in gnn- based SAT solving. ar Xiv preprint ar Xiv:2304.08738, 2023. Emre Yolcu and Barnab\u00e1s P\u00f3czos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong, and Lu Zhang. Nicolasat: Boosting local search with solution prediction. In International Joint Conference on Artificial Intelligence (IJCAI), 2020.",
    "72_conclusion_72_conclusion_in_this_work_we_present_g4satbench_a_benchmark_study_that_comprehensively_evaluates_gnn_models_in_sat_solving_g4satbench_offers_curated_synthetic_sat_datasets_sourced_from_various_domains_and_difficulty_levels_and_benchmarks_a_wide_range_of_gnn-_based_sat_solvers_under_diverse_settings_our_empirical_analysis_yields_valuable_insights_into_the_performances_of_gnn-_based_sat_solvers_and_further_provides_a_deeper_understanding_of_their_capabilities_and_limitations_we_hope_the_proposed_g4satbench_will_serve_as_a_solid_foundation_for_gnn-_based_sat_solving_and_inspire_future_research_in_this_exciting_field_acknowledgments_acknowledgments_this_work_was_supported_in_part_by_individual_discovery_grants_from_the_natural_sciences_and_engineering_research_council_of_canada_and_the_canada_cifar_ai_chair_program_references_saeed_amizadeh_sergiy_matusevych_and_markus_weimer_learning_to_solve_circuit-_sat_an_unsupervised_differentiable_approach_in_international_conference_on_learning_representations_iclr_2019a_saeed_amizadeh_sergiy_matusevych_and_markus_weimer_pdp_a_general_neural_framework_for_learning_constraint_satisfaction_solvers_ar_xiv_preprint_ar_xiv190301969_2019b_jimmy_lei_ba_jamie_ryan_kiros_and_geoffrey_e_hinton_layer_normalization_ar_xiv_preprint_ar_xiv160706450_2016_adrian_balint_and_andreas_fr\u00f6hlich_improving_stochastic_local_search_for_sat_with_a_new_probability_distribution_in_theory_and_applications_of_satisfiability_testing-_sat_2010_13th_international_conference_sat_2010_edinburgh_uk_july_11-_14_2010_proceedings_13_pp_10-_15_springer_2010_armin_biere_marijn_heule_and_hans_van_maaren_handbook_of_satisfiability_volume_185_ios_press_2009_b\u00e9la_bollob\u00e1s_and_paul_erd\u0151s_cliques_in_random_graphs_in_mathematical_proceedings_of_the_cambridge_philosophical_society_1976_benedikt_b\u00fcnz_and_matthew_lamm_graph_neural_networks_and_boolean_satisfiability_ar_xiv_preprint_ar_xiv170203592_2017_chris_cameron_rex_chen_jason_hartford_and_kevin_leyton-_brown_predicting_propositional_satisfiability_via_end-_to-_end_learning_in_aaai_conference_on_artificial_intelligence_aaai_2020_ting_chen_simon_kornblith_mohammad_norouzi_and_geoffrey_e_hinton_a_simple_framework_for_contrastive_learning_of_visual_representations_in_international_conference_on_machine_learning_icml_2020_ziliang_chen_and_zhanfu_yang_graph_neural_reasoning_may_fail_in_certifying_boolean_unsatisfiability_ar_xiv_preprint_ar_xiv190911588_2019_james_m_crawford_and_larry_d_auton_experimental_results_on_the_crossover_point_in_random_3-_sat_artificial_intelligence_1996_haonan_duan_pashootan_vaezipoor_max_b_paulus_yangjun_ruan_and_chris_j_maddison_augment_with_care_contrastive_learning_for_combinatorial_problems_in_international_conference_on_machine_learning_icml_2022_matthias_fey_and_jan_eric_lenssen_fast_graph_representation_learning_with_pytorch_geometric_ar_xiv_preprint_ar_xiv190302428_2019_abkfm_fleury_and_maximilian_heisinger_cadical_kissat_paracooba_plingeling_and_treengeling_entering_the_sat_competition_2020_sat_competition_2020": "Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. A modularity- based random SAT instances generator. In International Joint Conference on Artificial Intelligence (IJCAI), 2015. Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. Locality in random SAT instances. In International Joint Conference on Artificial Intelligence (IJCAI), 2017. Wenxuan Guo, Junchi Yan, Hui- Ling Zhen, Xijun Li, Mingxuan Yuan, and Yaohui Jin. Machine learning methods in solving the boolean satisfiability problem. ar Xiv preprint ar Xiv:2203.04755, 2022. Jesse Michael Han. Enhancing SAT solvers with glue variable predictions. ar Xiv preprint ar Xiv:2007.02559, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human- level performance on imagenet classification. In IEEE International Conference on Computer Vision (ICCV), 2015. Sean B Holden et al. Machine learning for automated theorem proving: Learning to solve SAT and QSAT. Foundations and Trends\u00ae in Machine Learning, 14(6):807- 989, 2021. Holger H Hoos and Thomas St\u00fctzle. SATLIB: An online resource for research on SAT. Workshop on Satisfiability (SAT), 2000. Sebastian Jaszczur, Michal \u0141uszczyk, and Henryk Michalewski. Neural heuristics for SAT solving. ar Xiv preprint ar Xiv:2005.13406, 2020. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. Thomas N. Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q- learning with graph networks learn a generalizable branching heuristic for a SAT solver? In Advances in Neural Information Processing Systems (Neur IPS), 2020. Massimo Lauria, Jan Elffers, Jakob Nordstr\u00f6m, and Marc Vinyals. Cnfen: A generator of crafted benchmarks. In Theory and Applications of Satisfiability Testing (SAT), 2017. Min Li, Zhengyuan Shi, Qiuxia Lai, Sadaf Khan, Shaowei Cai, and Qiang Xu. On eda- driven learning for sat solving. In Design Automation Conference (DAC), 2023. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations (ICLR), 2016. Zhaoyu Li and Xujie Si. NSNet: A general neural probabilistic framework for satisfiability problems. In Advances in Neural Information Processing Systems (Neur IPS), 2022. Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning (ICML), 2010. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural SAT solver. In International Joint Conference on Neural Networks (IJCNN), 2022. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. Yang, Zachary De Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high- performance deep learning library. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Bart Selman, Hector J. Levesque, and David G. Mitchell. A new method for solving hard satisfiability problems. In National Conference on Artificial Intelligence (AAAI), 1992.\n\nDaniel Selsam and Nikolaj S. Bj\u00f8rner. Guiding high- performance SAT solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing (SAT), 2019. Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations (ICLR), 2019. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui- Ling Zhen, Mingxuan Yuan, and Qiang Xu. Sathermer: Transformer- based unsat core learning. In International Conference on Computer Aided Design (ICCAD), 2023. Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP: A search algorithm for propositional satisfiability. IEEE Transactions on Computers, 1999. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth Mc Millan, and Risto Miikkulainen. Neurocomb: Improving SAT solving with graph neural networks. ar Xiv preprint ar Xiv:2110.14053, 2021. Nathan Wetzler, Marijn Heule, and Warren A. Hunt Jr. Drat- trim: Efficient checking and trimming using expressive clausal proofs. In Theory and Applications of Satisfiability Testing (SAT), 2014. Ben Wieland and Anant P. Godbole. On the domination number of a random graph. The Electronic Journal of Combinatorics, 2001. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019. Zhiyuan Yan, Min Li, Zhengyuan Shi, Wenjie Zhang, Yingcong Chen, and Hongce Zhang. Addressing variable dependency in gnn- based SAT solving. ar Xiv preprint ar Xiv:2304.08738, 2023. Emre Yolcu and Barnab\u00e1s P\u00f3czos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong, and Lu Zhang. Nicolasat: Boosting local search with solution prediction. In International Joint Conference on Artificial Intelligence (IJCAI), 2020.",
    "a_datasets_generators_to_generate_high-_quality_sat_datasets_that_do_not_contain_trivial_instances_we_have_employed_a_rigorous_process_of_selecting_appropriate_parameters_for_each_cnf_generator_in_g4satbench_table_7_provides_detailed_information_about_the_generators_we_have_used_table_7_details_of_the_synthetic_generators_employed_in_g4satbench_tabletrtddatasettdtddescriptiontdtdparameterstdtdnotestdtrtrtdsrtdtdthe_sr_dataset_is_composed_of_pairs_of_satisfiable_and_unsatisfiable_formulas_with_the_only_difference_between_each_pair_being_the_polarity_of_a_single_literal_given_the_number_of_variables_n_the_synthetic_generator_iteratively_samples_k_1bernoullibgeometricg_vari-ables_uniformly_at_random_without_replacement_and_negates_each_one_with_independent_probability_50_to_build_a_clause_this_procedure_continues_until_the_generated_formula_is_unsatisfiable_the_satisfiable_instance_is_then_constructed_by_negating_the_first_literal_in_the_last_clause_of_the_unsatisfiable_onetdtdgeneral_b_03_g_04_easy_dataset_n_uniform10_40_medium_dataset_n_uniform40_200_hard_dataset_n_uniform200_400tdtdthe_sampling_parameters_are_the_same_as_the_original_paper_selsam_et_al_2019tdtrtrtd3-sattdtdthe_3-sat_dataset_comprises_cnf_formulas_at_the_phase_transition_where_the_proportion_of_generated_satisfiable_and_unsatisfiable_formu-_las_is_roughly_equal_given_the_number_of_variables_n_and_clauses_m_the_synthetic_generator_iteratively_samples_three_variables_and_their_polarities_uniformly_at_random_until_m_clauses_are_obtainedtdtdgeneral_m_4258n_5826n-23_easy_dataset_n_uniform10_40_medium_dataset_n_uniform40_200_hard_dataset_n_uniform200_300tdtdthe_parameter_m_is_the_same_as_the_paper_crawford_ampamp_auton_1996tdtrtrtdcatdtdthe_ca_dataset_contains_sat_instances_that_are_designed_to_mimic_the_community_structures_and_modularity_features_found_in_real-world_industrial_instances_given_variable_number_n_clause_number_m_clause_size_k_community_number_c_and_modularity_q_the_synthetic_generator_iteratively_selects_k_literals_in_the_same_community_uni-_formly_at_random_with_probability_p_q_1c_and_selects_k_literals_in_the_distinct_community_uniformly_at_random_with_probability_1-p_to_build_a_clause_and_repeat_for_m_times_to_construct_a_cnf_formulatdtdgeneral_m_uniform13n_15n_k_uniform4_5_c_uniform3_10_q_uniform07_09_easy_dataset_n_uniform10_40_medium_dataset_n_uniform40_200_hard_dataset_n_uniform200_400tdtdthe_parameters_are_selected_based_on_the_experiments_in_the_original_paper_gir\u00e1ldez-cru_ampamp_levy_2015_and_our_study_to_ensure_that_the_generated_sat_instances_have_a_balance_of_satisfiability_and_unsatisfiabilitytdtrtrtdpstdtdps_dataset_encompasses_sat_instances_with_a_power-law_distribution_in_the_number_of_variable_occurrences_popularity_and_good_class-_tering_between_them_similarity_given_variable_number_n_clause_number_m_and_average_clause_size_k_the_synthetic_generator_first_as-_signs_random_angles_\u03b8i_\u03b8j_0_2\u03c0_to_each_variable_i_and_each_clause_j_and_then_randomly_samples_variable_i_in_clause_j_with_the_proba-_bility_p_11i\u03b2j\u03b2irt_here_\u03b8ij_\u03c0-\u03c0-\u03b8i-\u03b8j_is_the_angle_between_variable_i_and_clause_j_the_exponent_parameters_\u03b2_and_\u03b2_control_the_power-law_distribution_of_variable_occurrences_and_clause_size_respectively_the_temperature_parameter_t_controls_the_sharpness_of_the_probability_distribution_while_r_is_an_approximate_normalization_constant_that_ensures_the_average_number_of_selected_edges_is_kmtdtdgeneral_m_uniform6n_8n_k_uniform4_5_\u03b2_uniform0_1_\u03b2_1_c_uniform3_10_t_uniform075_15_easy_dataset_n_uniform10_40_medium_dataset_n_uniform40_200_hard_dataset_n_uniform200_300tdtdthe_parameters_are_selected_based_on_the_experiments_in_the_original_paper_gir\u00e1ldez-cru_ampamp_levy_2017_and_our_study_to_ensure_that_the_generated_sat_instances_have_a_balance_of_satisfiability_and_unsatisfiabilitytdtrtrtdk-cliquetdtdthe_k-clique_dataset_includes_sat_instances_that_encode_the_k-clique_problem_which_involves_determining_whether_there_exists_a_clique_ie_a_subset_of_vertices_that_are_all_adjacent_to_each_other_with_v_vertices_in_a_given_graph_given_the_number_of_cliques_k_the_synthetic_generator_produces_an_erd\u0151s-r\u00e9nyi_graph_with_v_vertices_and_a_given_edge_probability_p_and_then_transforms_the_corresponding_k-clique_problem_into_a_sat_instancetdtdgeneral_p_vk-1v_easy_dataset_v_uniform5_15_k_uniform3_4_medium_dataset_v_uniform15_20_k_uniform3_5_hard_dataset_v_uniform20_25_k_uniform4_6tdtdthe_parameter_p_is_selected_based_on_the_paper_bollob\u00e1s_ampamp_erd\u0151s_1976_making_the_expected_number_of_k-cliques_in_the_generated_graph_equals_1tdtrtrtdk-domsettdtdthe_k-domset_dataset_contains_sat_instances_that_encode_the_k-dominating_set_problem_this_problem_is_to_determine_whether_there_exists_a_dominating_set_ie_a_subset_of_vertices_such_that_every_vertex_in_the_graph_is_either_in_the_subset_or_adjacent_to_a_vertex_in_the_sub-_set_with_at_most_k_vertices_in_a_given_graph_given_the_domination_number_k_the_synthetic_generator_produces_an_erd\u0151s-r\u00e9nyi_graph_with_v_vertices_and_a_given_edge_probability_p_and_then_transforms_the_corresponding_k-dominating_set_problem_into_a_sat_instancetdtdgeneral_p_1-1-vk-1vk_easy_dataset_v_uniform5_15_k_uniform2_3_medium_dataset_v_uniform15_20_k_uniform3_5_hard_dataset_v_uniform20_25_k_uniform4_6tdtdthe_parameter_p_is_selected_based_on_the_paper_wieland_ampamp_godbole_2001_making_the_expected_number_of_domination_set_with_size_k_in_the_generated_graph_equals_1tdtrtrtdk-vercovtdtdthe_k-vercov_dataset_consists_of_sat_instances_that_encode_the_k-vercov_problem_ie_check_whether_there_exists_a_set_of_k_vertices_in_a_graph_such_that_every_edge_has_at_least_one_endpoint_in_this_set_given_the_vertex_cover_number_k_the_synthetic_generator_produces_a_complement_graph_of_an_erd\u0151s-r\u00e9nyi_graph_with_v_vertices_and_a_given_edge_probability_p_and_then_converts_the_corresponding_k-vercov_cover_problem_into_a_sat_instancetdtdgeneral_p_vk-1v_easy_dataset_v_uniform5_15_k_uniform3_5_medium_dataset_v_uniform10_20_k_uniform6_8_hard_dataset_v_uniform15_25_k_uniform9_10tdtdthe_generation_process_and_the_parameter_are_selected_based_on_the_relationship_between_k-vercov_cover_and_k-clique_problems_making_the_size_of_the_minimum_vertex_cover_in_the_generated_graph_around_ktdtrtable": "Statistics. To provide a comprehensive understanding of our generated datasets, we compute several characteristics across three difficulty levels. These statistics include the average number of variables and clauses, as well as graph measures such as average clustering coefficient (in VIG) and modularity (in VIG, VCG, and LCG). The dataset statistics are summarized in Table 8. Table 8: Dataset statistics across difficulty levels in G4SATBench. <table><tr><td rowspan=\"2\">Dataset</td><td colspan=\"6\">Easy Difficulty</td><td colspan=\"6\">Medium Difficulty</td><td colspan=\"6\">Hard Difficulty</td></tr><tr><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td></tr><tr><td>SR</td><td>25.00</td><td>148.35</td><td>0.98</td><td>0.00</td><td>0.25</td><td>0.33</td><td>118.36</td><td>646.54</td><td>0.62</td><td>0.06</td><td>0.31</td><td>0.37</td><td>299.64</td><td>1613.86</td><td>0.32</td><td>0.09</td><td>0.32</td><td>0.37</td></tr><tr><td>3-SAT</td><td>25.05</td><td>113.69</td><td>0.72</td><td>0.06</td><td>0.36</td><td>0.46</td><td>120.00</td><td>513.14</td><td>0.27</td><td>0.16</td><td>0.43</td><td>0.51</td><td>250.44</td><td>1067.34</td><td>0.14</td><td>0.17</td><td>0.45</td><td>0.52</td></tr><tr><td>CA</td><td>31.66</td><td>303.48</td><td>0.65</td><td>0.19</td><td>0.73</td><td>0.73</td><td>120.27</td><td>1661.07</td><td>0.54</td><td>0.38</td><td>0.80</td><td>0.80</td><td>299.68</td><td>4195.50</td><td>0.59</td><td>0.57</td><td>0.80</td><td>0.80</td></tr><tr><td>PS</td><td>25.41</td><td>176.68</td><td>0.98</td><td>0.00</td><td>0.27</td><td>0.32</td><td>118.75</td><td>822.78</td><td>0.86</td><td>0.05</td><td>0.35</td><td>0.37</td><td>249.61</td><td>1728.34</td><td>0.77</td><td>0.08</td><td>0.38</td><td>0.28</td></tr><tr><td>A-Clique</td><td>34.85</td><td>592.89</td><td>0.90</td><td>0.03</td><td>0.45</td><td>0.49</td><td>69.56</td><td>2220.05</td><td>0.91</td><td>0.03</td><td>0.48</td><td>0.49</td><td>112.87</td><td>5543.26</td><td>0.88</td><td>0.04</td><td>0.49</td><td>0.50</td></tr><tr><td>k-Domest</td><td>41.90</td><td>369.40</td><td>0.70</td><td>0.26</td><td>0.47</td><td>0.53</td><td>90.64</td><td>1736.22</td><td>0.70</td><td>0.21</td><td>0.49</td><td>0.51</td><td>137.31</td><td>4022.48</td><td>0.70</td><td>0.20</td><td>0.49</td><td>0.51</td></tr><tr><td>k-Verox</td><td>45.41</td><td>484.28</td><td>0.66</td><td>0.16</td><td>0.48</td><td>0.53</td><td>107.40</td><td>2634.14</td><td>0.69</td><td>0.16</td><td>0.49</td><td>0.51</td><td>190.24</td><td>8190.94</td><td>0.69</td><td>0.16</td><td>0.50</td><td>0.51</td></tr></table> ## B GNN Models Message-passing schemes on VCG*. Recall that VCG* incorporates two distinct edge types, G4SATBench employs different functions to execute heterogeneous message-passing in each direction of each edge type. Formally, we define a d-dimensional embedding for each variable and clause node, denoted by \\(h_l\\) and \\(h_c\\), respectively. These embeddings are initialized to two learnable vectors \\(h_v^0\\) and \\(h_c^0\\), depending on the node type. At the \\(k\\)-th iteration of message passing, these hidden representations are updated as follows: \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^+ \\left(h_v^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^- \\left(h_v^{(k-1)}\\right)\\right\\}\\right), h_c^{(k-1)}\\right), \\quad (7)\\] \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^+ \\left(h_c^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^- \\left(h_c^{(k-1)}\\right)\\right\\}\\right), h_v^{(k-1)}\\right),\\] where \\(c^+\\) and \\(c^-\\) denote the sets of variable nodes that occur in the clause \\(c\\) with positive and negative polarity, respectively. Similarly, \\(v^+\\) and \\(v^-\\) denote the sets of clause nodes where variable \\(v\\) occurs in positive and negative form. \\(\\mathrm{MLP}_v^+\\), \\(\\mathrm{MLP}_v^-\\), \\(\\mathrm{MLP}_c^+\\), and \\(\\mathrm{MLP}_c^-\\) are four MLPs. \\(\\mathrm{UPD}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. GNN baselines. Table 9 summarizes the message-passing algorithms of the GNN models used in G4SATBench. We adopt heterogeneous versions of GCN (Kipf & Welling, 2017), GGNN (Li et al., 2016), and GIN (Xu et al., 2019) on both LCG* and VCG*, while maintaining the original Neuro SAT (Selsam et al., 2019) only on LCG*. ## C Benchmarking Evaluation ### C.1 Implementation Details In G4SATBench, we provide the ground truth of satisfiability and satisfying assignments by calling the state-of-the-art modern SAT solver Ca Di Ca L (Fleury & Heisinger, 2020) and generate the truth labels for unsat- core variables by invoking the proof checker DRAT-trim (Wetzler et al., 2014). All neural networks in our study are implemented using Py Torch (Paszke et al., 2019) and Py Torch Geometric (Fey & Lenssen, 2019). For all GNN models, we set the feature dimension \\(d\\) to 128 and the number of message passing iterations \\(T\\) to 32. The MLPs in the models consist of two hidden layers with the Re LU (Nair & Hinton, 2010) activation function. To select the optimal hyperparameters for each GNN baseline, we conduct a grid search over several settings. Specifically, we explore different learning rates from \\(\\{10^{-3}, 5 \\times 10^{-4}, 10^{-4}, 5 \\times 10^{-5}, 10^{-5}\\}\\), training epochs from \\(\\{50, 100, 200\\}\\), weight decay values from \\(\\{10^{-6}, 10^{-7}, 10^{-8}, 10^{-9}, 10^{-10}\\}\\), and gradient clipping norms from \\(\\{0.1, 0.5, 1\\}\\). We employ Adam (Kingma & Ba, 2015) as the optimizer and set the batch size to 128, 64, or 32 to fit within the maximum GPU memory (48G). For the parameters \\(\\tau\\) and \\(\\kappa\\) of the unsupervised loss in Equation 4 and Equation 5, we try the default settings (\\(\\tau = t^{-0.4}\\) and \\(\\kappa = 10\\), where \\(t\\) is the global step during training) as the original paper (Amizadeh et al., 2019a) as well as other values (\\(\\tau \\in \\{0.05, 0.1, 0.2, 0.5\\}\\), \\(\\kappa \\in \\{1, 2, 5\\}\\)) and empirically find \\(\\tau = 0.1\\), \\(\\kappa = 1\\) yield the best results. Furthermore,\n\nTable 9: Supported GNN models in G4SATBench. <table><tr><td>Graph</td><td>Method</td><td>Message-passing Algorithm</td><td>Notes</td></tr><tr><td rowspan=\"2\">Neuro SAT</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>s, s1 are the hidden states which are initialized to zero vectors.</td></tr><tr><td>h(c), s(c) = Layer Norm LSTM2</td><td>h(c), s(c) = Layer Norm LSTM2</td><td></td></tr><tr><td rowspan=\"2\">LCG*</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and literal node l in LCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">GGNN</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GCN</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and variable node v in VCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">VCG*</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = GIN</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = GIN</td><td></td></tr></table> it is important to note that we use three different random seeds to benchmark the performance of different GNN models and assess the generalization ability of Neuro SAT and GGNN using one seed for simplicity. ## C.2 Satisfiability Prediction Evaluation across different difficulty levels. The complete results of Neuro SAT and GGNN across different difficulty levels are presented in Figure 6. Consistent with the findings on the SR and 3- SAT datasets, both GNN models exhibit limited generalization ability to larger instances beyond their training data, while displaying relatively better performance on smaller instances. This observation suggests that training these models on more challenging instances could potentially enhance their generalization ability and improve their performance on larger instances. <center>Figure 6: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different message passing iterations. To investigate the impact of message-passing iterations on the performance of GNN models during training and testing, we conducted experiments with varying iteration values. Figure 7 presents the results of Neuro SAT and GGNN trained and evaluated with different message passing iterations. Remarkably, using a training iteration value of 32 consistently yielded the best performance for both models. Conversely, employing too small or too large iteration values during training resulted in decreased performance. Furthermore, the models trained with 32 iterations also demonstrated good generalization ability to testing iterations 16 and 64. These findings emphasize the critical importance of selecting an appropriate message-passing iteration to ensure optimal learning and reasoning within GNN models. <center>Figure 7: Classification accuracy of satisfiability across different message passing iterations \\(T\\) . The x-axis denotes testing iterations and the y-axis denotes training iterations. </center> ## C.3 Satisfying Assignment Prediction Evaluation with different training losses. Table 10 presents the complete results of each GNN baseline across three different training objectives. Like the results of Neuro SAT and GGNN, all other GNN models with unsupervised training outperform their supervised training counterparts. Table 10: Solving accuracy on identical distribution with different training losses. The top and bottom 7 rows represent the results for easy and medium datasets, respectively. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"3\">SR</td><td colspan=\"3\">3-SAT</td><td colspan=\"3\">CA</td><td colspan=\"3\">PS</td><td colspan=\"3\">k-Clique</td><td colspan=\"3\">k-Domest</td><td colspan=\"3\">k-Vercov</td></tr><tr><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>88.47</td><td>82.30</td><td>79.79</td><td>78.39</td><td>80.23</td><td>80.59</td><td>0.27</td><td>82.17</td><td>89.34</td><td>39.18</td><td>89.23</td><td>88.79</td><td>66.30</td><td>88.34</td><td>63.43</td><td>69.61</td><td>96.74</td><td>98.85</td><td>85.15</td><td>99.36</td><td>99.73</td></tr><tr><td>GCN</td><td>83.74</td><td>73.09</td><td>77.02</td><td>70.34</td><td>74.79</td><td>75.31</td><td>0.17</td><td>75.30</td><td>82.41</td><td>39.66</td><td>82.75</td><td>84.89</td><td>63.85</td><td>82.60</td><td>86.17</td><td>59.29</td><td>97.50</td><td>97.55</td><td>76.83</td><td>99.16</td><td>99.28</td></tr><tr><td>GGNN</td><td>84.13</td><td>76.39</td><td>78.75</td><td>72.87</td><td>76.55</td><td>76.42</td><td>0.29</td><td>78.13</td><td>84.08</td><td>38.82</td><td>84.44</td><td>86.29</td><td>60.80</td><td>84.60</td><td>87.12</td><td>68.36</td><td>97.49</td><td>98.06</td><td>82.06</td><td>-</td><td>99.34</td></tr><tr><td>GIN</td><td>83.81</td><td>81.45</td><td>80.39</td><td>73.99</td><td>78.47</td><td>76.24</td><td>0.20</td><td>78.44</td><td>85.15</td><td>39.13</td><td>85.31</td><td>85.43</td><td>56.85</td><td>84.48</td><td>85.11</td><td>68.93</td><td>96.99</td><td>97.43</td><td>81.49</td><td>99.28</td><td>99.38</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>83.38</td><td>84.19</td><td>78.00</td><td>76.60</td><td>84.42</td><td>79.23</td><td>14.98</td><td>76.64</td><td>83.79</td><td>51.48</td><td>85.88</td><td>83.06</td><td>56.27</td><td>85.28</td><td>86.91</td><td>66.32</td><td>97.62</td><td>96.74</td><td>78.67</td><td>-</td><td>93.51</td></tr><tr><td>GGNN</td><td>86.30</td><td>87.16</td><td>81.00</td><td>77.96</td><td>88.97</td><td>79.32</td><td>15.11</td><td>76.32</td><td>83.12</td><td>47.67</td><td>86.85</td><td>87.17</td><td>66.86</td><td>86.31</td><td>87.48</td><td>66.42</td><td>-</td><td>98.42</td><td>82.61</td><td>-</td><td>99.52</td></tr><tr><td>GIN</td><td>84.61</td><td>89.56</td><td>83.27</td><td>79.23</td><td>87.65</td><td>81.72</td><td>17.81</td><td>83.28</td><td>86.03</td><td>48.92</td><td>91.21</td><td>85.65</td><td>60.67</td><td>86.12</td><td>88.09</td><td>67.67</td><td>-</td><td>81.01</td><td>99.38</td><td>99.41</td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>34.97</td><td>25.00</td><td>37.25</td><td>20.07</td><td>30.40</td><td>41.61</td><td>0.00</td><td>35.45</td><td>70.83</td><td>3.64</td><td>60.28</td><td>71.03</td><td>56.61</td><td>41.45</td><td>-</td><td>52.09</td><td>95.06</td><td>96.18</td><td>74.77</td><td>67.44</td><td>95.99</td></tr><tr><td>GCN</td><td>13.19</td><td>13.76</td><td>19.21</td><td>8.87</td><td>20.50</td><td>24.58</td><td>0.00</td><td>30.20</td><td>54.04</td><td>14.45</td><td>45.16</td><td>56.29</td><td>55.36</td><td>61.82</td><td>66.33</td><td>43.50</td><td>92.86</td><td>94.89</td><td>67.83</td><td>-</td><td>93.84</td></tr><tr><td>GGNN</td><td>14.15</td><td>16.55</td><td>21.18</td><td>7.96</td><td>22.84</td><td>25.68</td><td>0.00</td><td>28.12</td><td>50.66</td><td>2.33</td><td>44.89</td><td>57.96</td><td>52.35</td><td>54.29</td><td>68.91</td><td>49.07</td><td>-</td><td>92.26</td><td>69.21</td><td>66.37</td><td>94.30</td></tr><tr><td>GIN</td><td>15.36</td><td>18.60</td><td>22.17</td><td>9.66</td><td>21.38</td><td>24.93</td><td>0.00</td><td>35.76</td><td>57.81</td><td>2.02</td><td>43.43</td><td>57.62</td><td>53.07</td><td>44.60</td><td>66.32</td><td>44.39</td><td>93.3</td><td>93.82</td><td>70.59</td><td>55.59</td><td>95.69</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>20.59</td><td>9.21</td><td>22.44</td><td>12.48</td><td>17.00</td><td>29.53</td><td>0.44</td><td>39.04</td><td>48.99</td><td>2.29</td><td>35.99</td><td>55.46</td><td>46.09</td><td>25.90</td><td>68.62</td><td>46.96</td><td>-</td><td>92.68</td><td>69.15</td><td>-</td><td>96.46</td></tr><tr><td>GGNN</td><td>28.04</td><td>27.72</td><td>33.37</td><td>16.46</td><td>29.65</td><td>35.95</td><td>0.56</td><td>48.13</td><td>49.93</td><td>3.12</td><td>51.73</td><td>65.11</td><td>44.26</td><td>48.92</td><td>56.43</td><td>51.01</td><td>-</td><td>71.97</td><td>-</td><td>95.23</td></tr><tr><td>GIN</td><td>26.73</td><td>26.48</td><td>31.97</td><td>14.64</td><td>26.86</td><td>35.81</td><td>0.64</td><td>44.06</td><td>63.84</td><td>3.38</td><td>58.03</td><td>64.66</td><td>55.47</td><td>56.97</td><td>67.78</td><td>46.98</td><td>-</td><td>95.28</td><td>69.40</td><td>-</td><td>96.96</td></tr></table> Evaluation across different difficulty levels. The performance of Neuro SAT across different difficulty levels is shown in Figure 8. Notably, training on medium datasets yields superior generalization performance compared to training on easy datasets. This suggests that training on more challenging SAT instances with larger sizes can enhance the model's ability to generalize to a wider range of problem complexities. <center>Figure 8: Solving accuracy of Neuro SAT across different difficulty levels (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different datasets. Figure 9 illustrates the performance of Neuro SAT across different datasets. For easy datasets, we observe that Neuro SAT demonstrates a strong generalization ability to other datasets when trained on the SR, 3- SAT, CA, and PS datasets. However, when trained on the \\(k\\) - Clique, \\(k\\) - Domset, and \\(k\\) - Vercov datasets, which involve specific graph structures inherent to their combinatorial problems, Neuro SAT struggles to generalize effectively. This observation indicates that the GNN model may overfit to leverage specific graph features associated with these combinatorial datasets, without developing a generalized solving strategy that can be applied to other problem domains for satisfying assignment prediction. For medium datasets, Neuro SAT also faces challenges in generalization, as its performance is relatively limited. This can be attributed to the difficulty of these datasets, where finding satisfying assignments is much harder than easy datasets. <center>Figure 9: Solving accuracy of Neuro SAT across different datasets (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation with different inference algorithms. Figure 10 illustrates the results of Neuro SAT using various decoding algorithms (with \\(\\mathrm{UNS}_2\\) as the training loss). Notably, all three decoding algorithms demonstrate similar performances across all datasets. This observation indicates that utilizing the standard readout after message passing is sufficient for predicting a satisfying assignment. Also, the GNN model has successfully learned to identify potential satisfying assignments within the latent space, which can be extracted by clustering the literal embeddings. <center>Figure 10: Solving accuracy of Neuro SAT with different inference algorithms. </center> ## Evaluation with unsatisfiable training in- Evaluation with unsatisfiable training instances. Following previous works (Amizadeh et al., 2019a;b; Ozolins et al., 2022), our evaluation of GNN models focuses solely on satisfiable instances. However, in practical scenarios, the satisfiability of instances may not be known before training. To address this gap, we explore the effectiveness of training Neuro SAT using the unsupervised loss \\(\\mathrm{UNS}_2\\) on noisy datasets that contain unsatisfiable instances. Table 11 presents the results of Neuro SAT when trained on such datasets, where \\(50\\%\\) of the instances are unsatisfiable. Interestingly, incorporating unsatisfiable instances for training does not significantly affect the performance of the GNN model. This finding highlights the potential utility of training GNN models using \\(\\mathrm{UNS}_2\\) loss on new datasets, irrespective of any prior knowledge regarding their satisfiability. Table 11: Solving accuracy of Neuro SAT when trained on noisy datasets. Values in parentheses indicate the performance difference compared to the model trained without unsatisfiable instances. The \\(k\\) -Clique dataset is excluded as Neuro SAT fails during training. <table><tr><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td></tr><tr><td>78.84<br>(-0.95)</td><td>80.48<br>(-0.11)</td><td>87.01<br>(-2.33)</td><td>88.66<br>(-0.13)</td><td>98.00<br>(-0.85)</td><td>95.24<br>(-4.49)</td><td>37.21<br>(-0.04)</td><td>41.75<br>(+0.14)</td><td>76.49<br>(+5.64)</td><td>72.52<br>(+1.46)</td><td>94.93<br>(-1.25)</td><td>96.18<br>(+0.19)</td></tr></table> ## C.4 Unsat-core Variable Prediction Evaluation across different difficulty levels. The results across different difficulty levels are presented in Figure 11. Remarkably, both Neuro SAT and GGNN exhibit a strong generalization ability when trained on easy or medium datasets. This suggests that GNN models can effectively learn and generalize from the\n\ncharacteristics and patterns present in these datasets, enabling them to perform well on a wide range of problem complexities. <center>Figure 11: Classification accuracy of unsat-core variables across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation across different datasets. Figure 12 shows the generalization results across different datasets. Both Neuro SAT and GGNN demonstrate good generalization performance to datasets that are different from their training data, except for the CA dataset. This discrepancy can be attributed to the specific characteristics of the CA dataset, where the number of unsat- core variables is significantly smaller compared to the number of variables not in the unsat core. In contrast, other datasets have a different distribution, where the number of unsat- core variables is much larger. This variation in distribution presents a challenge for the models' generalization ability on the CA dataset. <center>Figure 12: Classification accuracy of unsat-core variables across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> ## D Advancing Evaluation ## D.1 Implementation details To create the augmented datasets, we leverage Ca Di Ca L (Fleury & Heisinger, 2020) to generate a DART proof (Wetzler et al., 2014) for each SAT instance, which tracks the clause learning procedure and records all the learned clauses during the solving process. These learned clauses are then added to each instance, with a maximum limit of 1,000 clauses. For experiments on augmented datasets, we keep all training settings identical to those used for the original datasets. For contrastive pretraining experiments, we treat each original formula and its augmented counterpart as a positive pair and all other instances in a mini- batch as negative pairs. We use an MLP projection to map the graph embedding \\(z_{i}\\) of each formula to \\(m_{i}\\) and employ the Sim CLR's contrastive loss (Chen et al., 2020), where the loss function for a positive pair of examples \\((i,j)\\) in a mini- batch of size \\(2N\\) is defined as: \\[\\mathcal{L}_{i,j} = -\\log \\frac{\\exp(\\sin(m_{i},m_{j}) / \\tau)}{\\sum_{k = 1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\sin(m_{i},m_{k}) / \\tau)}. \\quad (8)\\]\n\npredicts marginal distributions of all satisfying solutions to solve the SAT problem. Moreover, most previous research has experimented on different datasets that vary in a range of settings (e.g., data distribution, instance size, and dataset size), which leads to a lack of unified and standardized datasets for training and evaluation. Additionally, some work (Amizadeh et al., 2019b; Shi et al., 2023; Yan et al., 2023) has noted the difficulty of re- implementing prior approaches as baselines, rendering it arduous to draw consistent conclusions about the performance of peer methods. All of these issues impede the development of GNN- based solvers for SAT solving. To systematically quantify the progress in this field and facilitate rapid, reproducible, and generalizable research, we propose G4SATBench, the first comprehensive benchmark study for SAT solving with GNNs. G4SATBench is characterized as follows: - First, we construct a large and diverse collection of SAT datasets that includes instances from distinct sources and difficulty levels. Specifically, our benchmark consists of 7 different datasets from 3 benchmark families, including random instances, pseudo-industrial instances, and combinatorial problems. It not only covers a wide range of prior datasets but also introduces 3 levels of difficulty for each dataset to enable fine-grained analyses. - Second, we re-implement various GNN-based SAT solvers with unified interfaces and configuration settings, establishing a general evaluation protocol for fair and comprehensive comparisons. Our framework allows for evaluating different GNN models in SAT solving with various prediction tasks, training objectives, and inference algorithms, encompassing the diverse learning frameworks employed in the existing literature. - Third, we present baseline results and conduct thorough analyses of GNN-based SAT solvers, providing a detailed reference of prior work and laying a solid foundation for future research. Our evaluations assess the performances of different choices of GNN models (e.g., graph constructions, message-passing schemes) with particular attention to some critical parameters (e.g., message-passing iterations), as well as their generalization ability across different distributions. - Lastly, we conduct a series of in-depth experiments to explore the learning abilities of GNN-based SAT solvers. Specifically, we compare the training and solving processes of GNNs with the heuristics employed in both CDCL and LS-based SAT solvers. Our experimental results reveal that GNNs tend to develop a solving heuristic similar to greedy local search to find a satisfying assignment but fail to effectively learn the CDCL heuristic in the latent space. We believe that G4SATBench will help the research community to make significant strides in understanding the capabilities and limitations of GNNs for solving SAT and facilitate further endeavors in this domain. ## 2 Related Work SAT solving with GNNs. Existing GNN- based SAT solvers can be broadly categorized into two branches (Holden et al., 2021; Guo et al., 2022): standalone neural solvers and neural- guided solvers. Standalone neural solvers utilize GNNs to solve SAT instances directly. For example, a stream of research (B\u00fcnz & Lamm, 2017; Selsam et al., 2019; Jaszczur et al., 2020; Cameron et al., 2020; Shi et al., 2023) focuses on predicting the satisfiability of a given formula, while several alternative approaches (Amizadeh et al., 2019a;b; Ozolins et al., 2022; Li et al., 2023; Yan et al., 2023) aim to construct a satisfying assignment. Neural- guided solvers, on the other hand, integrate GNNs with modern SAT solvers, trying to improve their search heuristics with the prediction of GNNs. These methods typically train GNN models using supervised learning on some tasks such as unsat- core variable prediction (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021), satisfying assignment prediction (Zhang et al., 2020), glue variable prediction (Han, 2020), and assignment marginal prediction (Li & Si, 2022), or through reinforcement learning (Yolcu & P\u00f3czos, 2019; Kurin et al., 2020) by modeling the entire search procedure as a Markov decision process. Despite the rich literature on SAT solving with GNNs, there is no benchmark study to evaluate and compare the performance of these GNN models. We hope the proposed G4SATBench would address this gap.\n\nHere, \\(\\mathbb{1}_{[k \\neq i]}\\) is an indicator function that evaluates to 1 if \\(k \\neq i\\) , \\(\\tau\\) is a temperature parameter, and \\(\\text{sim}(\\cdot , \\cdot)\\) is the similarity function defined as \\(\\text{sim}(m_i, m_j) = m_i^\\top m_j / \\|m_i\\| \\|m_j\\|\\) . The final loss is the average over all positive pairs. In our experiments, we set the temperature parameter to 0.5 and utilize a learning rate of \\(10^{- 4}\\) with a weight decay of \\(10^{- 8}\\) . The pretraining process is performed for a total of 100 epochs. Once the pretraining is completed, we keep the GNN model and remove the projection head for downstream tasks. For experiments involving random initialization, we utilize Kaiming Initialization (He et al., 2015) to initialize all literal/variable and clause embeddings during both training and testing. For the predicted assignments, we utilize 2- clustering decoding to construct two possible assignment predictions for Neuro SAT\\* at each iteration. When calculating the number of flipped variables and unsatisfiable clauses for Neuro SAT\\*, we only consider the better assignment prediction of the two at each iteration, which is the one that satisfies more clauses. All other experimental settings remain the same as in the benchmarking evaluation. ## D.2 Comparisons with State-of-the-art SAT Solvers We compare Neuro SAT with two advanced CDCL and LS solvers, Ca Di Ca L Fleury & Heisinger (2020) and Sparrow (Balint & Fr\u00f6hlich, 2010). To enable a fair comparison, we first configure Sparrow to generate the same number of assignments as Neuro SAT by setting its maximum flip number to 32, allowing for an apples- to- apples comparison of both solvers' accuracy and execution time. Subsequently, we allow Sparrow and Ca Di Ca L to run without constraints to solve the satisfiable instances in G4SATBench. Considering that Neuro SAT processes a batch of problems in parallel on GPUs, we calculate its per- instance runtime by dividing the total execution time by the number of testing instances. The results, summarized in Table 12, indicate that GNN- based heuristics could outperform modern local search solvers like Sparrow, generating more satisfying assignments extremely fast when constrained to output a limited number of solutions. However, once such a constraint is lifted, both Sparrow and Ca Di Ca L can traverse the solution space efficiently and solve all satisfiable instances in G4SATBench, while GNN models like Neuro SAT may find it challenging due to their limited exploration capacity as evidenced in Figure 5a. Nevertheless, it's crucial to recognize that while GNN models are hard to compete with Ca Di Ca L and Sparrow, their assignment predictions could still serve as good initializations in these solvers, potentially leading to better performance (Zhang et al., 2020; Li & Si, 2022). Table 12: Results of Neuro SAT, Sparrow, and Ca Di Ca L. The top 2 rows represent the solving accuracy (%), and the bottom 4 rows represent the running time (second) per instance. Sparrow\\\\* refers to Sparrow limited to a maximum of 32 flips. <table><tr><td rowspan=\"2\">Method</td><td colspan=\"7\">Easy Datasets</td><td colspan=\"7\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td>Neuro SAT</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.461</td><td>70.83</td><td>71.03</td><td>32.48</td><td>96.18</td><td>95.99</td></tr><tr><td>Sparrow*</td><td>56.03</td><td>52.09</td><td>85.48</td><td>77.25</td><td>53.68</td><td>37.15</td><td>31.61</td><td>1.64</td><td>1.85</td><td>12.68</td><td>10.72</td><td>12.99</td><td>1.27</td><td>0.53</td></tr><tr><td>Neuro SAT</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.003</td><td>0.002</td><td>0.003</td><td>0.008</td><td>0.006</td><td>0.009</td><td>0.010</td><td>0.009</td><td>0.006</td><td>0.007</td></tr><tr><td>Sparrow*</td><td>0.005</td><td>0.005</td><td>0.006</td><td>0.006</td><td>0.005</td><td>0.005</td><td>0.005</td><td>0.008</td><td>0.007</td><td>0.006</td><td>0.006</td><td>0.006</td><td>0.007</td><td>0.006</td></tr><tr><td>Sparrow</td><td>0.007</td><td>0.007</td><td>0.008</td><td>0.008</td><td>0.007</td><td>0.009</td><td>0.009</td><td>0.013</td><td>0.013</td><td>0.010</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td></tr><tr><td>Ca Di Ca L</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.043</td><td>0.016</td><td>0.018</td><td>0.015</td><td>0.013</td><td>0.012</td></tr></table>\n\nSAT datasets. Several established SAT benchmarks, including the prestigious SATLIB (Hoos & St\u00fctzle, 2000) and the SAT Competitions over the years, have provided a variety of practical instances to assess the performance of modern SAT solvers. Regrettably, these datasets are not particularly amenable for GNNs to learn from, given their relatively modest scale (less than 100 instances for a specific domain) or overly extensive instances (exceeding 10 million variables and clauses). To address this issue, researchers have turned to synthetic SAT instance generators (Gir\u00e1ldez- Cruz & Levy, 2015; 2017; Lauria et al., 2017; Selsam et al., 2019), which allow for the creation of a flexible number of instances with customizable settings. However, most of the existing datasets generated from these sources are limited to a few domains (less than 3 generators), small in size (less than 10k instances), or easy in difficulty (less than 40 variables within an instance), and there is no standardized dataset for evaluation. In G4SATBench, we include a variety of synthetic generators with carefully selected configurations, aiming to construct a broad collection of SAT datasets that are highly conducive for training and evaluating GNNs. ## 3 Preliminaries The SAT problem. In propositional logic, a Boolean formula is constructed from Boolean variables and logical operators such as conjunctions \\((\\wedge)\\) , disjunctions \\((\\vee)\\) , and negations \\((\\neg)\\) . It is typical to represent Boolean formulas in conjunctive normal form (CNF), expressed as a conjunction of clauses, where each clause is a disjunction of literals, which can be either a variable or its negation. Given a CNF formula, the SAT problem is to determine if there exists an assignment of boolean values to its variables such that the formula evaluates to true. If this is the case, the formula is called satisfiable; otherwise, it is unsatisfiable. For a satisfiable instance, one is expected to construct a satisfying assignment to prove its satisfiability. On the other hand, for an unsatisfiable formula, one can find a minimal subset of clauses whose conjunction is still unsatisfiable. Such a set of clauses is termed the unsat core, and variables in the unsat core are referred to as unsat- core variables. Graph representations of CNF formulas. Traditionally, a CNF formula can be represented using 4 types of graphs (Biere et al., 2009): Literal- Clause Graph (LCG), Variable- Clause Graph (VCG), Literal- Incidence Graph (LIG), and Variable- Incidence Graph (VIG). The LCG is a bipartite graph with literal and clause nodes connected by edges indicating the presence of a literal in a clause. The VCG is formed by merging the positive and negative literals of the same variables in LCG. The LIG, on the other hand, only consists of literal nodes, with edges indicating co- occurrence in a clause. Lastly, the VIG is derived from LIG using the same merging operation as VCG. ## 4 G4SATBench: A Benchmark Study on GNNs for SAT Solving The goal of G4SATBench is to establish a general framework that enables comprehensive comparisons and evaluations of various GNN- based SAT solvers. In this section, we will delve into the details of G4SATBench, including its datasets, GNN models, prediction tasks, as well as training and testing methodologies. The overview of the G4SATBench framework is shown in Figure 1. ### 4.1 Datasets G4SATBench is built on a diverse set of synthetic CNF generators. It currently consists of 7 datasets sourced from 3 distinct domain areas: random problems, pseudo- industrial problems, and combinatorial problems. Specifically, we utilize the SR generator in Neuro SAT (Selsam et al., 2019) and the 3- SAT generator in CNFGen (Lauria et al., 2017) to produce random CNF formulas. For pseudo- industrial problems, we employ the Community Attachment (CA) model (Gir\u00e1ldez- Cruz & Levy, 2015) and the Popularity- Similarity (PS) model (Gir\u00e1ldez- Cruz & Levy, 2017), which generate synthetic instances that exhibit similar statistical features, such as the community and the locality, to those observed in real- world industrial SAT instances. For combinatorics, we resort to 3 synthetic generators in CNFGen (Lauria et al., 2017) to create SAT instances derived from the translation of \\(k\\) - Clique, \\(k\\) - Dominating Set, and \\(k\\) - Vertex Cover problems.\n\n<center>Figure 1: Framework overview of G4SATBench. </center> In addition to the diversity of datasets, G4SATBench offers distinct difficulty levels for all datasets to enable fine- grained analyses. These levels include easy, medium, and hard, with the latter representing more complex problems with increased instance sizes. For example, the easy SR dataset contains instances with 10 to 40 variables, the medium SR dataset contains formulas with 40 to 200 variables, and the hard SR dataset consists of formulas with variables ranging from 200 to 400. For each easy and medium dataset, we generate 80k pairs of satisfiable and unsatisfiable instances for training, 10k pairs for validation, and 10k pairs for testing. For each hard dataset, we produce 10k testing pairs. It is also worth noting that the parameters for our synthetic generators are meticulously selected to avoid generating trivial cases. For instance, we produce random 3- SAT formulas at the phase- transition region where the relationship between the number of clauses \\((m)\\) and variables \\((n)\\) is \\(m = 4.258n + 58.26n^{- 2 / 3}\\) (Crawford & Auton, 1996), and utilize the \\(v\\) vertex Erd\u0151s- R\u00e9nyi graph with an edge probability of \\(p = \\binom{v}{k}^{- 1 / \\binom{v}{2}}\\) to generate \\(k\\) - Clique problems, making the expected number of \\(k\\) - Cliques in a graph equals 1 (Bollob\u00e1s & Erd\u0151s, 1976). To provide a detailed characterization of our generated datasets, we compute several statistics of the SAT instances across difficulty levels in G4SATBench. Please refer to Appendix A for more information about the datasets. ### 4.2 GNN Baselines Graph constructions. It is important to note that traditional graph representations of a CNF formula often lack the requisite details for optimally constructing GNNs. Specifically, the LIG and VIG exclude clause- specific information, while the LCG and VCG fail to differentiate between positive and negative literals of the same variable. To address these limitations, existing approaches typically build GNN models on the refined versions of the LCG and VCG encodings. In the LCG, a new type of edge is added between each literal and its negation, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. <center>Figure 2: LCG\\* and VCG\\* of the CNF formula \\((x_{1} \\vee \\neg x_{2}) \\wedge (x_{1} \\vee x_{3}) \\wedge (\\neg x_{1} \\vee x_{2} \\vee x_{3})\\) . </center> tion, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. Message- passing schemes. G4SATBench enables performing various heterogeneous message- passage algorithms between neighboring nodes on the LCG\\* or VCG\\* encodings of a CNF formula. For the sake of illustration, we will take GNN models on the LCG\\* as an example. We first define a \\(d\\) - dimensional embedding for every literal node and clause node, denoted by \\(h_{l}\\) and \\(h_{c}\\) respectively. Initially, all these embeddings are assigned to two learnable vectors \\(h_{l}^{0}\\) and \\(h_{c}^{0}\\) , depending on their node types. At the \\(k\\) - th iteration of\n\nmessage passing, these hidden representations are updated as: \\[\\begin{array}{r l} & {h_{c}^{(k)} = \\mathrm{UP D}\\left(\\underset {l\\in \\mathcal{N}(c)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{l}^{(k - 1)}\\right)\\right\\} \\right),h_{c}^{(k - 1)}\\right),}\\\\ & {h_{l}^{(k)} = \\mathrm{UP D}\\left(\\underset {c\\in \\mathcal{N}(l)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{c}^{(k - 1)}\\right)\\right\\} \\right),h_{-l}^{(k - 1)},h_{l}^{(k - 1)}\\right),} \\end{array} \\quad (1)\\] where \\(\\mathcal{N}(\\cdot)\\) denotes the set of neighbor nodes, MLP is the multi- layer perception, \\(\\mathrm{UP D}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. Most GNN models on \\(\\mathrm{LCG}^{*}\\) use Equation 1 with different choices of the update function and aggregation function. For instance, Neuro SAT employs Layer Norm L- STM (Ba et al., 2016) as the update function and summation as the aggregation function. In G4SATBench, we provide a diverse range of GNN models, including Neuro SAT (Selsam et al., 2019), Graph Convolutional Network (GCN) (Kipf & Welling, 2017), Gated Graph Neural Network (GGNN) (Li et al., 2016), and Graph Isomorphism Network (GIN) (Xu et al., 2019), on the both \\(\\mathrm{LCG}^{*}\\) and \\(\\mathrm{VCG}^{*}\\) . More details of these GNN models are included in Appendix B. ### 4.3 Supported Tasks, Training and Testing Settings Prediction tasks. In G4SATBench, we support three essential prediction tasks for SAT solving: satisfiability prediction, satisfying assignment prediction, and unsat- core variable prediction. These tasks are widely used in both standalone neural solvers and neural- guided solvers. Technically, we model satisfiability prediction as a binary graph classification task, where \\(1 / 0\\) denotes the given SAT instance \\(\\phi\\) is satisfiable/unsatisfiable. Here, we take GNN models on the \\(\\mathrm{LCG}^{*}\\) as an example. After \\(T\\) message passing iterations, we obtain the graph embedding by applying mean pooling on all literal embeddings, and then predict the satisfiability using an MLP followed by the sigmoid function \\(\\sigma\\) : \\[y_{\\phi} = \\sigma \\left(\\mathrm{MLP}\\left(\\mathrm{MEAN}\\left(\\{h_{l}^{(T)},l\\in \\phi \\}\\right)\\right)\\right). \\quad (2)\\] For satisfying assignment prediction and unsat- core variable prediction, we formulate them as binary node classification tasks, predicting the label for each variable in the given CNF formula \\(\\phi\\) . In the case of GNNs on the \\(\\mathrm{LCG}^{*}\\) , we concatenate the embeddings of each pair of literals \\(h_{l}\\) and \\(h_{- l}\\) to construct the variable embedding, and then readout using an MLP and the sigmoid function \\(\\sigma\\) : \\[y_{v} = \\sigma \\left(\\mathrm{MLP}\\left(\\left[h_{l}^{(T)},h_{-l}^{(T)}\\right]\\right)\\right). \\quad (3)\\] Training objectives. To train GNN models on the aforementioned tasks, one common approach is to minimize the binary cross- entropy loss between the predictions and the ground truth labels. In addition to supervised learning, G4SATBench supports two unsupervised training paradigms for satisfying assignment prediction (Amizadeh et al., 2019a; Ozolins et al., 2022). The first approach aims to differentiate and maximize the satisfiability value of a CNF formula (Amizadeh et al., 2019a). It replaces the \\(\\neg\\) operator with the function \\(N(x_{i}) = 1 - x_{i}\\) and uses smooth max and min functions to replace the \\(\\vee\\) and \\(\\wedge\\) operators. The smooth max and min functions are defined as follows: \\[S_{m a x}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{x_{i} / \\tau}},\\quad S_{m i n}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{-x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{-x_{i} / \\tau}}, \\quad (4)\\] where \\(\\tau \\geq 0\\) is the temperature parameter. Given a predicted assignment \\(x\\) , we apply the smoothing logical operators and substitute variables in a formula \\(\\phi\\) with the corresponding values from \\(x\\) to calculate its satisfiability value \\(S(x)\\) . Then we can minimize the following loss function: \\[\\mathcal{L}_{\\phi}(x) = \\frac{(1 - S(x))^{\\kappa}}{(1 - S(x))^{\\kappa} + S(x)^{\\kappa}}. \\quad (5)\\] The second unsupervised loss is defined as follows (Ozolins et al., 2022): \\[V_{c}(x) = 1 - \\prod_{i\\in c^{+}}(1 - x_{i})\\prod_{i\\in c^{-}}x_{i},\\quad \\mathcal{L}_{\\phi}(x) = -\\log \\Bigl (\\prod_{c\\in \\phi}V_{c}(x)\\Bigr) = -\\sum_{c\\in \\phi}\\log \\bigl (V_{c}(x)\\bigr), \\quad (6)\\]\n\nwhere \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in the clause \\(c\\) in positive and negative form respectively. Note that these two losses reach the minimum only when the prediction \\(x\\) is a satisfying assignment, thus minimizing such losses could help to construct a possible satisfying assignment. Inference algorithms. Beyond the standard readout process like training, G4SATBench offers two alternative inference algorithms for satisfying assignment prediction (Selsam et al., 2019; Amizadeh et al., 2019b). The first method performs 2- clustering on the literal embeddings to obtain two centers \\(\\Delta_{1}\\) and \\(\\Delta_{2}\\) and then partitions the positive and negative literals of each variable into distinct groups based on the predicate \\(||x_{i} - \\Delta_{1}||^{2} + ||\\neg x_{i} - \\Delta_{2}||^{2}< ||x_{i} - \\Delta_{2}||^{2} + ||\\neg x_{i} - \\Delta_{1}||^{2}\\) (Selsam et al., 2019). This allows the construction of two possible assignments by mapping one group of literals to true. The second approach is to employ the readout function at each iteration of message passing, resulting in multiple assignment predictions for a given instance (Amizadeh et al., 2019b). Evaluation metrics. For satisfiability prediction and unsat- core variable prediction, we report the classification accuracy of each GNN model in G4SATBench. For satisfying assignment prediction, we report the solving accuracy of the predicted assignments. If multiple assignments are predicted for a SAT instance, the instance is considered solved if any of the predictions satisfy the formula. ## 5 Benchmarking Evaluation on G4SATBench In this section, we present the benchmarking results of G4SATBench. To ensure a fair comparison, we conduct a grid search to tune the hyperparameters of each GNN baseline. The best checkpoint for each GNN model is selected based on its performance on the validation set. To mitigate the impact of randomness, we use 3 different random seeds to repeat the experiment in each setting and report the average performance. Each experiment is performed on a single RTX8000 GPU and 16 AMD EPYC 7502 CPU cores, and the total time cost is approximately 8,000 GPU hours. For detailed experimental setup and hyperparameters, please refer to Appendix C.1. ### 5.1 Satisfiability Prediction Evaluation on the same distribution. Table 1 shows the benchmarking results of each GNN baseline when trained and evaluated on datasets possessing identical distributions. All GNN models exhibit strong performance across most easy and medium datasets, except for the medium SR dataset. This difficulty can be attributed to the inherent characteristic of this dataset, which includes satisfiable and unsatisfiable pairs of medium- sized instances distinguished by just a single differing literal. Such a subtle difference presents a substantial challenge for GNN models in satisfiability classification. Among all GNN models, the different graph constructions do not seem to have a significant impact on the results, and Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) achieve the best overall performance. Table 1: Classification accuracy of satisfiability on identical distribution. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>96.00</td><td>96.33</td><td>98.83</td><td>96.59</td><td>97.92</td><td>99.77</td><td>99.99</td><td>78.02</td><td>84.90</td><td>99.57</td><td>96.81</td><td>89.39</td><td>99.67</td></tr><tr><td>GCN</td><td>94.43</td><td>94.47</td><td>98.79</td><td>97.53</td><td>98.24</td><td>99.59</td><td>99.98</td><td>69.39</td><td>82.67</td><td>99.53</td><td>96.16</td><td>85.72</td><td>99.16</td></tr><tr><td>GGNN</td><td>96.36</td><td>95.70</td><td>98.81</td><td>97.47</td><td>98.80</td><td>99.77</td><td>99.97</td><td>71.44</td><td>83.45</td><td>99.50</td><td>96.21</td><td>81.20</td><td>99.69</td></tr><tr><td>GIN</td><td>95.78</td><td>95.37</td><td>98.14</td><td>96.98</td><td>97.60</td><td>99.71</td><td>99.97</td><td>70.54</td><td>82.80</td><td>99.49</td><td>95.80</td><td>83.87</td><td>99.61</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>93.19</td><td>94.92</td><td>97.82</td><td>95.79</td><td>98.72</td><td>99.54</td><td>99.99</td><td>66.35</td><td>83.75</td><td>99.49</td><td>95.48</td><td>82.99</td><td>99.42</td></tr><tr><td>GGNN</td><td>96.75</td><td>96.25</td><td>98.77</td><td>96.44</td><td>98.88</td><td>99.68</td><td>99.98</td><td>77.12</td><td>85.11</td><td>99.57</td><td>96.48</td><td>83.63</td><td>99.62</td></tr><tr><td>GIN</td><td>96.04</td><td>95.71</td><td>98.47</td><td>96.95</td><td>97.33</td><td>99.59</td><td>99.98</td><td>73.56</td><td>85.26</td><td>99.49</td><td>96.55</td><td>89.41</td><td>99.38</td></tr></table> Evaluation across different distributions. To assess the generalization ability of GNN models, we evaluate the performance of Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) across different datasets and difficulty levels. As shown in Figure 3 and Figure 4, Neuro SAT and GGNN struggle to generalize effectively to datasets distinct from their training data in most cases. However, when trained on the SR dataset, they exhibit better generalization performance across different datasets. Furthermore, while both GNN models\n\ndemonstrate limited generalization to larger formulas beyond their training data, they perform relatively better on smaller instances. These observations suggest that the generalization performance of GNN models for satisfiability prediction is influenced by the distinct nature and complexity of its training data. Training on more challenging instances could potentially enhance their generalization ability. <center>Figure 3: Classification accuracy of satisfiability across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> <center>Figure 4: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Due to the limited space, Figure 4 exclusively displays the performance of Neuro SAT and GGNN on the SR and 3- SAT datasets. Comprehensive results on the other five datasets, as well as the experimental results on different massage passing iterations, are provided in Appendix C.2. ### 5.2 Satisfying Assignment Prediction Evaluation with different training losses. Table 2 presents the results of Neuro SAT (on \\(\\mathrm{LCG}^{*}\\) ) and GGNN (on \\(\\mathrm{VCG}^{*}\\) ) across three different training objectives. The results of other GNN models are listed in Table 10 in Appendix C.3. Interestingly, the unsupervised training methods outperform the supervised learning approach across the majority of datasets. We hypothesize that this is due to the presence of multiple satisfying assignments in most satisfiable instances. Supervised training tends to bias GNN models towards learning a specific satisfying solution, thereby neglecting the exploration of other feasible ones. This bias may compromise the models' ability to generalize effectively. Such limitations become increasingly apparent when the space of satisfying solutions is much larger, as seen in the medium CA and PS datasets. Additionally, it is noteworthy that employing \\(\\mathrm{UNS}_1\\) as the loss function can result in instability during the training of some GNN models, leading to a failure to converge in some cases. Conversely, using \\(\\mathrm{UNS}_2\\) loss demonstrates strong and stable performance across all datasets. In addition to evaluating the performance of GNN models under various training loss functions, we extend our analysis to explore how these models perform across different data distributions and under various inference algorithms. Furthermore, we assess the robustness of these GNN models when trained on noisy datasets that include unsatisfiable instances in an unsupervised fashion. For detailed results of these evaluations across different GNN baselines, please refer to Appendix C.3.\n\nTable 2: Solving accuracy on identical distribution with different training losses. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td rowspan=\"2\">Loss</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"3\">LCG*</td><td rowspan=\"3\">Neuro SAT</td><td>SUP</td><td>88.47</td><td>78.39</td><td>0.27</td><td>39.18</td><td>66.30</td><td>69.61</td><td>85.15</td><td>34.97</td><td>20.07</td><td>0.00</td><td>3.64</td><td>56.61</td><td>52.09</td></tr><tr><td>UNS1</td><td>82.30</td><td>80.23</td><td>82.17</td><td>89.23</td><td>88.34</td><td>96.74</td><td>99.36</td><td>25.00</td><td>30.40</td><td>35.45</td><td>60.28</td><td>41.45</td><td>95.06</td></tr><tr><td>UNS2</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.61</td><td>70.83</td><td>71.03</td><td>-</td><td>96.18</td><td>95.99</td></tr><tr><td rowspan=\"3\">VCG*</td><td rowspan=\"3\">GGNN</td><td>SUP</td><td>84.13</td><td>72.87</td><td>0.29</td><td>38.82</td><td>60.80</td><td>68.36</td><td>82.06</td><td>14.15</td><td>7.96</td><td>0.00</td><td>2.33</td><td>52.35</td><td>49.07</td></tr><tr><td>UNS1</td><td>76.39</td><td>76.55</td><td>78.13</td><td>84.44</td><td>84.60</td><td>97.49</td><td>-</td><td>16.55</td><td>22.84</td><td>28.12</td><td>44.89</td><td>54.29</td><td>-</td></tr><tr><td>UNS2</td><td>78.75</td><td>76.42</td><td>84.08</td><td>86.29</td><td>87.12</td><td>98.06</td><td>99.34</td><td>21.18</td><td>25.68</td><td>50.66</td><td>57.96</td><td>68.91</td><td>92.26</td><td>94.30</td></tr></table> ### 5.3 Unsat-core Variable Prediction Evaluation on the same distribution. The benchmarking results presented in Table 3 exhibit the superior performance of all GNN models on both easy and medium datasets, with Neuro SAT consistently achieving the best results across most datasets. It is important to note that the primary objective of predicting unsat- core variables is not to solve SAT problems directly but to provide valuable guidance for enhancing the backtracking search process. As such, even imperfect predictions - for instance, those with a classification accuracy of \\(90\\%\\) - have been demonstrated to be sufficiently effective in improving the search heuristics employed by modern CDCL- based SAT solvers, as indicated by previous studies (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021). Table 3: Classification accuracy of unsat-core variables on identical distribution. Only unsatisfiable instances are evaluated. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>90.76</td><td>94.43</td><td>83.69</td><td>86.20</td><td>99.93</td><td>95.80</td><td>94.47</td><td>90.07</td><td>99.65</td><td>85.73</td><td>88.53</td><td>99.97</td><td>97.90</td></tr><tr><td>GCN</td><td>89.17</td><td>94.35</td><td>82.89</td><td>85.32</td><td>99.93</td><td>95.74</td><td>94.43</td><td>88.11</td><td>99.65</td><td>85.71</td><td>87.70</td><td>99.96</td><td>97.89</td></tr><tr><td>GGNN</td><td>90.02</td><td>94.38</td><td>83.59</td><td>86.03</td><td>99.93</td><td>95.79</td><td>94.46</td><td>89.05</td><td>99.65</td><td>85.69</td><td>87.95</td><td>99.96</td><td>97.89</td></tr><tr><td>GIN</td><td>89.29</td><td>94.33</td><td>83.71</td><td>85.97</td><td>99.93</td><td>95.81</td><td>94.47</td><td>88.85</td><td>99.65</td><td>85.71</td><td>87.92</td><td>99.96</td><td>97.89</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>88.57</td><td>94.34</td><td>83.17</td><td>85.27</td><td>99.93</td><td>95.79</td><td>94.46</td><td>88.17</td><td>99.65</td><td>85.70</td><td>87.37</td><td>99.96</td><td>97.90</td></tr><tr><td>GGNN</td><td>89.57</td><td>94.37</td><td>83.50</td><td>85.84</td><td>99.93</td><td>95.81</td><td>94.49</td><td>88.84</td><td>99.65</td><td>85.68</td><td>88.03</td><td>99.98</td><td>97.90</td></tr><tr><td>GIN</td><td>89.50</td><td>94.35</td><td>83.23</td><td>85.69</td><td>99.93</td><td>95.79</td><td>94.47</td><td>89.51</td><td>99.65</td><td>85.72</td><td>88.13</td><td>99.96</td><td>97.89</td></tr></table> We also conduct experiments to evaluate the generalization ability of GNN models on unsat- core variable prediction. Please see appendix C.4 for details. ## 6 Advancing Evaluation on G4SATBench To gain deeper insights into how GNNs tackle the SAT problem, we conduct comprehensive comparative analyses between GNN- based SAT solvers and the CDCL and LS heuristics in this section. Since these search heuristics aim to solve a SAT instance directly, our focus only lies on the tasks of (T1) satisfiability prediction and (T2) satisfying assignment prediction (with \\(\\mathrm{UNS}_2\\) as the training loss). We employ Neuro SAT (on \\(\\mathrm{LCG}^*\\) ) and GGNN (on \\(\\mathrm{VCG}^*\\) ) as our GNN models and experiment on the SR and 3- SAT datasets. Detailed experimental settings are included in Appendix D.1. ### 6.1 Comparison with the CDCL Heuristic Evaluation on the clause- learning augmented instances. CDCL- based SAT solvers enhance backtracking search with conflict analysis and clause learning, enabling efficient exploration of the search space by iteratively adding \"learned clauses\" to avoid similar conflicts in future searches (Silva & Sakallah, 1999). To assess whether GNN- based SAT solvers can learn and benefit from the backtracking search (with CDCL) heuristic, we augment the original formulas in the datasets with learned clauses and evaluate GNN models on these clause- augmented instances.\n\nTable 4 shows the testing results on augmented SAT datasets. Notably, training on the augmented instances leads to significant improvements in both satisfiability prediction and satisfying assignment prediction. These improvements can be attributed to the presence of \"learned clauses\" that effectively modify the structure of the original formulas, thereby facilitating GNNs to solve with relative ease. However, despite the augmented instances being easily solvable using the backtracking search within a few search steps, GNN models fail to effectively handle these instances when trained on the original instances. These findings suggest that GNNs may not implicitly learn the CDCL heuristic when trained for satisfiability prediction or satisfying assignment prediction. Table 4: Results on augmented datasets. Values inside/outside parentheses denote the results of models trained on augmented/original instances. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>100.00 (96.78)</td><td>100.00 (96.06)</td><td>100.00 (84.57)</td><td>96.78 (84.85)</td></tr><tr><td>GGNN</td><td>100.00 (97.66)</td><td>100.00 (95.46)</td><td>100.00 (84.01)</td><td>96.29 (85.80)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>85.05 (83.28)</td><td>83.50 (81.04)</td><td>51.95 (45.51)</td><td>39.00 (16.52)</td></tr><tr><td>GGNN</td><td>85.35 (83.42)</td><td>81.56 (79.99)</td><td>44.18 (40.09)</td><td>34.67 (14.75)</td></tr></table> Table 5: Results using contrastive pretraining. Values in parentheses denote the difference between the results without pretraining. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>96.68 (+0.68)</td><td>96.23 (+0.10)</td><td>78.31 (+0.29)</td><td>85.02 (+0.12)</td></tr><tr><td>GGNN</td><td>96.46 (+0.29)</td><td>96.45 (+0.20)</td><td>76.34 (+0.78)</td><td>85.17 (+0.06)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>80.54 (+0.75)</td><td>79.71 (-0.88)</td><td>36.42 (-0.83)</td><td>41.23 (-0.38)</td></tr><tr><td>GGNN</td><td>80.66 (-0.34)</td><td>79.23 (-0.09)</td><td>33.44 (+0.07)</td><td>36.39 (+0.44)</td></tr></table> Evaluation with contrastive pretraining. Observing that GNN models exhibit superior performance on clause- learning augmented SAT instances, there is potential to improve the performance of GNNs by learning a latent representation of the original formula similar to its augmented counterpart. Motivated by this, we also experiment with a contrastive learning approach (i.e., Sim CLR (Chen et al., 2020)) to pretrain the representation of CNF formulas to be close to their augmented ones (Duan et al., 2022), trying to explicitly embed the CDCL heuristic in the latent space through representation learning. The results of contrastive pretraining are presented in Table 5. In contrast to the findings in Duan et al. (2022), our results show limited performance improvement through contrastive pretraining, indicating that GNN models still encounter difficulties in effectively learning the CDCL heuristic in the latent space. This observation aligns with the conclusions drawn in Chen & Yang (2019), which highlight that static GNNs may fail to exactly replicate the same search operations due to the dynamic changes in the graph structure introduced by the clause learning technique. ### 6.2 Comparison with the LS Heuristic Evaluation with random initialization. LS- based SAT solvers typically begin by randomly initializing an assignment and then iteratively flip variables guided by specific heuristics until reaching a satisfying assignment. To compare the behaviors of GNNs with this solving procedure, we first conduct an evaluation of GNN models with randomized initial embeddings in both training and testing, emulating the initialization of LS SAT solvers. The results presented in Table 6 demonstrate that using random initialization has a limited impact on the overall performances of GNN- based SAT solvers. This suggests that GNN models do not aim to learn a fixed latent representation of each formula for satisfiability prediction and satisfying assignment prediction. Instead, they have developed a solving strategy that effectively exploits the inherent graph structure of each SAT instance. Table 6: Results using random initialization. Values in parentheses denote the difference between the results with learned initialization. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>97.24 (+1.24)</td><td>96.44 (+0.11)</td><td>77.29 (-0.91)</td><td>84.85 (-0.05)</td></tr><tr><td>GGNN</td><td>96.78 (+0.03)</td><td>96.38 (+0.13)</td><td>76.97 (-0.15)</td><td>85.80 (+0.69)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>79.09 (-0.70)</td><td>80.79 (+0.20)</td><td>37.27 (+0.02)</td><td>40.75 (-0.86)</td></tr><tr><td>GGNN</td><td>80.10 (-0.90)</td><td>79.83 (+0.51)</td><td>32.85 (-0.52)</td><td>36.59 (+0.64)</td></tr></table> Evaluation on the predicted assignments. Under random initialization, we further analyze the solving strategies of GNNs by evaluating their predicted assignments decoded from the latent space. For the task of satisfiability prediction, we employ the 2- clustering decoding algorithm to extract the predicted assignments from the literal embeddings of Neuro SAT at each iteration of message passing. For satisfying assignment"
  },
  "section_objects": [
    {
      "heading": "G4SATBench Benchmarking and Advancing SAT Solving",
      "content": "## Introduction\n\n\nprediction, we evaluate both Neuro SAT and GGNN using multiple- prediction decoding. Our evaluation focuses on three key aspects: (a) the number of distinct predicted assignments, (b) the number of flipped variables between two consecutive iterations, and (c) the number of unsatisfiable clauses associated with the predicted assignments. <center>Figure 5: Results on the predicted assignments with the increased message passing iteration \\(T\\) . Neuro SAT\\* refers to the model trained for satisfiability prediction. </center> As shown in Figure 5, all three GNN models initially generate a wide array of assignment predictions by flipping a considerable number of variables, resulting in a notable reduction in the number of unsatisfiable clauses. However, as the iterations progress, the number of flipped variables diminishes substantially, and most GNN models eventually converge towards predicting a specific assignment or making minimal changes to their predictions when there are no or very few unsatisfiable clauses remaining. This trend is reminiscent of the greedy solving strategy adopted by the LS solver GSAT (Selman et al., 1992), where changes are made to minimize the number of unsatisfied clauses in the new assignment. However, unlike GSAT's approach of flipping one variable at a time and incorporating random selection to break ties, GNN models simultaneously modify multiple variables and potentially converge to a particular unsatisfied assignment and find it challenging to deviate from such a prediction. It is also noteworthy that despite being trained for satisfiability prediction, Neuro SAT\\* demonstrates similar behavior to the GNN models trained for assignment prediction. This observation indicates that GNNs also learn to search for a satisfying assignment implicitly in the latent space while performing satisfiability prediction. To provide more insights into the strengths and limitations of GNN- based heuristics, we further conduct experiments to compare GNN- based SAT solvers against state- of- the- art CDCL and LS- based SAT solvers in Appendix D.2. ## 7 Discussions ### 7.1 Limitations and Future Work While G4SATBench represents a significant step in evaluating GNNs for SAT solving, there are still some limitations and potential future directions to consider. Firstly, G4SATBench primarily focuses on evaluating standalone neural SAT solvers, excluding the exploration of neural- guided SAT solvers that integrate GNNs with search- based SAT solvers. It also should be emphasized that the instances included in G4SATBench are considerably smaller compared to most practical instances found in real- world applications, where GNN models alone are not sufficient for solving such large- scale instances. The efficacy of GNN models in unsat- core prediction shows a promising avenue for combining GNNs with modern SAT solvers, and future research could explore more techniques to effectively leverage these neural- guided SAT solvers to scale up to real- world instances. Secondly, G4SATBench benchmarks general GNN models on the LCG\\* and VCG\\* graph representations for SAT solving, but does not consider sophisticated GNN models designed for specific graph constructions in certain domains, such as Circuit SAT problems. Investigating domain- specific GNN models tailored to the characteristics of specific problems could lead to improved performance in specialized instances. Lastly, all existing GNN- based SAT solvers in the literature are static GNNs, which have limited learning ability to capture the CDCL heuristic. Exploring dynamic GNN models that can effectively learn the CDCL heuristic is also a potential direction for future research.\n\n### 7.2 Conclusion 7.2 Conclusion In this work, we present G4SATBench, a benchmark study that comprehensively evaluates GNN models in SAT solving. G4SATBench offers curated synthetic SAT datasets sourced from various domains and difficulty levels and benchmarks a wide range of GNN- based SAT solvers under diverse settings. Our empirical analysis yields valuable insights into the performances of GNN- based SAT solvers and further provides a deeper understanding of their capabilities and limitations. We hope the proposed G4SATBench will serve as a solid foundation for GNN- based SAT solving and inspire future research in this exciting field. ## Acknowledgments Acknowledgments This work was supported, in part, by Individual Discovery Grants from the Natural Sciences and Engineering Research Council of Canada, and the Canada CIFAR AI Chair Program. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve Circuit- SAT: An unsupervised differentiable approach. In International Conference on Learning Representations (ICLR), 2019a. Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. PDP: A general neural framework for learning constraint satisfaction solvers. ar Xiv preprint ar Xiv:1903.01969, 2019b. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ar Xiv preprint ar Xiv:1607.06450, 2016. Adrian Balint and Andreas Fr\u00f6hlich. Improving stochastic local search for sat with a new probability distribution. In Theory and Applications of Satisfiability Testing- SAT 2010: 13th International Conference, SAT 2010, Edinburgh, UK, July 11- 14, 2010. Proceedings 13, pp. 10- 15. Springer, 2010. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of Satisfiability, volume 185. IOS press, 2009. B\u00e9la Bollob\u00e1s and Paul Erd\u0151s. Cliques in random graphs. In Mathematical Proceedings of the Cambridge Philosophical Society, 1976. Benedikt B\u00fcnz and Matthew Lamm. Graph neural networks and boolean satisfiability. ar Xiv preprint ar Xiv:1702.03592, 2017. Chris Cameron, Rex Chen, Jason Hartford, and Kevin Leyton- Brown. Predicting propositional satisfiability via end- to- end learning. In AAAI Conference on Artificial Intelligence (AAAI), 2020. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020. Ziliang Chen and Zhanfu Yang. Graph neural reasoning may fail in certifying boolean unsatisfiability. ar Xiv preprint ar Xiv:1909.11588, 2019. James M. Crawford and Larry D. Auton. Experimental results on the crossover point in random 3- SAT. Artificial Intelligence, 1996. Haonan Duan, Pashootan Vaezipoor, Max B. Paulus, Yangjun Ruan, and Chris J. Maddison. Augment with care: Contrastive learning for combinatorial problems. In International Conference on Machine Learning (ICML), 2022. Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. ar Xiv preprint ar Xiv:1903.02428, 2019. ABKFM Fleury and Maximilian Heisinger. Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020. SAT COMPETITION, 2020.\n\nJes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. A modularity- based random SAT instances generator. In International Joint Conference on Artificial Intelligence (IJCAI), 2015. Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. Locality in random SAT instances. In International Joint Conference on Artificial Intelligence (IJCAI), 2017. Wenxuan Guo, Junchi Yan, Hui- Ling Zhen, Xijun Li, Mingxuan Yuan, and Yaohui Jin. Machine learning methods in solving the boolean satisfiability problem. ar Xiv preprint ar Xiv:2203.04755, 2022. Jesse Michael Han. Enhancing SAT solvers with glue variable predictions. ar Xiv preprint ar Xiv:2007.02559, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human- level performance on imagenet classification. In IEEE International Conference on Computer Vision (ICCV), 2015. Sean B Holden et al. Machine learning for automated theorem proving: Learning to solve SAT and QSAT. Foundations and Trends\u00ae in Machine Learning, 14(6):807- 989, 2021. Holger H Hoos and Thomas St\u00fctzle. SATLIB: An online resource for research on SAT. Workshop on Satisfiability (SAT), 2000. Sebastian Jaszczur, Michal \u0141uszczyk, and Henryk Michalewski. Neural heuristics for SAT solving. ar Xiv preprint ar Xiv:2005.13406, 2020. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. Thomas N. Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q- learning with graph networks learn a generalizable branching heuristic for a SAT solver? In Advances in Neural Information Processing Systems (Neur IPS), 2020. Massimo Lauria, Jan Elffers, Jakob Nordstr\u00f6m, and Marc Vinyals. Cnfen: A generator of crafted benchmarks. In Theory and Applications of Satisfiability Testing (SAT), 2017. Min Li, Zhengyuan Shi, Qiuxia Lai, Sadaf Khan, Shaowei Cai, and Qiang Xu. On eda- driven learning for sat solving. In Design Automation Conference (DAC), 2023. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations (ICLR), 2016. Zhaoyu Li and Xujie Si. NSNet: A general neural probabilistic framework for satisfiability problems. In Advances in Neural Information Processing Systems (Neur IPS), 2022. Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning (ICML), 2010. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural SAT solver. In International Joint Conference on Neural Networks (IJCNN), 2022. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. Yang, Zachary De Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high- performance deep learning library. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Bart Selman, Hector J. Levesque, and David G. Mitchell. A new method for solving hard satisfiability problems. In National Conference on Artificial Intelligence (AAAI), 1992.\n\nDaniel Selsam and Nikolaj S. Bj\u00f8rner. Guiding high- performance SAT solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing (SAT), 2019. Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations (ICLR), 2019. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui- Ling Zhen, Mingxuan Yuan, and Qiang Xu. Sathermer: Transformer- based unsat core learning. In International Conference on Computer Aided Design (ICCAD), 2023. Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP: A search algorithm for propositional satisfiability. IEEE Transactions on Computers, 1999. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth Mc Millan, and Risto Miikkulainen. Neurocomb: Improving SAT solving with graph neural networks. ar Xiv preprint ar Xiv:2110.14053, 2021. Nathan Wetzler, Marijn Heule, and Warren A. Hunt Jr. Drat- trim: Efficient checking and trimming using expressive clausal proofs. In Theory and Applications of Satisfiability Testing (SAT), 2014. Ben Wieland and Anant P. Godbole. On the domination number of a random graph. The Electronic Journal of Combinatorics, 2001. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019. Zhiyuan Yan, Min Li, Zhengyuan Shi, Wenjie Zhang, Yingcong Chen, and Hongce Zhang. Addressing variable dependency in gnn- based SAT solving. ar Xiv preprint ar Xiv:2304.08738, 2023. Emre Yolcu and Barnab\u00e1s P\u00f3czos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong, and Lu Zhang. Nicolasat: Boosting local search with solution prediction. In International Joint Conference on Artificial Intelligence (IJCAI), 2020.\n\n## A Datasets Generators. To generate high- quality SAT datasets that do not contain trivial instances, we have employed a rigorous process of selecting appropriate parameters for each CNF generator in G4SATBench. Table 7 provides detailed information about the generators we have used. Table 7: Details of the synthetic generators employed in G4SATBench. <table><tr><td>Dataset</td><td>Description</td><td>Parameters</td><td>Notes</td></tr><tr><td>SR</td><td>The SR dataset is composed of pairs of satisfiable and unsatisfiable formulas, with the only difference between each pair being the polarity of a single literal. Given the number of variables n, the synthetic generator iteratively samples k = 1+Bernoulli(b)+Geometric(g) vari-ables uniformly at random without replacement and negates each one with independent probability 50% to build a clause. This procedure continues until the generated formula is unsatisfiable. The satisfiable instance is then constructed by negating the first literal in the last clause of the unsatisfiable one.</td><td>General: b = 0.3, g = 0.4, Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 400)</td><td>The sampling parameters are the same as the original paper (Selsam et al., 2019).</td></tr><tr><td>3-SAT</td><td>The 3-SAT dataset comprises CNF formulas at the phase transition, where the proportion of generated satisfiable and unsatisfiable formu- las is roughly equal. Given the number of variables n and clauses m, the synthetic generator iteratively samples three variables (and their polarities) uniformly at random until m clauses are obtained.</td><td>General: m = 4.258n + 58.26n-2/3, Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 300)</td><td>The parameter m is the same as the paper (Crawford &amp;amp; Auton, 1996)</td></tr><tr><td>CA</td><td>The CA dataset contains SAT instances that are designed to mimic the community structures and modularity features found in real-world industrial instances. Given variable number n, clause number m, clause size k, community number c, and modularity Q, the synthetic generator iteratively selects k literals in the same community uni- formly at random with probability P = Q + 1/c and selects k literals in the distinct community uniformly at random with probability 1-P to build a clause and repeat for m times to construct a CNF formula.</td><td>General: m ~ Uniform(13n, 15n), k ~ Uniform(4, 5), c ~ Uniform(3, 10), Q ~ Uniform(0.7, 0.9) Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 400)</td><td>The parameters are selected based on the experiments in the original paper (Gir\u00e1ldez-Cru &amp;amp; Levy, 2015) and our study to ensure that the generated SAT instances have a balance of satisfiability and unsatisfiability.</td></tr><tr><td>PS</td><td>PS dataset encompasses SAT instances with a power-law distribution in the number of variable occurrences (popularity), and good class- tering between them (similarity). Given variable number n, clause number m, and average clause size k, the synthetic generator first as- signs random angles \u03b8i, \u03b8j \u2208 [0, 2\u03c0] to each variable i and each clause j, and then randomly samples variable i in clause j with the proba- bility P = 1/(1+(i\u03b2j\u03b2i/R)T). Here, \u03b8ij = \u03c0-|\u03c0-|\u03b8i-|\u03b8j| is the angle between variable i and clause j. The exponent parameters \u03b2 and \u03b2\u2032 control the power-law distribution of variable occurrences and clause size respectively. The temperature parameter T controls the sharpness of the probability distribution, while R is an approximate normalization constant that ensures the average number of selected edges is km.</td><td>General: m ~ Uniform(6n, 8n), k ~ Uniform(4, 5), \u03b2 ~ Uniform(0, 1), \u03b2\u2032 = 1, c ~ Uniform(3, 10), T ~ Uniform(0.75, 1.5) Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 300)</td><td>The parameters are selected based on the experiments in the original paper (Gir\u00e1ldez-Cru &amp;amp; Levy, 2017) and our study to ensure that the generated SAT instances have a balance of satisfiability and unsatisfiability.</td></tr><tr><td>k-Clique</td><td>The k-Clique dataset includes SAT instances that encode the k-Clique problem, which involves determining whether there exists a clique (i.e., a subset of vertices that are all adjacent to each other) with v vertices in a given graph. Given the number of cliques k, the synthetic generator produces an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then transforms the corresponding k-Clique problem into a SAT instance.</td><td>General: p = (v)k-1/(v), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(3, 4), Medium dataset: v ~ Uniform(15, 20), k ~ Uniform(3, 5), Hard dataset: v ~ Uniform(20, 25), k ~ Uniform(4, 6)</td><td>The parameter p is selected based on the paper (Bollob\u00e1s &amp;amp; Erd\u0151s, 1976), making the expected number of k-Cliques in the generated graph equals 1.</td></tr><tr><td>k-Domset</td><td>The k-Domset dataset contains SAT instances that encode the k-Dominating Set problem. This problem is to determine whether there exists a dominating set (i.e., a subset of vertices such that every vertex in the graph is either in the subset or adjacent to a vertex in the sub- set) with at most k vertices in a given graph. Given the domination number k, the synthetic generator produces an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then transforms the corresponding k-Dominating Set problem into a SAT instance.</td><td>General: p = 1-(1-(v)k-1/(v)k), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(2, 3), Medium dataset: v ~ Uniform(15, 20), k ~ Uniform(3, 5), Hard dataset: v ~ Uniform(20, 25), k ~ Uniform(4, 6)</td><td>The parameter p is selected based on the paper (Wieland &amp;amp; Godbole, 2001), making the expected number of domination set with size k in the generated graph equals 1.</td></tr><tr><td>k-Vercov</td><td>The k-Vercov dataset consists of SAT instances that encode the k-Vercov problem, i.e., check whether there exists a set of k vertices in a graph such that every edge has at least one endpoint in this set. Given the vertex cover number k, the synthetic generator produces a complement graph of an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then converts the corresponding k-Vercov Cover problem into a SAT instance.</td><td>General: p = (v)k-1/(v), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(3, 5), Medium dataset: v ~ Uniform(10, 20), k ~ Uniform(6, 8), Hard dataset: v ~ Uniform(15, 25), k ~ Uniform(9, 10)</td><td>The generation process and the parameter are selected based on the relationship between k-Vercov Cover and k-Clique problems, making the size of the minimum vertex cover in the generated graph around k.</td></tr></table>\n\nStatistics. To provide a comprehensive understanding of our generated datasets, we compute several characteristics across three difficulty levels. These statistics include the average number of variables and clauses, as well as graph measures such as average clustering coefficient (in VIG) and modularity (in VIG, VCG, and LCG). The dataset statistics are summarized in Table 8. Table 8: Dataset statistics across difficulty levels in G4SATBench. <table><tr><td rowspan=\"2\">Dataset</td><td colspan=\"6\">Easy Difficulty</td><td colspan=\"6\">Medium Difficulty</td><td colspan=\"6\">Hard Difficulty</td></tr><tr><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td></tr><tr><td>SR</td><td>25.00</td><td>148.35</td><td>0.98</td><td>0.00</td><td>0.25</td><td>0.33</td><td>118.36</td><td>646.54</td><td>0.62</td><td>0.06</td><td>0.31</td><td>0.37</td><td>299.64</td><td>1613.86</td><td>0.32</td><td>0.09</td><td>0.32</td><td>0.37</td></tr><tr><td>3-SAT</td><td>25.05</td><td>113.69</td><td>0.72</td><td>0.06</td><td>0.36</td><td>0.46</td><td>120.00</td><td>513.14</td><td>0.27</td><td>0.16</td><td>0.43</td><td>0.51</td><td>250.44</td><td>1067.34</td><td>0.14</td><td>0.17</td><td>0.45</td><td>0.52</td></tr><tr><td>CA</td><td>31.66</td><td>303.48</td><td>0.65</td><td>0.19</td><td>0.73</td><td>0.73</td><td>120.27</td><td>1661.07</td><td>0.54</td><td>0.38</td><td>0.80</td><td>0.80</td><td>299.68</td><td>4195.50</td><td>0.59</td><td>0.57</td><td>0.80</td><td>0.80</td></tr><tr><td>PS</td><td>25.41</td><td>176.68</td><td>0.98</td><td>0.00</td><td>0.27</td><td>0.32</td><td>118.75</td><td>822.78</td><td>0.86</td><td>0.05</td><td>0.35</td><td>0.37</td><td>249.61</td><td>1728.34</td><td>0.77</td><td>0.08</td><td>0.38</td><td>0.28</td></tr><tr><td>A-Clique</td><td>34.85</td><td>592.89</td><td>0.90</td><td>0.03</td><td>0.45</td><td>0.49</td><td>69.56</td><td>2220.05</td><td>0.91</td><td>0.03</td><td>0.48</td><td>0.49</td><td>112.87</td><td>5543.26</td><td>0.88</td><td>0.04</td><td>0.49</td><td>0.50</td></tr><tr><td>k-Domest</td><td>41.90</td><td>369.40</td><td>0.70</td><td>0.26</td><td>0.47</td><td>0.53</td><td>90.64</td><td>1736.22</td><td>0.70</td><td>0.21</td><td>0.49</td><td>0.51</td><td>137.31</td><td>4022.48</td><td>0.70</td><td>0.20</td><td>0.49</td><td>0.51</td></tr><tr><td>k-Verox</td><td>45.41</td><td>484.28</td><td>0.66</td><td>0.16</td><td>0.48</td><td>0.53</td><td>107.40</td><td>2634.14</td><td>0.69</td><td>0.16</td><td>0.49</td><td>0.51</td><td>190.24</td><td>8190.94</td><td>0.69</td><td>0.16</td><td>0.50</td><td>0.51</td></tr></table> ## B GNN Models Message-passing schemes on VCG*. Recall that VCG* incorporates two distinct edge types, G4SATBench employs different functions to execute heterogeneous message-passing in each direction of each edge type. Formally, we define a d-dimensional embedding for each variable and clause node, denoted by \\(h_l\\) and \\(h_c\\), respectively. These embeddings are initialized to two learnable vectors \\(h_v^0\\) and \\(h_c^0\\), depending on the node type. At the \\(k\\)-th iteration of message passing, these hidden representations are updated as follows: \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^+ \\left(h_v^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^- \\left(h_v^{(k-1)}\\right)\\right\\}\\right), h_c^{(k-1)}\\right), \\quad (7)\\] \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^+ \\left(h_c^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^- \\left(h_c^{(k-1)}\\right)\\right\\}\\right), h_v^{(k-1)}\\right),\\] where \\(c^+\\) and \\(c^-\\) denote the sets of variable nodes that occur in the clause \\(c\\) with positive and negative polarity, respectively. Similarly, \\(v^+\\) and \\(v^-\\) denote the sets of clause nodes where variable \\(v\\) occurs in positive and negative form. \\(\\mathrm{MLP}_v^+\\), \\(\\mathrm{MLP}_v^-\\), \\(\\mathrm{MLP}_c^+\\), and \\(\\mathrm{MLP}_c^-\\) are four MLPs. \\(\\mathrm{UPD}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. GNN baselines. Table 9 summarizes the message-passing algorithms of the GNN models used in G4SATBench. We adopt heterogeneous versions of GCN (Kipf & Welling, 2017), GGNN (Li et al., 2016), and GIN (Xu et al., 2019) on both LCG* and VCG*, while maintaining the original Neuro SAT (Selsam et al., 2019) only on LCG*. ## C Benchmarking Evaluation ### C.1 Implementation Details In G4SATBench, we provide the ground truth of satisfiability and satisfying assignments by calling the state-of-the-art modern SAT solver Ca Di Ca L (Fleury & Heisinger, 2020) and generate the truth labels for unsat- core variables by invoking the proof checker DRAT-trim (Wetzler et al., 2014). All neural networks in our study are implemented using Py Torch (Paszke et al., 2019) and Py Torch Geometric (Fey & Lenssen, 2019). For all GNN models, we set the feature dimension \\(d\\) to 128 and the number of message passing iterations \\(T\\) to 32. The MLPs in the models consist of two hidden layers with the Re LU (Nair & Hinton, 2010) activation function. To select the optimal hyperparameters for each GNN baseline, we conduct a grid search over several settings. Specifically, we explore different learning rates from \\(\\{10^{-3}, 5 \\times 10^{-4}, 10^{-4}, 5 \\times 10^{-5}, 10^{-5}\\}\\), training epochs from \\(\\{50, 100, 200\\}\\), weight decay values from \\(\\{10^{-6}, 10^{-7}, 10^{-8}, 10^{-9}, 10^{-10}\\}\\), and gradient clipping norms from \\(\\{0.1, 0.5, 1\\}\\). We employ Adam (Kingma & Ba, 2015) as the optimizer and set the batch size to 128, 64, or 32 to fit within the maximum GPU memory (48G). For the parameters \\(\\tau\\) and \\(\\kappa\\) of the unsupervised loss in Equation 4 and Equation 5, we try the default settings (\\(\\tau = t^{-0.4}\\) and \\(\\kappa = 10\\), where \\(t\\) is the global step during training) as the original paper (Amizadeh et al., 2019a) as well as other values (\\(\\tau \\in \\{0.05, 0.1, 0.2, 0.5\\}\\), \\(\\kappa \\in \\{1, 2, 5\\}\\)) and empirically find \\(\\tau = 0.1\\), \\(\\kappa = 1\\) yield the best results. Furthermore,\n\nTable 9: Supported GNN models in G4SATBench. <table><tr><td>Graph</td><td>Method</td><td>Message-passing Algorithm</td><td>Notes</td></tr><tr><td rowspan=\"2\">Neuro SAT</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>s, s1 are the hidden states which are initialized to zero vectors.</td></tr><tr><td>h(c), s(c) = Layer Norm LSTM2</td><td>h(c), s(c) = Layer Norm LSTM2</td><td></td></tr><tr><td rowspan=\"2\">LCG*</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and literal node l in LCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">GGNN</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GCN</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and variable node v in VCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">VCG*</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = GIN</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = GIN</td><td></td></tr></table> it is important to note that we use three different random seeds to benchmark the performance of different GNN models and assess the generalization ability of Neuro SAT and GGNN using one seed for simplicity. ## C.2 Satisfiability Prediction Evaluation across different difficulty levels. The complete results of Neuro SAT and GGNN across different difficulty levels are presented in Figure 6. Consistent with the findings on the SR and 3- SAT datasets, both GNN models exhibit limited generalization ability to larger instances beyond their training data, while displaying relatively better performance on smaller instances. This observation suggests that training these models on more challenging instances could potentially enhance their generalization ability and improve their performance on larger instances. <center>Figure 6: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different message passing iterations. To investigate the impact of message-passing iterations on the performance of GNN models during training and testing, we conducted experiments with varying iteration values. Figure 7 presents the results of Neuro SAT and GGNN trained and evaluated with different message passing iterations. Remarkably, using a training iteration value of 32 consistently yielded the best performance for both models. Conversely, employing too small or too large iteration values during training resulted in decreased performance. Furthermore, the models trained with 32 iterations also demonstrated good generalization ability to testing iterations 16 and 64. These findings emphasize the critical importance of selecting an appropriate message-passing iteration to ensure optimal learning and reasoning within GNN models. <center>Figure 7: Classification accuracy of satisfiability across different message passing iterations \\(T\\) . The x-axis denotes testing iterations and the y-axis denotes training iterations. </center> ## C.3 Satisfying Assignment Prediction Evaluation with different training losses. Table 10 presents the complete results of each GNN baseline across three different training objectives. Like the results of Neuro SAT and GGNN, all other GNN models with unsupervised training outperform their supervised training counterparts. Table 10: Solving accuracy on identical distribution with different training losses. The top and bottom 7 rows represent the results for easy and medium datasets, respectively. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"3\">SR</td><td colspan=\"3\">3-SAT</td><td colspan=\"3\">CA</td><td colspan=\"3\">PS</td><td colspan=\"3\">k-Clique</td><td colspan=\"3\">k-Domest</td><td colspan=\"3\">k-Vercov</td></tr><tr><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>88.47</td><td>82.30</td><td>79.79</td><td>78.39</td><td>80.23</td><td>80.59</td><td>0.27</td><td>82.17</td><td>89.34</td><td>39.18</td><td>89.23</td><td>88.79</td><td>66.30</td><td>88.34</td><td>63.43</td><td>69.61</td><td>96.74</td><td>98.85</td><td>85.15</td><td>99.36</td><td>99.73</td></tr><tr><td>GCN</td><td>83.74</td><td>73.09</td><td>77.02</td><td>70.34</td><td>74.79</td><td>75.31</td><td>0.17</td><td>75.30</td><td>82.41</td><td>39.66</td><td>82.75</td><td>84.89</td><td>63.85</td><td>82.60</td><td>86.17</td><td>59.29</td><td>97.50</td><td>97.55</td><td>76.83</td><td>99.16</td><td>99.28</td></tr><tr><td>GGNN</td><td>84.13</td><td>76.39</td><td>78.75</td><td>72.87</td><td>76.55</td><td>76.42</td><td>0.29</td><td>78.13</td><td>84.08</td><td>38.82</td><td>84.44</td><td>86.29</td><td>60.80</td><td>84.60</td><td>87.12</td><td>68.36</td><td>97.49</td><td>98.06</td><td>82.06</td><td>-</td><td>99.34</td></tr><tr><td>GIN</td><td>83.81</td><td>81.45</td><td>80.39</td><td>73.99</td><td>78.47</td><td>76.24</td><td>0.20</td><td>78.44</td><td>85.15</td><td>39.13</td><td>85.31</td><td>85.43</td><td>56.85</td><td>84.48</td><td>85.11</td><td>68.93</td><td>96.99</td><td>97.43</td><td>81.49</td><td>99.28</td><td>99.38</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>83.38</td><td>84.19</td><td>78.00</td><td>76.60</td><td>84.42</td><td>79.23</td><td>14.98</td><td>76.64</td><td>83.79</td><td>51.48</td><td>85.88</td><td>83.06</td><td>56.27</td><td>85.28</td><td>86.91</td><td>66.32</td><td>97.62</td><td>96.74</td><td>78.67</td><td>-</td><td>93.51</td></tr><tr><td>GGNN</td><td>86.30</td><td>87.16</td><td>81.00</td><td>77.96</td><td>88.97</td><td>79.32</td><td>15.11</td><td>76.32</td><td>83.12</td><td>47.67</td><td>86.85</td><td>87.17</td><td>66.86</td><td>86.31</td><td>87.48</td><td>66.42</td><td>-</td><td>98.42</td><td>82.61</td><td>-</td><td>99.52</td></tr><tr><td>GIN</td><td>84.61</td><td>89.56</td><td>83.27</td><td>79.23</td><td>87.65</td><td>81.72</td><td>17.81</td><td>83.28</td><td>86.03</td><td>48.92</td><td>91.21</td><td>85.65</td><td>60.67</td><td>86.12</td><td>88.09</td><td>67.67</td><td>-</td><td>81.01</td><td>99.38</td><td>99.41</td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>34.97</td><td>25.00</td><td>37.25</td><td>20.07</td><td>30.40</td><td>41.61</td><td>0.00</td><td>35.45</td><td>70.83</td><td>3.64</td><td>60.28</td><td>71.03</td><td>56.61</td><td>41.45</td><td>-</td><td>52.09</td><td>95.06</td><td>96.18</td><td>74.77</td><td>67.44</td><td>95.99</td></tr><tr><td>GCN</td><td>13.19</td><td>13.76</td><td>19.21</td><td>8.87</td><td>20.50</td><td>24.58</td><td>0.00</td><td>30.20</td><td>54.04</td><td>14.45</td><td>45.16</td><td>56.29</td><td>55.36</td><td>61.82</td><td>66.33</td><td>43.50</td><td>92.86</td><td>94.89</td><td>67.83</td><td>-</td><td>93.84</td></tr><tr><td>GGNN</td><td>14.15</td><td>16.55</td><td>21.18</td><td>7.96</td><td>22.84</td><td>25.68</td><td>0.00</td><td>28.12</td><td>50.66</td><td>2.33</td><td>44.89</td><td>57.96</td><td>52.35</td><td>54.29</td><td>68.91</td><td>49.07</td><td>-</td><td>92.26</td><td>69.21</td><td>66.37</td><td>94.30</td></tr><tr><td>GIN</td><td>15.36</td><td>18.60</td><td>22.17</td><td>9.66</td><td>21.38</td><td>24.93</td><td>0.00</td><td>35.76</td><td>57.81</td><td>2.02</td><td>43.43</td><td>57.62</td><td>53.07</td><td>44.60</td><td>66.32</td><td>44.39</td><td>93.3</td><td>93.82</td><td>70.59</td><td>55.59</td><td>95.69</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>20.59</td><td>9.21</td><td>22.44</td><td>12.48</td><td>17.00</td><td>29.53</td><td>0.44</td><td>39.04</td><td>48.99</td><td>2.29</td><td>35.99</td><td>55.46</td><td>46.09</td><td>25.90</td><td>68.62</td><td>46.96</td><td>-</td><td>92.68</td><td>69.15</td><td>-</td><td>96.46</td></tr><tr><td>GGNN</td><td>28.04</td><td>27.72</td><td>33.37</td><td>16.46</td><td>29.65</td><td>35.95</td><td>0.56</td><td>48.13</td><td>49.93</td><td>3.12</td><td>51.73</td><td>65.11</td><td>44.26</td><td>48.92</td><td>56.43</td><td>51.01</td><td>-</td><td>71.97</td><td>-</td><td>95.23</td></tr><tr><td>GIN</td><td>26.73</td><td>26.48</td><td>31.97</td><td>14.64</td><td>26.86</td><td>35.81</td><td>0.64</td><td>44.06</td><td>63.84</td><td>3.38</td><td>58.03</td><td>64.66</td><td>55.47</td><td>56.97</td><td>67.78</td><td>46.98</td><td>-</td><td>95.28</td><td>69.40</td><td>-</td><td>96.96</td></tr></table> Evaluation across different difficulty levels. The performance of Neuro SAT across different difficulty levels is shown in Figure 8. Notably, training on medium datasets yields superior generalization performance compared to training on easy datasets. This suggests that training on more challenging SAT instances with larger sizes can enhance the model's ability to generalize to a wider range of problem complexities. <center>Figure 8: Solving accuracy of Neuro SAT across different difficulty levels (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different datasets. Figure 9 illustrates the performance of Neuro SAT across different datasets. For easy datasets, we observe that Neuro SAT demonstrates a strong generalization ability to other datasets when trained on the SR, 3- SAT, CA, and PS datasets. However, when trained on the \\(k\\) - Clique, \\(k\\) - Domset, and \\(k\\) - Vercov datasets, which involve specific graph structures inherent to their combinatorial problems, Neuro SAT struggles to generalize effectively. This observation indicates that the GNN model may overfit to leverage specific graph features associated with these combinatorial datasets, without developing a generalized solving strategy that can be applied to other problem domains for satisfying assignment prediction. For medium datasets, Neuro SAT also faces challenges in generalization, as its performance is relatively limited. This can be attributed to the difficulty of these datasets, where finding satisfying assignments is much harder than easy datasets. <center>Figure 9: Solving accuracy of Neuro SAT across different datasets (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation with different inference algorithms. Figure 10 illustrates the results of Neuro SAT using various decoding algorithms (with \\(\\mathrm{UNS}_2\\) as the training loss). Notably, all three decoding algorithms demonstrate similar performances across all datasets. This observation indicates that utilizing the standard readout after message passing is sufficient for predicting a satisfying assignment. Also, the GNN model has successfully learned to identify potential satisfying assignments within the latent space, which can be extracted by clustering the literal embeddings. <center>Figure 10: Solving accuracy of Neuro SAT with different inference algorithms. </center> ## Evaluation with unsatisfiable training in- Evaluation with unsatisfiable training instances. Following previous works (Amizadeh et al., 2019a;b; Ozolins et al., 2022), our evaluation of GNN models focuses solely on satisfiable instances. However, in practical scenarios, the satisfiability of instances may not be known before training. To address this gap, we explore the effectiveness of training Neuro SAT using the unsupervised loss \\(\\mathrm{UNS}_2\\) on noisy datasets that contain unsatisfiable instances. Table 11 presents the results of Neuro SAT when trained on such datasets, where \\(50\\%\\) of the instances are unsatisfiable. Interestingly, incorporating unsatisfiable instances for training does not significantly affect the performance of the GNN model. This finding highlights the potential utility of training GNN models using \\(\\mathrm{UNS}_2\\) loss on new datasets, irrespective of any prior knowledge regarding their satisfiability. Table 11: Solving accuracy of Neuro SAT when trained on noisy datasets. Values in parentheses indicate the performance difference compared to the model trained without unsatisfiable instances. The \\(k\\) -Clique dataset is excluded as Neuro SAT fails during training. <table><tr><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td></tr><tr><td>78.84<br>(-0.95)</td><td>80.48<br>(-0.11)</td><td>87.01<br>(-2.33)</td><td>88.66<br>(-0.13)</td><td>98.00<br>(-0.85)</td><td>95.24<br>(-4.49)</td><td>37.21<br>(-0.04)</td><td>41.75<br>(+0.14)</td><td>76.49<br>(+5.64)</td><td>72.52<br>(+1.46)</td><td>94.93<br>(-1.25)</td><td>96.18<br>(+0.19)</td></tr></table> ## C.4 Unsat-core Variable Prediction Evaluation across different difficulty levels. The results across different difficulty levels are presented in Figure 11. Remarkably, both Neuro SAT and GGNN exhibit a strong generalization ability when trained on easy or medium datasets. This suggests that GNN models can effectively learn and generalize from the\n\ncharacteristics and patterns present in these datasets, enabling them to perform well on a wide range of problem complexities. <center>Figure 11: Classification accuracy of unsat-core variables across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation across different datasets. Figure 12 shows the generalization results across different datasets. Both Neuro SAT and GGNN demonstrate good generalization performance to datasets that are different from their training data, except for the CA dataset. This discrepancy can be attributed to the specific characteristics of the CA dataset, where the number of unsat- core variables is significantly smaller compared to the number of variables not in the unsat core. In contrast, other datasets have a different distribution, where the number of unsat- core variables is much larger. This variation in distribution presents a challenge for the models' generalization ability on the CA dataset. <center>Figure 12: Classification accuracy of unsat-core variables across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> ## D Advancing Evaluation ## D.1 Implementation details To create the augmented datasets, we leverage Ca Di Ca L (Fleury & Heisinger, 2020) to generate a DART proof (Wetzler et al., 2014) for each SAT instance, which tracks the clause learning procedure and records all the learned clauses during the solving process. These learned clauses are then added to each instance, with a maximum limit of 1,000 clauses. For experiments on augmented datasets, we keep all training settings identical to those used for the original datasets. For contrastive pretraining experiments, we treat each original formula and its augmented counterpart as a positive pair and all other instances in a mini- batch as negative pairs. We use an MLP projection to map the graph embedding \\(z_{i}\\) of each formula to \\(m_{i}\\) and employ the Sim CLR's contrastive loss (Chen et al., 2020), where the loss function for a positive pair of examples \\((i,j)\\) in a mini- batch of size \\(2N\\) is defined as: \\[\\mathcal{L}_{i,j} = -\\log \\frac{\\exp(\\sin(m_{i},m_{j}) / \\tau)}{\\sum_{k = 1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\sin(m_{i},m_{k}) / \\tau)}. \\quad (8)\\]\n\npredicts marginal distributions of all satisfying solutions to solve the SAT problem. Moreover, most previous research has experimented on different datasets that vary in a range of settings (e.g., data distribution, instance size, and dataset size), which leads to a lack of unified and standardized datasets for training and evaluation. Additionally, some work (Amizadeh et al., 2019b; Shi et al., 2023; Yan et al., 2023) has noted the difficulty of re- implementing prior approaches as baselines, rendering it arduous to draw consistent conclusions about the performance of peer methods. All of these issues impede the development of GNN- based solvers for SAT solving. To systematically quantify the progress in this field and facilitate rapid, reproducible, and generalizable research, we propose G4SATBench, the first comprehensive benchmark study for SAT solving with GNNs. G4SATBench is characterized as follows: - First, we construct a large and diverse collection of SAT datasets that includes instances from distinct sources and difficulty levels. Specifically, our benchmark consists of 7 different datasets from 3 benchmark families, including random instances, pseudo-industrial instances, and combinatorial problems. It not only covers a wide range of prior datasets but also introduces 3 levels of difficulty for each dataset to enable fine-grained analyses. - Second, we re-implement various GNN-based SAT solvers with unified interfaces and configuration settings, establishing a general evaluation protocol for fair and comprehensive comparisons. Our framework allows for evaluating different GNN models in SAT solving with various prediction tasks, training objectives, and inference algorithms, encompassing the diverse learning frameworks employed in the existing literature. - Third, we present baseline results and conduct thorough analyses of GNN-based SAT solvers, providing a detailed reference of prior work and laying a solid foundation for future research. Our evaluations assess the performances of different choices of GNN models (e.g., graph constructions, message-passing schemes) with particular attention to some critical parameters (e.g., message-passing iterations), as well as their generalization ability across different distributions. - Lastly, we conduct a series of in-depth experiments to explore the learning abilities of GNN-based SAT solvers. Specifically, we compare the training and solving processes of GNNs with the heuristics employed in both CDCL and LS-based SAT solvers. Our experimental results reveal that GNNs tend to develop a solving heuristic similar to greedy local search to find a satisfying assignment but fail to effectively learn the CDCL heuristic in the latent space. We believe that G4SATBench will help the research community to make significant strides in understanding the capabilities and limitations of GNNs for solving SAT and facilitate further endeavors in this domain. ## 2 Related Work SAT solving with GNNs. Existing GNN- based SAT solvers can be broadly categorized into two branches (Holden et al., 2021; Guo et al., 2022): standalone neural solvers and neural- guided solvers. Standalone neural solvers utilize GNNs to solve SAT instances directly. For example, a stream of research (B\u00fcnz & Lamm, 2017; Selsam et al., 2019; Jaszczur et al., 2020; Cameron et al., 2020; Shi et al., 2023) focuses on predicting the satisfiability of a given formula, while several alternative approaches (Amizadeh et al., 2019a;b; Ozolins et al., 2022; Li et al., 2023; Yan et al., 2023) aim to construct a satisfying assignment. Neural- guided solvers, on the other hand, integrate GNNs with modern SAT solvers, trying to improve their search heuristics with the prediction of GNNs. These methods typically train GNN models using supervised learning on some tasks such as unsat- core variable prediction (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021), satisfying assignment prediction (Zhang et al., 2020), glue variable prediction (Han, 2020), and assignment marginal prediction (Li & Si, 2022), or through reinforcement learning (Yolcu & P\u00f3czos, 2019; Kurin et al., 2020) by modeling the entire search procedure as a Markov decision process. Despite the rich literature on SAT solving with GNNs, there is no benchmark study to evaluate and compare the performance of these GNN models. We hope the proposed G4SATBench would address this gap.\n\nHere, \\(\\mathbb{1}_{[k \\neq i]}\\) is an indicator function that evaluates to 1 if \\(k \\neq i\\) , \\(\\tau\\) is a temperature parameter, and \\(\\text{sim}(\\cdot , \\cdot)\\) is the similarity function defined as \\(\\text{sim}(m_i, m_j) = m_i^\\top m_j / \\|m_i\\| \\|m_j\\|\\) . The final loss is the average over all positive pairs. In our experiments, we set the temperature parameter to 0.5 and utilize a learning rate of \\(10^{- 4}\\) with a weight decay of \\(10^{- 8}\\) . The pretraining process is performed for a total of 100 epochs. Once the pretraining is completed, we keep the GNN model and remove the projection head for downstream tasks. For experiments involving random initialization, we utilize Kaiming Initialization (He et al., 2015) to initialize all literal/variable and clause embeddings during both training and testing. For the predicted assignments, we utilize 2- clustering decoding to construct two possible assignment predictions for Neuro SAT\\* at each iteration. When calculating the number of flipped variables and unsatisfiable clauses for Neuro SAT\\*, we only consider the better assignment prediction of the two at each iteration, which is the one that satisfies more clauses. All other experimental settings remain the same as in the benchmarking evaluation. ## D.2 Comparisons with State-of-the-art SAT Solvers We compare Neuro SAT with two advanced CDCL and LS solvers, Ca Di Ca L Fleury & Heisinger (2020) and Sparrow (Balint & Fr\u00f6hlich, 2010). To enable a fair comparison, we first configure Sparrow to generate the same number of assignments as Neuro SAT by setting its maximum flip number to 32, allowing for an apples- to- apples comparison of both solvers' accuracy and execution time. Subsequently, we allow Sparrow and Ca Di Ca L to run without constraints to solve the satisfiable instances in G4SATBench. Considering that Neuro SAT processes a batch of problems in parallel on GPUs, we calculate its per- instance runtime by dividing the total execution time by the number of testing instances. The results, summarized in Table 12, indicate that GNN- based heuristics could outperform modern local search solvers like Sparrow, generating more satisfying assignments extremely fast when constrained to output a limited number of solutions. However, once such a constraint is lifted, both Sparrow and Ca Di Ca L can traverse the solution space efficiently and solve all satisfiable instances in G4SATBench, while GNN models like Neuro SAT may find it challenging due to their limited exploration capacity as evidenced in Figure 5a. Nevertheless, it's crucial to recognize that while GNN models are hard to compete with Ca Di Ca L and Sparrow, their assignment predictions could still serve as good initializations in these solvers, potentially leading to better performance (Zhang et al., 2020; Li & Si, 2022). Table 12: Results of Neuro SAT, Sparrow, and Ca Di Ca L. The top 2 rows represent the solving accuracy (%), and the bottom 4 rows represent the running time (second) per instance. Sparrow\\\\* refers to Sparrow limited to a maximum of 32 flips. <table><tr><td rowspan=\"2\">Method</td><td colspan=\"7\">Easy Datasets</td><td colspan=\"7\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td>Neuro SAT</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.461</td><td>70.83</td><td>71.03</td><td>32.48</td><td>96.18</td><td>95.99</td></tr><tr><td>Sparrow*</td><td>56.03</td><td>52.09</td><td>85.48</td><td>77.25</td><td>53.68</td><td>37.15</td><td>31.61</td><td>1.64</td><td>1.85</td><td>12.68</td><td>10.72</td><td>12.99</td><td>1.27</td><td>0.53</td></tr><tr><td>Neuro SAT</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.003</td><td>0.002</td><td>0.003</td><td>0.008</td><td>0.006</td><td>0.009</td><td>0.010</td><td>0.009</td><td>0.006</td><td>0.007</td></tr><tr><td>Sparrow*</td><td>0.005</td><td>0.005</td><td>0.006</td><td>0.006</td><td>0.005</td><td>0.005</td><td>0.005</td><td>0.008</td><td>0.007</td><td>0.006</td><td>0.006</td><td>0.006</td><td>0.007</td><td>0.006</td></tr><tr><td>Sparrow</td><td>0.007</td><td>0.007</td><td>0.008</td><td>0.008</td><td>0.007</td><td>0.009</td><td>0.009</td><td>0.013</td><td>0.013</td><td>0.010</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td></tr><tr><td>Ca Di Ca L</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.043</td><td>0.016</td><td>0.018</td><td>0.015</td><td>0.013</td><td>0.012</td></tr></table>\n\nSAT datasets. Several established SAT benchmarks, including the prestigious SATLIB (Hoos & St\u00fctzle, 2000) and the SAT Competitions over the years, have provided a variety of practical instances to assess the performance of modern SAT solvers. Regrettably, these datasets are not particularly amenable for GNNs to learn from, given their relatively modest scale (less than 100 instances for a specific domain) or overly extensive instances (exceeding 10 million variables and clauses). To address this issue, researchers have turned to synthetic SAT instance generators (Gir\u00e1ldez- Cruz & Levy, 2015; 2017; Lauria et al., 2017; Selsam et al., 2019), which allow for the creation of a flexible number of instances with customizable settings. However, most of the existing datasets generated from these sources are limited to a few domains (less than 3 generators), small in size (less than 10k instances), or easy in difficulty (less than 40 variables within an instance), and there is no standardized dataset for evaluation. In G4SATBench, we include a variety of synthetic generators with carefully selected configurations, aiming to construct a broad collection of SAT datasets that are highly conducive for training and evaluating GNNs. ## 3 Preliminaries The SAT problem. In propositional logic, a Boolean formula is constructed from Boolean variables and logical operators such as conjunctions \\((\\wedge)\\) , disjunctions \\((\\vee)\\) , and negations \\((\\neg)\\) . It is typical to represent Boolean formulas in conjunctive normal form (CNF), expressed as a conjunction of clauses, where each clause is a disjunction of literals, which can be either a variable or its negation. Given a CNF formula, the SAT problem is to determine if there exists an assignment of boolean values to its variables such that the formula evaluates to true. If this is the case, the formula is called satisfiable; otherwise, it is unsatisfiable. For a satisfiable instance, one is expected to construct a satisfying assignment to prove its satisfiability. On the other hand, for an unsatisfiable formula, one can find a minimal subset of clauses whose conjunction is still unsatisfiable. Such a set of clauses is termed the unsat core, and variables in the unsat core are referred to as unsat- core variables. Graph representations of CNF formulas. Traditionally, a CNF formula can be represented using 4 types of graphs (Biere et al., 2009): Literal- Clause Graph (LCG), Variable- Clause Graph (VCG), Literal- Incidence Graph (LIG), and Variable- Incidence Graph (VIG). The LCG is a bipartite graph with literal and clause nodes connected by edges indicating the presence of a literal in a clause. The VCG is formed by merging the positive and negative literals of the same variables in LCG. The LIG, on the other hand, only consists of literal nodes, with edges indicating co- occurrence in a clause. Lastly, the VIG is derived from LIG using the same merging operation as VCG. ## 4 G4SATBench: A Benchmark Study on GNNs for SAT Solving The goal of G4SATBench is to establish a general framework that enables comprehensive comparisons and evaluations of various GNN- based SAT solvers. In this section, we will delve into the details of G4SATBench, including its datasets, GNN models, prediction tasks, as well as training and testing methodologies. The overview of the G4SATBench framework is shown in Figure 1. ### 4.1 Datasets G4SATBench is built on a diverse set of synthetic CNF generators. It currently consists of 7 datasets sourced from 3 distinct domain areas: random problems, pseudo- industrial problems, and combinatorial problems. Specifically, we utilize the SR generator in Neuro SAT (Selsam et al., 2019) and the 3- SAT generator in CNFGen (Lauria et al., 2017) to produce random CNF formulas. For pseudo- industrial problems, we employ the Community Attachment (CA) model (Gir\u00e1ldez- Cruz & Levy, 2015) and the Popularity- Similarity (PS) model (Gir\u00e1ldez- Cruz & Levy, 2017), which generate synthetic instances that exhibit similar statistical features, such as the community and the locality, to those observed in real- world industrial SAT instances. For combinatorics, we resort to 3 synthetic generators in CNFGen (Lauria et al., 2017) to create SAT instances derived from the translation of \\(k\\) - Clique, \\(k\\) - Dominating Set, and \\(k\\) - Vertex Cover problems.\n\n<center>Figure 1: Framework overview of G4SATBench. </center> In addition to the diversity of datasets, G4SATBench offers distinct difficulty levels for all datasets to enable fine- grained analyses. These levels include easy, medium, and hard, with the latter representing more complex problems with increased instance sizes. For example, the easy SR dataset contains instances with 10 to 40 variables, the medium SR dataset contains formulas with 40 to 200 variables, and the hard SR dataset consists of formulas with variables ranging from 200 to 400. For each easy and medium dataset, we generate 80k pairs of satisfiable and unsatisfiable instances for training, 10k pairs for validation, and 10k pairs for testing. For each hard dataset, we produce 10k testing pairs. It is also worth noting that the parameters for our synthetic generators are meticulously selected to avoid generating trivial cases. For instance, we produce random 3- SAT formulas at the phase- transition region where the relationship between the number of clauses \\((m)\\) and variables \\((n)\\) is \\(m = 4.258n + 58.26n^{- 2 / 3}\\) (Crawford & Auton, 1996), and utilize the \\(v\\) vertex Erd\u0151s- R\u00e9nyi graph with an edge probability of \\(p = \\binom{v}{k}^{- 1 / \\binom{v}{2}}\\) to generate \\(k\\) - Clique problems, making the expected number of \\(k\\) - Cliques in a graph equals 1 (Bollob\u00e1s & Erd\u0151s, 1976). To provide a detailed characterization of our generated datasets, we compute several statistics of the SAT instances across difficulty levels in G4SATBench. Please refer to Appendix A for more information about the datasets. ### 4.2 GNN Baselines Graph constructions. It is important to note that traditional graph representations of a CNF formula often lack the requisite details for optimally constructing GNNs. Specifically, the LIG and VIG exclude clause- specific information, while the LCG and VCG fail to differentiate between positive and negative literals of the same variable. To address these limitations, existing approaches typically build GNN models on the refined versions of the LCG and VCG encodings. In the LCG, a new type of edge is added between each literal and its negation, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. <center>Figure 2: LCG\\* and VCG\\* of the CNF formula \\((x_{1} \\vee \\neg x_{2}) \\wedge (x_{1} \\vee x_{3}) \\wedge (\\neg x_{1} \\vee x_{2} \\vee x_{3})\\) . </center> tion, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. Message- passing schemes. G4SATBench enables performing various heterogeneous message- passage algorithms between neighboring nodes on the LCG\\* or VCG\\* encodings of a CNF formula. For the sake of illustration, we will take GNN models on the LCG\\* as an example. We first define a \\(d\\) - dimensional embedding for every literal node and clause node, denoted by \\(h_{l}\\) and \\(h_{c}\\) respectively. Initially, all these embeddings are assigned to two learnable vectors \\(h_{l}^{0}\\) and \\(h_{c}^{0}\\) , depending on their node types. At the \\(k\\) - th iteration of\n\nmessage passing, these hidden representations are updated as: \\[\\begin{array}{r l} & {h_{c}^{(k)} = \\mathrm{UP D}\\left(\\underset {l\\in \\mathcal{N}(c)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{l}^{(k - 1)}\\right)\\right\\} \\right),h_{c}^{(k - 1)}\\right),}\\\\ & {h_{l}^{(k)} = \\mathrm{UP D}\\left(\\underset {c\\in \\mathcal{N}(l)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{c}^{(k - 1)}\\right)\\right\\} \\right),h_{-l}^{(k - 1)},h_{l}^{(k - 1)}\\right),} \\end{array} \\quad (1)\\] where \\(\\mathcal{N}(\\cdot)\\) denotes the set of neighbor nodes, MLP is the multi- layer perception, \\(\\mathrm{UP D}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. Most GNN models on \\(\\mathrm{LCG}^{*}\\) use Equation 1 with different choices of the update function and aggregation function. For instance, Neuro SAT employs Layer Norm L- STM (Ba et al., 2016) as the update function and summation as the aggregation function. In G4SATBench, we provide a diverse range of GNN models, including Neuro SAT (Selsam et al., 2019), Graph Convolutional Network (GCN) (Kipf & Welling, 2017), Gated Graph Neural Network (GGNN) (Li et al., 2016), and Graph Isomorphism Network (GIN) (Xu et al., 2019), on the both \\(\\mathrm{LCG}^{*}\\) and \\(\\mathrm{VCG}^{*}\\) . More details of these GNN models are included in Appendix B. ### 4.3 Supported Tasks, Training and Testing Settings Prediction tasks. In G4SATBench, we support three essential prediction tasks for SAT solving: satisfiability prediction, satisfying assignment prediction, and unsat- core variable prediction. These tasks are widely used in both standalone neural solvers and neural- guided solvers. Technically, we model satisfiability prediction as a binary graph classification task, where \\(1 / 0\\) denotes the given SAT instance \\(\\phi\\) is satisfiable/unsatisfiable. Here, we take GNN models on the \\(\\mathrm{LCG}^{*}\\) as an example. After \\(T\\) message passing iterations, we obtain the graph embedding by applying mean pooling on all literal embeddings, and then predict the satisfiability using an MLP followed by the sigmoid function \\(\\sigma\\) : \\[y_{\\phi} = \\sigma \\left(\\mathrm{MLP}\\left(\\mathrm{MEAN}\\left(\\{h_{l}^{(T)},l\\in \\phi \\}\\right)\\right)\\right). \\quad (2)\\] For satisfying assignment prediction and unsat- core variable prediction, we formulate them as binary node classification tasks, predicting the label for each variable in the given CNF formula \\(\\phi\\) . In the case of GNNs on the \\(\\mathrm{LCG}^{*}\\) , we concatenate the embeddings of each pair of literals \\(h_{l}\\) and \\(h_{- l}\\) to construct the variable embedding, and then readout using an MLP and the sigmoid function \\(\\sigma\\) : \\[y_{v} = \\sigma \\left(\\mathrm{MLP}\\left(\\left[h_{l}^{(T)},h_{-l}^{(T)}\\right]\\right)\\right). \\quad (3)\\] Training objectives. To train GNN models on the aforementioned tasks, one common approach is to minimize the binary cross- entropy loss between the predictions and the ground truth labels. In addition to supervised learning, G4SATBench supports two unsupervised training paradigms for satisfying assignment prediction (Amizadeh et al., 2019a; Ozolins et al., 2022). The first approach aims to differentiate and maximize the satisfiability value of a CNF formula (Amizadeh et al., 2019a). It replaces the \\(\\neg\\) operator with the function \\(N(x_{i}) = 1 - x_{i}\\) and uses smooth max and min functions to replace the \\(\\vee\\) and \\(\\wedge\\) operators. The smooth max and min functions are defined as follows: \\[S_{m a x}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{x_{i} / \\tau}},\\quad S_{m i n}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{-x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{-x_{i} / \\tau}}, \\quad (4)\\] where \\(\\tau \\geq 0\\) is the temperature parameter. Given a predicted assignment \\(x\\) , we apply the smoothing logical operators and substitute variables in a formula \\(\\phi\\) with the corresponding values from \\(x\\) to calculate its satisfiability value \\(S(x)\\) . Then we can minimize the following loss function: \\[\\mathcal{L}_{\\phi}(x) = \\frac{(1 - S(x))^{\\kappa}}{(1 - S(x))^{\\kappa} + S(x)^{\\kappa}}. \\quad (5)\\] The second unsupervised loss is defined as follows (Ozolins et al., 2022): \\[V_{c}(x) = 1 - \\prod_{i\\in c^{+}}(1 - x_{i})\\prod_{i\\in c^{-}}x_{i},\\quad \\mathcal{L}_{\\phi}(x) = -\\log \\Bigl (\\prod_{c\\in \\phi}V_{c}(x)\\Bigr) = -\\sum_{c\\in \\phi}\\log \\bigl (V_{c}(x)\\bigr), \\quad (6)\\]\n\nwhere \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in the clause \\(c\\) in positive and negative form respectively. Note that these two losses reach the minimum only when the prediction \\(x\\) is a satisfying assignment, thus minimizing such losses could help to construct a possible satisfying assignment. Inference algorithms. Beyond the standard readout process like training, G4SATBench offers two alternative inference algorithms for satisfying assignment prediction (Selsam et al., 2019; Amizadeh et al., 2019b). The first method performs 2- clustering on the literal embeddings to obtain two centers \\(\\Delta_{1}\\) and \\(\\Delta_{2}\\) and then partitions the positive and negative literals of each variable into distinct groups based on the predicate \\(||x_{i} - \\Delta_{1}||^{2} + ||\\neg x_{i} - \\Delta_{2}||^{2}< ||x_{i} - \\Delta_{2}||^{2} + ||\\neg x_{i} - \\Delta_{1}||^{2}\\) (Selsam et al., 2019). This allows the construction of two possible assignments by mapping one group of literals to true. The second approach is to employ the readout function at each iteration of message passing, resulting in multiple assignment predictions for a given instance (Amizadeh et al., 2019b). Evaluation metrics. For satisfiability prediction and unsat- core variable prediction, we report the classification accuracy of each GNN model in G4SATBench. For satisfying assignment prediction, we report the solving accuracy of the predicted assignments. If multiple assignments are predicted for a SAT instance, the instance is considered solved if any of the predictions satisfy the formula. ## 5 Benchmarking Evaluation on G4SATBench In this section, we present the benchmarking results of G4SATBench. To ensure a fair comparison, we conduct a grid search to tune the hyperparameters of each GNN baseline. The best checkpoint for each GNN model is selected based on its performance on the validation set. To mitigate the impact of randomness, we use 3 different random seeds to repeat the experiment in each setting and report the average performance. Each experiment is performed on a single RTX8000 GPU and 16 AMD EPYC 7502 CPU cores, and the total time cost is approximately 8,000 GPU hours. For detailed experimental setup and hyperparameters, please refer to Appendix C.1. ### 5.1 Satisfiability Prediction Evaluation on the same distribution. Table 1 shows the benchmarking results of each GNN baseline when trained and evaluated on datasets possessing identical distributions. All GNN models exhibit strong performance across most easy and medium datasets, except for the medium SR dataset. This difficulty can be attributed to the inherent characteristic of this dataset, which includes satisfiable and unsatisfiable pairs of medium- sized instances distinguished by just a single differing literal. Such a subtle difference presents a substantial challenge for GNN models in satisfiability classification. Among all GNN models, the different graph constructions do not seem to have a significant impact on the results, and Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) achieve the best overall performance. Table 1: Classification accuracy of satisfiability on identical distribution. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>96.00</td><td>96.33</td><td>98.83</td><td>96.59</td><td>97.92</td><td>99.77</td><td>99.99</td><td>78.02</td><td>84.90</td><td>99.57</td><td>96.81</td><td>89.39</td><td>99.67</td></tr><tr><td>GCN</td><td>94.43</td><td>94.47</td><td>98.79</td><td>97.53</td><td>98.24</td><td>99.59</td><td>99.98</td><td>69.39</td><td>82.67</td><td>99.53</td><td>96.16</td><td>85.72</td><td>99.16</td></tr><tr><td>GGNN</td><td>96.36</td><td>95.70</td><td>98.81</td><td>97.47</td><td>98.80</td><td>99.77</td><td>99.97</td><td>71.44</td><td>83.45</td><td>99.50</td><td>96.21</td><td>81.20</td><td>99.69</td></tr><tr><td>GIN</td><td>95.78</td><td>95.37</td><td>98.14</td><td>96.98</td><td>97.60</td><td>99.71</td><td>99.97</td><td>70.54</td><td>82.80</td><td>99.49</td><td>95.80</td><td>83.87</td><td>99.61</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>93.19</td><td>94.92</td><td>97.82</td><td>95.79</td><td>98.72</td><td>99.54</td><td>99.99</td><td>66.35</td><td>83.75</td><td>99.49</td><td>95.48</td><td>82.99</td><td>99.42</td></tr><tr><td>GGNN</td><td>96.75</td><td>96.25</td><td>98.77</td><td>96.44</td><td>98.88</td><td>99.68</td><td>99.98</td><td>77.12</td><td>85.11</td><td>99.57</td><td>96.48</td><td>83.63</td><td>99.62</td></tr><tr><td>GIN</td><td>96.04</td><td>95.71</td><td>98.47</td><td>96.95</td><td>97.33</td><td>99.59</td><td>99.98</td><td>73.56</td><td>85.26</td><td>99.49</td><td>96.55</td><td>89.41</td><td>99.38</td></tr></table> Evaluation across different distributions. To assess the generalization ability of GNN models, we evaluate the performance of Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) across different datasets and difficulty levels. As shown in Figure 3 and Figure 4, Neuro SAT and GGNN struggle to generalize effectively to datasets distinct from their training data in most cases. However, when trained on the SR dataset, they exhibit better generalization performance across different datasets. Furthermore, while both GNN models\n\ndemonstrate limited generalization to larger formulas beyond their training data, they perform relatively better on smaller instances. These observations suggest that the generalization performance of GNN models for satisfiability prediction is influenced by the distinct nature and complexity of its training data. Training on more challenging instances could potentially enhance their generalization ability. <center>Figure 3: Classification accuracy of satisfiability across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> <center>Figure 4: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Due to the limited space, Figure 4 exclusively displays the performance of Neuro SAT and GGNN on the SR and 3- SAT datasets. Comprehensive results on the other five datasets, as well as the experimental results on different massage passing iterations, are provided in Appendix C.2. ### 5.2 Satisfying Assignment Prediction Evaluation with different training losses. Table 2 presents the results of Neuro SAT (on \\(\\mathrm{LCG}^{*}\\) ) and GGNN (on \\(\\mathrm{VCG}^{*}\\) ) across three different training objectives. The results of other GNN models are listed in Table 10 in Appendix C.3. Interestingly, the unsupervised training methods outperform the supervised learning approach across the majority of datasets. We hypothesize that this is due to the presence of multiple satisfying assignments in most satisfiable instances. Supervised training tends to bias GNN models towards learning a specific satisfying solution, thereby neglecting the exploration of other feasible ones. This bias may compromise the models' ability to generalize effectively. Such limitations become increasingly apparent when the space of satisfying solutions is much larger, as seen in the medium CA and PS datasets. Additionally, it is noteworthy that employing \\(\\mathrm{UNS}_1\\) as the loss function can result in instability during the training of some GNN models, leading to a failure to converge in some cases. Conversely, using \\(\\mathrm{UNS}_2\\) loss demonstrates strong and stable performance across all datasets. In addition to evaluating the performance of GNN models under various training loss functions, we extend our analysis to explore how these models perform across different data distributions and under various inference algorithms. Furthermore, we assess the robustness of these GNN models when trained on noisy datasets that include unsatisfiable instances in an unsupervised fashion. For detailed results of these evaluations across different GNN baselines, please refer to Appendix C.3.\n\nTable 2: Solving accuracy on identical distribution with different training losses. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td rowspan=\"2\">Loss</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"3\">LCG*</td><td rowspan=\"3\">Neuro SAT</td><td>SUP</td><td>88.47</td><td>78.39</td><td>0.27</td><td>39.18</td><td>66.30</td><td>69.61</td><td>85.15</td><td>34.97</td><td>20.07</td><td>0.00</td><td>3.64</td><td>56.61</td><td>52.09</td></tr><tr><td>UNS1</td><td>82.30</td><td>80.23</td><td>82.17</td><td>89.23</td><td>88.34</td><td>96.74</td><td>99.36</td><td>25.00</td><td>30.40</td><td>35.45</td><td>60.28</td><td>41.45</td><td>95.06</td></tr><tr><td>UNS2</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.61</td><td>70.83</td><td>71.03</td><td>-</td><td>96.18</td><td>95.99</td></tr><tr><td rowspan=\"3\">VCG*</td><td rowspan=\"3\">GGNN</td><td>SUP</td><td>84.13</td><td>72.87</td><td>0.29</td><td>38.82</td><td>60.80</td><td>68.36</td><td>82.06</td><td>14.15</td><td>7.96</td><td>0.00</td><td>2.33</td><td>52.35</td><td>49.07</td></tr><tr><td>UNS1</td><td>76.39</td><td>76.55</td><td>78.13</td><td>84.44</td><td>84.60</td><td>97.49</td><td>-</td><td>16.55</td><td>22.84</td><td>28.12</td><td>44.89</td><td>54.29</td><td>-</td></tr><tr><td>UNS2</td><td>78.75</td><td>76.42</td><td>84.08</td><td>86.29</td><td>87.12</td><td>98.06</td><td>99.34</td><td>21.18</td><td>25.68</td><td>50.66</td><td>57.96</td><td>68.91</td><td>92.26</td><td>94.30</td></tr></table> ### 5.3 Unsat-core Variable Prediction Evaluation on the same distribution. The benchmarking results presented in Table 3 exhibit the superior performance of all GNN models on both easy and medium datasets, with Neuro SAT consistently achieving the best results across most datasets. It is important to note that the primary objective of predicting unsat- core variables is not to solve SAT problems directly but to provide valuable guidance for enhancing the backtracking search process. As such, even imperfect predictions - for instance, those with a classification accuracy of \\(90\\%\\) - have been demonstrated to be sufficiently effective in improving the search heuristics employed by modern CDCL- based SAT solvers, as indicated by previous studies (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021). Table 3: Classification accuracy of unsat-core variables on identical distribution. Only unsatisfiable instances are evaluated. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>90.76</td><td>94.43</td><td>83.69</td><td>86.20</td><td>99.93</td><td>95.80</td><td>94.47</td><td>90.07</td><td>99.65</td><td>85.73</td><td>88.53</td><td>99.97</td><td>97.90</td></tr><tr><td>GCN</td><td>89.17</td><td>94.35</td><td>82.89</td><td>85.32</td><td>99.93</td><td>95.74</td><td>94.43</td><td>88.11</td><td>99.65</td><td>85.71</td><td>87.70</td><td>99.96</td><td>97.89</td></tr><tr><td>GGNN</td><td>90.02</td><td>94.38</td><td>83.59</td><td>86.03</td><td>99.93</td><td>95.79</td><td>94.46</td><td>89.05</td><td>99.65</td><td>85.69</td><td>87.95</td><td>99.96</td><td>97.89</td></tr><tr><td>GIN</td><td>89.29</td><td>94.33</td><td>83.71</td><td>85.97</td><td>99.93</td><td>95.81</td><td>94.47</td><td>88.85</td><td>99.65</td><td>85.71</td><td>87.92</td><td>99.96</td><td>97.89</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>88.57</td><td>94.34</td><td>83.17</td><td>85.27</td><td>99.93</td><td>95.79</td><td>94.46</td><td>88.17</td><td>99.65</td><td>85.70</td><td>87.37</td><td>99.96</td><td>97.90</td></tr><tr><td>GGNN</td><td>89.57</td><td>94.37</td><td>83.50</td><td>85.84</td><td>99.93</td><td>95.81</td><td>94.49</td><td>88.84</td><td>99.65</td><td>85.68</td><td>88.03</td><td>99.98</td><td>97.90</td></tr><tr><td>GIN</td><td>89.50</td><td>94.35</td><td>83.23</td><td>85.69</td><td>99.93</td><td>95.79</td><td>94.47</td><td>89.51</td><td>99.65</td><td>85.72</td><td>88.13</td><td>99.96</td><td>97.89</td></tr></table> We also conduct experiments to evaluate the generalization ability of GNN models on unsat- core variable prediction. Please see appendix C.4 for details. ## 6 Advancing Evaluation on G4SATBench To gain deeper insights into how GNNs tackle the SAT problem, we conduct comprehensive comparative analyses between GNN- based SAT solvers and the CDCL and LS heuristics in this section. Since these search heuristics aim to solve a SAT instance directly, our focus only lies on the tasks of (T1) satisfiability prediction and (T2) satisfying assignment prediction (with \\(\\mathrm{UNS}_2\\) as the training loss). We employ Neuro SAT (on \\(\\mathrm{LCG}^*\\) ) and GGNN (on \\(\\mathrm{VCG}^*\\) ) as our GNN models and experiment on the SR and 3- SAT datasets. Detailed experimental settings are included in Appendix D.1. ### 6.1 Comparison with the CDCL Heuristic Evaluation on the clause- learning augmented instances. CDCL- based SAT solvers enhance backtracking search with conflict analysis and clause learning, enabling efficient exploration of the search space by iteratively adding \"learned clauses\" to avoid similar conflicts in future searches (Silva & Sakallah, 1999). To assess whether GNN- based SAT solvers can learn and benefit from the backtracking search (with CDCL) heuristic, we augment the original formulas in the datasets with learned clauses and evaluate GNN models on these clause- augmented instances.\n\nTable 4 shows the testing results on augmented SAT datasets. Notably, training on the augmented instances leads to significant improvements in both satisfiability prediction and satisfying assignment prediction. These improvements can be attributed to the presence of \"learned clauses\" that effectively modify the structure of the original formulas, thereby facilitating GNNs to solve with relative ease. However, despite the augmented instances being easily solvable using the backtracking search within a few search steps, GNN models fail to effectively handle these instances when trained on the original instances. These findings suggest that GNNs may not implicitly learn the CDCL heuristic when trained for satisfiability prediction or satisfying assignment prediction. Table 4: Results on augmented datasets. Values inside/outside parentheses denote the results of models trained on augmented/original instances. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>100.00 (96.78)</td><td>100.00 (96.06)</td><td>100.00 (84.57)</td><td>96.78 (84.85)</td></tr><tr><td>GGNN</td><td>100.00 (97.66)</td><td>100.00 (95.46)</td><td>100.00 (84.01)</td><td>96.29 (85.80)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>85.05 (83.28)</td><td>83.50 (81.04)</td><td>51.95 (45.51)</td><td>39.00 (16.52)</td></tr><tr><td>GGNN</td><td>85.35 (83.42)</td><td>81.56 (79.99)</td><td>44.18 (40.09)</td><td>34.67 (14.75)</td></tr></table> Table 5: Results using contrastive pretraining. Values in parentheses denote the difference between the results without pretraining. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>96.68 (+0.68)</td><td>96.23 (+0.10)</td><td>78.31 (+0.29)</td><td>85.02 (+0.12)</td></tr><tr><td>GGNN</td><td>96.46 (+0.29)</td><td>96.45 (+0.20)</td><td>76.34 (+0.78)</td><td>85.17 (+0.06)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>80.54 (+0.75)</td><td>79.71 (-0.88)</td><td>36.42 (-0.83)</td><td>41.23 (-0.38)</td></tr><tr><td>GGNN</td><td>80.66 (-0.34)</td><td>79.23 (-0.09)</td><td>33.44 (+0.07)</td><td>36.39 (+0.44)</td></tr></table> Evaluation with contrastive pretraining. Observing that GNN models exhibit superior performance on clause- learning augmented SAT instances, there is potential to improve the performance of GNNs by learning a latent representation of the original formula similar to its augmented counterpart. Motivated by this, we also experiment with a contrastive learning approach (i.e., Sim CLR (Chen et al., 2020)) to pretrain the representation of CNF formulas to be close to their augmented ones (Duan et al., 2022), trying to explicitly embed the CDCL heuristic in the latent space through representation learning. The results of contrastive pretraining are presented in Table 5. In contrast to the findings in Duan et al. (2022), our results show limited performance improvement through contrastive pretraining, indicating that GNN models still encounter difficulties in effectively learning the CDCL heuristic in the latent space. This observation aligns with the conclusions drawn in Chen & Yang (2019), which highlight that static GNNs may fail to exactly replicate the same search operations due to the dynamic changes in the graph structure introduced by the clause learning technique. ### 6.2 Comparison with the LS Heuristic Evaluation with random initialization. LS- based SAT solvers typically begin by randomly initializing an assignment and then iteratively flip variables guided by specific heuristics until reaching a satisfying assignment. To compare the behaviors of GNNs with this solving procedure, we first conduct an evaluation of GNN models with randomized initial embeddings in both training and testing, emulating the initialization of LS SAT solvers. The results presented in Table 6 demonstrate that using random initialization has a limited impact on the overall performances of GNN- based SAT solvers. This suggests that GNN models do not aim to learn a fixed latent representation of each formula for satisfiability prediction and satisfying assignment prediction. Instead, they have developed a solving strategy that effectively exploits the inherent graph structure of each SAT instance. Table 6: Results using random initialization. Values in parentheses denote the difference between the results with learned initialization. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>97.24 (+1.24)</td><td>96.44 (+0.11)</td><td>77.29 (-0.91)</td><td>84.85 (-0.05)</td></tr><tr><td>GGNN</td><td>96.78 (+0.03)</td><td>96.38 (+0.13)</td><td>76.97 (-0.15)</td><td>85.80 (+0.69)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>79.09 (-0.70)</td><td>80.79 (+0.20)</td><td>37.27 (+0.02)</td><td>40.75 (-0.86)</td></tr><tr><td>GGNN</td><td>80.10 (-0.90)</td><td>79.83 (+0.51)</td><td>32.85 (-0.52)</td><td>36.59 (+0.64)</td></tr></table> Evaluation on the predicted assignments. Under random initialization, we further analyze the solving strategies of GNNs by evaluating their predicted assignments decoded from the latent space. For the task of satisfiability prediction, we employ the 2- clustering decoding algorithm to extract the predicted assignments from the literal embeddings of Neuro SAT at each iteration of message passing. For satisfying assignment",
      "level": 1,
      "line_start": 1,
      "line_end": 43
    },
    {
      "heading": "Introduction",
      "content": "prediction, we evaluate both Neuro SAT and GGNN using multiple- prediction decoding. Our evaluation focuses on three key aspects: (a) the number of distinct predicted assignments, (b) the number of flipped variables between two consecutive iterations, and (c) the number of unsatisfiable clauses associated with the predicted assignments. <center>Figure 5: Results on the predicted assignments with the increased message passing iteration \\(T\\) . Neuro SAT\\* refers to the model trained for satisfiability prediction. </center> As shown in Figure 5, all three GNN models initially generate a wide array of assignment predictions by flipping a considerable number of variables, resulting in a notable reduction in the number of unsatisfiable clauses. However, as the iterations progress, the number of flipped variables diminishes substantially, and most GNN models eventually converge towards predicting a specific assignment or making minimal changes to their predictions when there are no or very few unsatisfiable clauses remaining. This trend is reminiscent of the greedy solving strategy adopted by the LS solver GSAT (Selman et al., 1992), where changes are made to minimize the number of unsatisfied clauses in the new assignment. However, unlike GSAT's approach of flipping one variable at a time and incorporating random selection to break ties, GNN models simultaneously modify multiple variables and potentially converge to a particular unsatisfied assignment and find it challenging to deviate from such a prediction. It is also noteworthy that despite being trained for satisfiability prediction, Neuro SAT\\* demonstrates similar behavior to the GNN models trained for assignment prediction. This observation indicates that GNNs also learn to search for a satisfying assignment implicitly in the latent space while performing satisfiability prediction. To provide more insights into the strengths and limitations of GNN- based heuristics, we further conduct experiments to compare GNN- based SAT solvers against state- of- the- art CDCL and LS- based SAT solvers in Appendix D.2. ## 7 Discussions ### 7.1 Limitations and Future Work While G4SATBench represents a significant step in evaluating GNNs for SAT solving, there are still some limitations and potential future directions to consider. Firstly, G4SATBench primarily focuses on evaluating standalone neural SAT solvers, excluding the exploration of neural- guided SAT solvers that integrate GNNs with search- based SAT solvers. It also should be emphasized that the instances included in G4SATBench are considerably smaller compared to most practical instances found in real- world applications, where GNN models alone are not sufficient for solving such large- scale instances. The efficacy of GNN models in unsat- core prediction shows a promising avenue for combining GNNs with modern SAT solvers, and future research could explore more techniques to effectively leverage these neural- guided SAT solvers to scale up to real- world instances. Secondly, G4SATBench benchmarks general GNN models on the LCG\\* and VCG\\* graph representations for SAT solving, but does not consider sophisticated GNN models designed for specific graph constructions in certain domains, such as Circuit SAT problems. Investigating domain- specific GNN models tailored to the characteristics of specific problems could lead to improved performance in specialized instances. Lastly, all existing GNN- based SAT solvers in the literature are static GNNs, which have limited learning ability to capture the CDCL heuristic. Exploring dynamic GNN models that can effectively learn the CDCL heuristic is also a potential direction for future research.\n\n### 7.2 Conclusion 7.2 Conclusion In this work, we present G4SATBench, a benchmark study that comprehensively evaluates GNN models in SAT solving. G4SATBench offers curated synthetic SAT datasets sourced from various domains and difficulty levels and benchmarks a wide range of GNN- based SAT solvers under diverse settings. Our empirical analysis yields valuable insights into the performances of GNN- based SAT solvers and further provides a deeper understanding of their capabilities and limitations. We hope the proposed G4SATBench will serve as a solid foundation for GNN- based SAT solving and inspire future research in this exciting field. ## Acknowledgments Acknowledgments This work was supported, in part, by Individual Discovery Grants from the Natural Sciences and Engineering Research Council of Canada, and the Canada CIFAR AI Chair Program. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve Circuit- SAT: An unsupervised differentiable approach. In International Conference on Learning Representations (ICLR), 2019a. Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. PDP: A general neural framework for learning constraint satisfaction solvers. ar Xiv preprint ar Xiv:1903.01969, 2019b. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ar Xiv preprint ar Xiv:1607.06450, 2016. Adrian Balint and Andreas Fr\u00f6hlich. Improving stochastic local search for sat with a new probability distribution. In Theory and Applications of Satisfiability Testing- SAT 2010: 13th International Conference, SAT 2010, Edinburgh, UK, July 11- 14, 2010. Proceedings 13, pp. 10- 15. Springer, 2010. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of Satisfiability, volume 185. IOS press, 2009. B\u00e9la Bollob\u00e1s and Paul Erd\u0151s. Cliques in random graphs. In Mathematical Proceedings of the Cambridge Philosophical Society, 1976. Benedikt B\u00fcnz and Matthew Lamm. Graph neural networks and boolean satisfiability. ar Xiv preprint ar Xiv:1702.03592, 2017. Chris Cameron, Rex Chen, Jason Hartford, and Kevin Leyton- Brown. Predicting propositional satisfiability via end- to- end learning. In AAAI Conference on Artificial Intelligence (AAAI), 2020. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020. Ziliang Chen and Zhanfu Yang. Graph neural reasoning may fail in certifying boolean unsatisfiability. ar Xiv preprint ar Xiv:1909.11588, 2019. James M. Crawford and Larry D. Auton. Experimental results on the crossover point in random 3- SAT. Artificial Intelligence, 1996. Haonan Duan, Pashootan Vaezipoor, Max B. Paulus, Yangjun Ruan, and Chris J. Maddison. Augment with care: Contrastive learning for combinatorial problems. In International Conference on Machine Learning (ICML), 2022. Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. ar Xiv preprint ar Xiv:1903.02428, 2019. ABKFM Fleury and Maximilian Heisinger. Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020. SAT COMPETITION, 2020.\n\nJes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. A modularity- based random SAT instances generator. In International Joint Conference on Artificial Intelligence (IJCAI), 2015. Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. Locality in random SAT instances. In International Joint Conference on Artificial Intelligence (IJCAI), 2017. Wenxuan Guo, Junchi Yan, Hui- Ling Zhen, Xijun Li, Mingxuan Yuan, and Yaohui Jin. Machine learning methods in solving the boolean satisfiability problem. ar Xiv preprint ar Xiv:2203.04755, 2022. Jesse Michael Han. Enhancing SAT solvers with glue variable predictions. ar Xiv preprint ar Xiv:2007.02559, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human- level performance on imagenet classification. In IEEE International Conference on Computer Vision (ICCV), 2015. Sean B Holden et al. Machine learning for automated theorem proving: Learning to solve SAT and QSAT. Foundations and Trends\u00ae in Machine Learning, 14(6):807- 989, 2021. Holger H Hoos and Thomas St\u00fctzle. SATLIB: An online resource for research on SAT. Workshop on Satisfiability (SAT), 2000. Sebastian Jaszczur, Michal \u0141uszczyk, and Henryk Michalewski. Neural heuristics for SAT solving. ar Xiv preprint ar Xiv:2005.13406, 2020. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. Thomas N. Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q- learning with graph networks learn a generalizable branching heuristic for a SAT solver? In Advances in Neural Information Processing Systems (Neur IPS), 2020. Massimo Lauria, Jan Elffers, Jakob Nordstr\u00f6m, and Marc Vinyals. Cnfen: A generator of crafted benchmarks. In Theory and Applications of Satisfiability Testing (SAT), 2017. Min Li, Zhengyuan Shi, Qiuxia Lai, Sadaf Khan, Shaowei Cai, and Qiang Xu. On eda- driven learning for sat solving. In Design Automation Conference (DAC), 2023. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations (ICLR), 2016. Zhaoyu Li and Xujie Si. NSNet: A general neural probabilistic framework for satisfiability problems. In Advances in Neural Information Processing Systems (Neur IPS), 2022. Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning (ICML), 2010. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural SAT solver. In International Joint Conference on Neural Networks (IJCNN), 2022. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. Yang, Zachary De Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high- performance deep learning library. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Bart Selman, Hector J. Levesque, and David G. Mitchell. A new method for solving hard satisfiability problems. In National Conference on Artificial Intelligence (AAAI), 1992.\n\nDaniel Selsam and Nikolaj S. Bj\u00f8rner. Guiding high- performance SAT solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing (SAT), 2019. Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations (ICLR), 2019. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui- Ling Zhen, Mingxuan Yuan, and Qiang Xu. Sathermer: Transformer- based unsat core learning. In International Conference on Computer Aided Design (ICCAD), 2023. Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP: A search algorithm for propositional satisfiability. IEEE Transactions on Computers, 1999. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth Mc Millan, and Risto Miikkulainen. Neurocomb: Improving SAT solving with graph neural networks. ar Xiv preprint ar Xiv:2110.14053, 2021. Nathan Wetzler, Marijn Heule, and Warren A. Hunt Jr. Drat- trim: Efficient checking and trimming using expressive clausal proofs. In Theory and Applications of Satisfiability Testing (SAT), 2014. Ben Wieland and Anant P. Godbole. On the domination number of a random graph. The Electronic Journal of Combinatorics, 2001. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019. Zhiyuan Yan, Min Li, Zhengyuan Shi, Wenjie Zhang, Yingcong Chen, and Hongce Zhang. Addressing variable dependency in gnn- based SAT solving. ar Xiv preprint ar Xiv:2304.08738, 2023. Emre Yolcu and Barnab\u00e1s P\u00f3czos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong, and Lu Zhang. Nicolasat: Boosting local search with solution prediction. In International Joint Conference on Artificial Intelligence (IJCAI), 2020.",
      "level": 2,
      "line_start": 4,
      "line_end": 14
    },
    {
      "heading": "7.2 Conclusion 7.2 Conclusion In this work, we present G4SATBench, a benchmark study that comprehensively evaluates GNN models in SAT solving. G4SATBench offers curated synthetic SAT datasets sourced from various domains and difficulty levels and benchmarks a wide range of GNN- based SAT solvers under diverse settings. Our empirical analysis yields valuable insights into the performances of GNN- based SAT solvers and further provides a deeper understanding of their capabilities and limitations. We hope the proposed G4SATBench will serve as a solid foundation for GNN- based SAT solving and inspire future research in this exciting field. ## Acknowledgments Acknowledgments This work was supported, in part, by Individual Discovery Grants from the Natural Sciences and Engineering Research Council of Canada, and the Canada CIFAR AI Chair Program. ## References Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve Circuit- SAT: An unsupervised differentiable approach. In International Conference on Learning Representations (ICLR), 2019a. Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. PDP: A general neural framework for learning constraint satisfaction solvers. ar Xiv preprint ar Xiv:1903.01969, 2019b. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. ar Xiv preprint ar Xiv:1607.06450, 2016. Adrian Balint and Andreas Fr\u00f6hlich. Improving stochastic local search for sat with a new probability distribution. In Theory and Applications of Satisfiability Testing- SAT 2010: 13th International Conference, SAT 2010, Edinburgh, UK, July 11- 14, 2010. Proceedings 13, pp. 10- 15. Springer, 2010. Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of Satisfiability, volume 185. IOS press, 2009. B\u00e9la Bollob\u00e1s and Paul Erd\u0151s. Cliques in random graphs. In Mathematical Proceedings of the Cambridge Philosophical Society, 1976. Benedikt B\u00fcnz and Matthew Lamm. Graph neural networks and boolean satisfiability. ar Xiv preprint ar Xiv:1702.03592, 2017. Chris Cameron, Rex Chen, Jason Hartford, and Kevin Leyton- Brown. Predicting propositional satisfiability via end- to- end learning. In AAAI Conference on Artificial Intelligence (AAAI), 2020. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020. Ziliang Chen and Zhanfu Yang. Graph neural reasoning may fail in certifying boolean unsatisfiability. ar Xiv preprint ar Xiv:1909.11588, 2019. James M. Crawford and Larry D. Auton. Experimental results on the crossover point in random 3- SAT. Artificial Intelligence, 1996. Haonan Duan, Pashootan Vaezipoor, Max B. Paulus, Yangjun Ruan, and Chris J. Maddison. Augment with care: Contrastive learning for combinatorial problems. In International Conference on Machine Learning (ICML), 2022. Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. ar Xiv preprint ar Xiv:1903.02428, 2019. ABKFM Fleury and Maximilian Heisinger. Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020. SAT COMPETITION, 2020.",
      "content": "Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. A modularity- based random SAT instances generator. In International Joint Conference on Artificial Intelligence (IJCAI), 2015. Jes\u00fas Gir\u00e1ldez- Cru and Jordi Levy. Locality in random SAT instances. In International Joint Conference on Artificial Intelligence (IJCAI), 2017. Wenxuan Guo, Junchi Yan, Hui- Ling Zhen, Xijun Li, Mingxuan Yuan, and Yaohui Jin. Machine learning methods in solving the boolean satisfiability problem. ar Xiv preprint ar Xiv:2203.04755, 2022. Jesse Michael Han. Enhancing SAT solvers with glue variable predictions. ar Xiv preprint ar Xiv:2007.02559, 2020. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human- level performance on imagenet classification. In IEEE International Conference on Computer Vision (ICCV), 2015. Sean B Holden et al. Machine learning for automated theorem proving: Learning to solve SAT and QSAT. Foundations and Trends\u00ae in Machine Learning, 14(6):807- 989, 2021. Holger H Hoos and Thomas St\u00fctzle. SATLIB: An online resource for research on SAT. Workshop on Satisfiability (SAT), 2000. Sebastian Jaszczur, Michal \u0141uszczyk, and Henryk Michalewski. Neural heuristics for SAT solving. ar Xiv preprint ar Xiv:2005.13406, 2020. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2015. Thomas N. Kipf and Max Welling. Semi- supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017. Vitaly Kurin, Saad Godil, Shimon Whiteson, and Bryan Catanzaro. Can q- learning with graph networks learn a generalizable branching heuristic for a SAT solver? In Advances in Neural Information Processing Systems (Neur IPS), 2020. Massimo Lauria, Jan Elffers, Jakob Nordstr\u00f6m, and Marc Vinyals. Cnfen: A generator of crafted benchmarks. In Theory and Applications of Satisfiability Testing (SAT), 2017. Min Li, Zhengyuan Shi, Qiuxia Lai, Sadaf Khan, Shaowei Cai, and Qiang Xu. On eda- driven learning for sat solving. In Design Automation Conference (DAC), 2023. Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. Gated graph sequence neural networks. In International Conference on Learning Representations (ICLR), 2016. Zhaoyu Li and Xujie Si. NSNet: A general neural probabilistic framework for satisfiability problems. In Advances in Neural Information Processing Systems (Neur IPS), 2022. Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning (ICML), 2010. Emils Ozolins, Karlis Freivalds, Andis Draguns, Eliza Gaile, Ronalds Zakovskis, and Sergejs Kozlovics. Goal- aware neural SAT solver. In International Joint Conference on Neural Networks (IJCNN), 2022. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Z. Yang, Zachary De Vito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high- performance deep learning library. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Bart Selman, Hector J. Levesque, and David G. Mitchell. A new method for solving hard satisfiability problems. In National Conference on Artificial Intelligence (AAAI), 1992.\n\nDaniel Selsam and Nikolaj S. Bj\u00f8rner. Guiding high- performance SAT solvers with unsat- core predictions. In Theory and Applications of Satisfiability Testing (SAT), 2019. Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, and David L. Dill. Learning a SAT solver from single- bit supervision. In International Conference on Learning Representations (ICLR), 2019. Zhengyuan Shi, Min Li, Yi Liu, Sadaf Khan, Junhua Huang, Hui- Ling Zhen, Mingxuan Yuan, and Qiang Xu. Sathermer: Transformer- based unsat core learning. In International Conference on Computer Aided Design (ICCAD), 2023. Jo\u00e3o P. Marques Silva and Karem A. Sakallah. GRASP: A search algorithm for propositional satisfiability. IEEE Transactions on Computers, 1999. Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth Mc Millan, and Risto Miikkulainen. Neurocomb: Improving SAT solving with graph neural networks. ar Xiv preprint ar Xiv:2110.14053, 2021. Nathan Wetzler, Marijn Heule, and Warren A. Hunt Jr. Drat- trim: Efficient checking and trimming using expressive clausal proofs. In Theory and Applications of Satisfiability Testing (SAT), 2014. Ben Wieland and Anant P. Godbole. On the domination number of a random graph. The Electronic Journal of Combinatorics, 2001. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019. Zhiyuan Yan, Min Li, Zhengyuan Shi, Wenjie Zhang, Yingcong Chen, and Hongce Zhang. Addressing variable dependency in gnn- based SAT solving. ar Xiv preprint ar Xiv:2304.08738, 2023. Emre Yolcu and Barnab\u00e1s P\u00f3czos. Learning local search heuristics for boolean satisfiability. In Advances in Neural Information Processing Systems (Neur IPS), 2019. Wenjie Zhang, Zeyu Sun, Qihao Zhu, Ge Li, Shaowei Cai, Yingfei Xiong, and Lu Zhang. Nicolasat: Boosting local search with solution prediction. In International Joint Conference on Artificial Intelligence (IJCAI), 2020.",
      "level": 3,
      "line_start": 9,
      "line_end": 14
    },
    {
      "heading": "A Datasets Generators. To generate high- quality SAT datasets that do not contain trivial instances, we have employed a rigorous process of selecting appropriate parameters for each CNF generator in G4SATBench. Table 7 provides detailed information about the generators we have used. Table 7: Details of the synthetic generators employed in G4SATBench. <table><tr><td>Dataset</td><td>Description</td><td>Parameters</td><td>Notes</td></tr><tr><td>SR</td><td>The SR dataset is composed of pairs of satisfiable and unsatisfiable formulas, with the only difference between each pair being the polarity of a single literal. Given the number of variables n, the synthetic generator iteratively samples k = 1+Bernoulli(b)+Geometric(g) vari-ables uniformly at random without replacement and negates each one with independent probability 50% to build a clause. This procedure continues until the generated formula is unsatisfiable. The satisfiable instance is then constructed by negating the first literal in the last clause of the unsatisfiable one.</td><td>General: b = 0.3, g = 0.4, Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 400)</td><td>The sampling parameters are the same as the original paper (Selsam et al., 2019).</td></tr><tr><td>3-SAT</td><td>The 3-SAT dataset comprises CNF formulas at the phase transition, where the proportion of generated satisfiable and unsatisfiable formu- las is roughly equal. Given the number of variables n and clauses m, the synthetic generator iteratively samples three variables (and their polarities) uniformly at random until m clauses are obtained.</td><td>General: m = 4.258n + 58.26n-2/3, Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 300)</td><td>The parameter m is the same as the paper (Crawford &amp;amp; Auton, 1996)</td></tr><tr><td>CA</td><td>The CA dataset contains SAT instances that are designed to mimic the community structures and modularity features found in real-world industrial instances. Given variable number n, clause number m, clause size k, community number c, and modularity Q, the synthetic generator iteratively selects k literals in the same community uni- formly at random with probability P = Q + 1/c and selects k literals in the distinct community uniformly at random with probability 1-P to build a clause and repeat for m times to construct a CNF formula.</td><td>General: m ~ Uniform(13n, 15n), k ~ Uniform(4, 5), c ~ Uniform(3, 10), Q ~ Uniform(0.7, 0.9) Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 400)</td><td>The parameters are selected based on the experiments in the original paper (Gir\u00e1ldez-Cru &amp;amp; Levy, 2015) and our study to ensure that the generated SAT instances have a balance of satisfiability and unsatisfiability.</td></tr><tr><td>PS</td><td>PS dataset encompasses SAT instances with a power-law distribution in the number of variable occurrences (popularity), and good class- tering between them (similarity). Given variable number n, clause number m, and average clause size k, the synthetic generator first as- signs random angles \u03b8i, \u03b8j \u2208 [0, 2\u03c0] to each variable i and each clause j, and then randomly samples variable i in clause j with the proba- bility P = 1/(1+(i\u03b2j\u03b2i/R)T). Here, \u03b8ij = \u03c0-|\u03c0-|\u03b8i-|\u03b8j| is the angle between variable i and clause j. The exponent parameters \u03b2 and \u03b2\u2032 control the power-law distribution of variable occurrences and clause size respectively. The temperature parameter T controls the sharpness of the probability distribution, while R is an approximate normalization constant that ensures the average number of selected edges is km.</td><td>General: m ~ Uniform(6n, 8n), k ~ Uniform(4, 5), \u03b2 ~ Uniform(0, 1), \u03b2\u2032 = 1, c ~ Uniform(3, 10), T ~ Uniform(0.75, 1.5) Easy dataset: n ~ Uniform(10, 40), Medium dataset: n ~ Uniform(40, 200), Hard dataset: n ~ Uniform(200, 300)</td><td>The parameters are selected based on the experiments in the original paper (Gir\u00e1ldez-Cru &amp;amp; Levy, 2017) and our study to ensure that the generated SAT instances have a balance of satisfiability and unsatisfiability.</td></tr><tr><td>k-Clique</td><td>The k-Clique dataset includes SAT instances that encode the k-Clique problem, which involves determining whether there exists a clique (i.e., a subset of vertices that are all adjacent to each other) with v vertices in a given graph. Given the number of cliques k, the synthetic generator produces an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then transforms the corresponding k-Clique problem into a SAT instance.</td><td>General: p = (v)k-1/(v), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(3, 4), Medium dataset: v ~ Uniform(15, 20), k ~ Uniform(3, 5), Hard dataset: v ~ Uniform(20, 25), k ~ Uniform(4, 6)</td><td>The parameter p is selected based on the paper (Bollob\u00e1s &amp;amp; Erd\u0151s, 1976), making the expected number of k-Cliques in the generated graph equals 1.</td></tr><tr><td>k-Domset</td><td>The k-Domset dataset contains SAT instances that encode the k-Dominating Set problem. This problem is to determine whether there exists a dominating set (i.e., a subset of vertices such that every vertex in the graph is either in the subset or adjacent to a vertex in the sub- set) with at most k vertices in a given graph. Given the domination number k, the synthetic generator produces an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then transforms the corresponding k-Dominating Set problem into a SAT instance.</td><td>General: p = 1-(1-(v)k-1/(v)k), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(2, 3), Medium dataset: v ~ Uniform(15, 20), k ~ Uniform(3, 5), Hard dataset: v ~ Uniform(20, 25), k ~ Uniform(4, 6)</td><td>The parameter p is selected based on the paper (Wieland &amp;amp; Godbole, 2001), making the expected number of domination set with size k in the generated graph equals 1.</td></tr><tr><td>k-Vercov</td><td>The k-Vercov dataset consists of SAT instances that encode the k-Vercov problem, i.e., check whether there exists a set of k vertices in a graph such that every edge has at least one endpoint in this set. Given the vertex cover number k, the synthetic generator produces a complement graph of an Erd\u0151s-R\u00e9nyi graph with v vertices and a given edge probability p and then converts the corresponding k-Vercov Cover problem into a SAT instance.</td><td>General: p = (v)k-1/(v), Easy dataset: v ~ Uniform(5, 15), k ~ Uniform(3, 5), Medium dataset: v ~ Uniform(10, 20), k ~ Uniform(6, 8), Hard dataset: v ~ Uniform(15, 25), k ~ Uniform(9, 10)</td><td>The generation process and the parameter are selected based on the relationship between k-Vercov Cover and k-Clique problems, making the size of the minimum vertex cover in the generated graph around k.</td></tr></table>",
      "content": "Statistics. To provide a comprehensive understanding of our generated datasets, we compute several characteristics across three difficulty levels. These statistics include the average number of variables and clauses, as well as graph measures such as average clustering coefficient (in VIG) and modularity (in VIG, VCG, and LCG). The dataset statistics are summarized in Table 8. Table 8: Dataset statistics across difficulty levels in G4SATBench. <table><tr><td rowspan=\"2\">Dataset</td><td colspan=\"6\">Easy Difficulty</td><td colspan=\"6\">Medium Difficulty</td><td colspan=\"6\">Hard Difficulty</td></tr><tr><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VIG)</td><td>Mod.(LCG)</td><td>#Variables</td><td>#Clauses</td><td>C.C.(VIG)</td><td>Mod.(VCG)</td><td>Mod.(LCG)</td></tr><tr><td>SR</td><td>25.00</td><td>148.35</td><td>0.98</td><td>0.00</td><td>0.25</td><td>0.33</td><td>118.36</td><td>646.54</td><td>0.62</td><td>0.06</td><td>0.31</td><td>0.37</td><td>299.64</td><td>1613.86</td><td>0.32</td><td>0.09</td><td>0.32</td><td>0.37</td></tr><tr><td>3-SAT</td><td>25.05</td><td>113.69</td><td>0.72</td><td>0.06</td><td>0.36</td><td>0.46</td><td>120.00</td><td>513.14</td><td>0.27</td><td>0.16</td><td>0.43</td><td>0.51</td><td>250.44</td><td>1067.34</td><td>0.14</td><td>0.17</td><td>0.45</td><td>0.52</td></tr><tr><td>CA</td><td>31.66</td><td>303.48</td><td>0.65</td><td>0.19</td><td>0.73</td><td>0.73</td><td>120.27</td><td>1661.07</td><td>0.54</td><td>0.38</td><td>0.80</td><td>0.80</td><td>299.68</td><td>4195.50</td><td>0.59</td><td>0.57</td><td>0.80</td><td>0.80</td></tr><tr><td>PS</td><td>25.41</td><td>176.68</td><td>0.98</td><td>0.00</td><td>0.27</td><td>0.32</td><td>118.75</td><td>822.78</td><td>0.86</td><td>0.05</td><td>0.35</td><td>0.37</td><td>249.61</td><td>1728.34</td><td>0.77</td><td>0.08</td><td>0.38</td><td>0.28</td></tr><tr><td>A-Clique</td><td>34.85</td><td>592.89</td><td>0.90</td><td>0.03</td><td>0.45</td><td>0.49</td><td>69.56</td><td>2220.05</td><td>0.91</td><td>0.03</td><td>0.48</td><td>0.49</td><td>112.87</td><td>5543.26</td><td>0.88</td><td>0.04</td><td>0.49</td><td>0.50</td></tr><tr><td>k-Domest</td><td>41.90</td><td>369.40</td><td>0.70</td><td>0.26</td><td>0.47</td><td>0.53</td><td>90.64</td><td>1736.22</td><td>0.70</td><td>0.21</td><td>0.49</td><td>0.51</td><td>137.31</td><td>4022.48</td><td>0.70</td><td>0.20</td><td>0.49</td><td>0.51</td></tr><tr><td>k-Verox</td><td>45.41</td><td>484.28</td><td>0.66</td><td>0.16</td><td>0.48</td><td>0.53</td><td>107.40</td><td>2634.14</td><td>0.69</td><td>0.16</td><td>0.49</td><td>0.51</td><td>190.24</td><td>8190.94</td><td>0.69</td><td>0.16</td><td>0.50</td><td>0.51</td></tr></table> ## B GNN Models Message-passing schemes on VCG*. Recall that VCG* incorporates two distinct edge types, G4SATBench employs different functions to execute heterogeneous message-passing in each direction of each edge type. Formally, we define a d-dimensional embedding for each variable and clause node, denoted by \\(h_l\\) and \\(h_c\\), respectively. These embeddings are initialized to two learnable vectors \\(h_v^0\\) and \\(h_c^0\\), depending on the node type. At the \\(k\\)-th iteration of message passing, these hidden representations are updated as follows: \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^+ \\left(h_v^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_v^- \\left(h_v^{(k-1)}\\right)\\right\\}\\right), h_c^{(k-1)}\\right), \\quad (7)\\] \\[h_v^{(k)} = \\mathrm{UPD}\\left(\\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^+ \\left(h_c^{(k-1)}\\right)\\right\\}\\right), \\mathrm{AGG}\\left(\\left\\{\\mathrm{MLP}_c^- \\left(h_c^{(k-1)}\\right)\\right\\}\\right), h_v^{(k-1)}\\right),\\] where \\(c^+\\) and \\(c^-\\) denote the sets of variable nodes that occur in the clause \\(c\\) with positive and negative polarity, respectively. Similarly, \\(v^+\\) and \\(v^-\\) denote the sets of clause nodes where variable \\(v\\) occurs in positive and negative form. \\(\\mathrm{MLP}_v^+\\), \\(\\mathrm{MLP}_v^-\\), \\(\\mathrm{MLP}_c^+\\), and \\(\\mathrm{MLP}_c^-\\) are four MLPs. \\(\\mathrm{UPD}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. GNN baselines. Table 9 summarizes the message-passing algorithms of the GNN models used in G4SATBench. We adopt heterogeneous versions of GCN (Kipf & Welling, 2017), GGNN (Li et al., 2016), and GIN (Xu et al., 2019) on both LCG* and VCG*, while maintaining the original Neuro SAT (Selsam et al., 2019) only on LCG*. ## C Benchmarking Evaluation ### C.1 Implementation Details In G4SATBench, we provide the ground truth of satisfiability and satisfying assignments by calling the state-of-the-art modern SAT solver Ca Di Ca L (Fleury & Heisinger, 2020) and generate the truth labels for unsat- core variables by invoking the proof checker DRAT-trim (Wetzler et al., 2014). All neural networks in our study are implemented using Py Torch (Paszke et al., 2019) and Py Torch Geometric (Fey & Lenssen, 2019). For all GNN models, we set the feature dimension \\(d\\) to 128 and the number of message passing iterations \\(T\\) to 32. The MLPs in the models consist of two hidden layers with the Re LU (Nair & Hinton, 2010) activation function. To select the optimal hyperparameters for each GNN baseline, we conduct a grid search over several settings. Specifically, we explore different learning rates from \\(\\{10^{-3}, 5 \\times 10^{-4}, 10^{-4}, 5 \\times 10^{-5}, 10^{-5}\\}\\), training epochs from \\(\\{50, 100, 200\\}\\), weight decay values from \\(\\{10^{-6}, 10^{-7}, 10^{-8}, 10^{-9}, 10^{-10}\\}\\), and gradient clipping norms from \\(\\{0.1, 0.5, 1\\}\\). We employ Adam (Kingma & Ba, 2015) as the optimizer and set the batch size to 128, 64, or 32 to fit within the maximum GPU memory (48G). For the parameters \\(\\tau\\) and \\(\\kappa\\) of the unsupervised loss in Equation 4 and Equation 5, we try the default settings (\\(\\tau = t^{-0.4}\\) and \\(\\kappa = 10\\), where \\(t\\) is the global step during training) as the original paper (Amizadeh et al., 2019a) as well as other values (\\(\\tau \\in \\{0.05, 0.1, 0.2, 0.5\\}\\), \\(\\kappa \\in \\{1, 2, 5\\}\\)) and empirically find \\(\\tau = 0.1\\), \\(\\kappa = 1\\) yield the best results. Furthermore,\n\nTable 9: Supported GNN models in G4SATBench. <table><tr><td>Graph</td><td>Method</td><td>Message-passing Algorithm</td><td>Notes</td></tr><tr><td rowspan=\"2\">Neuro SAT</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>h(c), s(c) = Layer Norm LSTM1</td><td>s, s1 are the hidden states which are initialized to zero vectors.</td></tr><tr><td>h(c), s(c) = Layer Norm LSTM2</td><td>h(c), s(c) = Layer Norm LSTM2</td><td></td></tr><tr><td rowspan=\"2\">LCG*</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and literal node l in LCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">GGNN</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GCN</td><td>h(c) = Linear1</td><td>h(c) = Linear1</td><td>d, d1 are the degrees of clause node c and variable node v in VCG respectively.</td></tr><tr><td>h(c) = Linear2</td><td>h(c) = Linear2</td><td></td></tr><tr><td rowspan=\"2\">VCG*</td><td>h(c) = GRU1</td><td>h(c) = GRU1</td><td></td></tr><tr><td>h(c) = GRU2</td><td>h(c) = GRU2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = MLP1</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = MLP2</td><td></td></tr><tr><td rowspan=\"2\">GIN</td><td>h(c) = MLP1</td><td>h(c) = GIN</td><td></td></tr><tr><td>h(c) = MLP2</td><td>h(c) = GIN</td><td></td></tr></table> it is important to note that we use three different random seeds to benchmark the performance of different GNN models and assess the generalization ability of Neuro SAT and GGNN using one seed for simplicity. ## C.2 Satisfiability Prediction Evaluation across different difficulty levels. The complete results of Neuro SAT and GGNN across different difficulty levels are presented in Figure 6. Consistent with the findings on the SR and 3- SAT datasets, both GNN models exhibit limited generalization ability to larger instances beyond their training data, while displaying relatively better performance on smaller instances. This observation suggests that training these models on more challenging instances could potentially enhance their generalization ability and improve their performance on larger instances. <center>Figure 6: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different message passing iterations. To investigate the impact of message-passing iterations on the performance of GNN models during training and testing, we conducted experiments with varying iteration values. Figure 7 presents the results of Neuro SAT and GGNN trained and evaluated with different message passing iterations. Remarkably, using a training iteration value of 32 consistently yielded the best performance for both models. Conversely, employing too small or too large iteration values during training resulted in decreased performance. Furthermore, the models trained with 32 iterations also demonstrated good generalization ability to testing iterations 16 and 64. These findings emphasize the critical importance of selecting an appropriate message-passing iteration to ensure optimal learning and reasoning within GNN models. <center>Figure 7: Classification accuracy of satisfiability across different message passing iterations \\(T\\) . The x-axis denotes testing iterations and the y-axis denotes training iterations. </center> ## C.3 Satisfying Assignment Prediction Evaluation with different training losses. Table 10 presents the complete results of each GNN baseline across three different training objectives. Like the results of Neuro SAT and GGNN, all other GNN models with unsupervised training outperform their supervised training counterparts. Table 10: Solving accuracy on identical distribution with different training losses. The top and bottom 7 rows represent the results for easy and medium datasets, respectively. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"3\">SR</td><td colspan=\"3\">3-SAT</td><td colspan=\"3\">CA</td><td colspan=\"3\">PS</td><td colspan=\"3\">k-Clique</td><td colspan=\"3\">k-Domest</td><td colspan=\"3\">k-Vercov</td></tr><tr><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td>SUP</td><td>UNS1</td><td>UNS2</td><td>SUP</td><td>UNS1</td><td>UNS2</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>88.47</td><td>82.30</td><td>79.79</td><td>78.39</td><td>80.23</td><td>80.59</td><td>0.27</td><td>82.17</td><td>89.34</td><td>39.18</td><td>89.23</td><td>88.79</td><td>66.30</td><td>88.34</td><td>63.43</td><td>69.61</td><td>96.74</td><td>98.85</td><td>85.15</td><td>99.36</td><td>99.73</td></tr><tr><td>GCN</td><td>83.74</td><td>73.09</td><td>77.02</td><td>70.34</td><td>74.79</td><td>75.31</td><td>0.17</td><td>75.30</td><td>82.41</td><td>39.66</td><td>82.75</td><td>84.89</td><td>63.85</td><td>82.60</td><td>86.17</td><td>59.29</td><td>97.50</td><td>97.55</td><td>76.83</td><td>99.16</td><td>99.28</td></tr><tr><td>GGNN</td><td>84.13</td><td>76.39</td><td>78.75</td><td>72.87</td><td>76.55</td><td>76.42</td><td>0.29</td><td>78.13</td><td>84.08</td><td>38.82</td><td>84.44</td><td>86.29</td><td>60.80</td><td>84.60</td><td>87.12</td><td>68.36</td><td>97.49</td><td>98.06</td><td>82.06</td><td>-</td><td>99.34</td></tr><tr><td>GIN</td><td>83.81</td><td>81.45</td><td>80.39</td><td>73.99</td><td>78.47</td><td>76.24</td><td>0.20</td><td>78.44</td><td>85.15</td><td>39.13</td><td>85.31</td><td>85.43</td><td>56.85</td><td>84.48</td><td>85.11</td><td>68.93</td><td>96.99</td><td>97.43</td><td>81.49</td><td>99.28</td><td>99.38</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>83.38</td><td>84.19</td><td>78.00</td><td>76.60</td><td>84.42</td><td>79.23</td><td>14.98</td><td>76.64</td><td>83.79</td><td>51.48</td><td>85.88</td><td>83.06</td><td>56.27</td><td>85.28</td><td>86.91</td><td>66.32</td><td>97.62</td><td>96.74</td><td>78.67</td><td>-</td><td>93.51</td></tr><tr><td>GGNN</td><td>86.30</td><td>87.16</td><td>81.00</td><td>77.96</td><td>88.97</td><td>79.32</td><td>15.11</td><td>76.32</td><td>83.12</td><td>47.67</td><td>86.85</td><td>87.17</td><td>66.86</td><td>86.31</td><td>87.48</td><td>66.42</td><td>-</td><td>98.42</td><td>82.61</td><td>-</td><td>99.52</td></tr><tr><td>GIN</td><td>84.61</td><td>89.56</td><td>83.27</td><td>79.23</td><td>87.65</td><td>81.72</td><td>17.81</td><td>83.28</td><td>86.03</td><td>48.92</td><td>91.21</td><td>85.65</td><td>60.67</td><td>86.12</td><td>88.09</td><td>67.67</td><td>-</td><td>81.01</td><td>99.38</td><td>99.41</td><td></td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>34.97</td><td>25.00</td><td>37.25</td><td>20.07</td><td>30.40</td><td>41.61</td><td>0.00</td><td>35.45</td><td>70.83</td><td>3.64</td><td>60.28</td><td>71.03</td><td>56.61</td><td>41.45</td><td>-</td><td>52.09</td><td>95.06</td><td>96.18</td><td>74.77</td><td>67.44</td><td>95.99</td></tr><tr><td>GCN</td><td>13.19</td><td>13.76</td><td>19.21</td><td>8.87</td><td>20.50</td><td>24.58</td><td>0.00</td><td>30.20</td><td>54.04</td><td>14.45</td><td>45.16</td><td>56.29</td><td>55.36</td><td>61.82</td><td>66.33</td><td>43.50</td><td>92.86</td><td>94.89</td><td>67.83</td><td>-</td><td>93.84</td></tr><tr><td>GGNN</td><td>14.15</td><td>16.55</td><td>21.18</td><td>7.96</td><td>22.84</td><td>25.68</td><td>0.00</td><td>28.12</td><td>50.66</td><td>2.33</td><td>44.89</td><td>57.96</td><td>52.35</td><td>54.29</td><td>68.91</td><td>49.07</td><td>-</td><td>92.26</td><td>69.21</td><td>66.37</td><td>94.30</td></tr><tr><td>GIN</td><td>15.36</td><td>18.60</td><td>22.17</td><td>9.66</td><td>21.38</td><td>24.93</td><td>0.00</td><td>35.76</td><td>57.81</td><td>2.02</td><td>43.43</td><td>57.62</td><td>53.07</td><td>44.60</td><td>66.32</td><td>44.39</td><td>93.3</td><td>93.82</td><td>70.59</td><td>55.59</td><td>95.69</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>20.59</td><td>9.21</td><td>22.44</td><td>12.48</td><td>17.00</td><td>29.53</td><td>0.44</td><td>39.04</td><td>48.99</td><td>2.29</td><td>35.99</td><td>55.46</td><td>46.09</td><td>25.90</td><td>68.62</td><td>46.96</td><td>-</td><td>92.68</td><td>69.15</td><td>-</td><td>96.46</td></tr><tr><td>GGNN</td><td>28.04</td><td>27.72</td><td>33.37</td><td>16.46</td><td>29.65</td><td>35.95</td><td>0.56</td><td>48.13</td><td>49.93</td><td>3.12</td><td>51.73</td><td>65.11</td><td>44.26</td><td>48.92</td><td>56.43</td><td>51.01</td><td>-</td><td>71.97</td><td>-</td><td>95.23</td></tr><tr><td>GIN</td><td>26.73</td><td>26.48</td><td>31.97</td><td>14.64</td><td>26.86</td><td>35.81</td><td>0.64</td><td>44.06</td><td>63.84</td><td>3.38</td><td>58.03</td><td>64.66</td><td>55.47</td><td>56.97</td><td>67.78</td><td>46.98</td><td>-</td><td>95.28</td><td>69.40</td><td>-</td><td>96.96</td></tr></table> Evaluation across different difficulty levels. The performance of Neuro SAT across different difficulty levels is shown in Figure 8. Notably, training on medium datasets yields superior generalization performance compared to training on easy datasets. This suggests that training on more challenging SAT instances with larger sizes can enhance the model's ability to generalize to a wider range of problem complexities. <center>Figure 8: Solving accuracy of Neuro SAT across different difficulty levels (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center>\n\nEvaluation with different datasets. Figure 9 illustrates the performance of Neuro SAT across different datasets. For easy datasets, we observe that Neuro SAT demonstrates a strong generalization ability to other datasets when trained on the SR, 3- SAT, CA, and PS datasets. However, when trained on the \\(k\\) - Clique, \\(k\\) - Domset, and \\(k\\) - Vercov datasets, which involve specific graph structures inherent to their combinatorial problems, Neuro SAT struggles to generalize effectively. This observation indicates that the GNN model may overfit to leverage specific graph features associated with these combinatorial datasets, without developing a generalized solving strategy that can be applied to other problem domains for satisfying assignment prediction. For medium datasets, Neuro SAT also faces challenges in generalization, as its performance is relatively limited. This can be attributed to the difficulty of these datasets, where finding satisfying assignments is much harder than easy datasets. <center>Figure 9: Solving accuracy of Neuro SAT across different datasets (with \\(\\mathrm{UNS}_2\\) as the training loss). The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation with different inference algorithms. Figure 10 illustrates the results of Neuro SAT using various decoding algorithms (with \\(\\mathrm{UNS}_2\\) as the training loss). Notably, all three decoding algorithms demonstrate similar performances across all datasets. This observation indicates that utilizing the standard readout after message passing is sufficient for predicting a satisfying assignment. Also, the GNN model has successfully learned to identify potential satisfying assignments within the latent space, which can be extracted by clustering the literal embeddings. <center>Figure 10: Solving accuracy of Neuro SAT with different inference algorithms. </center> ## Evaluation with unsatisfiable training in- Evaluation with unsatisfiable training instances. Following previous works (Amizadeh et al., 2019a;b; Ozolins et al., 2022), our evaluation of GNN models focuses solely on satisfiable instances. However, in practical scenarios, the satisfiability of instances may not be known before training. To address this gap, we explore the effectiveness of training Neuro SAT using the unsupervised loss \\(\\mathrm{UNS}_2\\) on noisy datasets that contain unsatisfiable instances. Table 11 presents the results of Neuro SAT when trained on such datasets, where \\(50\\%\\) of the instances are unsatisfiable. Interestingly, incorporating unsatisfiable instances for training does not significantly affect the performance of the GNN model. This finding highlights the potential utility of training GNN models using \\(\\mathrm{UNS}_2\\) loss on new datasets, irrespective of any prior knowledge regarding their satisfiability. Table 11: Solving accuracy of Neuro SAT when trained on noisy datasets. Values in parentheses indicate the performance difference compared to the model trained without unsatisfiable instances. The \\(k\\) -Clique dataset is excluded as Neuro SAT fails during training. <table><tr><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Domset</td><td>k-Vercov</td></tr><tr><td>78.84<br>(-0.95)</td><td>80.48<br>(-0.11)</td><td>87.01<br>(-2.33)</td><td>88.66<br>(-0.13)</td><td>98.00<br>(-0.85)</td><td>95.24<br>(-4.49)</td><td>37.21<br>(-0.04)</td><td>41.75<br>(+0.14)</td><td>76.49<br>(+5.64)</td><td>72.52<br>(+1.46)</td><td>94.93<br>(-1.25)</td><td>96.18<br>(+0.19)</td></tr></table> ## C.4 Unsat-core Variable Prediction Evaluation across different difficulty levels. The results across different difficulty levels are presented in Figure 11. Remarkably, both Neuro SAT and GGNN exhibit a strong generalization ability when trained on easy or medium datasets. This suggests that GNN models can effectively learn and generalize from the\n\ncharacteristics and patterns present in these datasets, enabling them to perform well on a wide range of problem complexities. <center>Figure 11: Classification accuracy of unsat-core variables across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Evaluation across different datasets. Figure 12 shows the generalization results across different datasets. Both Neuro SAT and GGNN demonstrate good generalization performance to datasets that are different from their training data, except for the CA dataset. This discrepancy can be attributed to the specific characteristics of the CA dataset, where the number of unsat- core variables is significantly smaller compared to the number of variables not in the unsat core. In contrast, other datasets have a different distribution, where the number of unsat- core variables is much larger. This variation in distribution presents a challenge for the models' generalization ability on the CA dataset. <center>Figure 12: Classification accuracy of unsat-core variables across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> ## D Advancing Evaluation ## D.1 Implementation details To create the augmented datasets, we leverage Ca Di Ca L (Fleury & Heisinger, 2020) to generate a DART proof (Wetzler et al., 2014) for each SAT instance, which tracks the clause learning procedure and records all the learned clauses during the solving process. These learned clauses are then added to each instance, with a maximum limit of 1,000 clauses. For experiments on augmented datasets, we keep all training settings identical to those used for the original datasets. For contrastive pretraining experiments, we treat each original formula and its augmented counterpart as a positive pair and all other instances in a mini- batch as negative pairs. We use an MLP projection to map the graph embedding \\(z_{i}\\) of each formula to \\(m_{i}\\) and employ the Sim CLR's contrastive loss (Chen et al., 2020), where the loss function for a positive pair of examples \\((i,j)\\) in a mini- batch of size \\(2N\\) is defined as: \\[\\mathcal{L}_{i,j} = -\\log \\frac{\\exp(\\sin(m_{i},m_{j}) / \\tau)}{\\sum_{k = 1}^{2N}\\mathbb{1}_{[k\\neq i]}\\exp(\\sin(m_{i},m_{k}) / \\tau)}. \\quad (8)\\]\n\npredicts marginal distributions of all satisfying solutions to solve the SAT problem. Moreover, most previous research has experimented on different datasets that vary in a range of settings (e.g., data distribution, instance size, and dataset size), which leads to a lack of unified and standardized datasets for training and evaluation. Additionally, some work (Amizadeh et al., 2019b; Shi et al., 2023; Yan et al., 2023) has noted the difficulty of re- implementing prior approaches as baselines, rendering it arduous to draw consistent conclusions about the performance of peer methods. All of these issues impede the development of GNN- based solvers for SAT solving. To systematically quantify the progress in this field and facilitate rapid, reproducible, and generalizable research, we propose G4SATBench, the first comprehensive benchmark study for SAT solving with GNNs. G4SATBench is characterized as follows: - First, we construct a large and diverse collection of SAT datasets that includes instances from distinct sources and difficulty levels. Specifically, our benchmark consists of 7 different datasets from 3 benchmark families, including random instances, pseudo-industrial instances, and combinatorial problems. It not only covers a wide range of prior datasets but also introduces 3 levels of difficulty for each dataset to enable fine-grained analyses. - Second, we re-implement various GNN-based SAT solvers with unified interfaces and configuration settings, establishing a general evaluation protocol for fair and comprehensive comparisons. Our framework allows for evaluating different GNN models in SAT solving with various prediction tasks, training objectives, and inference algorithms, encompassing the diverse learning frameworks employed in the existing literature. - Third, we present baseline results and conduct thorough analyses of GNN-based SAT solvers, providing a detailed reference of prior work and laying a solid foundation for future research. Our evaluations assess the performances of different choices of GNN models (e.g., graph constructions, message-passing schemes) with particular attention to some critical parameters (e.g., message-passing iterations), as well as their generalization ability across different distributions. - Lastly, we conduct a series of in-depth experiments to explore the learning abilities of GNN-based SAT solvers. Specifically, we compare the training and solving processes of GNNs with the heuristics employed in both CDCL and LS-based SAT solvers. Our experimental results reveal that GNNs tend to develop a solving heuristic similar to greedy local search to find a satisfying assignment but fail to effectively learn the CDCL heuristic in the latent space. We believe that G4SATBench will help the research community to make significant strides in understanding the capabilities and limitations of GNNs for solving SAT and facilitate further endeavors in this domain. ## 2 Related Work SAT solving with GNNs. Existing GNN- based SAT solvers can be broadly categorized into two branches (Holden et al., 2021; Guo et al., 2022): standalone neural solvers and neural- guided solvers. Standalone neural solvers utilize GNNs to solve SAT instances directly. For example, a stream of research (B\u00fcnz & Lamm, 2017; Selsam et al., 2019; Jaszczur et al., 2020; Cameron et al., 2020; Shi et al., 2023) focuses on predicting the satisfiability of a given formula, while several alternative approaches (Amizadeh et al., 2019a;b; Ozolins et al., 2022; Li et al., 2023; Yan et al., 2023) aim to construct a satisfying assignment. Neural- guided solvers, on the other hand, integrate GNNs with modern SAT solvers, trying to improve their search heuristics with the prediction of GNNs. These methods typically train GNN models using supervised learning on some tasks such as unsat- core variable prediction (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021), satisfying assignment prediction (Zhang et al., 2020), glue variable prediction (Han, 2020), and assignment marginal prediction (Li & Si, 2022), or through reinforcement learning (Yolcu & P\u00f3czos, 2019; Kurin et al., 2020) by modeling the entire search procedure as a Markov decision process. Despite the rich literature on SAT solving with GNNs, there is no benchmark study to evaluate and compare the performance of these GNN models. We hope the proposed G4SATBench would address this gap.\n\nHere, \\(\\mathbb{1}_{[k \\neq i]}\\) is an indicator function that evaluates to 1 if \\(k \\neq i\\) , \\(\\tau\\) is a temperature parameter, and \\(\\text{sim}(\\cdot , \\cdot)\\) is the similarity function defined as \\(\\text{sim}(m_i, m_j) = m_i^\\top m_j / \\|m_i\\| \\|m_j\\|\\) . The final loss is the average over all positive pairs. In our experiments, we set the temperature parameter to 0.5 and utilize a learning rate of \\(10^{- 4}\\) with a weight decay of \\(10^{- 8}\\) . The pretraining process is performed for a total of 100 epochs. Once the pretraining is completed, we keep the GNN model and remove the projection head for downstream tasks. For experiments involving random initialization, we utilize Kaiming Initialization (He et al., 2015) to initialize all literal/variable and clause embeddings during both training and testing. For the predicted assignments, we utilize 2- clustering decoding to construct two possible assignment predictions for Neuro SAT\\* at each iteration. When calculating the number of flipped variables and unsatisfiable clauses for Neuro SAT\\*, we only consider the better assignment prediction of the two at each iteration, which is the one that satisfies more clauses. All other experimental settings remain the same as in the benchmarking evaluation. ## D.2 Comparisons with State-of-the-art SAT Solvers We compare Neuro SAT with two advanced CDCL and LS solvers, Ca Di Ca L Fleury & Heisinger (2020) and Sparrow (Balint & Fr\u00f6hlich, 2010). To enable a fair comparison, we first configure Sparrow to generate the same number of assignments as Neuro SAT by setting its maximum flip number to 32, allowing for an apples- to- apples comparison of both solvers' accuracy and execution time. Subsequently, we allow Sparrow and Ca Di Ca L to run without constraints to solve the satisfiable instances in G4SATBench. Considering that Neuro SAT processes a batch of problems in parallel on GPUs, we calculate its per- instance runtime by dividing the total execution time by the number of testing instances. The results, summarized in Table 12, indicate that GNN- based heuristics could outperform modern local search solvers like Sparrow, generating more satisfying assignments extremely fast when constrained to output a limited number of solutions. However, once such a constraint is lifted, both Sparrow and Ca Di Ca L can traverse the solution space efficiently and solve all satisfiable instances in G4SATBench, while GNN models like Neuro SAT may find it challenging due to their limited exploration capacity as evidenced in Figure 5a. Nevertheless, it's crucial to recognize that while GNN models are hard to compete with Ca Di Ca L and Sparrow, their assignment predictions could still serve as good initializations in these solvers, potentially leading to better performance (Zhang et al., 2020; Li & Si, 2022). Table 12: Results of Neuro SAT, Sparrow, and Ca Di Ca L. The top 2 rows represent the solving accuracy (%), and the bottom 4 rows represent the running time (second) per instance. Sparrow\\\\* refers to Sparrow limited to a maximum of 32 flips. <table><tr><td rowspan=\"2\">Method</td><td colspan=\"7\">Easy Datasets</td><td colspan=\"7\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td>Neuro SAT</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.461</td><td>70.83</td><td>71.03</td><td>32.48</td><td>96.18</td><td>95.99</td></tr><tr><td>Sparrow*</td><td>56.03</td><td>52.09</td><td>85.48</td><td>77.25</td><td>53.68</td><td>37.15</td><td>31.61</td><td>1.64</td><td>1.85</td><td>12.68</td><td>10.72</td><td>12.99</td><td>1.27</td><td>0.53</td></tr><tr><td>Neuro SAT</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.002</td><td>0.003</td><td>0.002</td><td>0.003</td><td>0.008</td><td>0.006</td><td>0.009</td><td>0.010</td><td>0.009</td><td>0.006</td><td>0.007</td></tr><tr><td>Sparrow*</td><td>0.005</td><td>0.005</td><td>0.006</td><td>0.006</td><td>0.005</td><td>0.005</td><td>0.005</td><td>0.008</td><td>0.007</td><td>0.006</td><td>0.006</td><td>0.006</td><td>0.007</td><td>0.006</td></tr><tr><td>Sparrow</td><td>0.007</td><td>0.007</td><td>0.008</td><td>0.008</td><td>0.007</td><td>0.009</td><td>0.009</td><td>0.013</td><td>0.013</td><td>0.010</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td></tr><tr><td>Ca Di Ca L</td><td>0.013</td><td>0.013</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.012</td><td>0.011</td><td>0.014</td><td>0.043</td><td>0.016</td><td>0.018</td><td>0.015</td><td>0.013</td><td>0.012</td></tr></table>\n\nSAT datasets. Several established SAT benchmarks, including the prestigious SATLIB (Hoos & St\u00fctzle, 2000) and the SAT Competitions over the years, have provided a variety of practical instances to assess the performance of modern SAT solvers. Regrettably, these datasets are not particularly amenable for GNNs to learn from, given their relatively modest scale (less than 100 instances for a specific domain) or overly extensive instances (exceeding 10 million variables and clauses). To address this issue, researchers have turned to synthetic SAT instance generators (Gir\u00e1ldez- Cruz & Levy, 2015; 2017; Lauria et al., 2017; Selsam et al., 2019), which allow for the creation of a flexible number of instances with customizable settings. However, most of the existing datasets generated from these sources are limited to a few domains (less than 3 generators), small in size (less than 10k instances), or easy in difficulty (less than 40 variables within an instance), and there is no standardized dataset for evaluation. In G4SATBench, we include a variety of synthetic generators with carefully selected configurations, aiming to construct a broad collection of SAT datasets that are highly conducive for training and evaluating GNNs. ## 3 Preliminaries The SAT problem. In propositional logic, a Boolean formula is constructed from Boolean variables and logical operators such as conjunctions \\((\\wedge)\\) , disjunctions \\((\\vee)\\) , and negations \\((\\neg)\\) . It is typical to represent Boolean formulas in conjunctive normal form (CNF), expressed as a conjunction of clauses, where each clause is a disjunction of literals, which can be either a variable or its negation. Given a CNF formula, the SAT problem is to determine if there exists an assignment of boolean values to its variables such that the formula evaluates to true. If this is the case, the formula is called satisfiable; otherwise, it is unsatisfiable. For a satisfiable instance, one is expected to construct a satisfying assignment to prove its satisfiability. On the other hand, for an unsatisfiable formula, one can find a minimal subset of clauses whose conjunction is still unsatisfiable. Such a set of clauses is termed the unsat core, and variables in the unsat core are referred to as unsat- core variables. Graph representations of CNF formulas. Traditionally, a CNF formula can be represented using 4 types of graphs (Biere et al., 2009): Literal- Clause Graph (LCG), Variable- Clause Graph (VCG), Literal- Incidence Graph (LIG), and Variable- Incidence Graph (VIG). The LCG is a bipartite graph with literal and clause nodes connected by edges indicating the presence of a literal in a clause. The VCG is formed by merging the positive and negative literals of the same variables in LCG. The LIG, on the other hand, only consists of literal nodes, with edges indicating co- occurrence in a clause. Lastly, the VIG is derived from LIG using the same merging operation as VCG. ## 4 G4SATBench: A Benchmark Study on GNNs for SAT Solving The goal of G4SATBench is to establish a general framework that enables comprehensive comparisons and evaluations of various GNN- based SAT solvers. In this section, we will delve into the details of G4SATBench, including its datasets, GNN models, prediction tasks, as well as training and testing methodologies. The overview of the G4SATBench framework is shown in Figure 1. ### 4.1 Datasets G4SATBench is built on a diverse set of synthetic CNF generators. It currently consists of 7 datasets sourced from 3 distinct domain areas: random problems, pseudo- industrial problems, and combinatorial problems. Specifically, we utilize the SR generator in Neuro SAT (Selsam et al., 2019) and the 3- SAT generator in CNFGen (Lauria et al., 2017) to produce random CNF formulas. For pseudo- industrial problems, we employ the Community Attachment (CA) model (Gir\u00e1ldez- Cruz & Levy, 2015) and the Popularity- Similarity (PS) model (Gir\u00e1ldez- Cruz & Levy, 2017), which generate synthetic instances that exhibit similar statistical features, such as the community and the locality, to those observed in real- world industrial SAT instances. For combinatorics, we resort to 3 synthetic generators in CNFGen (Lauria et al., 2017) to create SAT instances derived from the translation of \\(k\\) - Clique, \\(k\\) - Dominating Set, and \\(k\\) - Vertex Cover problems.\n\n<center>Figure 1: Framework overview of G4SATBench. </center> In addition to the diversity of datasets, G4SATBench offers distinct difficulty levels for all datasets to enable fine- grained analyses. These levels include easy, medium, and hard, with the latter representing more complex problems with increased instance sizes. For example, the easy SR dataset contains instances with 10 to 40 variables, the medium SR dataset contains formulas with 40 to 200 variables, and the hard SR dataset consists of formulas with variables ranging from 200 to 400. For each easy and medium dataset, we generate 80k pairs of satisfiable and unsatisfiable instances for training, 10k pairs for validation, and 10k pairs for testing. For each hard dataset, we produce 10k testing pairs. It is also worth noting that the parameters for our synthetic generators are meticulously selected to avoid generating trivial cases. For instance, we produce random 3- SAT formulas at the phase- transition region where the relationship between the number of clauses \\((m)\\) and variables \\((n)\\) is \\(m = 4.258n + 58.26n^{- 2 / 3}\\) (Crawford & Auton, 1996), and utilize the \\(v\\) vertex Erd\u0151s- R\u00e9nyi graph with an edge probability of \\(p = \\binom{v}{k}^{- 1 / \\binom{v}{2}}\\) to generate \\(k\\) - Clique problems, making the expected number of \\(k\\) - Cliques in a graph equals 1 (Bollob\u00e1s & Erd\u0151s, 1976). To provide a detailed characterization of our generated datasets, we compute several statistics of the SAT instances across difficulty levels in G4SATBench. Please refer to Appendix A for more information about the datasets. ### 4.2 GNN Baselines Graph constructions. It is important to note that traditional graph representations of a CNF formula often lack the requisite details for optimally constructing GNNs. Specifically, the LIG and VIG exclude clause- specific information, while the LCG and VCG fail to differentiate between positive and negative literals of the same variable. To address these limitations, existing approaches typically build GNN models on the refined versions of the LCG and VCG encodings. In the LCG, a new type of edge is added between each literal and its negation, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. <center>Figure 2: LCG\\* and VCG\\* of the CNF formula \\((x_{1} \\vee \\neg x_{2}) \\wedge (x_{1} \\vee x_{3}) \\wedge (\\neg x_{1} \\vee x_{2} \\vee x_{3})\\) . </center> tion, while the VCG is modified by using two types of edges to indicate the polarities of variables within a clause. These modified encodings are termed the LCG\\* and VCG\\* respectively, and an example of them is shown in Figure 2. It is also worth noting alternative graph encodings like the And- Inverter- Graph (AIG), can be applied for SAT instances that are not in CNF. However, such representations are specialized to specific applications (like Circuit SAT) and are not designed for general purposes. Given this specialization, we choose to keep them outside the scope of the current G4SATBench. Message- passing schemes. G4SATBench enables performing various heterogeneous message- passage algorithms between neighboring nodes on the LCG\\* or VCG\\* encodings of a CNF formula. For the sake of illustration, we will take GNN models on the LCG\\* as an example. We first define a \\(d\\) - dimensional embedding for every literal node and clause node, denoted by \\(h_{l}\\) and \\(h_{c}\\) respectively. Initially, all these embeddings are assigned to two learnable vectors \\(h_{l}^{0}\\) and \\(h_{c}^{0}\\) , depending on their node types. At the \\(k\\) - th iteration of\n\nmessage passing, these hidden representations are updated as: \\[\\begin{array}{r l} & {h_{c}^{(k)} = \\mathrm{UP D}\\left(\\underset {l\\in \\mathcal{N}(c)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{l}^{(k - 1)}\\right)\\right\\} \\right),h_{c}^{(k - 1)}\\right),}\\\\ & {h_{l}^{(k)} = \\mathrm{UP D}\\left(\\underset {c\\in \\mathcal{N}(l)}{\\mathrm{A G G}}\\left(\\left\\{\\mathrm{MLP}\\left(h_{c}^{(k - 1)}\\right)\\right\\} \\right),h_{-l}^{(k - 1)},h_{l}^{(k - 1)}\\right),} \\end{array} \\quad (1)\\] where \\(\\mathcal{N}(\\cdot)\\) denotes the set of neighbor nodes, MLP is the multi- layer perception, \\(\\mathrm{UP D}(\\cdot)\\) is the update function, and \\(\\mathrm{AGG}(\\cdot)\\) is the aggregation function. Most GNN models on \\(\\mathrm{LCG}^{*}\\) use Equation 1 with different choices of the update function and aggregation function. For instance, Neuro SAT employs Layer Norm L- STM (Ba et al., 2016) as the update function and summation as the aggregation function. In G4SATBench, we provide a diverse range of GNN models, including Neuro SAT (Selsam et al., 2019), Graph Convolutional Network (GCN) (Kipf & Welling, 2017), Gated Graph Neural Network (GGNN) (Li et al., 2016), and Graph Isomorphism Network (GIN) (Xu et al., 2019), on the both \\(\\mathrm{LCG}^{*}\\) and \\(\\mathrm{VCG}^{*}\\) . More details of these GNN models are included in Appendix B. ### 4.3 Supported Tasks, Training and Testing Settings Prediction tasks. In G4SATBench, we support three essential prediction tasks for SAT solving: satisfiability prediction, satisfying assignment prediction, and unsat- core variable prediction. These tasks are widely used in both standalone neural solvers and neural- guided solvers. Technically, we model satisfiability prediction as a binary graph classification task, where \\(1 / 0\\) denotes the given SAT instance \\(\\phi\\) is satisfiable/unsatisfiable. Here, we take GNN models on the \\(\\mathrm{LCG}^{*}\\) as an example. After \\(T\\) message passing iterations, we obtain the graph embedding by applying mean pooling on all literal embeddings, and then predict the satisfiability using an MLP followed by the sigmoid function \\(\\sigma\\) : \\[y_{\\phi} = \\sigma \\left(\\mathrm{MLP}\\left(\\mathrm{MEAN}\\left(\\{h_{l}^{(T)},l\\in \\phi \\}\\right)\\right)\\right). \\quad (2)\\] For satisfying assignment prediction and unsat- core variable prediction, we formulate them as binary node classification tasks, predicting the label for each variable in the given CNF formula \\(\\phi\\) . In the case of GNNs on the \\(\\mathrm{LCG}^{*}\\) , we concatenate the embeddings of each pair of literals \\(h_{l}\\) and \\(h_{- l}\\) to construct the variable embedding, and then readout using an MLP and the sigmoid function \\(\\sigma\\) : \\[y_{v} = \\sigma \\left(\\mathrm{MLP}\\left(\\left[h_{l}^{(T)},h_{-l}^{(T)}\\right]\\right)\\right). \\quad (3)\\] Training objectives. To train GNN models on the aforementioned tasks, one common approach is to minimize the binary cross- entropy loss between the predictions and the ground truth labels. In addition to supervised learning, G4SATBench supports two unsupervised training paradigms for satisfying assignment prediction (Amizadeh et al., 2019a; Ozolins et al., 2022). The first approach aims to differentiate and maximize the satisfiability value of a CNF formula (Amizadeh et al., 2019a). It replaces the \\(\\neg\\) operator with the function \\(N(x_{i}) = 1 - x_{i}\\) and uses smooth max and min functions to replace the \\(\\vee\\) and \\(\\wedge\\) operators. The smooth max and min functions are defined as follows: \\[S_{m a x}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{x_{i} / \\tau}},\\quad S_{m i n}(x_{1},x_{2},\\ldots ,x_{d}) = \\frac{\\sum_{i = 1}^{d}x_{i}\\cdot e^{-x_{i} / \\tau}}{\\sum_{i = 1}^{d}e^{-x_{i} / \\tau}}, \\quad (4)\\] where \\(\\tau \\geq 0\\) is the temperature parameter. Given a predicted assignment \\(x\\) , we apply the smoothing logical operators and substitute variables in a formula \\(\\phi\\) with the corresponding values from \\(x\\) to calculate its satisfiability value \\(S(x)\\) . Then we can minimize the following loss function: \\[\\mathcal{L}_{\\phi}(x) = \\frac{(1 - S(x))^{\\kappa}}{(1 - S(x))^{\\kappa} + S(x)^{\\kappa}}. \\quad (5)\\] The second unsupervised loss is defined as follows (Ozolins et al., 2022): \\[V_{c}(x) = 1 - \\prod_{i\\in c^{+}}(1 - x_{i})\\prod_{i\\in c^{-}}x_{i},\\quad \\mathcal{L}_{\\phi}(x) = -\\log \\Bigl (\\prod_{c\\in \\phi}V_{c}(x)\\Bigr) = -\\sum_{c\\in \\phi}\\log \\bigl (V_{c}(x)\\bigr), \\quad (6)\\]\n\nwhere \\(c^{+}\\) and \\(c^{- }\\) are the sets of variables that occur in the clause \\(c\\) in positive and negative form respectively. Note that these two losses reach the minimum only when the prediction \\(x\\) is a satisfying assignment, thus minimizing such losses could help to construct a possible satisfying assignment. Inference algorithms. Beyond the standard readout process like training, G4SATBench offers two alternative inference algorithms for satisfying assignment prediction (Selsam et al., 2019; Amizadeh et al., 2019b). The first method performs 2- clustering on the literal embeddings to obtain two centers \\(\\Delta_{1}\\) and \\(\\Delta_{2}\\) and then partitions the positive and negative literals of each variable into distinct groups based on the predicate \\(||x_{i} - \\Delta_{1}||^{2} + ||\\neg x_{i} - \\Delta_{2}||^{2}< ||x_{i} - \\Delta_{2}||^{2} + ||\\neg x_{i} - \\Delta_{1}||^{2}\\) (Selsam et al., 2019). This allows the construction of two possible assignments by mapping one group of literals to true. The second approach is to employ the readout function at each iteration of message passing, resulting in multiple assignment predictions for a given instance (Amizadeh et al., 2019b). Evaluation metrics. For satisfiability prediction and unsat- core variable prediction, we report the classification accuracy of each GNN model in G4SATBench. For satisfying assignment prediction, we report the solving accuracy of the predicted assignments. If multiple assignments are predicted for a SAT instance, the instance is considered solved if any of the predictions satisfy the formula. ## 5 Benchmarking Evaluation on G4SATBench In this section, we present the benchmarking results of G4SATBench. To ensure a fair comparison, we conduct a grid search to tune the hyperparameters of each GNN baseline. The best checkpoint for each GNN model is selected based on its performance on the validation set. To mitigate the impact of randomness, we use 3 different random seeds to repeat the experiment in each setting and report the average performance. Each experiment is performed on a single RTX8000 GPU and 16 AMD EPYC 7502 CPU cores, and the total time cost is approximately 8,000 GPU hours. For detailed experimental setup and hyperparameters, please refer to Appendix C.1. ### 5.1 Satisfiability Prediction Evaluation on the same distribution. Table 1 shows the benchmarking results of each GNN baseline when trained and evaluated on datasets possessing identical distributions. All GNN models exhibit strong performance across most easy and medium datasets, except for the medium SR dataset. This difficulty can be attributed to the inherent characteristic of this dataset, which includes satisfiable and unsatisfiable pairs of medium- sized instances distinguished by just a single differing literal. Such a subtle difference presents a substantial challenge for GNN models in satisfiability classification. Among all GNN models, the different graph constructions do not seem to have a significant impact on the results, and Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) achieve the best overall performance. Table 1: Classification accuracy of satisfiability on identical distribution. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Vercov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>96.00</td><td>96.33</td><td>98.83</td><td>96.59</td><td>97.92</td><td>99.77</td><td>99.99</td><td>78.02</td><td>84.90</td><td>99.57</td><td>96.81</td><td>89.39</td><td>99.67</td></tr><tr><td>GCN</td><td>94.43</td><td>94.47</td><td>98.79</td><td>97.53</td><td>98.24</td><td>99.59</td><td>99.98</td><td>69.39</td><td>82.67</td><td>99.53</td><td>96.16</td><td>85.72</td><td>99.16</td></tr><tr><td>GGNN</td><td>96.36</td><td>95.70</td><td>98.81</td><td>97.47</td><td>98.80</td><td>99.77</td><td>99.97</td><td>71.44</td><td>83.45</td><td>99.50</td><td>96.21</td><td>81.20</td><td>99.69</td></tr><tr><td>GIN</td><td>95.78</td><td>95.37</td><td>98.14</td><td>96.98</td><td>97.60</td><td>99.71</td><td>99.97</td><td>70.54</td><td>82.80</td><td>99.49</td><td>95.80</td><td>83.87</td><td>99.61</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>93.19</td><td>94.92</td><td>97.82</td><td>95.79</td><td>98.72</td><td>99.54</td><td>99.99</td><td>66.35</td><td>83.75</td><td>99.49</td><td>95.48</td><td>82.99</td><td>99.42</td></tr><tr><td>GGNN</td><td>96.75</td><td>96.25</td><td>98.77</td><td>96.44</td><td>98.88</td><td>99.68</td><td>99.98</td><td>77.12</td><td>85.11</td><td>99.57</td><td>96.48</td><td>83.63</td><td>99.62</td></tr><tr><td>GIN</td><td>96.04</td><td>95.71</td><td>98.47</td><td>96.95</td><td>97.33</td><td>99.59</td><td>99.98</td><td>73.56</td><td>85.26</td><td>99.49</td><td>96.55</td><td>89.41</td><td>99.38</td></tr></table> Evaluation across different distributions. To assess the generalization ability of GNN models, we evaluate the performance of Neuro SAT (on LCG\\*) and GGNN (on VCG\\*) across different datasets and difficulty levels. As shown in Figure 3 and Figure 4, Neuro SAT and GGNN struggle to generalize effectively to datasets distinct from their training data in most cases. However, when trained on the SR dataset, they exhibit better generalization performance across different datasets. Furthermore, while both GNN models\n\ndemonstrate limited generalization to larger formulas beyond their training data, they perform relatively better on smaller instances. These observations suggest that the generalization performance of GNN models for satisfiability prediction is influenced by the distinct nature and complexity of its training data. Training on more challenging instances could potentially enhance their generalization ability. <center>Figure 3: Classification accuracy of satisfiability across different datasets. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> <center>Figure 4: Classification accuracy of satisfiability across different difficulty levels. The x-axis denotes testing datasets and the y-axis denotes training datasets. </center> Due to the limited space, Figure 4 exclusively displays the performance of Neuro SAT and GGNN on the SR and 3- SAT datasets. Comprehensive results on the other five datasets, as well as the experimental results on different massage passing iterations, are provided in Appendix C.2. ### 5.2 Satisfying Assignment Prediction Evaluation with different training losses. Table 2 presents the results of Neuro SAT (on \\(\\mathrm{LCG}^{*}\\) ) and GGNN (on \\(\\mathrm{VCG}^{*}\\) ) across three different training objectives. The results of other GNN models are listed in Table 10 in Appendix C.3. Interestingly, the unsupervised training methods outperform the supervised learning approach across the majority of datasets. We hypothesize that this is due to the presence of multiple satisfying assignments in most satisfiable instances. Supervised training tends to bias GNN models towards learning a specific satisfying solution, thereby neglecting the exploration of other feasible ones. This bias may compromise the models' ability to generalize effectively. Such limitations become increasingly apparent when the space of satisfying solutions is much larger, as seen in the medium CA and PS datasets. Additionally, it is noteworthy that employing \\(\\mathrm{UNS}_1\\) as the loss function can result in instability during the training of some GNN models, leading to a failure to converge in some cases. Conversely, using \\(\\mathrm{UNS}_2\\) loss demonstrates strong and stable performance across all datasets. In addition to evaluating the performance of GNN models under various training loss functions, we extend our analysis to explore how these models perform across different data distributions and under various inference algorithms. Furthermore, we assess the robustness of these GNN models when trained on noisy datasets that include unsatisfiable instances in an unsupervised fashion. For detailed results of these evaluations across different GNN baselines, please refer to Appendix C.3.\n\nTable 2: Solving accuracy on identical distribution with different training losses. SUP denotes the supervised loss, \\(\\mathrm{UNS}_1\\) and \\(\\mathrm{UNS}_2\\) correspond to the unsupervised losses defined in Equation 5 and Equation 6, respectively. The symbol \"-\" indicates that some seeds failed during training. Note that only satisfiable instances are evaluated in this experiment. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td rowspan=\"2\">Loss</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td></tr><tr><td rowspan=\"3\">LCG*</td><td rowspan=\"3\">Neuro SAT</td><td>SUP</td><td>88.47</td><td>78.39</td><td>0.27</td><td>39.18</td><td>66.30</td><td>69.61</td><td>85.15</td><td>34.97</td><td>20.07</td><td>0.00</td><td>3.64</td><td>56.61</td><td>52.09</td></tr><tr><td>UNS1</td><td>82.30</td><td>80.23</td><td>82.17</td><td>89.23</td><td>88.34</td><td>96.74</td><td>99.36</td><td>25.00</td><td>30.40</td><td>35.45</td><td>60.28</td><td>41.45</td><td>95.06</td></tr><tr><td>UNS2</td><td>79.79</td><td>80.59</td><td>89.34</td><td>88.79</td><td>63.43</td><td>98.85</td><td>99.73</td><td>37.25</td><td>41.61</td><td>70.83</td><td>71.03</td><td>-</td><td>96.18</td><td>95.99</td></tr><tr><td rowspan=\"3\">VCG*</td><td rowspan=\"3\">GGNN</td><td>SUP</td><td>84.13</td><td>72.87</td><td>0.29</td><td>38.82</td><td>60.80</td><td>68.36</td><td>82.06</td><td>14.15</td><td>7.96</td><td>0.00</td><td>2.33</td><td>52.35</td><td>49.07</td></tr><tr><td>UNS1</td><td>76.39</td><td>76.55</td><td>78.13</td><td>84.44</td><td>84.60</td><td>97.49</td><td>-</td><td>16.55</td><td>22.84</td><td>28.12</td><td>44.89</td><td>54.29</td><td>-</td></tr><tr><td>UNS2</td><td>78.75</td><td>76.42</td><td>84.08</td><td>86.29</td><td>87.12</td><td>98.06</td><td>99.34</td><td>21.18</td><td>25.68</td><td>50.66</td><td>57.96</td><td>68.91</td><td>92.26</td><td>94.30</td></tr></table> ### 5.3 Unsat-core Variable Prediction Evaluation on the same distribution. The benchmarking results presented in Table 3 exhibit the superior performance of all GNN models on both easy and medium datasets, with Neuro SAT consistently achieving the best results across most datasets. It is important to note that the primary objective of predicting unsat- core variables is not to solve SAT problems directly but to provide valuable guidance for enhancing the backtracking search process. As such, even imperfect predictions - for instance, those with a classification accuracy of \\(90\\%\\) - have been demonstrated to be sufficiently effective in improving the search heuristics employed by modern CDCL- based SAT solvers, as indicated by previous studies (Selsam & Bj\u00f8rner, 2019; Wang et al., 2021). Table 3: Classification accuracy of unsat-core variables on identical distribution. Only unsatisfiable instances are evaluated. <table><tr><td rowspan=\"2\">Graph</td><td rowspan=\"2\">Method</td><td colspan=\"6\">Easy Datasets</td><td colspan=\"6\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>SR</td><td>3-SAT</td><td>CA</td><td>PS</td><td>k-Clique</td><td>k-Domest</td><td>k-Verov</td></tr><tr><td rowspan=\"4\">LCG*</td><td>Neuro SAT</td><td>90.76</td><td>94.43</td><td>83.69</td><td>86.20</td><td>99.93</td><td>95.80</td><td>94.47</td><td>90.07</td><td>99.65</td><td>85.73</td><td>88.53</td><td>99.97</td><td>97.90</td></tr><tr><td>GCN</td><td>89.17</td><td>94.35</td><td>82.89</td><td>85.32</td><td>99.93</td><td>95.74</td><td>94.43</td><td>88.11</td><td>99.65</td><td>85.71</td><td>87.70</td><td>99.96</td><td>97.89</td></tr><tr><td>GGNN</td><td>90.02</td><td>94.38</td><td>83.59</td><td>86.03</td><td>99.93</td><td>95.79</td><td>94.46</td><td>89.05</td><td>99.65</td><td>85.69</td><td>87.95</td><td>99.96</td><td>97.89</td></tr><tr><td>GIN</td><td>89.29</td><td>94.33</td><td>83.71</td><td>85.97</td><td>99.93</td><td>95.81</td><td>94.47</td><td>88.85</td><td>99.65</td><td>85.71</td><td>87.92</td><td>99.96</td><td>97.89</td></tr><tr><td rowspan=\"3\">VCG*</td><td>GCN</td><td>88.57</td><td>94.34</td><td>83.17</td><td>85.27</td><td>99.93</td><td>95.79</td><td>94.46</td><td>88.17</td><td>99.65</td><td>85.70</td><td>87.37</td><td>99.96</td><td>97.90</td></tr><tr><td>GGNN</td><td>89.57</td><td>94.37</td><td>83.50</td><td>85.84</td><td>99.93</td><td>95.81</td><td>94.49</td><td>88.84</td><td>99.65</td><td>85.68</td><td>88.03</td><td>99.98</td><td>97.90</td></tr><tr><td>GIN</td><td>89.50</td><td>94.35</td><td>83.23</td><td>85.69</td><td>99.93</td><td>95.79</td><td>94.47</td><td>89.51</td><td>99.65</td><td>85.72</td><td>88.13</td><td>99.96</td><td>97.89</td></tr></table> We also conduct experiments to evaluate the generalization ability of GNN models on unsat- core variable prediction. Please see appendix C.4 for details. ## 6 Advancing Evaluation on G4SATBench To gain deeper insights into how GNNs tackle the SAT problem, we conduct comprehensive comparative analyses between GNN- based SAT solvers and the CDCL and LS heuristics in this section. Since these search heuristics aim to solve a SAT instance directly, our focus only lies on the tasks of (T1) satisfiability prediction and (T2) satisfying assignment prediction (with \\(\\mathrm{UNS}_2\\) as the training loss). We employ Neuro SAT (on \\(\\mathrm{LCG}^*\\) ) and GGNN (on \\(\\mathrm{VCG}^*\\) ) as our GNN models and experiment on the SR and 3- SAT datasets. Detailed experimental settings are included in Appendix D.1. ### 6.1 Comparison with the CDCL Heuristic Evaluation on the clause- learning augmented instances. CDCL- based SAT solvers enhance backtracking search with conflict analysis and clause learning, enabling efficient exploration of the search space by iteratively adding \"learned clauses\" to avoid similar conflicts in future searches (Silva & Sakallah, 1999). To assess whether GNN- based SAT solvers can learn and benefit from the backtracking search (with CDCL) heuristic, we augment the original formulas in the datasets with learned clauses and evaluate GNN models on these clause- augmented instances.\n\nTable 4 shows the testing results on augmented SAT datasets. Notably, training on the augmented instances leads to significant improvements in both satisfiability prediction and satisfying assignment prediction. These improvements can be attributed to the presence of \"learned clauses\" that effectively modify the structure of the original formulas, thereby facilitating GNNs to solve with relative ease. However, despite the augmented instances being easily solvable using the backtracking search within a few search steps, GNN models fail to effectively handle these instances when trained on the original instances. These findings suggest that GNNs may not implicitly learn the CDCL heuristic when trained for satisfiability prediction or satisfying assignment prediction. Table 4: Results on augmented datasets. Values inside/outside parentheses denote the results of models trained on augmented/original instances. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>100.00 (96.78)</td><td>100.00 (96.06)</td><td>100.00 (84.57)</td><td>96.78 (84.85)</td></tr><tr><td>GGNN</td><td>100.00 (97.66)</td><td>100.00 (95.46)</td><td>100.00 (84.01)</td><td>96.29 (85.80)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>85.05 (83.28)</td><td>83.50 (81.04)</td><td>51.95 (45.51)</td><td>39.00 (16.52)</td></tr><tr><td>GGNN</td><td>85.35 (83.42)</td><td>81.56 (79.99)</td><td>44.18 (40.09)</td><td>34.67 (14.75)</td></tr></table> Table 5: Results using contrastive pretraining. Values in parentheses denote the difference between the results without pretraining. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>96.68 (+0.68)</td><td>96.23 (+0.10)</td><td>78.31 (+0.29)</td><td>85.02 (+0.12)</td></tr><tr><td>GGNN</td><td>96.46 (+0.29)</td><td>96.45 (+0.20)</td><td>76.34 (+0.78)</td><td>85.17 (+0.06)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>80.54 (+0.75)</td><td>79.71 (-0.88)</td><td>36.42 (-0.83)</td><td>41.23 (-0.38)</td></tr><tr><td>GGNN</td><td>80.66 (-0.34)</td><td>79.23 (-0.09)</td><td>33.44 (+0.07)</td><td>36.39 (+0.44)</td></tr></table> Evaluation with contrastive pretraining. Observing that GNN models exhibit superior performance on clause- learning augmented SAT instances, there is potential to improve the performance of GNNs by learning a latent representation of the original formula similar to its augmented counterpart. Motivated by this, we also experiment with a contrastive learning approach (i.e., Sim CLR (Chen et al., 2020)) to pretrain the representation of CNF formulas to be close to their augmented ones (Duan et al., 2022), trying to explicitly embed the CDCL heuristic in the latent space through representation learning. The results of contrastive pretraining are presented in Table 5. In contrast to the findings in Duan et al. (2022), our results show limited performance improvement through contrastive pretraining, indicating that GNN models still encounter difficulties in effectively learning the CDCL heuristic in the latent space. This observation aligns with the conclusions drawn in Chen & Yang (2019), which highlight that static GNNs may fail to exactly replicate the same search operations due to the dynamic changes in the graph structure introduced by the clause learning technique. ### 6.2 Comparison with the LS Heuristic Evaluation with random initialization. LS- based SAT solvers typically begin by randomly initializing an assignment and then iteratively flip variables guided by specific heuristics until reaching a satisfying assignment. To compare the behaviors of GNNs with this solving procedure, we first conduct an evaluation of GNN models with randomized initial embeddings in both training and testing, emulating the initialization of LS SAT solvers. The results presented in Table 6 demonstrate that using random initialization has a limited impact on the overall performances of GNN- based SAT solvers. This suggests that GNN models do not aim to learn a fixed latent representation of each formula for satisfiability prediction and satisfying assignment prediction. Instead, they have developed a solving strategy that effectively exploits the inherent graph structure of each SAT instance. Table 6: Results using random initialization. Values in parentheses denote the difference between the results with learned initialization. <table><tr><td rowspan=\"2\">Task</td><td rowspan=\"2\">Method</td><td colspan=\"2\">Easy Datasets</td><td colspan=\"2\">Medium Datasets</td></tr><tr><td>SR</td><td>3-SAT</td><td>SR</td><td>3-SAT</td></tr><tr><td rowspan=\"2\">T1</td><td>Neuro SAT</td><td>97.24 (+1.24)</td><td>96.44 (+0.11)</td><td>77.29 (-0.91)</td><td>84.85 (-0.05)</td></tr><tr><td>GGNN</td><td>96.78 (+0.03)</td><td>96.38 (+0.13)</td><td>76.97 (-0.15)</td><td>85.80 (+0.69)</td></tr><tr><td rowspan=\"2\">T2</td><td>Neuro SAT</td><td>79.09 (-0.70)</td><td>80.79 (+0.20)</td><td>37.27 (+0.02)</td><td>40.75 (-0.86)</td></tr><tr><td>GGNN</td><td>80.10 (-0.90)</td><td>79.83 (+0.51)</td><td>32.85 (-0.52)</td><td>36.59 (+0.64)</td></tr></table> Evaluation on the predicted assignments. Under random initialization, we further analyze the solving strategies of GNNs by evaluating their predicted assignments decoded from the latent space. For the task of satisfiability prediction, we employ the 2- clustering decoding algorithm to extract the predicted assignments from the literal embeddings of Neuro SAT at each iteration of message passing. For satisfying assignment",
      "level": 2,
      "line_start": 15,
      "line_end": 43
    }
  ]
}